% vim:syntax=tex

In this paper we conducted a study on modeling the topics of changesets in
comparison to the traditional snapshot approach.  We use latent Dirichlet
allocation (LDA) to extract linguistic topics from changesets and snapshots
(releases).

We addressed two research questions regarding the performance of a TM-based FLT
trained on changesets.  First, we compare a batch TM-based FLT trained on the
changesets of a project's history to one trained on the snapshot of source code
entities.  We found that changesets can perform as well as or better than
snapshots.  Second, we compare a batch TM-based FLT trained on changesets to
a historical simulation of a TM-based FLT trained on the same changesets over
time.  We show that the historical simulation more accurately portrays how a FLT
would execute in a real environment.

Our results encourage the idea that there is still much to explore in the area
of feature location. What other untapped resources might be available? We show
changesets are yet another viable resource researchers and practitioners should
be taking advantage of for the feature location task.  Our results also show
that research remains not only in improving accuracies of FLTs, but also in
solving the practical aspects of building FLTs that are robust \emph{and} agile
enough to keep up with fast-changing software.

Future work includes deploying this appoach in a development environment.  Since
the source code to our approach is online, we encourage other researchers to
investigate this future work as well.  We also would like to expand the simulation 
parts of this study to include both snapshots and changesets.  It would be
particularly useful to compare results between batch snapshots and simulated
snapshots. 

Additional future work exists in regard to configuration. In a changeset
it may be desirable to parse further for source code entities using
island grammar parsing~\cite{Moonen:2001}.  It may also be desirable to
only use portions of the changeset, such as only using added or removed
lines, or extracting changes between the abstract syntax
trees~\cite{Fluri-etal:2007}. Most importantly, like previous
work~\cite{Biggers-etal:2014}, it would be wise to further investigate
the effects of the two online LDA variables, $\tau_0$ and $\kappa$.  We
leave these options for future work.

