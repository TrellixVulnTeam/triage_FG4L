<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sat May 16 23:26:48 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/BOOKKEEPER-432/BOOKKEEPER-432.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[BOOKKEEPER-432] Improve performance of entry log range read per ledger entries </title>
                <link>https://issues.apache.org/jira/browse/BOOKKEEPER-432</link>
                <project id="12311293" key="BOOKKEEPER">Bookkeeper</project>
                    <description>&lt;p&gt;We observed random I/O reads when some subscribers fall behind (on some topics), as delivery needs to scan the entry logs (thru ledger index), which are interleaved with ledger entries across all ledgers being served.&lt;/p&gt;

&lt;p&gt;Essentially, the ledger index is a non-clustered index. It is not effective when a large number of ledger entries need to be served, which tend to be scattered around due to interleaving.&lt;/p&gt;

&lt;p&gt;Some possible improvements:&lt;br/&gt;
1. Change the ledger entries buffer to use a SkipList (or other suitable), sorted on (ledger, entry sequence). When the buffer is flushed, the entry log is written out in the already-sorted order. &lt;/p&gt;

&lt;p&gt;The &quot;active&quot; ledger index can point to the entries buffer (SkipList), and fixed up with entry-log position once latter is persisted.&lt;/p&gt;

&lt;p&gt;Or, the ledger index can be just rebuilt on demand. The entry log file tail can have index attached (light-weight b-tree, similar with big-table). We need to track per ledger which log files contribute entries to it, so that in-memory index can be rebuilt from the tails of corresponding log files.&lt;/p&gt;

&lt;p&gt;2. Use affinity concept to make ensembles of ledgers (belonging to same topic) as identical as possible. This will help above 1. be more effective.&lt;/p&gt;
</description>
                <environment>&lt;p&gt;Linux&lt;/p&gt;</environment>
        <key id="12611657">BOOKKEEPER-432</key>
            <summary>Improve performance of entry log range read per ledger entries </summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yx3zhu@gmail.com">Yixue (Andrew) Zhu</assignee>
                                    <reporter username="yx3zhu@gmail.com">Yixue (Andrew) Zhu</reporter>
                        <labels>
                            <label>patch</label>
                    </labels>
                <created>Sat, 13 Oct 2012 01:55:06 +0100</created>
                <updated>Wed, 12 Mar 2014 20:58:27 +0000</updated>
                            <resolved>Wed, 12 Mar 2014 20:27:59 +0000</resolved>
                                    <version>4.2.0</version>
                                    <fixVersion>4.3.0</fixVersion>
                                    <component>bookkeeper-server</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13477989" author="ikelly" created="Wed, 17 Oct 2012 17:13:31 +0100"  >&lt;p&gt;I think 1. can be split into two parts, sorting before flushing, and maintaining skiplists rather than index files. Sorting before flushing should give us a really easy win and shouldn&apos;t be very difficult to implement.&lt;/p&gt;

&lt;p&gt;For example, lets say we have 1k entries and are writing at 50k entries per second to 1000 ledgers. Lets assume flushing takes 1 second (in reality for 1000 ledgers it&apos;ll be more like 2 minutes).&lt;/p&gt;

&lt;p&gt;This means the amount of data flushed will be 50MB. As it currently is now, entries will be evenly distributed across this, so for 1000 ledgers, there will be 999KB (999 other 1KB entries) between any 2 entries of the same ledger. This is well outside of the size of the read ahead (128KB), so on average, we have to seek for every single entry. &lt;/p&gt;

&lt;p&gt;By contrast, with sorting, a single seek would get us 50 entries.&lt;/p&gt;

&lt;p&gt;I don&apos;t think we explicitly need to sort either. We can have a block pool of 50k blocks. Each ledger on the server side has chain of blocks from the pool. When we flush, we flush the blocks from each ledger in order. If we run out of blocks, we flush (without a disk force) a ledger, and return the blocks to the pool.&lt;/p&gt;</comment>
                            <comment id="13478196" author="yx3zhu@gmail.com" created="Wed, 17 Oct 2012 19:29:34 +0100"  >&lt;p&gt;Thanks Ivan,&lt;br/&gt;
The index file depends on the log offset of entry log. If we just do part 1 or pool of blocks, the index cache need to be filled/fixed after entry log is sorted (and flushed).&lt;br/&gt;
One possibly choice is to chain the flushing of entry block to the filling/correcting index cache, adding some complexity.&lt;br/&gt;
Thoughts?&lt;/p&gt;
</comment>
                            <comment id="13478750" author="ikelly" created="Thu, 18 Oct 2012 08:20:23 +0100"  >&lt;p&gt;We&apos;d have to change to point at which entries are added to the index cache also. It does add some complexity to the change, but it still keeps all the changes in the entrylogger for now. Are you working on this at the moment? I was thinking of picking this up next week.&lt;/p&gt;</comment>
                            <comment id="13480384" author="yx3zhu@gmail.com" created="Fri, 19 Oct 2012 21:59:19 +0100"  >&lt;p&gt;I am going to send draft node, including a couple of choices.&lt;br/&gt;
I can work on it.&lt;/p&gt;</comment>
                            <comment id="13480386" author="i0exception" created="Fri, 19 Oct 2012 22:01:49 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ikelly&quot; class=&quot;user-hover&quot; rel=&quot;ikelly&quot;&gt;Ivan Kelly&lt;/a&gt; I had a similar approach in mind to what you have suggested with some auto-tuning. I can do this over the weekend while &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yx3zhu%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;yx3zhu@gmail.com&quot;&gt;Yixue (Andrew) Zhu&lt;/a&gt; works on a more formal skip list based design. Is that okay? &lt;/p&gt;</comment>
                            <comment id="13480733" author="fpj" created="Sat, 20 Oct 2012 14:33:57 +0100"  >&lt;p&gt;I like the idea of using skip lists, it might be particularly useful when Hedwig subscribers are catching up. I also like the idea of sorting before flushing, but I&apos;m not so sure how much it will improve performance. It mostly depends on the number of entries we actually have upon a flush.&lt;/p&gt;</comment>
                            <comment id="13481279" author="ikelly" created="Mon, 22 Oct 2012 10:55:03 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fpj&quot; class=&quot;user-hover&quot; rel=&quot;fpj&quot;&gt;Flavio Junqueira&lt;/a&gt; with 1000 ledgers, flushing can take up a couple of minutes. but even if it took only one second, at 50k entries per second, it would mean reading 50 entries per seek rather than 1.&lt;/p&gt;</comment>
                            <comment id="13481495" author="fpj" created="Mon, 22 Oct 2012 17:48:05 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ikelly&quot; class=&quot;user-hover&quot; rel=&quot;ikelly&quot;&gt;Ivan Kelly&lt;/a&gt; are you talking about flushing ledger entries or ledger index pages?&lt;/p&gt;</comment>
                            <comment id="13482195" author="ikelly" created="Tue, 23 Oct 2012 09:23:03 +0100"  >&lt;p&gt;Both, both are flushed in the same operation, LedgerStorage#flush() called from the sync thread. its the index files which are taking the time, as flush time increases as number of ledgers does.&lt;/p&gt;</comment>
                            <comment id="13482196" author="ikelly" created="Tue, 23 Oct 2012 09:25:03 +0100"  >&lt;p&gt;Even without the data write time, for 1000 ledgers, there are 1000 seeks, so the lower bound is 8 seconds (1 seek = 8ms)&lt;/p&gt;</comment>
                            <comment id="13482479" author="ikelly" created="Tue, 23 Oct 2012 18:18:29 +0100"  >&lt;p&gt;I&apos;ve added a tool to github which i&apos;ve been using to bench the ledgerstorage performance. It should be useful when developing this patch.&lt;br/&gt;
&lt;a href=&quot;https://github.com/ivankelly/bkvhbase&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/ivankelly/bkvhbase&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13487015" author="ikelly" created="Tue, 30 Oct 2012 17:01:16 +0000"  >&lt;p&gt;It would be good to get a more detailed description of both the btree &amp;amp; skiplist disk formats.&lt;br/&gt;
For btree, I&apos;m not sure the approach makes sense. The workload is append only, so with a tree, you&apos;re going to be constantly skewing to the right, and having to rebalance.&lt;br/&gt;
For skiplist, how many levels of skiplists do you envisage? The index file format you describe is effectively the top level.&lt;/p&gt;</comment>
                            <comment id="13487351" author="yx3zhu@gmail.com" created="Tue, 30 Oct 2012 23:07:34 +0000"  >&lt;p&gt;The B-tree will be read-only once it is written out from snapshotted Skip-List (like bulk import), i.e. we do not need to rebalance it.&lt;br/&gt;
SkipList can use ConcurrentSkipListSet to start as simple.&lt;br/&gt;
The index file format is on-disk format. We can maintain an in-memory only data structure to speedup per-ledger read initial seek, using current ledger cache format, just that is it cached on demand (from the index file and B-tree/skipList).&lt;/p&gt;

&lt;p&gt;Uploaded revised document.&lt;/p&gt;</comment>
                            <comment id="13487391" author="hustlmsp" created="Wed, 31 Oct 2012 00:07:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yx3zhu%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;yx3zhu@gmail.com&quot;&gt;Yixue (Andrew) Zhu&lt;/a&gt; After took a look at your proposal, it was quite similar as a LSM implementation. (If I am not right, please correct me.) If that, why not leverage a mature LSM implementation, like leveldb, which also maintain in-memory data in skip lists, have data snapshotted on disk in a btree-like structures, and compacted data to improve locality of entries.&lt;/p&gt;

&lt;p&gt;I did some prototype works on using leveldb last year. I could try to pick up it again to bench its performance using Ivan&apos;s scripts.&lt;/p&gt;</comment>
                            <comment id="13487398" author="stuhood" created="Wed, 31 Oct 2012 00:22:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hustlmsp&quot; class=&quot;user-hover&quot; rel=&quot;hustlmsp&quot;&gt;Sijie Guo&lt;/a&gt;: Please do post that code. Seeing a prototype involving an existing LSM tree would be very useful before we go too far toward implementing our own.&lt;/p&gt;</comment>
                            <comment id="13487400" author="yx3zhu@gmail.com" created="Wed, 31 Oct 2012 00:23:57 +0000"  >&lt;p&gt;The level-db stack is not suitable for bookkeeper usage, as it is tailored to reduce compaction impact (using levels), in the same time increases write I/O overhead (twice for write-intensive workload).&lt;/p&gt;

&lt;p&gt;Here, we do not need frequent compaction to make sure read not going thru multiple levels. We just need compaction if the entry log is mostly empty (i.e. most entries already consumed).&lt;/p&gt;


</comment>
                            <comment id="13487402" author="yx3zhu@gmail.com" created="Wed, 31 Oct 2012 00:27:26 +0000"  >&lt;p&gt;General K/V store implementation (including level-db) deals with update and introduce version/timestamp, which we do not need. &lt;/p&gt;</comment>
                            <comment id="13487600" author="hustlmsp" created="Wed, 31 Oct 2012 07:21:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stuhood&quot; class=&quot;user-hover&quot; rel=&quot;stuhood&quot;&gt;Stu Hood&lt;/a&gt; I would try to generate a patch for it.&lt;/p&gt;</comment>
                            <comment id="13487659" author="ikelly" created="Wed, 31 Oct 2012 10:30:27 +0000"  >&lt;p&gt;Thanks for clarifying Yixue. It would be good if the doc separated the btree and skiplist approaches completely, but I this I understand the overall jist.&lt;/p&gt;

&lt;p&gt;Both the designs seem to be motivated by quick access to individual entries. I think this motivation isn&apos;t fully correct. Really what we need is quick access to a suffix of entries. &lt;/p&gt;

&lt;p&gt;Lets say a flush takes 60 seconds, for 1000 ledgers, 1KB entries, writing at 50k per second. For an individual ledger, there will be ((60*50k)/1000) = 3000 entries, or roughly 3MB of data. The offset of the block has to written to the index. A 7.2k rpm disk can read sequentially at 100MB/s, and can do about 120 seeks a second. We need one seek to get to the block in any case. Now, if want to get to the precise entry, we need to seek again. Or we can just read the whole block. Which is quicker? I would say they&apos;re roughly the same, but one requires much more complicated data structures.&lt;/p&gt;

&lt;p&gt;Now, if a flush takes longer, the tradeoff changes, and I have seen flushes taking longer before, but if we change the index from storing the every entry, to just the start of a sequence of entries, flushes should get faster. And even then, if we want to add skips, we should add extra entries in the index rather than in the entrylog, as that is why we have an index. Having an auxiliary index negates the need for complex data structures in the entrylog itself.&lt;/p&gt;
</comment>
                            <comment id="13487959" author="yx3zhu@gmail.com" created="Wed, 31 Oct 2012 17:01:42 +0000"  >&lt;p&gt;Thanks Ivan for the review.&lt;br/&gt;
The SkipList is for initial staging of caching newly added entries to transform random I/O to sequential, it will not be used afterwards.&lt;/p&gt;

&lt;p&gt;The B-tree uses sparse index, is tailored for sequential data block read.&lt;/p&gt;

&lt;p&gt;The index file is to track which B-tree to cache per-ledger entry log starting position to start block read with.&lt;/p&gt;

&lt;p&gt;To be more concrete, the B-tree data blocks will be cached on demand (using a pool of blocks).  &lt;/p&gt;</comment>
                            <comment id="13488013" author="ikelly" created="Wed, 31 Oct 2012 17:53:34 +0000"  >&lt;p&gt;Ah, got it. The skiplist is inmemory, preflush. The btree is on disk post flush. The skiplist makes sense to me, the btree not so much. Trees are O(logn). If the means logn seeks, then the approach aleady loses against an approach that flushes the skiplist directly, and stores the per ledger offsets in the index, which would be O(1).&lt;/p&gt;

&lt;p&gt;Also, I don&apos;t think caching full blocks makes much sense for BKs usecases. BK provides a writeahead log, which means, in the normal case, the average number of times a block will be read is 0. Rarely, it will be read once. It would be extremely rare that it would be read more than once.&lt;/p&gt;</comment>
                            <comment id="13488131" author="yx3zhu@gmail.com" created="Wed, 31 Oct 2012 19:24:09 +0000"  >&lt;p&gt;The B-Tree is block based, and are consecutively stored in the (ledger-id, entry-id) order. The index blocks are at tail of the file, will not interfere with read-ahead. &lt;/p&gt;

&lt;p&gt;If you mean Ledger Log by write-ahead-log, yes, we will not read them unless during recovery. I am not proposing caching it.&lt;/p&gt;

&lt;p&gt;By entry-log, I mean entry data (messages), which is stored in data blocks (aka pages, chunks). These data blocks can be cached on demand, using LRU replacement policy. &lt;/p&gt;

&lt;p&gt;We will keep per-ledger offsets in memory, which is cached on demand from B-tree, to speed up locating the first entry, followed by chunk read from consecutive data blocks. &lt;/p&gt;

&lt;p&gt;The idea of using sparse index is that we are tuning for bulk read. &lt;br/&gt;
We could put dense index blocks in the B-tree if performance measurement show otherwise.  &lt;/p&gt;</comment>
                            <comment id="13488199" author="ikelly" created="Wed, 31 Oct 2012 20:30:30 +0000"  >&lt;p&gt;Are the intermediatory levels of the btree between the root and the leaves in the btree stored on disk, or is it only the leaves? Do you maintain separate index files per ledger also? Sorry for all the questions, I&apos;m trying to get the full picture in my head &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you mean Ledger Log by write-ahead-log, yes, we will not read them unless during recovery. I am not proposing caching it.&lt;/p&gt;

&lt;p&gt;By entry-log, I mean entry data (messages), which is stored in data blocks (aka pages, chunks). These data blocks can be cached on demand, using LRU replacement policy. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;By write ahead log, I mean that the usecase BK, as a whole is designed for, is as a write ahead log, which, by it&apos;s nature should be seldom read. I&apos;m not refering to the bookie&apos;s own journal. I could imagine one usecases where multiple reads could be necessary (such as hedwig, with many subscribers, consuming at different rates) but these should be handled at a higher level (such as the read ahead cache in hedwig).&lt;/p&gt;</comment>
                            <comment id="13488290" author="yx3zhu@gmail.com" created="Wed, 31 Oct 2012 22:07:08 +0000"  >&lt;p&gt;Only the leave level of btree are data blocks (for bookkeeper usage, we probably ends up just one level of index block, if sparse index is used).&lt;br/&gt;
All data blocks and index blocks are stored on disk.&lt;/p&gt;

&lt;p&gt;The Bookie&apos;s ReadEntryProcessor uses LedgerStorage::getEntry to retrieve individual entries. The LRU block cache should help next calls from Hedwig to read more entries.&lt;/p&gt;

&lt;p&gt;The per-ledger index file just holds information which btree-file the entries are stored. We could just look up the b-tree using its index block and data blocks, which are all LRU cached.&lt;/p&gt;

&lt;p&gt;To speed up entry look up, we can maintain in-memory-only per-ledger index cache, which retrieve information from b-tree on demand, with each retrieval caches starting offset of a batch of entries.&lt;/p&gt;

&lt;p&gt;Once this is in place, we can enhance HedWig to batch read entries from Bookies, which can handle it well using the design.&lt;/p&gt;


</comment>
                            <comment id="13489363" author="ikelly" created="Fri, 2 Nov 2012 11:15:12 +0000"  >&lt;p&gt;I&apos;ve posted some results we had benchmarking against hbase&apos;s hregion format which you guys might be interested in.&lt;br/&gt;
&lt;a href=&quot;https://github.com/ivankelly/bkvhbase/wiki/Performance-Graphs&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/ivankelly/bkvhbase/wiki/Performance-Graphs&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The per-ledger index file just holds information which btree-file the entries are stored. We could just look up the b-tree using its index block and data blocks, which are all LRU cached&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;So all entries for a single ledger will be stored sequentially on disk in a single file. Instead of storing, in the index file, which btree file contains the ledger entries, couldn&apos;t you store the file and the offset to the entries? It would save you having to go to the file index at all.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;we can enhance HedWig to batch read entries from Bookies.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is something I think the bookkeeper client has needed for quite a while.&lt;/p&gt;</comment>
                            <comment id="13489523" author="fpj" created="Fri, 2 Nov 2012 16:34:24 +0000"  >&lt;p&gt;I&apos;m really glad you guys are working on this and it sounds like it will be a nice addition to the project. I have a few comments about the proposal, and hopefully they haven&apos;t been asked before. I skimmed through the comments and haven&apos;t seen anything so here they are.&lt;/p&gt;

&lt;p&gt;The design says that once a B-tree is created and complete, it will not be updated. I&apos;m wondering if this means that we accumulate entries in a skiplist and once we fill up the buffer with entries, we organize the entries in a B-tree and flush it. If so, I suppose that you&apos;re thinking of having two buffers so that we can flush one while filling up the next. In general, my concern here is impacting write throughput. The current design has this nice feature that the throughput is actually limited by the speed of the journal and not the speed of the ledger store (in the absence of reads).&lt;/p&gt;

&lt;p&gt;I&apos;m also wondering how compaction will affect overall performance. My current intuition is that it shouldn&apos;t be much more expensive than the current compaction we have, but I&apos;m interested in your opinion.   &lt;/p&gt;</comment>
                            <comment id="13489536" author="yx3zhu@gmail.com" created="Fri, 2 Nov 2012 16:51:21 +0000"  >&lt;p&gt;Thanks Ivan for the graph. W.r.t. the write throughput, does the graph reflect compaction in HBase? Are the regions hosted in one machine? It reinforces my argument of not using HBase or LevelDb as it is. &lt;/p&gt;

&lt;p&gt;The proposal will not use HBase&apos;s compaction or multi-region design, so the write performance cannot be reflected in the graph.&lt;/p&gt;

&lt;p&gt;Re - &quot;So all entries for a single ledger will be stored sequentially on disk in a single file.&quot;&lt;br/&gt;
Not all entries. Some clustered entries store in one file, the next clustered entries in another file.&lt;/p&gt;

&lt;p&gt;The idea of not storing index entries offset is that the offset is not finalized until the SkipList is flushed. Using on-demand index entry page cache should get the read-performance on-par.&lt;/p&gt;

&lt;p&gt;Of course, we can pin the index entries in-memory, until the SkipList is flushed.&lt;br/&gt;
I can go with this approach. Does it address your concern, Ivan?&lt;/p&gt;





</comment>
                            <comment id="13489557" author="yx3zhu@gmail.com" created="Fri, 2 Nov 2012 17:20:22 +0000"  >&lt;p&gt;Thanks Flavio, they are good questions.&lt;br/&gt;
Yes, we will use more than one skiplist (created on demand), while one is being flushed, another will be filled in. (level-db uses at most two skiplists).&lt;/p&gt;

&lt;p&gt;Unlike level-db or HBase, we do not need aggressive compaction to reduce multiple-update-version impact to readers, where union iterator is used. We can disable current minor compaction in bookie.&lt;/p&gt;

&lt;p&gt;LRU-data-block-caching should help disk contention among readers w/ different read entry id.&lt;/p&gt;</comment>
                            <comment id="13489645" author="ikelly" created="Fri, 2 Nov 2012 18:49:45 +0000"  >&lt;blockquote&gt;&lt;p&gt;&lt;br/&gt;
Thanks Ivan for the graph. W.r.t. the write throughput, does the graph reflect compaction in HBase? Are the regions hosted in one machine? It reinforces my argument of not using HBase or LevelDb as it is. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, it&apos;s single disk even, with compaction. What really kills the throughput though, is that each region flushes to a separate file, so its seeking all over the place. Same will go for leveldb.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Re - &quot;So all entries for a single ledger will be stored sequentially on disk in a single file.&quot;&lt;br/&gt;
Not all entries. Some clustered entries store in one file, the next clustered entries in another file&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;yup, thats what I meant, but articulated badly. All entries for a ledger within one file are sequential, though the ledger is across many files.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The idea of not storing index entries offset is that the offset is not finalized until the SkipList is flushed. Using on-demand index entry page cache should get the read-performance on-par.&lt;/p&gt;

&lt;p&gt;Of course, we can pin the index entries in-memory, until the SkipList is flushed.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ah, i understand your rationale now. You only need to store one offset per ledger while the skiplist is being flushed. With a million ledgers, this is only 4 megs, and i think it simplifies the design (and removes one seek, though this isnt so important i guess). plus this same index format can then be used with the sorted entrylog aniruddha is implementing in &lt;a href=&quot;https://issues.apache.org/jira/browse/BOOKKEEPER-451&quot; title=&quot;Reorder writes based on ledger-id before writing to the log file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BOOKKEEPER-451&quot;&gt;&lt;del&gt;BOOKKEEPER-451&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13490497" author="yx3zhu@gmail.com" created="Mon, 5 Nov 2012 08:06:42 +0000"  >&lt;p&gt;Ivan, Flavio,&lt;br/&gt;
I have changed the design so that it can be backward compatible.&lt;br/&gt;
Yet, it keep the entries sorted in the entry log file.&lt;br/&gt;
Let me know your thoughts.&lt;/p&gt;</comment>
                            <comment id="13490756" author="yx3zhu@gmail.com" created="Mon, 5 Nov 2012 17:29:11 +0000"  >&lt;p&gt;Added staging to the proposal.&lt;/p&gt;</comment>
                            <comment id="13491539" author="ikelly" created="Tue, 6 Nov 2012 15:39:37 +0000"  >&lt;p&gt;The new log entry you propose is for the journal? If so, im not sure it&apos;s needed,as we already mark the journal after each flush, to allow persisted entries to be cleaned up.&lt;/p&gt;</comment>
                            <comment id="13491618" author="yx3zhu@gmail.com" created="Tue, 6 Nov 2012 17:06:42 +0000"  >&lt;p&gt;The new log entry is for the journal. It is designed to speedup replay - as the entry log file content will be identical, replay can skip replaying entries, if the crash happened before entry log flushed (but accumulated a lot of entries already). The marker is like database checkpoint record, it just reduce the amount of log to replay (since last flush).&lt;/p&gt;

&lt;p&gt;We do not need to implement it as first cut. &lt;/p&gt;</comment>
                            <comment id="13492271" author="ikelly" created="Wed, 7 Nov 2012 11:11:07 +0000"  >&lt;p&gt;After each flush, we call Journal.LastLogMark.rollLog(), which should have the same effect. We read the last mark during recovery to skip to the point in the journal from which entries have not been persisted. &lt;/p&gt;

&lt;p&gt;In any case, I think this is outside the scope of this jira, as this is bookie recovery and this jira should focus on read performance.&lt;/p&gt;</comment>
                            <comment id="13500842" author="yx3zhu@gmail.com" created="Tue, 20 Nov 2012 05:38:58 +0000"  >&lt;p&gt;   Uses skip list to sort entries before adding them to entry log file, to improve ledger read performance. Memory arena is used to allocate skip list entries, to avoid GC impact.&lt;br/&gt;
    A single-threaded scheduler is used to flush skip list to buffered entry log file channel, once configured data size limit is reached. Sync thread is notified as well to flush file buffers.&lt;br/&gt;
    Compaction uses Skip list, to merge entries together as well as remove duplicate entries.&lt;br/&gt;
    This change also fix an existing issue of old entry logs being removed w/o forcing new entry logs flushed.&lt;/p&gt;

&lt;p&gt;    It is the first cut of &lt;a href=&quot;https://issues.apache.org/jira/browse/BOOKKEEPER-432&quot; title=&quot;Improve performance of entry log range read per ledger entries &quot; class=&quot;issue-link&quot; data-issue-key=&quot;BOOKKEEPER-432&quot;&gt;&lt;del&gt;BOOKKEEPER-432&lt;/del&gt;&lt;/a&gt; implementation.&lt;/p&gt;</comment>
                            <comment id="13500843" author="yx3zhu@gmail.com" created="Tue, 20 Nov 2012 05:40:42 +0000"  >&lt;p&gt;   Uses skip list to sort entries before adding them to entry log file, to improve ledger read performance. Memory arena is used to allocate skip list entries, to avoid GC impact.&lt;br/&gt;
    A single-threaded scheduler is used to flush skip list to buffered entry log file channel, once configured data size limit is reached. Sync thread is notified as well to flush file buffers.&lt;br/&gt;
    Compaction uses Skip list, to  merge entries together as well as remove duplicate entries.&lt;br/&gt;
    This change also fix an existing issue of old entry logs being removed w/o forcing new entry logs flushed.&lt;/p&gt;

&lt;p&gt;    It is the first cut of &lt;a href=&quot;https://issues.apache.org/jira/browse/BOOKKEEPER-432&quot; title=&quot;Improve performance of entry log range read per ledger entries &quot; class=&quot;issue-link&quot; data-issue-key=&quot;BOOKKEEPER-432&quot;&gt;&lt;del&gt;BOOKKEEPER-432&lt;/del&gt;&lt;/a&gt; implementation.&lt;/p&gt;</comment>
                            <comment id="13504555" author="hadoopqa" created="Tue, 27 Nov 2012 11:52:44 +0000"  >&lt;p&gt;Testing JIRA &lt;a href=&quot;https://issues.apache.org/jira/browse/BOOKKEEPER-432&quot; title=&quot;Improve performance of entry log range read per ledger entries &quot; class=&quot;issue-link&quot; data-issue-key=&quot;BOOKKEEPER-432&quot;&gt;&lt;del&gt;BOOKKEEPER-432&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WARNING: Running test-patch on a dirty local svn workspace&lt;/p&gt;

&lt;p&gt;Patch &amp;lt;a href=&quot;/jira/secure/attachment/12554292/SkipList.patch&quot;&amp;gt;/jira/secure/attachment/12554292/SkipList.patch&amp;lt;/a&amp;gt; downloaded at Tue Nov 27 11:50:12 UTC 2012&lt;/p&gt;

&lt;p&gt;----------------------------&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; Patch failed to apply to head of branch&lt;/p&gt;

&lt;p&gt;----------------------------&lt;/p&gt;</comment>
                            <comment id="13508921" author="yx3zhu@gmail.com" created="Mon, 3 Dec 2012 18:25:56 +0000"  >&lt;p&gt;Updated patch to resolve conflict&lt;/p&gt;</comment>
                            <comment id="13508944" author="hadoopqa" created="Mon, 3 Dec 2012 18:58:42 +0000"  >&lt;p&gt;Testing JIRA &lt;a href=&quot;https://issues.apache.org/jira/browse/BOOKKEEPER-432&quot; title=&quot;Improve performance of entry log range read per ledger entries &quot; class=&quot;issue-link&quot; data-issue-key=&quot;BOOKKEEPER-432&quot;&gt;&lt;del&gt;BOOKKEEPER-432&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WARNING: Running test-patch on a dirty local svn workspace&lt;/p&gt;

&lt;p&gt;Patch &amp;lt;a href=&quot;/jira/secure/attachment/12555797/PortSkipListLedgerStorage.patch&quot;&amp;gt;/jira/secure/attachment/12555797/PortSkipListLedgerStorage.patch&amp;lt;/a&amp;gt; downloaded at Mon Dec  3 18:31:38 UTC 2012&lt;/p&gt;

&lt;p&gt;----------------------------&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 PATCH_APPLIES&lt;/font&gt;&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 CLEAN&lt;/font&gt;&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;-1 RAW_PATCH_ANALYSIS&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not introduce any @author tags&lt;br/&gt;
.    &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; the patch contains 1 line(s) with tabs&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not introduce any trailing spaces&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not introduce any line longer than 120&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does adds/modifies 6 testcase(s)&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 RAT&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not seem to introduce new RAT warnings&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;-1 JAVADOC&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; the patch seems to introduce 3 new Javadoc warning(s)&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 COMPILE&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; HEAD compiles&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; patch compiles&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not seem to introduce new javac warnings&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;-1 FINDBUGS&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; the patch seems to introduce 8 new Findbugs warning(s) in module(s) &lt;span class=&quot;error&quot;&gt;&amp;#91;bookkeeper-server&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;-1 TESTS&lt;/font&gt;&lt;br/&gt;
.    Tests run: 393&lt;br/&gt;
.    Tests failed: 2&lt;br/&gt;
.    Tests errors: 0&lt;/p&gt;

&lt;p&gt;.    The patch failed the following testcases:&lt;/p&gt;

&lt;p&gt;.      testLedgerDelete&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;(org.apache.bookkeeper.test.LedgerDeleteTest)&lt;br/&gt;
.      testLedgerDelete&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;(org.apache.bookkeeper.test.LedgerDeleteTest)&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 DISTRO&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; distro tarball builds with the patch &lt;/p&gt;

&lt;p&gt;----------------------------&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;&lt;b&gt;-1 Overall result, please check the reported -1(s)&lt;/b&gt;&lt;/font&gt;&lt;/p&gt;


&lt;p&gt;The full output of the test-patch run is available at&lt;/p&gt;

&lt;p&gt;.   &lt;a href=&quot;https://builds.apache.org/job/bookkeeper-trunk-precommit-build/70/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/bookkeeper-trunk-precommit-build/70/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13508958" author="hadoopqa" created="Mon, 3 Dec 2012 19:24:39 +0000"  >&lt;p&gt;Testing JIRA &lt;a href=&quot;https://issues.apache.org/jira/browse/BOOKKEEPER-432&quot; title=&quot;Improve performance of entry log range read per ledger entries &quot; class=&quot;issue-link&quot; data-issue-key=&quot;BOOKKEEPER-432&quot;&gt;&lt;del&gt;BOOKKEEPER-432&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WARNING: Running test-patch on a dirty local svn workspace&lt;/p&gt;

&lt;p&gt;Patch &amp;lt;a href=&quot;/jira/secure/attachment/12555803/PortSkipListLedgerStore.patch&quot;&amp;gt;/jira/secure/attachment/12555803/PortSkipListLedgerStore.patch&amp;lt;/a&amp;gt; downloaded at Mon Dec  3 18:58:51 UTC 2012&lt;/p&gt;

&lt;p&gt;----------------------------&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 PATCH_APPLIES&lt;/font&gt;&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 CLEAN&lt;/font&gt;&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;-1 RAW_PATCH_ANALYSIS&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not introduce any @author tags&lt;br/&gt;
.    &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; the patch contains 1 line(s) with tabs&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not introduce any trailing spaces&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not introduce any line longer than 120&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does adds/modifies 7 testcase(s)&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 RAT&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not seem to introduce new RAT warnings&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;-1 JAVADOC&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; the patch seems to introduce 3 new Javadoc warning(s)&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 COMPILE&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; HEAD compiles&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; patch compiles&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not seem to introduce new javac warnings&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;-1 FINDBUGS&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; the patch seems to introduce 8 new Findbugs warning(s) in module(s) &lt;span class=&quot;error&quot;&gt;&amp;#91;bookkeeper-server&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 TESTS&lt;/font&gt;&lt;br/&gt;
.    Tests run: 393&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 DISTRO&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; distro tarball builds with the patch &lt;/p&gt;

&lt;p&gt;----------------------------&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;&lt;b&gt;-1 Overall result, please check the reported -1(s)&lt;/b&gt;&lt;/font&gt;&lt;/p&gt;


&lt;p&gt;The full output of the test-patch run is available at&lt;/p&gt;

&lt;p&gt;.   &lt;a href=&quot;https://builds.apache.org/job/bookkeeper-trunk-precommit-build/71/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/bookkeeper-trunk-precommit-build/71/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13509519" author="yx3zhu@gmail.com" created="Tue, 4 Dec 2012 05:31:48 +0000"  >&lt;p&gt;Address findbugs&lt;/p&gt;</comment>
                            <comment id="13509593" author="hadoopqa" created="Tue, 4 Dec 2012 08:43:07 +0000"  >&lt;p&gt;Testing JIRA &lt;a href=&quot;https://issues.apache.org/jira/browse/BOOKKEEPER-432&quot; title=&quot;Improve performance of entry log range read per ledger entries &quot; class=&quot;issue-link&quot; data-issue-key=&quot;BOOKKEEPER-432&quot;&gt;&lt;del&gt;BOOKKEEPER-432&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Patch &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12555895/PortSkipListLedgerStore.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;PortSkipListLedgerStore.patch&lt;/a&gt; downloaded at Tue Dec  4 08:18:20 UTC 2012&lt;/p&gt;

&lt;p&gt;----------------------------&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 PATCH_APPLIES&lt;/font&gt;&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 CLEAN&lt;/font&gt;&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;-1 RAW_PATCH_ANALYSIS&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not introduce any @author tags&lt;br/&gt;
.    &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; the patch contains 1 line(s) with tabs&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not introduce any trailing spaces&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not introduce any line longer than 120&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does adds/modifies 7 testcase(s)&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 RAT&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not seem to introduce new RAT warnings&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;-1 JAVADOC&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; the patch seems to introduce 3 new Javadoc warning(s)&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 COMPILE&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; HEAD compiles&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; patch compiles&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not seem to introduce new javac warnings&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 FINDBUGS&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not seem to introduce new Findbugs warnings&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 TESTS&lt;/font&gt;&lt;br/&gt;
.    Tests run: 393&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 DISTRO&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; distro tarball builds with the patch &lt;/p&gt;

&lt;p&gt;----------------------------&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;&lt;b&gt;-1 Overall result, please check the reported -1(s)&lt;/b&gt;&lt;/font&gt;&lt;/p&gt;


&lt;p&gt;The full output of the test-patch run is available at&lt;/p&gt;

&lt;p&gt;.   &lt;a href=&quot;https://builds.apache.org/job/bookkeeper-trunk-precommit-build/73/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/bookkeeper-trunk-precommit-build/73/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13510216" author="yx3zhu@gmail.com" created="Wed, 5 Dec 2012 02:07:49 +0000"  >&lt;p&gt;Review board&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/8350/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/8350/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13609376" author="fpj" created="Thu, 21 Mar 2013 19:49:57 +0000"  >&lt;p&gt;This patch has gone stale, I&apos;m sorry about the delay, Andrew. Is there still interest in getting this in? Should we get back to discussing it?&lt;/p&gt;</comment>
                            <comment id="13657209" author="ikelly" created="Tue, 14 May 2013 18:04:08 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hustlmsp&quot; class=&quot;user-hover&quot; rel=&quot;hustlmsp&quot;&gt;Sijie Guo&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yx3zhu%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;yx3zhu@gmail.com&quot;&gt;Yixue (Andrew) Zhu&lt;/a&gt; I&apos;ve made a first pass on rebasing this on current trunk. I&apos;ve put it skiplist stuff in a new package to keep things tidy. &lt;/p&gt;

&lt;p&gt;SkipListArena.java lacks a license. Is this code copy pasted from somewhere? Can I just put the ASF Licence 2.0 on it?&lt;/p&gt;

&lt;p&gt;Some tests are failing with SortedLedgerStorage. I&apos;d like to understand why, and fix them.&lt;/p&gt;

&lt;p&gt;I&apos;ve removed the stats stuff, because that belongs in a separate jira. We need to clean up stats in BK in general anyhow. Currently we only report to JMX and JMX sucks. Perhaps we could use something like Codahale&apos;s metrics (&lt;a href=&quot;http://metrics.codahale.com/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://metrics.codahale.com/&lt;/a&gt; &amp;lt;- seems he works downstairs from you guys).&lt;/p&gt;

&lt;p&gt;How have you guys benched this?&lt;/p&gt;</comment>
                            <comment id="13657249" author="i0exception" created="Tue, 14 May 2013 18:35:05 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ikelly&quot; class=&quot;user-hover&quot; rel=&quot;ikelly&quot;&gt;Ivan Kelly&lt;/a&gt;, You can put an ASF license on it. AFAIK, it&apos;s not copy pasted. What tests are failing? As far as the stats stuff goes, we have integrated twitter science stats (open sourced on github) to both bookkeeper and hedwig. We could rebase on top of the current trunk if you&apos;d like to integrate them. Stats are exported on http endpoints. &lt;/p&gt;</comment>
                            <comment id="13657266" author="ikelly" created="Tue, 14 May 2013 18:45:17 +0100"  >&lt;p&gt;EntryLogTest, ReadOnlyBookieTest, LedgerCacheTest, CompactionTest &amp;amp; LedgerDeleteTest. I think they fail due to assumptions about entrylog rolling though. I&apos;ll add ASF to the file.&lt;/p&gt;

&lt;p&gt;Re: stats, it&apos;s a different change so it should go in another patch in any case. I&apos;ve looked at twitter stats package before. I couldn&apos;t find much in the way of docs or even how to build it. I also heard(on iago mailing list) that you guys would be replacing it, and ostrich with some common metrics platform.&lt;/p&gt;</comment>
                            <comment id="13657292" author="i0exception" created="Tue, 14 May 2013 19:00:21 +0100"  >&lt;p&gt;Yes. That is the plan going forward. The stats change is such that it abstracts out the implementation from how bookkeeper/hedwig report stats. So, introducing the new metrics library should not be a big change. We can do this in a separate patch.&lt;/p&gt;</comment>
                            <comment id="13657416" author="ikelly" created="Tue, 14 May 2013 20:42:22 +0100"  >&lt;p&gt;ah yes, this would be ideal. &lt;/p&gt;</comment>
                            <comment id="13657782" author="hustlmsp" created="Wed, 15 May 2013 02:10:35 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ikelly&quot; class=&quot;user-hover&quot; rel=&quot;ikelly&quot;&gt;Ivan Kelly&lt;/a&gt; I haven&apos;t take a look at the patch. you might get the changes of those tests from here: &lt;a href=&quot;https://github.com/twitter/bookkeeper/commit/38fdce9920efa0088bdc5d1ee193f0852ffa1194&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/twitter/bookkeeper/commit/38fdce9920efa0088bdc5d1ee193f0852ffa1194&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;it might help some but not sure whether it helps all.&lt;/p&gt;</comment>
                            <comment id="13658177" author="ikelly" created="Wed, 15 May 2013 09:54:03 +0100"  >&lt;p&gt;The problem stems from the change in entry logger, where on an addEntry, the InterleavedLedgerStorage will roll if a limit is reached, but Sorted will not. So the number of log files, which is what the test checks, will be different. So it&apos;s natural enough that it will run fine if we just disable the sorted storage for LedgerDeleteTest. I think the other test fix from that changelist is already in anyhow.&lt;/p&gt;

&lt;p&gt;For the 4.3.0 release, I&apos;m going to disable sorted storage by default. But I do want some tests to run for the new ledger storage also. I&apos;ll try to pick out a subset I want to run, but actually, that will also be a big patch, so I may do it in a separate jira.&lt;/p&gt;</comment>
                            <comment id="13686238" author="hustlmsp" created="Tue, 18 Jun 2013 01:35:22 +0100"  >&lt;p&gt;I just did a quick review. I assumed that you didn&apos;t change the original patch. most of the part would be good, unless the checkpoint part.&lt;/p&gt;

&lt;p&gt;since &lt;a href=&quot;https://issues.apache.org/jira/browse/BOOKKEEPER-564&quot; title=&quot;Better checkpoint mechanism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BOOKKEEPER-564&quot;&gt;&lt;del&gt;BOOKKEEPER-564&lt;/del&gt;&lt;/a&gt;&apos;s checkpoint interface is a bit difference from what we did it before, so I think we need to change the checkpoint behavior here, otherwise it would keep flushing memory tables which affects performance.&lt;/p&gt;</comment>
                            <comment id="13686525" author="ikelly" created="Tue, 18 Jun 2013 10:27:57 +0100"  >&lt;p&gt;I think the behaviour is ok, but something needs to be done about flush interval. Alternatively, you could have SortedLedgerStorage decide the checkpoint, and use the #checkpoint call to simply learn to what point the ledger storage has been checkpointed.&lt;/p&gt;</comment>
                            <comment id="13888866" author="hustlmsp" created="Sun, 2 Feb 2014 08:37:06 +0000"  >&lt;p&gt;attach latest patch. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ikelly&quot; class=&quot;user-hover&quot; rel=&quot;ikelly&quot;&gt;Ivan Kelly&lt;/a&gt; as we discussed in &lt;a href=&quot;https://issues.apache.org/jira/browse/BOOKKEEPER-613&quot; title=&quot;Package refactor on ledger storages&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BOOKKEEPER-613&quot;&gt;BOOKKEEPER-613&lt;/a&gt;, we would get those changes in and then you could do refactor later. if you are ok with the new patch, we could get it in. so I could start generating stats patch for server side.&lt;/p&gt;</comment>
                            <comment id="13888882" author="hadoopqa" created="Sun, 2 Feb 2014 09:36:03 +0000"  >&lt;p&gt;Testing JIRA &lt;a href=&quot;https://issues.apache.org/jira/browse/BOOKKEEPER-432&quot; title=&quot;Improve performance of entry log range read per ledger entries &quot; class=&quot;issue-link&quot; data-issue-key=&quot;BOOKKEEPER-432&quot;&gt;&lt;del&gt;BOOKKEEPER-432&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Patch &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12626518/BOOKKEEPER-432.diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;BOOKKEEPER-432.diff&lt;/a&gt; downloaded at Sun Feb  2 09:07:56 UTC 2014&lt;/p&gt;

&lt;p&gt;----------------------------&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 PATCH_APPLIES&lt;/font&gt;&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 CLEAN&lt;/font&gt;&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 RAW_PATCH_ANALYSIS&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not introduce any @author tags&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not introduce any tabs&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not introduce any trailing spaces&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not introduce any line longer than 120&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does adds/modifies 5 testcase(s)&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;-1 RAT&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; the patch seems to introduce 1 new RAT warning(s)&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 JAVADOC&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not seem to introduce new Javadoc warnings&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 COMPILE&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; HEAD compiles&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; patch compiles&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not seem to introduce new javac warnings&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 FINDBUGS&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; the patch does not seem to introduce new Findbugs warnings&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 TESTS&lt;/font&gt;&lt;br/&gt;
.    Tests run: 893&lt;br/&gt;
&lt;font color=&quot;green&quot;&gt;+1 DISTRO&lt;/font&gt;&lt;br/&gt;
.    &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; distro tarball builds with the patch &lt;/p&gt;

&lt;p&gt;----------------------------&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;&lt;b&gt;-1 Overall result, please check the reported -1(s)&lt;/b&gt;&lt;/font&gt;&lt;/p&gt;


&lt;p&gt;The full output of the test-patch run is available at&lt;/p&gt;

&lt;p&gt;.   &lt;a href=&quot;https://builds.apache.org/job/bookkeeper-trunk-precommit-build/575/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/bookkeeper-trunk-precommit-build/575/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13924146" author="ikelly" created="Fri, 7 Mar 2014 18:16:20 +0000"  >&lt;p&gt;@sijie just to clarify, does the latest patch take the changes we made to snapshotting into account? &lt;/p&gt;</comment>
                            <comment id="13924156" author="hustlmsp" created="Fri, 7 Mar 2014 18:22:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ikelly&quot; class=&quot;user-hover&quot; rel=&quot;ikelly&quot;&gt;Ivan Kelly&lt;/a&gt; what does &apos;snapshotting to account&apos; refer to?&lt;/p&gt;</comment>
                            <comment id="13924193" author="ikelly" created="Fri, 7 Mar 2014 18:47:31 +0000"  >&lt;p&gt;Sorry, I meant checkpointing. When the new checkpointing went into trunk, it changes a bit from what you guys have been using. I remember you mentioning before that the skiplist stuff didn&apos;t work out of the box with it, I wasn&apos;t wondering if this had been fixed.&lt;/p&gt;</comment>
                            <comment id="13924199" author="hustlmsp" created="Fri, 7 Mar 2014 18:50:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ikelly&quot; class=&quot;user-hover&quot; rel=&quot;ikelly&quot;&gt;Ivan Kelly&lt;/a&gt; it is fixed in the new patch, using the same checkpoint holder that used in Interleaved ledger storage.&lt;/p&gt;</comment>
                            <comment id="13932307" author="ikelly" created="Wed, 12 Mar 2014 20:27:59 +0000"  >&lt;p&gt;Committed r1576883. Thanks for all the work on this guys.&lt;/p&gt;</comment>
                            <comment id="13932362" author="hudson" created="Wed, 12 Mar 2014 20:58:27 +0000"  >&lt;p&gt;SUCCESS: Integrated in bookkeeper-trunk #582 (See &lt;a href=&quot;https://builds.apache.org/job/bookkeeper-trunk/582/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/bookkeeper-trunk/582/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/BOOKKEEPER-432&quot; title=&quot;Improve performance of entry log range read per ledger entries &quot; class=&quot;issue-link&quot; data-issue-key=&quot;BOOKKEEPER-432&quot;&gt;&lt;del&gt;BOOKKEEPER-432&lt;/del&gt;&lt;/a&gt;: Improve performance of entry log range read per ledger entries (yixue, sijie via ivank) (ivank: rev 1576883)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/CacheCallback.java&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryKeyValue.java&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryMemTable.java&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/InterleavedLedgerStorage.java&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/SkipListArena.java&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/SkipListFlusher.java&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/SortedLedgerStorage.java&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/main/java/org/apache/bookkeeper/conf/ServerConfiguration.java&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/main/java/org/apache/bookkeeper/proto/BookieServer.java&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/main/resources/findbugsExclude.xml&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/CompactionTest.java&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/EntryLogTest.java&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/LedgerCacheTest.java&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/test/java/org/apache/bookkeeper/test/LedgerDeleteTest.java&lt;/li&gt;
	&lt;li&gt;/zookeeper/bookkeeper/trunk/bookkeeper-server/src/test/java/org/apache/bookkeeper/test/ReadOnlyBookieTest.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12583152" name="0001-BOOKKEEPER-432-First-pass.patch" size="50681" author="ikelly" created="Tue, 14 May 2013 18:04:08 +0100"/>
                            <attachment id="12626518" name="BOOKKEEPER-432.diff" size="55060" author="hustlmsp" created="Sun, 2 Feb 2014 08:37:06 +0000"/>
                            <attachment id="12552129" name="BookieLedgerStorageProposal.pdf" size="35867" author="yx3zhu@gmail.com" created="Mon, 5 Nov 2012 17:29:11 +0000"/>
                            <attachment id="12555895" name="PortSkipListLedgerStore.patch" size="81082" author="yx3zhu@gmail.com" created="Tue, 4 Dec 2012 05:31:48 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 17 Oct 2012 16:13:31 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>248151</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy3ge7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>53972</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>