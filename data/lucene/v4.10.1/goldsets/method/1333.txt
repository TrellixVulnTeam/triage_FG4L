lucli.LuceneMethods.invertDocument(Document)
org.apache.lucene.analysis.br.BrazilianStemFilter.next()
org.apache.lucene.analysis.br.BrazilianStemFilter.next(Token)
org.apache.lucene.analysis.BuffTokenFilter.BuffTokenFilter(TokenStream)
org.apache.lucene.analysis.CachingTokenFilter.CachingTokenFilter(TokenStream)
org.apache.lucene.analysis.CachingTokenFilter.fillCache()
org.apache.lucene.analysis.CachingTokenFilter.fillCache(Token)
org.apache.lucene.analysis.CharTokenizer.normalize(char)
org.apache.lucene.analysis.CharTokenizer.reset(Reader)
org.apache.lucene.analysis.cn.ChineseFilter.ChineseFilter(TokenStream)
org.apache.lucene.analysis.cn.ChineseTokenizer.flush()
org.apache.lucene.analysis.cn.ChineseTokenizer.flush(Token)
org.apache.lucene.analysis.cn.ChineseTokenizer.push(char)
org.apache.lucene.analysis.cn.TestChineseTokenizer.testOtherLetterOffset()
org.apache.lucene.analysis.compound.CompoundWordTokenFilterBase.createToken(int,int,Token)
org.apache.lucene.analysis.compound.CompoundWordTokenFilterBase.decompose(Token)
org.apache.lucene.analysis.compound.CompoundWordTokenFilterBase.makeDictionary(String[])
org.apache.lucene.analysis.compound.TestCompoundWordTokenFilter.assertFiltersTo(TokenFilter,String[],int[],int[],int[])
org.apache.lucene.analysis.compound.TestCompoundWordTokenFilter.getHyphenationPatternFileContents()
org.apache.lucene.analysis.de.GermanStemFilter.GermanStemFilter(TokenStream)
org.apache.lucene.analysis.de.GermanStemFilter.GermanStemFilter(TokenStream,Set)
org.apache.lucene.analysis.de.TestGermanStemFilter.check(String,String)
org.apache.lucene.analysis.el.GreekAnalyzerTest.assertAnalyzesTo(Analyzer,String,String[])
org.apache.lucene.analysis.el.GreekLowerCaseFilter.GreekLowerCaseFilter(TokenStream,char[])
org.apache.lucene.analysis.fr.ElisionFilter.ElisionFilter(TokenStream,String[])
org.apache.lucene.analysis.fr.ElisionFilter.setArticles(Set)
org.apache.lucene.analysis.fr.FrenchStemFilter.FrenchStemFilter(TokenStream)
org.apache.lucene.analysis.fr.TestElision.filtre(TokenFilter)
org.apache.lucene.analysis.KeywordTokenizer.KeywordTokenizer(Reader,int)
org.apache.lucene.analysis.LengthFilter.LengthFilter(TokenStream,int,int)
org.apache.lucene.analysis.LowerCaseFilter.LowerCaseFilter(TokenStream)
org.apache.lucene.analysis.miscellaneous.EmptyTokenStream.close()
org.apache.lucene.analysis.miscellaneous.EmptyTokenStream.reset()
org.apache.lucene.analysis.miscellaneous.PrefixAndSuffixAwareTokenFilter.updateSuffixToken(Token,Token)
org.apache.lucene.analysis.miscellaneous.PrefixAwareTokenFilter.CopyableToken.copyFrom(Token)
org.apache.lucene.analysis.miscellaneous.PrefixAwareTokenFilter.getPrefix()
org.apache.lucene.analysis.miscellaneous.PrefixAwareTokenFilter.PrefixAwareTokenFilter(TokenStream,TokenStream)
org.apache.lucene.analysis.miscellaneous.PrefixAwareTokenFilter.setSuffix(TokenStream)
org.apache.lucene.analysis.miscellaneous.SingleTokenTokenStream.getToken()
org.apache.lucene.analysis.miscellaneous.SingleTokenTokenStream.setToken(Token)
org.apache.lucene.analysis.miscellaneous.SingleTokenTokenStream.SingleTokenTokenStream(Token)
org.apache.lucene.analysis.miscellaneous.TestPrefixAndSuffixAwareTokenFilter.assertNext(TokenStream,String,int,int)
org.apache.lucene.analysis.miscellaneous.TestPrefixAndSuffixAwareTokenFilter.assertNext(TokenStream,Token,String,int,int)
org.apache.lucene.analysis.miscellaneous.TestPrefixAndSuffixAwareTokenFilter.createToken(String,int,int)
org.apache.lucene.analysis.miscellaneous.TestSingleTokenTokenFilter.test()
org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter.EdgeNGramTokenFilter(TokenStream,String,int,int)
org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter.ngram(Token)
org.apache.lucene.analysis.ngram.EdgeNGramTokenFilterTest.testBackRangeOfNgrams()
org.apache.lucene.analysis.ngram.EdgeNGramTokenFilterTest.testBackUnigram()
org.apache.lucene.analysis.ngram.EdgeNGramTokenFilterTest.testFrontRangeOfNgrams()
org.apache.lucene.analysis.ngram.EdgeNGramTokenFilterTest.testFrontUnigram()
org.apache.lucene.analysis.ngram.EdgeNGramTokenFilterTest.testOversizedNgrams()
org.apache.lucene.analysis.ngram.EdgeNGramTokenizer.EdgeNGramTokenizer(Reader,String,int,int)
org.apache.lucene.analysis.ngram.NGramTokenFilter.NGramTokenFilter(TokenStream)
org.apache.lucene.analysis.ngram.NGramTokenFilterTest.testBigrams()
org.apache.lucene.analysis.ngram.NGramTokenFilterTest.testNgrams()
org.apache.lucene.analysis.ngram.NGramTokenFilterTest.testUnigrams()
org.apache.lucene.analysis.ngram.NGramTokenizer.NGramTokenizer(Reader)
org.apache.lucene.analysis.nl.DutchStemFilter.DutchStemFilter(TokenStream)
org.apache.lucene.analysis.nl.DutchStemFilter.DutchStemFilter(TokenStream,Set)
org.apache.lucene.analysis.payloads.NumericPayloadTokenFilter.NumericPayloadTokenFilter(TokenStream,float,String)
org.apache.lucene.analysis.payloads.NumericPayloadTokenFilterTest.WordTokenFilter.WordTokenFilter(TokenStream)
org.apache.lucene.analysis.payloads.TokenOffsetPayloadTokenFilter.TokenOffsetPayloadTokenFilter(TokenStream)
org.apache.lucene.analysis.payloads.TypeAsPayloadTokenFilter.TypeAsPayloadTokenFilter(TokenStream)
org.apache.lucene.analysis.PorterStemFilter.PorterStemFilter(TokenStream)
org.apache.lucene.analysis.ru.RussianLowerCaseFilter.RussianLowerCaseFilter(TokenStream,char[])
org.apache.lucene.analysis.ru.RussianStemFilter.RussianStemFilter(TokenStream,char[])
org.apache.lucene.analysis.ru.TestRussianAnalyzer.test1251()
org.apache.lucene.analysis.ru.TestRussianAnalyzer.testDigitsInRussianCharset()
org.apache.lucene.analysis.ru.TestRussianAnalyzer.testKOI8()
org.apache.lucene.analysis.ru.TestRussianAnalyzer.testUnicode()
org.apache.lucene.analysis.shingle.ShingleAnalyzerWrapperTest.testShingleAnalyzerWrapperBooleanQuery()
org.apache.lucene.analysis.shingle.ShingleAnalyzerWrapperTest.testShingleAnalyzerWrapperPhraseQuery()
org.apache.lucene.analysis.shingle.ShingleFilter.clearShingles()
org.apache.lucene.analysis.shingle.ShingleFilter.fillOutputBuf()
org.apache.lucene.analysis.shingle.ShingleFilter.fillOutputBuf(Token)
org.apache.lucene.analysis.shingle.ShingleFilter.getNextToken()
org.apache.lucene.analysis.shingle.ShingleFilter.getNextToken(Token)
org.apache.lucene.analysis.shingle.ShingleFilterTest.main(String[])
org.apache.lucene.analysis.shingle.ShingleFilterTest.setUp()
org.apache.lucene.analysis.shingle.ShingleFilterTest.shingleFilterTest(int,Token[],Token[],int[],String[])
org.apache.lucene.analysis.shingle.ShingleFilterTest.TestTokenStream.TestTokenStream(Token[])
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.assertNext(TokenStream,String)
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.assertNext(TokenStream,String,int,float)
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.assertNext(TokenStream,String,int,float,int,int)
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.assertNext(TokenStream,Token,String)
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.assertNext(TokenStream,Token,String,int,float)
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.assertNext(TokenStream,Token,String,int,float,int,int)
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.testBehavingAsShingleFilter()
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.testMatrix()
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.testTokenStream()
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.tokenFactory(String,int,float)
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.tokenFactory(String,int,float,int,int)
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.tokenFactory(String,int,float,int,int,ShingleMatrixFilter.TokenPositioner)
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.tokenFactory(String,int,int,int)
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.TokenListStream.TokenListStream(TokenStream)
org.apache.lucene.analysis.sinks.DateRecognizerSinkTokenizer.add(Token)
org.apache.lucene.analysis.SinkTokenizer.SinkTokenizer()
org.apache.lucene.analysis.SinkTokenizer.SinkTokenizer(int)
org.apache.lucene.analysis.SinkTokenizer.SinkTokenizer(List)
org.apache.lucene.analysis.snowball.SnowballFilter.SnowballFilter(TokenStream,String)
org.apache.lucene.analysis.snowball.TestSnowball.testFilterTokens()
org.apache.lucene.analysis.StopFilter.makeStopSet(String[],boolean)
org.apache.lucene.analysis.TeeSinkTokenTest.testMultipleSources()
org.apache.lucene.analysis.TeeSinkTokenTest.testPerformance()
org.apache.lucene.analysis.TeeTokenFilter.TeeTokenFilter(TokenStream,SinkTokenizer)
org.apache.lucene.analysis.TestAnalyzers.testStop()
org.apache.lucene.analysis.TestAnalyzers.verifyPayload(TokenStream)
org.apache.lucene.analysis.TestCachingTokenFilter.checkTokens(TokenStream)
org.apache.lucene.analysis.TestCachingTokenFilter.testCaching()
org.apache.lucene.analysis.TestISOLatin1AccentFilter.testU()
org.apache.lucene.analysis.TestLengthFilter.testFilter()
org.apache.lucene.analysis.TestPerFieldAnalzyerWrapper.testPerField()
org.apache.lucene.analysis.TestStandardAnalyzer.assertAnalyzesTo(Analyzer,String,String[],String[],int[])
org.apache.lucene.analysis.TestStopAnalyzer.testDefaults()
org.apache.lucene.analysis.TestStopAnalyzer.testStopList()
org.apache.lucene.analysis.TestStopAnalyzer.testStopListPositions()
org.apache.lucene.analysis.TestStopFilter.doTestStopPositons(StopFilter,boolean)
org.apache.lucene.analysis.TestStopFilter.testExactCase()
org.apache.lucene.analysis.TestStopFilter.testIgnoreCase()
org.apache.lucene.analysis.TestStopFilter.testStopFilt()
org.apache.lucene.AnalysisTest.test(Reader,boolean,long)
org.apache.lucene.analysis.TestToken.testClone()
org.apache.lucene.analysis.TestToken.testCtor()
org.apache.lucene.analysis.TestToken.testGrow()
org.apache.lucene.analysis.TestToken.testMixedStringArray()
org.apache.lucene.analysis.TestToken.testResize()
org.apache.lucene.analysis.TestToken.TestToken(String)
org.apache.lucene.analysis.TestToken.testToString()
org.apache.lucene.analysis.th.ThaiWordFilter.ThaiWordFilter(TokenStream)
org.apache.lucene.analysis.Token.clearNoTermBuffer()
org.apache.lucene.analysis.Token.clone()
org.apache.lucene.analysis.Token.clone(char[],int,int,int,int)
org.apache.lucene.analysis.Token.endOffset()
org.apache.lucene.analysis.Token.equals(Object)
org.apache.lucene.analysis.Token.growTermBuffer(int)
org.apache.lucene.analysis.Token.hashCode()
org.apache.lucene.analysis.Token.reinit(char[],int,int,int,int)
org.apache.lucene.analysis.Token.reinit(char[],int,int,int,int,String)
org.apache.lucene.analysis.Token.reinit(String,int,int)
org.apache.lucene.analysis.Token.reinit(String,int,int,int,int)
org.apache.lucene.analysis.Token.reinit(String,int,int,int,int,String)
org.apache.lucene.analysis.Token.reinit(String,int,int,String)
org.apache.lucene.analysis.Token.reinit(Token)
org.apache.lucene.analysis.Token.reinit(Token,char[],int,int)
org.apache.lucene.analysis.Token.reinit(Token,String)
org.apache.lucene.analysis.Token.resizeTermBuffer(int)
org.apache.lucene.analysis.Token.setFlags(int)
org.apache.lucene.analysis.Token.setPositionIncrement(int)
org.apache.lucene.analysis.Token.setStartOffset(int)
org.apache.lucene.analysis.Token.setTermBuffer(char[],int,int)
org.apache.lucene.analysis.Token.setTermBuffer(String)
org.apache.lucene.analysis.Token.setTermBuffer(String,int,int)
org.apache.lucene.analysis.Token.setTermLength(int)
org.apache.lucene.analysis.Token.setTermText(String)
org.apache.lucene.analysis.Token.subEqual(Object,Object)
org.apache.lucene.analysis.Token.term()
org.apache.lucene.analysis.Token.termBuffer()
org.apache.lucene.analysis.Token.termLength()
org.apache.lucene.analysis.Token.termText()
org.apache.lucene.analysis.Token.Token(char[],int,int,int,int)
org.apache.lucene.analysis.Token.Token(int,int)
org.apache.lucene.analysis.Token.Token(int,int,int)
org.apache.lucene.analysis.Token.Token(int,int,String)
org.apache.lucene.analysis.Token.Token(String,int,int)
org.apache.lucene.analysis.Token.Token(String,int,int,int)
org.apache.lucene.analysis.Token.Token(String,int,int,String)
org.apache.lucene.demo.html.HTMLParser.HTMLParser(java.io.InputStream)
org.apache.lucene.demo.html.HTMLParser.HTMLParser(java.io.InputStream,String)
org.apache.lucene.demo.html.HTMLParser.jj_add_error_token(int,int)
org.apache.lucene.demo.html.HTMLParser.jj_rescan_token()
org.apache.lucene.demo.html.HTMLParser.ReInit(java.io.InputStream)
org.apache.lucene.demo.html.HTMLParser.ReInit(java.io.InputStream,String)
org.apache.lucene.demo.html.HTMLParserTokenManager.HTMLParserTokenManager(SimpleCharStream)
org.apache.lucene.demo.html.HTMLParserTokenManager.HTMLParserTokenManager(SimpleCharStream,int)
org.apache.lucene.demo.html.ParseException.add_escapes(String)
org.apache.lucene.demo.html.ParseException.getMessage()
org.apache.lucene.demo.html.SimpleCharStream.ExpandBuff(boolean)
org.apache.lucene.demo.html.SimpleCharStream.getTabSize(int)
org.apache.lucene.demo.html.SimpleCharStream.ReInit(java.io.InputStream,int,int)
org.apache.lucene.demo.html.SimpleCharStream.ReInit(java.io.InputStream,int,int,int)
org.apache.lucene.demo.html.SimpleCharStream.ReInit(java.io.InputStream,String,int,int)
org.apache.lucene.demo.html.SimpleCharStream.ReInit(java.io.InputStream,String,int,int,int)
org.apache.lucene.demo.html.SimpleCharStream.ReInit(java.io.Reader)
org.apache.lucene.demo.html.SimpleCharStream.ReInit(java.io.Reader,int,int)
org.apache.lucene.demo.html.SimpleCharStream.ReInit(java.io.Reader,int,int,int)
org.apache.lucene.demo.html.SimpleCharStream.setTabSize(int)
org.apache.lucene.demo.html.SimpleCharStream.SimpleCharStream(java.io.InputStream)
org.apache.lucene.demo.html.SimpleCharStream.SimpleCharStream(java.io.InputStream,int,int)
org.apache.lucene.demo.html.SimpleCharStream.SimpleCharStream(java.io.InputStream,int,int,int)
org.apache.lucene.demo.html.SimpleCharStream.SimpleCharStream(java.io.InputStream,String)
org.apache.lucene.demo.html.SimpleCharStream.SimpleCharStream(java.io.InputStream,String,int,int)
org.apache.lucene.demo.html.SimpleCharStream.SimpleCharStream(java.io.InputStream,String,int,int,int)
org.apache.lucene.demo.html.SimpleCharStream.SimpleCharStream(java.io.Reader,int,int)
org.apache.lucene.demo.html.SimpleCharStream.SimpleCharStream(java.io.Reader,int,int,int)
org.apache.lucene.demo.html.SimpleCharStream.UpdateLineColumn(char)
org.apache.lucene.demo.html.TokenMgrError.addEscapes(String)
org.apache.lucene.index.DocInverterPerField.processFields(Fieldable[],int)
org.apache.lucene.index.memory.AnalyzerUtil.getLoggingAnalyzer(Analyzer,PrintStream,String)
org.apache.lucene.index.memory.AnalyzerUtil.getLoggingAnalyzer.tokenStream(String,Reader)
org.apache.lucene.index.memory.AnalyzerUtil.getLoggingAnalyzer.tokenStream.toString(Token)
org.apache.lucene.index.memory.AnalyzerUtil.getMaxTokenAnalyzer(Analyzer,int)
org.apache.lucene.index.memory.AnalyzerUtil.getMostFrequentTerms(Analyzer,String,int)
org.apache.lucene.index.memory.AnalyzerUtil.getTokenCachingAnalyzer(Analyzer)
org.apache.lucene.index.memory.MemoryIndex.addField(String,TokenStream,float)
org.apache.lucene.index.memory.MemoryIndex.keywordTokenStream(Collection)
org.apache.lucene.index.memory.PatternAnalyzer.FastStringTokenizer.FastStringTokenizer(String,boolean,boolean,Set)
org.apache.lucene.index.memory.PatternAnalyzer.FastStringTokenizer.isTokenChar(char,boolean)
org.apache.lucene.index.memory.PatternAnalyzer.PatternTokenizer.PatternTokenizer(String,Pattern,boolean)
org.apache.lucene.index.memory.PatternAnalyzerTest.assertEquals(List,List)
org.apache.lucene.index.memory.PatternAnalyzerTest.getTokens(TokenStream)
org.apache.lucene.index.memory.PatternAnalyzerTest.toString(List)
org.apache.lucene.index.memory.SynonymTokenFilter.createToken(String,Token)
org.apache.lucene.index.memory.SynonymTokenFilter.createToken(String,Token,Token)
org.apache.lucene.index.memory.SynonymTokenFilter.SynonymTokenFilter(TokenStream,SynonymMap,int)
org.apache.lucene.index.Payload.byteAt(int)
org.apache.lucene.index.Payload.copyTo(byte[],int)
org.apache.lucene.index.Payload.getData()
org.apache.lucene.index.Payload.getOffset()
org.apache.lucene.index.Payload.length()
org.apache.lucene.index.Payload.Payload()
org.apache.lucene.index.Payload.Payload(byte[])
org.apache.lucene.index.Payload.Payload(byte[],int,int)
org.apache.lucene.index.Payload.setData(byte[])
org.apache.lucene.index.Payload.setData(byte[],int,int)
org.apache.lucene.index.Payload.toByteArray()
org.apache.lucene.index.RepeatingTokenStream.RepeatingTokenStream(String)
org.apache.lucene.index.TestDocumentWriter.testPreAnalyzedField()
org.apache.lucene.index.TestDocumentWriter.testTokenReuse()
org.apache.lucene.index.TestIndexWriter.CrashingFilter.CrashingFilter(String,TokenStream)
org.apache.lucene.index.TestIndexWriter.testExceptionFromTokenStream()
org.apache.lucene.index.TestIndexWriter.testNegativePositions()
org.apache.lucene.index.TestMultiLevelSkipList.PayloadFilter.PayloadFilter(TokenStream)
org.apache.lucene.index.TestPayloads.PayloadFilter.PayloadFilter(TokenStream,byte[],int,int)
org.apache.lucene.index.TestPayloads.PoolingPayloadTokenStream.PoolingPayloadTokenStream(ByteArrayPool)
org.apache.lucene.queryParser.analyzing.AnalyzingQueryParser.getFuzzyQuery(String,String,float)
org.apache.lucene.queryParser.analyzing.AnalyzingQueryParser.getPrefixQuery(String,String)
org.apache.lucene.queryParser.analyzing.AnalyzingQueryParser.getRangeQuery(String,String,String,boolean)
org.apache.lucene.queryParser.analyzing.AnalyzingQueryParser.getWildcardQuery(String,String)
org.apache.lucene.queryParser.precedence.CharStream.getColumn()
org.apache.lucene.queryParser.precedence.CharStream.getLine()
org.apache.lucene.queryParser.precedence.CharStream.readChar()
org.apache.lucene.queryParser.precedence.PrecedenceQueryParser.getFieldQuery(String,String)
org.apache.lucene.queryParser.QueryParser.generateParseException()
org.apache.lucene.queryParser.TestMultiAnalyzer.TestFilter.TestFilter(TokenStream)
org.apache.lucene.queryParser.TestMultiAnalyzer.TestPosIncrementFilter.TestPosIncrementFilter(TokenStream)
org.apache.lucene.search.FuzzyLikeThisQuery.addTerms(IndexReader,FieldVals)
org.apache.lucene.search.FuzzyLikeThisQuery.rewrite(IndexReader)
org.apache.lucene.search.highlight.Highlighter.getBestTextFragments(TokenStream,String,boolean,int)
org.apache.lucene.search.highlight.HighlighterTest.getTS2()
org.apache.lucene.search.highlight.HighlighterTest.getTS2a()
org.apache.lucene.search.highlight.HighlighterTest.tearDown()
org.apache.lucene.search.highlight.QueryScorer.getTokenScore(Token)
org.apache.lucene.search.highlight.SimpleSpanFragmenter.isNewFragment(Token)
org.apache.lucene.search.highlight.SynonymTokenizer.SynonymTokenizer(TokenStream,Map)
org.apache.lucene.search.highlight.TokenGroup.addToken(Token,float)
org.apache.lucene.search.highlight.TokenSources.getTokenStream(Document,String,Analyzer)
org.apache.lucene.search.highlight.TokenSources.getTokenStream.StoredTokenStream.StoredTokenStream(Token)
org.apache.lucene.search.highlight.TokenSources.getTokenStream(String,String,Analyzer)
org.apache.lucene.search.highlight.TokenSources.getTokenStream(TermPositionVector,boolean)
org.apache.lucene.search.payloads.TestBoostingTermQuery.PayloadFilter.PayloadFilter(TokenStream,String)
org.apache.lucene.search.QueryTermVector.QueryTermVector(String,Analyzer)
org.apache.lucene.search.similar.MoreLikeThis.addTermFrequencies(Reader,Map,String)
org.apache.lucene.search.similar.SimilarityQueries.formSimilarQuery(String,Analyzer,String,Set)
org.apache.lucene.search.TestPositionIncrement.testIncrementingPositions()
org.apache.lucene.search.TestPositionIncrement.testSetPosition()
org.apache.lucene.store.instantiated.InstantiatedIndexWriter.addDocument(InstantiatedDocument,Analyzer)
org.apache.lucene.store.instantiated.TestIndicesEquals.assembleDocument(Document,int)
org.apache.lucene.store.instantiated.TestIndicesEquals.createToken(String,int,int,String)
org.apache.lucene.store.instantiated.TestIndicesEquals.testEquals(Directory,InstantiatedIndex)
org.apache.lucene.util.ArrayUtil.getShrinkSize(int,int)
org.apache.lucene.util.ArrayUtil.hashCode(byte[],int,int)
org.apache.lucene.util.ArrayUtil.hashCode(char[],int,int)
org.apache.lucene.util.ArrayUtil.shrink(byte[],int)
org.apache.lucene.wikipedia.analysis.WikipediaTokenizer.collapseAndSaveTokens(Token,int,String)
org.apache.lucene.wikipedia.analysis.WikipediaTokenizer.collapseTokens(Token,int)
org.apache.lucene.wikipedia.analysis.WikipediaTokenizer.setupSavedToken(Token,int,String)
org.apache.lucene.wikipedia.analysis.WikipediaTokenizer.setupToken(Token)
org.apache.lucene.wikipedia.analysis.WikipediaTokenizerTest.checkLinkPhrases(WikipediaTokenizer)
org.apache.lucene.wikipedia.analysis.WikipediaTokenizerTest.testBoth()
org.apache.lucene.wikipedia.analysis.WikipediaTokenizerTest.testHandwritten()
org.apache.lucene.wikipedia.analysis.WikipediaTokenizerTest.testLinkPhrases()
org.apache.lucene.wikipedia.analysis.WikipediaTokenizerTest.testLinks()
org.apache.lucene.wikipedia.analysis.WikipediaTokenizerTest.testLucene1133()
org.apache.lucene.wordnet.SynExpand.expand(String,Searcher,Analyzer,String,float)
org.apache.lucene.xmlparser.builders.LikeThisQueryBuilder.getQuery(Element)
org.apache.lucene.xmlparser.builders.SpanOrTermsBuilder.getSpanQuery(Element)
org.apache.lucene.xmlparser.builders.TermsFilterBuilder.getFilter(Element)
