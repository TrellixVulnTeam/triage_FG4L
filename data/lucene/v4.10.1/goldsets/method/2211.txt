org.apache.lucene.analysis.BaseTokenStreamTestCase.assertTokenStreamContents(TokenStream,String[],int,int,String,int)
org.apache.lucene.analysis.BaseTokenStreamTestCase.CheckClearAttributesAttributeImpl.clear()
org.apache.lucene.analysis.BaseTokenStreamTestCase.CheckClearAttributesAttributeImpl.copyTo(AttributeImpl)
org.apache.lucene.analysis.BaseTokenStreamTestCase.CheckClearAttributesAttributeImpl.equals(Object)
org.apache.lucene.analysis.BaseTokenStreamTestCase.CheckClearAttributesAttributeImpl.getAndResetClearCalled()
org.apache.lucene.analysis.BaseTokenStreamTestCase.CheckClearAttributesAttributeImpl.hashCode()
org.apache.lucene.analysis.compound.CompoundWordTokenFilterBase.makeDictionary(Version,String[])
org.apache.lucene.analysis.compound.CompoundWordTokenFilterBase.setToken(Token)
org.apache.lucene.analysis.miscellaneous.PrefixAwareTokenFilter.setCurrentToken(Token)
org.apache.lucene.analysis.miscellaneous.TestPrefixAndSuffixAwareTokenFilter.assertNext(TokenStream,String,int,int)
org.apache.lucene.analysis.miscellaneous.TestPrefixAndSuffixAwareTokenFilter.createToken(String,int,int)
org.apache.lucene.analysis.miscellaneous.TestPrefixAndSuffixAwareTokenFilter.test()
org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter.incrementToken()
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.testBehavingAsShingleFilter()
org.apache.lucene.analysis.TestCachingTokenFilter.testCaching()
org.apache.lucene.analysis.TestTeeSinkTokenFilter.testGeneral()
org.apache.lucene.analysis.TestTeeSinkTokenFilter.testMultipleSources()
org.apache.lucene.index.memory.MemoryIndex.$GenericMethodDeclaration$()
org.apache.lucene.index.memory.MemoryIndex.keywordTokenStream(Collection<T>,T)
org.apache.lucene.index.TestDocumentWriter.testPreAnalyzedField()
org.apache.lucene.search.highlight.HighlighterTest.getTS2()
org.apache.lucene.search.highlight.HighlighterTest.getTS2a()
org.apache.lucene.search.highlight.TokenSources.getTokenStream(TermPositionVector,boolean)
org.apache.lucene.search.TestPositionIncrement.testSetPosition()
org.apache.lucene.search.TestPositionIncrement.testSetPosition.tokenStream(String,Reader)
org.apache.lucene.wikipedia.analysis.WikipediaTokenizerTest.testHandwritten()
org.apache.lucene.wikipedia.analysis.WikipediaTokenizerTest.testSimple()
org.apache.lucene.wikipedia.analysis.WikipediaTokenizerTest.WikipediaTokenizerTest(String)
