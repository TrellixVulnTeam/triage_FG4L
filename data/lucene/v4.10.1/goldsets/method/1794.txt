org.apache.lucene.analysis.ar.ArabicAnalyzer.tokenStream(String,Reader)
org.apache.lucene.analysis.ar.TestArabicAnalyzer.assertAnalyzesToReuse(Analyzer,String,String[])
org.apache.lucene.analysis.ar.TestArabicAnalyzer.testBasicFeatures()
org.apache.lucene.analysis.br.BrazilianAnalyzer.setStemExclusionTable(File)
org.apache.lucene.analysis.br.BrazilianAnalyzer.setStemExclusionTable(Map)
org.apache.lucene.analysis.br.BrazilianAnalyzer.setStemExclusionTable(String[])
org.apache.lucene.analysis.br.TestBrazilianStemmer.checkReuse(Analyzer,String,String)
org.apache.lucene.analysis.br.TestBrazilianStemmer.check(String,String)
org.apache.lucene.analysis.br.TestBrazilianStemmer.testExclusionTableReuse()
org.apache.lucene.analysis.br.TestBrazilianStemmer.testStemExclusionTable()
org.apache.lucene.analysis.cjk.CJKTokenizer.end()
org.apache.lucene.analysis.cjk.CJKTokenizer.reset()
org.apache.lucene.analysis.cjk.CJKTokenizer.reset(Reader)
org.apache.lucene.analysis.cjk.TestCJKTokenizer.checkCJKTokenReusable(Analyzer,String,TestToken[])
org.apache.lucene.analysis.cjk.TestCJKTokenizer.checkCJKToken(String,TestToken[])
org.apache.lucene.analysis.cjk.TestCJKTokenizer.testJa1()
org.apache.lucene.analysis.cjk.TestCJKTokenizer.testSingleChar()
org.apache.lucene.analysis.cn.smart.SentenceTokenizer.incrementToken()
org.apache.lucene.analysis.cn.TestChineseTokenizer.assertAnalyzesToReuse(Analyzer,String,String[],int,int)
org.apache.lucene.analysis.cn.TestChineseTokenizer.testOtherLetterOffset()
org.apache.lucene.analysis.cn.TestSmartChineseAnalyzer.testOffsets()
org.apache.lucene.analysis.compound.CompoundWordTokenFilterBase.decomposeInternal(Token)
org.apache.lucene.analysis.compound.CompoundWordTokenFilterBase.decompose(Token)
org.apache.lucene.analysis.compound.TestCompoundWordTokenFilter.assertFiltersTo(TokenFilter,String[],int[],int[],int[])
org.apache.lucene.analysis.compound.TestCompoundWordTokenFilter.testDumbCompoundWordsSELongestMatch()
org.apache.lucene.analysis.compound.TestCompoundWordTokenFilter.testReset()
org.apache.lucene.analysis.cz.CzechAnalyzer.loadStopWords(InputStream,String)
org.apache.lucene.analysis.cz.TestCzechAnalyzer.assertAnalyzesTo(Analyzer,String,String[])
org.apache.lucene.analysis.cz.TestCzechAnalyzer.testInvalidStopWordFile()
org.apache.lucene.analysis.cz.TestCzechAnalyzer.testReusableTokenStream()
org.apache.lucene.analysis.cz.TestCzechAnalyzer.testStopWord()
org.apache.lucene.analysis.cz.TestCzechAnalyzer.testStopWordFileReuse()
org.apache.lucene.analysis.cz.TestCzechAnalyzer.UnreliableInputStream.read()
org.apache.lucene.analysis.de.GermanAnalyzer.GermanAnalyzer()
org.apache.lucene.analysis.de.GermanAnalyzer.GermanAnalyzer(File)
org.apache.lucene.analysis.de.GermanAnalyzer.GermanAnalyzer(Map)
org.apache.lucene.analysis.de.GermanAnalyzer.GermanAnalyzer(String[])
org.apache.lucene.analysis.de.TestGermanStemFilter.testLUCENE1678BWComp()
org.apache.lucene.analysis.de.TestGermanStemFilter.testStemming()
org.apache.lucene.analysis.el.GreekAnalyzerTest.testAnalyzer()
org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter.next()
org.apache.lucene.analysis.ngram.EdgeNGramTokenFilterTest.testSmallTokenInStream()
org.apache.lucene.analysis.ngram.EdgeNGramTokenizerTest.testBackRangeOfNgrams()
org.apache.lucene.analysis.ngram.NGramTokenizerTest.testOversizedNgrams()
org.apache.lucene.analysis.nl.DutchAnalyzer.DutchAnalyzer()
org.apache.lucene.analysis.nl.DutchAnalyzer.DutchAnalyzer(File)
org.apache.lucene.analysis.nl.DutchAnalyzer.DutchAnalyzer(HashSet)
org.apache.lucene.analysis.nl.DutchAnalyzer.DutchAnalyzer(String[])
org.apache.lucene.analysis.nl.DutchAnalyzer.reusableTokenStream(String,Reader)
org.apache.lucene.analysis.nl.DutchAnalyzer.setStemDictionary(File)
org.apache.lucene.analysis.nl.DutchAnalyzer.setStemExclusionTable(HashSet)
org.apache.lucene.analysis.nl.TestDutchStemmer.testStemDictionaryReuse()
org.apache.lucene.analysis.nl.TestDutchStemmer.testWithSnowballExamples()
org.apache.lucene.analysis.query.QueryAutoStopWordAnalyzer.addStopWords(IndexReader,String,int)
org.apache.lucene.analysis.query.QueryAutoStopWordAnalyzer.QueryAutoStopWordAnalyzer(Analyzer)
org.apache.lucene.analysis.query.QueryAutoStopWordAnalyzerTest.QueryAutoStopWordSubclassAnalyzer.QueryAutoStopWordSubclassAnalyzer()
org.apache.lucene.analysis.query.QueryAutoStopWordAnalyzerTest.testNoFieldNamePollution()
org.apache.lucene.analysis.ru.TestRussianAnalyzer.testDigitsInRussianCharset()
org.apache.lucene.analysis.shingle.ShingleAnalyzerWrapper.setOutputUnigrams(boolean)
org.apache.lucene.analysis.shingle.ShingleAnalyzerWrapper.ShingleAnalyzerWrapper()
org.apache.lucene.analysis.shingle.ShingleAnalyzerWrapper.ShingleAnalyzerWrapper(Analyzer)
org.apache.lucene.analysis.shingle.ShingleAnalyzerWrapper.ShingleAnalyzerWrapper(Analyzer,int)
org.apache.lucene.analysis.shingle.ShingleAnalyzerWrapper.ShingleAnalyzerWrapper(int)
org.apache.lucene.analysis.shingle.ShingleAnalyzerWrapperTest.assertAnalyzesToReuse(Analyzer,String,String[],int[],int[],int[])
org.apache.lucene.analysis.shingle.ShingleAnalyzerWrapperTest.testShingleAnalyzerWrapperBooleanQuery()
org.apache.lucene.analysis.shingle.ShingleAnalyzerWrapperTest.testWrappedAnalyzerDoesNotReuse()
org.apache.lucene.analysis.shingle.ShingleFilterTest.shingleFilterTest(int,Token[],Token[],int[],String[])
org.apache.lucene.analysis.shingle.ShingleFilterTest.testTriGramFilter()
org.apache.lucene.analysis.snowball.SnowballAnalyzer.SnowballAnalyzer(String)
org.apache.lucene.analysis.snowball.SnowballAnalyzer.SnowballAnalyzer(String,String[])
org.apache.lucene.analysis.snowball.TestSnowball.SnowballSubclassAnalyzer.SnowballSubclassAnalyzer(String)
org.apache.lucene.analysis.snowball.TestSnowball.testEnglish()
org.apache.lucene.analysis.snowball.TestSnowball.testFilterTokens()
org.apache.lucene.analysis.th.TestThaiAnalyzer.assertAnalyzesTo(Analyzer,String,String[],int,int,String)
org.apache.lucene.analysis.th.ThaiAnalyzer.ThaiAnalyzer()
org.apache.lucene.index.memory.SynonymTokenFilter.randomize(Object[])
org.apache.lucene.index.memory.TestSynonymTokenFilter.assertAnalyzesTo(Analyzer,String,String[],int,int,int)
org.apache.lucene.index.memory.TestSynonymTokenFilter.assertAnalyzesToReuse(Analyzer,String,String[],int,int,int)
org.apache.lucene.index.memory.TestSynonymTokenFilter.SynonymWhitespaceAnalyzer.SynonymWhitespaceAnalyzer(SynonymMap,int)
org.apache.lucene.index.memory.TestSynonymTokenFilter.testSynonyms()
org.apache.lucene.index.memory.TestSynonymTokenFilter.testSynonymsLimitedAmount()
