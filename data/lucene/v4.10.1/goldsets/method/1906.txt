org.apache.lucene.analysis.BaseCharFilter.correct(int)
org.apache.lucene.analysis.CharTokenizer.end()
org.apache.lucene.analysis.cjk.CJKTokenizer.incrementToken()
org.apache.lucene.analysis.cn.ChineseTokenizer.flush()
org.apache.lucene.analysis.MappingCharFilter.MappingCharFilter(NormalizeCharMap,CharStream)
org.apache.lucene.analysis.MappingCharFilter.MappingCharFilter(NormalizeCharMap,Reader)
org.apache.lucene.analysis.standard.StandardTokenizer.init(Reader,boolean)
org.apache.lucene.analysis.TestMappingCharFilter.setUp()
org.apache.lucene.analysis.TestMappingCharFilter.test1to1()
org.apache.lucene.analysis.TestMappingCharFilter.test1to2()
org.apache.lucene.analysis.TestMappingCharFilter.test1to3()
org.apache.lucene.analysis.TestMappingCharFilter.test2to1()
org.apache.lucene.analysis.TestMappingCharFilter.test2to4()
org.apache.lucene.analysis.TestMappingCharFilter.test3to1()
org.apache.lucene.analysis.TestMappingCharFilter.test4to2()
org.apache.lucene.analysis.TestMappingCharFilter.test5to0()
org.apache.lucene.analysis.TestMappingCharFilter.testNothingChange()
org.apache.lucene.analysis.TestMappingCharFilter.testReaderReset()
org.apache.lucene.analysis.Tokenizer.close()
org.apache.lucene.analysis.Tokenizer.correctOffset(int)
org.apache.lucene.analysis.Tokenizer.reset(CharStream)
org.apache.lucene.analysis.Tokenizer.Tokenizer()
org.apache.lucene.analysis.Tokenizer.Tokenizer(AttributeFactory,CharStream)
org.apache.lucene.analysis.Tokenizer.Tokenizer(AttributeFactory,Reader)
org.apache.lucene.analysis.Tokenizer.Tokenizer(AttributeSource,CharStream)
org.apache.lucene.analysis.Tokenizer.Tokenizer(AttributeSource,Reader)
org.apache.lucene.analysis.Tokenizer.Tokenizer(CharStream)
org.apache.lucene.analysis.Tokenizer.Tokenizer(Reader)
org.apache.lucene.wikipedia.analysis.WikipediaTokenizer.collapseAndSaveTokens(int,String)
org.apache.lucene.wikipedia.analysis.WikipediaTokenizer.collapseTokens(int)
org.apache.lucene.wikipedia.analysis.WikipediaTokenizer.reset()
org.apache.lucene.wikipedia.analysis.WikipediaTokenizer.reset(Reader)
org.apache.lucene.wikipedia.analysis.WikipediaTokenizer.setInput(Reader)
org.apache.lucene.wikipedia.analysis.WikipediaTokenizer.setupToken()
