org.apache.lucene.analysis.ar.ArabicAnalyzer.reusableTokenStream(String,Reader)
org.apache.lucene.analysis.ar.ArabicAnalyzer.tokenStream(String,Reader)
org.apache.lucene.analysis.br.BrazilianAnalyzer.setStemExclusionTable(File)
org.apache.lucene.analysis.br.BrazilianAnalyzer.setStemExclusionTable(Map)
org.apache.lucene.analysis.br.BrazilianAnalyzer.setStemExclusionTable(String[])
org.apache.lucene.analysis.br.TestBrazilianStemmer.check(String,String)
org.apache.lucene.analysis.br.TestBrazilianStemmer.testNormalization()
org.apache.lucene.analysis.br.TestBrazilianStemmer.testReusableTokenStream()
org.apache.lucene.analysis.br.TestBrazilianStemmer.testStemExclusionTable()
org.apache.lucene.analysis.br.TestBrazilianStemmer.testWithSnowballExamples()
org.apache.lucene.analysis.cjk.TestCJKTokenizer.testFullWidth()
org.apache.lucene.analysis.cjk.TestCJKTokenizer.testNonIdeographic()
org.apache.lucene.analysis.cjk.TestCJKTokenizer.testNonIdeographicNonLetter()
org.apache.lucene.analysis.cjk.TestCJKTokenizer.testSingleChar()
org.apache.lucene.analysis.cjk.TestCJKTokenizer.testTokenStream()
org.apache.lucene.analysis.cn.ChineseAnalyzer.ChineseAnalyzer()
org.apache.lucene.analysis.cn.SmartChineseAnalyzer.SmartChineseAnalyzer()
org.apache.lucene.analysis.cn.TestChineseTokenizer.assertAnalyzesTo(Analyzer,String,String[])
org.apache.lucene.analysis.cn.TestChineseTokenizer.assertAnalyzesToReuse(Analyzer,String,String[],int,int)
org.apache.lucene.analysis.cn.TestChineseTokenizer.testEnglish()
org.apache.lucene.analysis.cn.TestChineseTokenizer.testNumerics()
org.apache.lucene.analysis.cn.TestSmartChineseAnalyzer.assertAnalyzesTo(Analyzer,String,String[],int,int)
org.apache.lucene.analysis.cn.TestSmartChineseAnalyzer.assertAnalyzesTo(Analyzer,String,String[],int,int,String)
org.apache.lucene.analysis.cn.TestSmartChineseAnalyzer.assertAnalyzesTo(Analyzer,String,String[],String[])
org.apache.lucene.analysis.cn.TestSmartChineseAnalyzer.testChineseAnalyzer()
org.apache.lucene.analysis.cn.TestSmartChineseAnalyzer.testChineseStopWordsDefault()
org.apache.lucene.analysis.cn.TestSmartChineseAnalyzer.testChineseStopWordsDefaultTwoPhrasesIdeoSpace()
org.apache.lucene.analysis.cn.TestSmartChineseAnalyzer.testChineseStopWordsDefaultTwoPhrasesIdeoSpache()
org.apache.lucene.analysis.cn.TestSmartChineseAnalyzer.testChineseStopWordsOff()
org.apache.lucene.analysis.cn.TestSmartChineseAnalyzer.testDelimiters()
org.apache.lucene.analysis.cn.TestSmartChineseAnalyzer.testMixedLatinChinese()
org.apache.lucene.analysis.cn.TestSmartChineseAnalyzer.testNonChinese()
org.apache.lucene.analysis.cn.TestSmartChineseAnalyzer.testOffsets()
org.apache.lucene.analysis.cn.TestSmartChineseAnalyzer.testOOV()
org.apache.lucene.analysis.compound.CompoundWordTokenFilterBase.makeDictionary(String[])
org.apache.lucene.analysis.compound.DictionaryCompoundWordTokenFilter.DictionaryCompoundWordTokenFilter(TokenStream,String[])
org.apache.lucene.analysis.compound.hyphenation.HyphenationTree.loadPatterns(File)
org.apache.lucene.analysis.cz.CzechAnalyzer.loadStopWords(InputStream,String)
org.apache.lucene.analysis.cz.TestCzechAnalyzer.testStopWord()
org.apache.lucene.analysis.de.GermanAnalyzer.GermanAnalyzer()
org.apache.lucene.analysis.de.GermanStemFilter.incrementToken()
org.apache.lucene.analysis.de.GermanStemFilter.setStemmer(GermanStemmer)
org.apache.lucene.analysis.de.TestGermanStemFilter.checkReuse(Analyzer,String,String)
org.apache.lucene.analysis.de.TestGermanStemFilter.testLUCENE1678BWComp()
org.apache.lucene.analysis.el.GreekAnalyzer.GreekAnalyzer(char[],Map)
org.apache.lucene.analysis.fa.PersianAnalyzer.PersianAnalyzer(File)
org.apache.lucene.analysis.fr.ElisionFilter.ElisionFilter(TokenStream,String[])
org.apache.lucene.analysis.fr.FrenchStemFilter.setStemmer(FrenchStemmer)
org.apache.lucene.analysis.ngram.NGramTokenFilter.NGramTokenFilter(TokenStream)
org.apache.lucene.analysis.ngram.NGramTokenizer.NGramTokenizer(Reader)
org.apache.lucene.analysis.ngram.NGramTokenizer.NGramTokenizer(Reader,int,int)
org.apache.lucene.analysis.nl.DutchAnalyzer.setStemDictionary(File)
org.apache.lucene.analysis.nl.DutchStemFilter.setStemmer(DutchStemmer)
org.apache.lucene.analysis.payloads.PayloadEncoder.encode(char[],int,int)
org.apache.lucene.analysis.payloads.PayloadHelper.decodeFloat(byte[],int)
org.apache.lucene.analysis.query.QueryAutoStopWordAnalyzer.QueryAutoStopWordAnalyzer(Analyzer)
org.apache.lucene.analysis.query.QueryAutoStopWordAnalyzerTest.testWrappingNonReusableAnalyzer()
org.apache.lucene.analysis.ru.RussianAnalyzer.RussianAnalyzer(char[],Map)
org.apache.lucene.analysis.ru.RussianStemFilter.setStemmer(RussianStemmer)
org.apache.lucene.analysis.shingle.ShingleMatrixFilter.SimpleThreeDimensionalTokenSettingsCodec.getWeight(Token)
org.apache.lucene.analysis.shingle.ShingleMatrixFilter.TokenSettingsCodec.getTokenPositioner(Token)
org.apache.lucene.analysis.shingle.TestShingleMatrixFilter.testMatrix()
org.apache.lucene.analysis.th.TestThaiAnalyzer.testAnalyzer()
org.apache.lucene.analysis.th.TestThaiAnalyzer.testBuggyTokenType()
org.apache.lucene.analysis.th.ThaiWordFilter.next(Token)
