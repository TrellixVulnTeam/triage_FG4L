This is like StopFilter, except if the token is the very last token
and there were no non-token characters after it, it keeps the token.

This is useful with analyzing suggesters (AnalyzingSuggester,
AnalyzingInfixSuggester, FuzzySuggester), where you often want to
remove stop words, but not if it's the last word and the user hasn't
finished typing it.

E.g. "fast a" might complete to "fast amoeba", but if you simply use
StopFilter then the a is removed.

Really our analysis APIs aren't quite designed to handle a "partial"
tokens that suggesters need to work with.