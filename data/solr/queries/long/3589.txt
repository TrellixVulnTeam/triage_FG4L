With edismax mm set to 100%  if one of the tokens is split into two tokens by the analyzer chain (i.e. "fire-fly"  => fire fly), the mm parameter is ignored and the equivalent of  OR query for "fire OR fly" is produced.
This is particularly a problem for languages that do not use white space to separate words such as Chinese or Japenese.

See these messages for more discussion:
http://lucene.472066.n3.nabble.com/edismax-parser-ignores-mm-parameter-when-tokenizer-splits-tokens-hypenated-words-WDF-splitting-etc-tc3991911.html

http://lucene.472066.n3.nabble.com/edismax-parser-ignores-mm-parameter-when-tokenizer-splits-tokens-i-e-CJK-tc3991438.html

http://lucene.472066.n3.nabble.com/Why-won-t-dismax-create-multiple-DisjunctionMaxQueries-when-autoGeneratePhraseQueries-is-false-tc3992109.html

