<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 05:25:42 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/SOLR-561/SOLR-561.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[SOLR-561] Solr replication by Solr (for windows also)</title>
                <link>https://issues.apache.org/jira/browse/SOLR-561</link>
                <project id="12310230" key="SOLR">Solr</project>
                    <description>&lt;p&gt;The current replication strategy in solr involves shell scripts . The following are the drawbacks with the approach&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;It does not work with windows&lt;/li&gt;
	&lt;li&gt;Replication works as a separate piece not integrated with solr.&lt;/li&gt;
	&lt;li&gt;Cannot control replication from solr admin/JMX&lt;/li&gt;
	&lt;li&gt;Each operation requires manual telnet to the host&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Doing the replication in java has the following advantages&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Platform independence&lt;/li&gt;
	&lt;li&gt;Manual steps can be completely eliminated. Everything can be driven from solrconfig.xml .
	&lt;ul&gt;
		&lt;li&gt;Adding the url of the master in the slaves should be good enough to enable replication. Other things like frequency of&lt;br/&gt;
snapshoot/snappull can also be configured . All other information can be automatically obtained.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Start/stop can be triggered from solr/admin or JMX&lt;/li&gt;
	&lt;li&gt;Can get the status/progress while replication is going on. It can also abort an ongoing replication&lt;/li&gt;
	&lt;li&gt;No need to have a login into the machine&lt;/li&gt;
	&lt;li&gt;From a development perspective, we can unit test it&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This issue can track the implementation of solr replication in java&lt;/p&gt;</description>
                <environment>&lt;p&gt;All&lt;/p&gt;</environment>
        <key id="12395304">SOLR-561</key>
            <summary>Solr replication by Solr (for windows also)</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="shalinmangar">Shalin Shekhar Mangar</assignee>
                                    <reporter username="noble.paul">Noble Paul</reporter>
                        <labels>
                    </labels>
                <created>Mon, 5 May 2008 10:58:14 +0100</created>
                <updated>Thu, 2 May 2013 03:29:16 +0100</updated>
                            <resolved>Tue, 21 Oct 2008 10:45:22 +0100</resolved>
                                    <version>1.4</version>
                                    <fixVersion>1.4</fixVersion>
                                    <component>replication (java)</component>
                        <due></due>
                            <votes>5</votes>
                                    <watches>12</watches>
                                                                <comments>
                            <comment id="12599474" author="yseeley@gmail.com" created="Fri, 23 May 2008 20:17:06 +0100"  >&lt;p&gt;How about posting a snapshot of what you have, with a few paragraphs explaining how things work, etc.  Early feedback is better, and it allows more people to add their expertise.  I&apos;m sure many are interested in the ease-of-use gains this patch can bring.&lt;/p&gt;</comment>
                            <comment id="12599559" author="noble.paul" created="Sat, 24 May 2008 05:17:03 +0100"  >&lt;p&gt;We shall post a patch in the next few days&lt;/p&gt;

&lt;p&gt;The design is as follows:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;SnapShooter.java :  registered as a listener on &lt;em&gt;postCommit/postOptimize&lt;/em&gt; . It makes a copy of the latest index to a new snapshot folder (same as it is today). Only in master. It can optionally take in a &apos;snapDir&apos; as configuration if the snapshot is to be created ina folder other than the data directory.&lt;/li&gt;
	&lt;li&gt;ReplicationHandler: A requesthandler. This is registered in master &amp;amp; slave. It takes in the following config in the slave. Master node just needs an empty requesthandler registration.
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;solrconfig.xml&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt; 
&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;requestHandler name=&lt;span class=&quot;code-quote&quot;&gt;&quot;replication&quot;&lt;/span&gt; class=&lt;span class=&quot;code-quote&quot;&gt;&quot;solr.ReplicationHandler&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;str name=&lt;span class=&quot;code-quote&quot;&gt;&quot;masterUrl&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;http://&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;host&amp;gt;&lt;/span&gt;:&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;port&amp;gt;&lt;/span&gt;/solr/&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;corename&amp;gt;&lt;/span&gt;/replication&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;str name=&lt;span class=&quot;code-quote&quot;&gt;&quot;pollInterVal&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;HH:MM:SS&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;
&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/requestHandler&amp;gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;ReplicationHandler Implements the following methods. Every method is invoked over &lt;b&gt;http GET&lt;/b&gt;. These methods are usually trigerred from the slave (over http) or timer (for snappull). Admin can provide means to invoke some methods  like snappull,snapshoot .&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;CMD_GET_FILE: &lt;em&gt;(command=filecontent&amp;amp;snapshhot=&amp;lt;snapshotname&amp;gt;&amp;amp;file=&amp;lt; filename&amp;gt;&amp;amp;offset=&amp;lt;fileOffset&amp;gt;&amp;amp;len=&amp;lt;length-ofchunk&amp;gt;&amp;amp;checksum=&amp;lt;true|false&amp;gt;)&lt;/em&gt; .  This is invoked by a slave  only to fetch a file or a part of it . This uses a custom format (described later)&lt;/li&gt;
	&lt;li&gt;CMD_LATEST_SNAP: &lt;em&gt;(command=latestsnap)&lt;/em&gt;. Returns the name of the latest snapshot (a namedlist response)&lt;/li&gt;
	&lt;li&gt;CMD_GET_SNAPSHOTS: &lt;em&gt;(command=snaplist)&lt;/em&gt;. Returns a list of all snapshot names (a namedlist response)&lt;/li&gt;
	&lt;li&gt;CMD_GET_FILE_LIST: &lt;em&gt;(command=filelist&amp;amp;snap=&amp;lt;snapshotname&amp;gt;)&lt;/em&gt; . A list of all the files in the snapshot .conains name, lastmodified,size. (a namedlist response)&lt;/li&gt;
	&lt;li&gt;CMD_SNAP_SHOOT: &lt;em&gt;(command=snapshoot)&lt;/em&gt;. Do a force snapshoot.&lt;/li&gt;
	&lt;li&gt;CMD_DISABLE_SNAPPOLL: &lt;em&gt;(command=disablesnappoll)&lt;/em&gt;. For stopping the timer task&lt;/li&gt;
	&lt;li&gt;CMD_SNAP_PULL : &lt;em&gt;(command=snappull)&lt;/em&gt;. Does the following operations (done in slave). It is mostly triggered from a timertask based on the pollInterval value.
	&lt;ul&gt;
		&lt;li&gt;calls a CMD_LATEST_SNAP to the master and get the latest snapshot name&lt;/li&gt;
		&lt;li&gt;checks if it has the same (or if a snappull is going on)&lt;/li&gt;
		&lt;li&gt;if it is to be pulled, call CMD_GET_FILE_LIST to the master&lt;/li&gt;
		&lt;li&gt;for each file in the list make a call CMD_GET_FILE to the master. This command works in the following way
		&lt;ul&gt;
			&lt;li&gt;the server reads the file stream&lt;/li&gt;
			&lt;li&gt;It uses a CustomStreamResponseWriter &lt;em&gt;(wt=filestream)&lt;/em&gt; to write the content. It has a packetSize (say 1mb)&lt;/li&gt;
			&lt;li&gt;It writes an int for length and another long for Adler32 checksum (if checksum=true). The packets are written one after another till EOF or an Exception.&lt;/li&gt;
			&lt;li&gt;SnapPuller.java In the client reads the packet length and checksum and tries to read the packet.If it is unable to read the given packet or the checksum does not match or there is an exception , it closes the connection and makes a new CMD_GET_FILE  command with the offset = (totalbytesReceived). If everything is fine the packets are read till the _&lt;em&gt;bytesDownloaded == fileSize&lt;/em&gt;_&lt;/li&gt;
			&lt;li&gt;This is continued till all the files are downloaded.&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
		&lt;li&gt;creates a folder index.tmp&lt;/li&gt;
		&lt;li&gt;for each file in the copied snapshot , try to create a hardlink in the index.tmp folder.(runs an OS specific command)&lt;/li&gt;
		&lt;li&gt;If hardlink creation fails use a copy&lt;/li&gt;
		&lt;li&gt;rename &lt;em&gt;index.tmp&lt;/em&gt; to &lt;em&gt;index&lt;/em&gt;&lt;/li&gt;
		&lt;li&gt;calls a commit on the updatehandler&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;**note: The download tries to use the same stream to download the complete file .&lt;/p&gt;

&lt;p&gt;Please comment on the design&lt;/p&gt;</comment>
                            <comment id="12599831" author="otis" created="Mon, 26 May 2008 13:34:35 +0100"  >&lt;p&gt;I think the above sounds more or less right (read it quickly).&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Should there exist a mechanism for preventing infinite loops (try to get a file, fail for some reason, try again, and over and over and over until some disk gets filled over night, for example)?&lt;/li&gt;
	&lt;li&gt;I see &amp;amp;snapshhot=&amp;lt;snapshotname&amp;gt; as well as &amp;amp;snap=&amp;lt;snapshotname&amp;gt;.  This may be a typo in the JIRA comment only, I don&apos;t know.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Thinking about the Admin display of replication information:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Is there anything that keeps track of overall data transfer progress?
	&lt;ul&gt;
		&lt;li&gt;the name of the snapshot being replicated currently&lt;/li&gt;
		&lt;li&gt;the name of the file being replicated currently&lt;/li&gt;
		&lt;li&gt;the total number of bytes transfered vs. the size of the snapshot&lt;/li&gt;
		&lt;li&gt;any failures (number of failures + info)&lt;br/&gt;
...&lt;br/&gt;
...&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I imagine those wanting Enterprise Solr will desire this type of stuff, so even if we don&apos;t have any of this in the UI at this point, it might be good keeping this in mind and providing the necessary hooks, callbacks, etc.&lt;/p&gt;</comment>
                            <comment id="12599848" author="noble.paul" created="Mon, 26 May 2008 15:34:47 +0100"  >&lt;p&gt;Otis: All the points you have enumerated are valid . We actually think they should be there in the final solution.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;It should have a way to prevent infinite loops.&lt;/li&gt;
	&lt;li&gt;snap=&amp;lt;snapshotname&amp;gt; is the correct command&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;All the admin related changes are planned exactly as you have asked .  But we can leave the hooks open and push through with the basic stuff. The design documentation just tries to cover everything which the scripts currently cover. &lt;br/&gt;
If everything else is fine we shall give a rough patch for your review in another 2-3 days&lt;/p&gt;</comment>
                            <comment id="12600706" author="noble.paul" created="Thu, 29 May 2008 09:41:10 +0100"  >&lt;p&gt;There are problems with index replacement in windows.&lt;br/&gt;
Windows does not allow as to delete the index folder, because it is being used .&lt;br/&gt;
 How do we solve this?&lt;/p&gt;</comment>
                            <comment id="12600745" author="asavory" created="Thu, 29 May 2008 12:28:36 +0100"  >&lt;p&gt;This looks like an extremely useful addition. More comments when the patch is available, but an initial observation:&lt;br/&gt;
&amp;lt;str name=&quot;pollInterVal&quot;&amp;gt;HH:MM:SS&amp;lt;/str&amp;gt;&lt;br/&gt;
For consistency, could this be specified cron-style instead? e.g.&lt;br/&gt;
&amp;lt;str name=&quot;pollInterVal&quot;&amp;gt;*/30 * * * *&amp;lt;/str&amp;gt;&lt;/p&gt;</comment>
                            <comment id="12600772" author="shalinmangar" created="Thu, 29 May 2008 14:46:59 +0100"  >&lt;p&gt;I think hh:MM:ss is universally recognizable and very intuitive. We should also keep in mind that this solution will be used on a multiple platforms and an OS like Windows does not have cron so it&apos;s administrators may not be familiar with the cron format.&lt;/p&gt;</comment>
                            <comment id="12600775" author="asavory" created="Thu, 29 May 2008 15:21:39 +0100"  >&lt;p&gt;Shalin,&lt;/p&gt;

&lt;p&gt;I&apos;m assuming that pollInterVal is intended to specify the frequency of replication. hh:MM:ss is universally recognizable for specifying a single time, certainly. But how do you represent &quot;every hour&quot;, or &quot;four times a day&quot;, or &quot;the first tuesday of each month&quot; with that notation?&lt;/p&gt;

&lt;p&gt;Certainly Windows doesn&apos;t have cron but we&apos;re talking about a pure java implementation, so that&apos;s not a problem. Quartz might be a perfect solution for scheduling: &lt;a href=&quot;http://www.opensymphony.com/quartz/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.opensymphony.com/quartz/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12600779" author="shalinmangar" created="Thu, 29 May 2008 15:30:20 +0100"  >&lt;p&gt;Does anybody really do things like &quot;first tuesday of each month&quot; for polling the Solr master? The slave&apos;s poll is usually set to run every few minutes. Atleast that&apos;s how we use it in our production environments. Quartz is nice but the thing is that we don&apos;t need all those features. A timer task is good enough for our needs.&lt;/p&gt;

&lt;p&gt;Yes, hh:MM:ss represents time but it isn&apos;t difficult to view it as a countdown timer. It&apos;s definitely easier to understand than specifying number of seconds/minutes as an integer for a poll interval. What do you think?&lt;/p&gt;</comment>
                            <comment id="12600792" author="noble.paul" created="Thu, 29 May 2008 15:58:55 +0100"  >&lt;p&gt;for polling a simple interval this syntax may be enough. Polling is not a very expensive operation. It just sends a request and get the latest snapshotname. So we can schedule it to run even every minute also&lt;/p&gt;

&lt;p&gt;If there is a need for such complex scheduling we can consider that syntax.&lt;/p&gt;


</comment>
                            <comment id="12600794" author="noble.paul" created="Thu, 29 May 2008 16:05:32 +0100"  >&lt;p&gt;A possible solution to the windows replication problem would be.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Make changes to Solr Core to load the index from a given directory instead of hardcoding the directory name.In our case we can give the new snapshot directory&lt;/li&gt;
	&lt;li&gt;After the new IndexSearcher/writer is loaded, Close the original index searcher . Then it is ok to delete that&lt;/li&gt;
	&lt;li&gt;Delete old contents and Copy hardlinks to the index directory. So if you restart solr it will get the index from the right place&lt;/li&gt;
&lt;/ul&gt;

</comment>
                            <comment id="12600823" author="otis" created="Thu, 29 May 2008 17:27:33 +0100"  >&lt;p&gt;Re poll interval: I think the HH:MM:ss is enough.  Does that allow polling, say, every 72 hours?  Just use 72:00:00, right?&lt;/p&gt;

&lt;p&gt;Re Winblows problem: I&apos;d like the switch to the current/latest snapshot, but this prevents us from always knowing the location of the active directory.  We&apos;d have to rely on sorting the dir with snapshot names and assuming the currently active index is the one with the most recent snapshot, no?  Symlinks would be great here, but again, Winblows doesn&apos;t have them (and I think using shortcuts for this wouldn&apos;t work).&lt;/p&gt;</comment>
                            <comment id="12600827" author="shalinmangar" created="Thu, 29 May 2008 17:40:40 +0100"  >&lt;blockquote&gt;&lt;p&gt;Re poll interval: I think the HH:MM:ss is enough. Does that allow polling, say, every 72 hours? Just use 72:00:00, right?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Correct, 72:00:00 will work.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Re Winblows problem: I&apos;d like the switch to the current/latest snapshot, but this prevents us from always knowing the location of the active directory. We&apos;d have to rely on sorting the dir with snapshot names and assuming the currently active index is the one with the most recent snapshot, no? Symlinks would be great here, but again, Winblows doesn&apos;t have them (and I think using shortcuts for this wouldn&apos;t work).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As Noble suggested, once the new searcher is in use and the older one is closed, hopefully windows will kindly grant us permission to delete the files in the index directory. We can then create links to the files in the snapshot being used into the index directory. The latest snapshot directory will be the active one but we&apos;ll know what index is being used through the links in the index folder.&lt;/p&gt;</comment>
                            <comment id="12600850" author="noble.paul" created="Thu, 29 May 2008 18:37:00 +0100"  >&lt;p&gt;windows has symlinks/hardlink. &quot;fsutil create hardlink &quot; is the command. It woks well as long as your windows version&amp;gt;win2K&lt;/p&gt;

</comment>
                            <comment id="12600989" author="jasonrutherglen" created="Fri, 30 May 2008 01:52:55 +0100"  >&lt;p&gt;Is there a reason why IndexDeletionPolicy is not being used?  It allows keeping snapshot files available for replication without creating a specific snapshot directory.  This would be cleaner than creating an external process.  &lt;/p&gt;</comment>
                            <comment id="12601007" author="noble.paul" created="Fri, 30 May 2008 05:31:47 +0100"  >&lt;p&gt;The strategy of keeping the index directory name hard coded is a bit tricky. We need to do a lot of File System specific jugglery. The best strategy would be.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;keep a file index.properties in the data dir&lt;/li&gt;
	&lt;li&gt;Have an entry currentindex=&amp;lt;new.index&amp;gt; in that file&lt;/li&gt;
	&lt;li&gt;This file may keep other extra information if we need it&lt;/li&gt;
	&lt;li&gt;When a new indexsearcher/writer is loaded, read this property and try to load the index from that folder&lt;/li&gt;
	&lt;li&gt;if it is absent , default to the hardcoded value&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This way we never need to make hardlinks etc . &lt;/p&gt;</comment>
                            <comment id="12601184" author="yseeley@gmail.com" created="Fri, 30 May 2008 17:08:57 +0100"  >&lt;blockquote&gt;&lt;p&gt;Is there a reason why IndexDeletionPolicy is not being used? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, that&apos;s what I suggested in the initial email thread.&lt;br/&gt;
With a little more smarts, it seems like the new files could be replicated directly from the master index directory, directly to the slave index directory.  One wouldn&apos;t want to copy &lt;b&gt;all&lt;/b&gt; the new files though... only those files that are part of the latest index... (hmmm, does Lucene have a way of getting that info?)&lt;/p&gt;
</comment>
                            <comment id="12601276" author="yseeley@gmail.com" created="Fri, 30 May 2008 23:29:34 +0100"  >&lt;p&gt;Just checked: Lucene&apos;s IndexCommit.getFileNames() returns all the files associated with a particular commit point.&lt;/p&gt;</comment>
                            <comment id="12601355" author="noble.paul" created="Sat, 31 May 2008 07:10:00 +0100"  >&lt;p&gt;Yonik: This would be very useful in optimizing the file transfers .We must incorporate this if possible&lt;/p&gt;

&lt;p&gt;BTW . What do you recommend for windows Index deletion?. Is the solution proposed by me fine?&lt;/p&gt;</comment>
                            <comment id="12601448" author="noble.paul" created="Sun, 1 Jun 2008 08:42:29 +0100"  >&lt;p&gt;The first cut. very crude , but worx .No OS specific commands&lt;br/&gt;
The design for snapshoot , snappull is same as described in the design overview&lt;br/&gt;
snapinstall is done the following way&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;write out a file index.properties in dataDirectory.&lt;/li&gt;
	&lt;li&gt;call commit command&lt;/li&gt;
	&lt;li&gt;The SolrCore is modified. A new method getNewIndexDir() is added. It loads the properties file (if exists, else fall back to the old behavior), read a property &apos;index&apos;  and return&lt;/li&gt;
	&lt;li&gt;Any new SolrIndexWriter, SolrIndexSearcher is loaded from the new index dir&lt;/li&gt;
	&lt;li&gt;Old ones continue to use the old index dir . getindexDir() returns the index dir used by the current SolrIndexReader/SolrIndexWriter&lt;br/&gt;
Use the following configuration&lt;br/&gt;
in master &lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
	&lt;li&gt;register snapshooter
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt;
  &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;listener event=&lt;span class=&quot;code-quote&quot;&gt;&quot;postCommit&quot;&lt;/span&gt; class=&lt;span class=&quot;code-quote&quot;&gt;&quot;solr.SnapShooter&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;    
          &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;bool name=&lt;span class=&quot;code-quote&quot;&gt;&quot;wait&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;true&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/bool&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/listener&amp;gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;register replication Handler
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt;
 &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;requestHandler name=&lt;span class=&quot;code-quote&quot;&gt;&quot;/replication&quot;&lt;/span&gt; class=&lt;span class=&quot;code-quote&quot;&gt;&quot;solr.ReplicationHandler&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;register a new ResponseWriter
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt;
&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;queryResponseWriter name=&lt;span class=&quot;code-quote&quot;&gt;&quot;filestream&quot;&lt;/span&gt; class=&lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.solr.request.CustomBinaryResponseWriter&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;In the Slave &lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;register the replication handler
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt;
  &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;requestHandler name=&lt;span class=&quot;code-quote&quot;&gt;&quot;/replication&quot;&lt;/span&gt; class=&lt;span class=&quot;code-quote&quot;&gt;&quot;solr.ReplicationHandler&quot;&lt;/span&gt; &amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;str name=&lt;span class=&quot;code-quote&quot;&gt;&quot;masterUrl&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;http://localhost:8080/solr/replication&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;str name=&lt;span class=&quot;code-quote&quot;&gt;&quot;pollInterval&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;00:00:30&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/requestHandler&amp;gt;&lt;/span&gt;  
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;

</comment>
                            <comment id="12601450" author="tpeuss" created="Sun, 1 Jun 2008 09:03:18 +0100"  >&lt;p&gt;A library like &quot;Quartz&quot; (&lt;a href=&quot;http://www.opensymphony.com/quartz/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.opensymphony.com/quartz/&lt;/a&gt;) would give you the possibility to provide both types of schedules (HH:MM:SS and cron like). Quartz uses the ASF 2.0 license. So there are at least no licensing issues.&lt;/p&gt;

&lt;p&gt;I have not looked at the code but it is possible to do snapshots/snappull at a certain time (e.g. every day 1am)? Quartz would give you the possibility to do that as well. Quartz would even provide scenarios like &lt;em&gt;every 1st monday of the month&lt;/em&gt;.&lt;/p&gt;</comment>
                            <comment id="12601451" author="noble.paul" created="Sun, 1 Jun 2008 09:24:59 +0100"  >&lt;p&gt;Thomas: This is something that can be considered. But , I am still not very convinced that people use it that way. It is going to introduce some dependency on a new library. Let us see if there is enough demand from users&lt;/p&gt;

&lt;p&gt;&lt;b&gt;note&lt;/b&gt; :All the operations can be triggerred using http get. So a &lt;em&gt;wget&lt;/em&gt; from cron can do the trick in the current form&lt;/p&gt;</comment>
                            <comment id="12601457" author="tpeuss" created="Sun, 1 Jun 2008 10:35:56 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Thomas: This is something that can be considered. But , I am still not very convinced that people use it that way. It is going to introduce some dependency on a new library. Let us see if there is enough demand from users&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The basic functionality is much more important of course (and much harder to do).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;note :All the operations can be triggerred using http get. So a wget from cron can do the trick in the current form&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK. Then ignore my comment. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12601604" author="noble.paul" created="Mon, 2 Jun 2008 12:55:25 +0100"  >&lt;p&gt;This patch includes &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;a new method in ReplicationHandler &lt;em&gt;filechecksum&lt;/em&gt;  , which can return the checksums of a given list of files in a snapshot&lt;/li&gt;
	&lt;li&gt;The snappuller will request for the checksums of the files if the name and size are same (compared to the current index)&lt;/li&gt;
	&lt;li&gt;Only if the checksums are different the file is downloaded&lt;/li&gt;
	&lt;li&gt;Other files are copied from the current index&lt;/li&gt;
&lt;/ul&gt;


</comment>
                            <comment id="12601659" author="asavory" created="Mon, 2 Jun 2008 17:13:12 +0100"  >&lt;p&gt;Please don&apos;t ignore Thomas&apos;s repeat suggestion to use Quartz!&lt;/p&gt;

&lt;p&gt;Having replication built-in but then having to use an external cron job to trigger the operations seems suboptimal to me. Being able to configure &lt;b&gt;everything&lt;/b&gt; related to replication within the solr deployment seems far more elegant.&lt;/p&gt;</comment>
                            <comment id="12601663" author="noble.paul" created="Mon, 2 Jun 2008 17:22:35 +0100"  >&lt;p&gt;This feature is far from complete . Enhanced admin features is probably the next priority&lt;br/&gt;
If scheduling is indeed important we will take it up.  &lt;br/&gt;
Meanwhile we need to ensure that the solution is usable and bug free.&lt;/p&gt;</comment>
                            <comment id="12601775" author="hossman" created="Mon, 2 Jun 2008 23:27:57 +0100"  >&lt;blockquote&gt;&lt;p&gt;If scheduling is indeed important we will take it up.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Meanwhile we need to ensure that the solution is usable and bug free.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;agreed ... the challenge here is (efficient) pure java equivalents of snapshooter/snappuller/snapinstaller ... the scheduling mechanism is largely orthogonal, particularly since Paul is using a &quot;ReplicationHandler&quot; as the main API.  it could easily be dealt with later (or in parallel if anyone wants to take on the task)&lt;/p&gt;

&lt;p&gt;i don&apos;t think the ReplicationHandler should know &lt;b&gt;anything&lt;/b&gt; about scheduling or recurance. A generic Scheduling system could be hooked into SolrCore that can hit arbitrary RequestHandlers according to whatever configuration it has (similar to the QuerySendEventListener) which would handle this case, as well as other interesting use cases (ie: rebuild a spelling dictionary using an external datasource every hour, even if the index hasn&apos;t changed)&lt;/p&gt;

&lt;p&gt;the scheduling aspect can easily be dealt with later (or in parallel if anyone wants to take on the task)&lt;/p&gt;</comment>
                            <comment id="12601824" author="noble.paul" created="Tue, 3 Jun 2008 05:03:48 +0100"  >&lt;blockquote&gt;&lt;p&gt;A generic Scheduling system could be hooked into SolrCore that can hit arbitrary RequestHandlers according to whatever configuration.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;hoss: currently the timer task itself is a part of &lt;em&gt;SnapPuller.java&lt;/em&gt; . I endorse your idea of having a scheduling feature built into SolrCore if it is useful to more than one components. As you mentioned every operation is triggerred by the &lt;em&gt;ReplicationHandler&lt;/em&gt;&apos;s REST API. So if another servive can give a callback at the right time it is the best solution.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;the challenge here is (efficient) pure java equivalents of &lt;em&gt;snapshooter/snappuller/snapinstaller&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes , this indeed is the challenge. I wish people to look into the implementation and comment on how these operations can be made more efficient. I already am thinking of caching the file checksums because there are more than one slaves requesting for the same. &lt;/p&gt;

&lt;p&gt;The other important item that needs review is the changes made to &lt;em&gt;SolrCore.getNewIndexDir()&lt;/em&gt;&lt;/p&gt;</comment>
                            <comment id="12601891" author="noble.paul" created="Tue, 3 Jun 2008 11:49:44 +0100"  >&lt;p&gt;Should we plan this feature for Solr 1.3 release ?.  If yes, what all are the items pending to be completed?&lt;/p&gt;</comment>
                            <comment id="12601951" author="asavory" created="Tue, 3 Jun 2008 15:27:19 +0100"  >&lt;p&gt;I&apos;d certainly like to see this in 1.3, it would make my life easier!&lt;br/&gt;
I&apos;m trying out the code now and hope to feedback in depth soon.&lt;br/&gt;
Meanwhile some initial comments: there&apos;s inconsistency between 4 space and 2 space tabs in the code, and a few System.out.println that you probably want to remove or replace with proper logging.&lt;/p&gt;</comment>
                            <comment id="12602536" author="noble.paul" created="Thu, 5 Jun 2008 05:27:45 +0100"  >&lt;p&gt;The next step is to replicate files in conf folder. &lt;br/&gt;
Thre strategy is as follows,&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Mention the files to be replicated from the master, in the &lt;em&gt;ReplicationHandler&lt;/em&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt;
  &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;requestHandler name=&lt;span class=&quot;code-quote&quot;&gt;&quot;/replication&quot;&lt;/span&gt; class=&lt;span class=&quot;code-quote&quot;&gt;&quot;solr.ReplicationHandler&quot;&lt;/span&gt; &amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;str name=&lt;span class=&quot;code-quote&quot;&gt;&quot;confFiles&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;schema.xml,stopwords.txt,elevate.xml&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;  
    &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/requestHandler&amp;gt;&lt;/span&gt;  
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;For the CMD_FILE_LIST command response include these files also&lt;/li&gt;
	&lt;li&gt;The slave can compare the files with its local copy and if it is modified download them&lt;/li&gt;
	&lt;li&gt;A backup of the current files are taken and the new files are placed into the conf folder&lt;/li&gt;
	&lt;li&gt;If a conf file is changed the the SolrCore must be reloaded&lt;/li&gt;
	&lt;li&gt;There must be separate strategies for reloading core for single core or multicore&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12603040" author="noble.paul" created="Fri, 6 Jun 2008 14:34:13 +0100"  >&lt;p&gt;can we make &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-551&quot; title=&quot;Solr replication should include the schema also&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-551&quot;&gt;&lt;del&gt;SOLR-551&lt;/del&gt;&lt;/a&gt; a subproject of this?&lt;/p&gt;</comment>
                            <comment id="12603081" author="otis" created="Fri, 6 Jun 2008 16:44:58 +0100"  >&lt;p&gt;I think so.  You already started doing that with your comment from 04/Jun.&lt;br/&gt;
2 quick thoughts:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Does it make sense to support regular expressions in that confFiles file list?  Something a la FileFilter - &lt;a href=&quot;http://java.sun.com/javase/6/docs/api/java/io/FileFilter.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://java.sun.com/javase/6/docs/api/java/io/FileFilter.html&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;I like the backup idea. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  As a matter of fact, I&apos;d make backups with timestamps, so we don&apos;t have just one backup, but have a bit of history.  Backups &amp;gt; N days old can be periodically deleted either as part of this java-based replication mechanism, or via a cron job&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12603097" author="noble.paul" created="Fri, 6 Jun 2008 17:59:32 +0100"  >&lt;blockquote&gt;&lt;p&gt;Does it make sense to support regular expressions in that confFiles file list?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It;s easy to implement with a wild card . But , very few files need to be replicated .Isn&apos;t it  better to explicitly mention the names so that no file accidentally gets replicated. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I like the backup idea.  As a matter of fact, I&apos;d make backups with timestamps&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, timestamps, the same format used by the snapshots&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Backups &amp;gt; N days old can be periodically deleted &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is a good idea. It must be a feature of replication. Old conf files as well as indexes should be purged periodically&lt;/p&gt;</comment>
                            <comment id="12603764" author="yseeley@gmail.com" created="Tue, 10 Jun 2008 05:03:52 +0100"  >&lt;p&gt;Attaching deletion_policy.patch&lt;br/&gt;
This exports a SolrDeletionPolicy via UpdateHandler.getDeletionPolicy()&lt;/p&gt;

&lt;p&gt;It can be used to get the latest SolrIndexCommit, which lists the files that are part of the commit, and can be used to reserve/lease the commit point for a certain amount of time.  This could be used to enable replication directly out of the index directory and avoid copying on systems like Windows.&lt;/p&gt;

&lt;p&gt;Each SolrIndexCommit has an id, which can be used by a client as a correlation id.  Since a single file can be part of multiple commit points, a replication client should specify what commit point it is copying.  The server can then look up that commit point and extend the lease.&lt;/p&gt;</comment>
                            <comment id="12603766" author="noble.paul" created="Tue, 10 Jun 2008 05:23:28 +0100"  >&lt;p&gt;This can be used for a very optimized index copy.  I shall incorporate this also in the next patch. A few points stand out&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Is it relevant to use this in  a &lt;em&gt;postOptimize&lt;/em&gt;? . I guess not&lt;/li&gt;
	&lt;li&gt;Taking snapshots can serve as a backup . If we adopt &lt;b&gt;this strategy only&lt;/b&gt; users will lose that feature of the existing mechanism.&lt;/li&gt;
	&lt;li&gt;Let us make it configurable for user to choose which strategy he prefers . say &lt;tt&gt;&amp;lt;bool name=&quot;snapshoot&quot;&amp;gt;true&amp;lt;/bool&amp;gt;&lt;/tt&gt; .&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12608660" author="yajunliu" created="Fri, 27 Jun 2008 06:35:20 +0100"  >&lt;p&gt;I&apos;m using Solr to build a search service for my company. From operation or maybe performance point view, we need to use java to replicate index.&lt;/p&gt;

&lt;p&gt;From very high level, my design is similar to what Noble mentioned here. It is like this:&lt;/p&gt;

&lt;p&gt;1) First we have an active master, some standby masters and search slaves. The active master handles crawling data and update index; standby masters are redundant to active master. If active master goes away, one of the standby will become active. Standby masters replicate index from active master to act as backup; search slaves only replicate index from active master.&lt;/p&gt;

&lt;p&gt;2) On active master, there is a index snapshots manager. Whenever there&apos;s an update, it takes a snapshot. On window, it uses copy (I should try fsutil) and on linux it uses hard link..The snapshot manager also clean up old snapshots. From time to time, I still got index corruption when commit update. When that happen, shapshot manager allows us to rollback to previous good snapshot.&lt;/p&gt;

&lt;p&gt;3) On active master, there is a replication server component which listens at a specific port (The reason I did not use http port is I do not use solr as it is. I embed solr in our application server, so go through http would be not very efficient for us). Each standby and slave has replication client component. The following is the protocol between the replication client and server:&lt;br/&gt;
  a) client ping the a directory server for the location of active master&lt;br/&gt;
  b) connect to the active master at the specific port&lt;br/&gt;
  c) handshake: right now just check for version and authentication. in the future, it will negotiate security, compression, etc.&lt;br/&gt;
  d) client sends SNAPSHOT_OPEN command followed by index name. The master could manage multiple indexes. Server sends index_not_found if index does not exist or ok followed by snapshot name of the latest snapshot;&lt;br/&gt;
  e) if the index is found, client compares the timestamp with that of local snapshot. The timestamp of snapshot is derived from snapshot name because part of snapshot name is encoded timestamps. If local is newer, tell the server to close the snapshot; otherwise, ask server for a list of files in the snapshot. If ok, server sends ok op, followed by a file list including filename, timestamp, etc.&lt;br/&gt;
  f) client creates a tmp directory and hard link everything from its local index directory, then for each file in the file list, if it does not exit locally, get new file from server; if it is newer than local one, ask server for update like rsync; if local files do not exist in file list, delete them. in the case of compound file is used for index, the file update will update only diff blocks.&lt;br/&gt;
  g) if everything goes well, tell server to close the snapshot, rename the tmp directory to a proper place, create solr-core using this new index, warmup any cache if necessary, route new request to this solr-core, close old solr-core, remove old index directory.&lt;/p&gt;

&lt;p&gt;Right now a client replicates index from active master every 3 mins. for a slow change datasource. It works fine because create new solr-core and warmup cache take less than 3 mins. We plan to use it for a fast changing datasource, so create new solr-core and dump all the cache is not feasible. Any suggestion? &lt;/p&gt;</comment>
                            <comment id="12608668" author="noble.paul" created="Fri, 27 Jun 2008 07:20:29 +0100"  >&lt;p&gt;bq: First we have an active master, some standby masters and search slaves&lt;/p&gt;

&lt;p&gt;This looks like a good approach. In the current design I must allow users to specify multiple &apos;materUrl&apos; . This must take care of one or more standby masters.  It can automatically fallback to another master if one fails. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;On active master, there is a index snapshots manager. Whenever there&apos;s an update, it takes a snapshot. On window, it uses copy (I should try fsutil) and on linux it uses hard link..The snapshot manager also clean up old snapshots. From time to time, I still got index corruption when commit update. When that happen, shapshot manager allows us to rollback to previous good snapshot.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;How can I know if the index got corrupted? if I can know it the best way to implement that would be to add a command to ReplicationHandler to rollback to latest .&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;On active master, there is a replication server component which listens at a specific port &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;plain socket communication is more work than relying over the simple http protocol .The little extra efficiency you may achieve may not justify that (http is not too solw either). In this case the servlet container provides you with sockets , threads etc etc. Take a look at the patch on how efficiently is it done in the current patch. &lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;client creates a tmp directory and hard link everything from its local index directory, then for each file in the file list, if it does not exit locally, get new file from server; if it is newer than local one, ask server for update like rsync; if local files do not exist in file list, delete them. in the case of compound file is used for index, the file update will update only diff blocks.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The current implementation is more or less like what you have done. For a compound file I am not sure if a diff based sync can be more efficient. Because it is hard to get the similar blocks in the file. I rely on checksums  of whole file. If there is an efficient mechanism to obtain identical blocks, share the code I can incorporate that&lt;br/&gt;
The hardlink approach may be not necessary now as I made the SolrCore not to hardcode the index folder. &lt;/p&gt;





</comment>
                            <comment id="12611989" author="noble.paul" created="Wed, 9 Jul 2008 12:29:46 +0100"  >&lt;p&gt;This patch relies on the IndexDeletionPolicy to identify files to be replicated. It also supports replication of conf files. No need to register any listeners/ QueryResponseWriters&lt;/p&gt;

&lt;p&gt;The configuration is as follows&lt;br/&gt;
on master &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;solrconfig.xml&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&amp;lt;requestHandler name=&lt;span class=&quot;code-quote&quot;&gt;&quot;/replication&quot;&lt;/span&gt; class=&lt;span class=&quot;code-quote&quot;&gt;&quot;solr.ReplicationHandler&quot;&lt;/span&gt; &amp;gt;
    &amp;lt;lst name=&lt;span class=&quot;code-quote&quot;&gt;&quot;master&quot;&lt;/span&gt;&amp;gt;
        &amp;lt;!--Replicate on &apos;optimize&apos; it can also be  &apos;commit&apos; --&amp;gt;
        &amp;lt;str name=&lt;span class=&quot;code-quote&quot;&gt;&quot;replicateAfter&quot;&lt;/span&gt;&amp;gt;commit&amp;lt;/str&amp;gt;
        &amp;lt;!--Config files to be to be replicated--&amp;gt;
         &amp;lt;str name=&lt;span class=&quot;code-quote&quot;&gt;&quot;confFiles&quot;&lt;/span&gt;&amp;gt;schema.xml,stopwords.txt,elevate.xml&amp;lt;/str&amp;gt;          
    &amp;lt;/lst&amp;gt;
&amp;lt;/requestHandler&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;on slave&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;solrconfig.xml&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&amp;lt;requestHandler name=&lt;span class=&quot;code-quote&quot;&gt;&quot;/replication&quot;&lt;/span&gt; class=&lt;span class=&quot;code-quote&quot;&gt;&quot;solr.ReplicationHandler&quot;&lt;/span&gt; &amp;gt;
    &amp;lt;lst name=&lt;span class=&quot;code-quote&quot;&gt;&quot;slave&quot;&lt;/span&gt;&amp;gt;
        &amp;lt;str name=&lt;span class=&quot;code-quote&quot;&gt;&quot;masterUrl&quot;&lt;/span&gt;&amp;gt;http:&lt;span class=&quot;code-comment&quot;&gt;//localhost:port/solr/corename/replication&amp;lt;/str&amp;gt;  
&lt;/span&gt;        &amp;lt;str name=&lt;span class=&quot;code-quote&quot;&gt;&quot;pollInterval&quot;&lt;/span&gt;&amp;gt;00:00:20&amp;lt;/str&amp;gt;  
     &amp;lt;/lst&amp;gt;
&amp;lt;/requestHandler&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The Replication strategy is changed as follows&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;CMD_INDEX_VERSION: (command=indexversion)gets the version of the current &lt;em&gt;IndexCommit&lt;/em&gt; to be replicated from the master. if the version is same, no need to replicate. If it is different&lt;/li&gt;
	&lt;li&gt;CMD_FILE_LIST : (command=filelist)Get the list of file names for the current &lt;em&gt;IndexCommit&lt;/em&gt; . Checks with the local index and identifies modified files by comparing names an sizes. It also returns the details of the conf files&lt;/li&gt;
	&lt;li&gt;CMD-FILE_CONTENT : (command=filecontent)For each files to be downloaded, issue this command an download the content to a temp folder. After successful completion copy them to the index folder  and isse a commit&lt;/li&gt;
	&lt;li&gt;If the current index is stale, or not able to synchronize, copy all the files . An &lt;em&gt;index.properties&lt;/em&gt; file is written, which has the location of the new index directory&lt;/li&gt;
	&lt;li&gt;&lt;em&gt;CoreDescriptor&lt;/em&gt; has a new method to reload core.&lt;/li&gt;
	&lt;li&gt;If conf files are modified they are copied to the conf folder after taking a backup of the old. Then the core is reloaded&lt;/li&gt;
&lt;/ul&gt;






</comment>
                            <comment id="12614146" author="yseeley@gmail.com" created="Thu, 17 Jul 2008 00:13:26 +0100"  >&lt;p&gt;I love how easy this is to set up!&lt;/p&gt;

&lt;p&gt;A couple of issues I noticed while testing:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;it doesn&apos;t seem like old files are being removed on the slave for me... actually I think this is related to the fact that I don&apos;t see old searchers being cleaned up... my slave currently has 4 open - one for each index version.&lt;/li&gt;
	&lt;li&gt;segment_* should be copied last... then if we crash in the middle, everything will work fine... lucene will open the previous index version automatically.&lt;/li&gt;
	&lt;li&gt;since a single index file is likely to be part of multiple indicies, commands from the slave to the master to replicate this file should reference the index version being replicated.  This allows time-based reservation of a specific index commit point.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;What happens when the slave is replicating an index, and some of the files become missing on the master?  Seems like the slave should simply abandon the current replication effort.  Next time the master is polled, the new index version will be discovered and the process can start again as normal.&lt;/p&gt;

&lt;p&gt;What happens if replication takes a really long time?  I assume that no new replications will be kicked off until the current one has finished?&lt;/p&gt;</comment>
                            <comment id="12614215" author="noblepaul" created="Thu, 17 Jul 2008 05:26:32 +0100"  >&lt;p&gt;Thanks.&lt;br/&gt;
I guess Lucene must be cleaning it up because that is what the&lt;br/&gt;
deletion policy says&lt;br/&gt;
Good point. Will incorporate that&lt;br/&gt;
Because the file names are unique it did not matter if I used the&lt;br/&gt;
index version (or does it) . Please clarify&lt;br/&gt;
Yeah . It does that . If all the files are not copied completely it aborts.&lt;br/&gt;
You are right. When the replication process starts , a lock is&lt;br/&gt;
acquired. The lock is released only after the process completes&lt;/p&gt;



&lt;p&gt;&amp;#8211; &lt;br/&gt;
--Noble Paul&lt;/p&gt;</comment>
                            <comment id="12614218" author="yseeley@gmail.com" created="Thu, 17 Jul 2008 05:36:06 +0100"  >&lt;blockquote&gt;&lt;p&gt;it doesn&apos;t seem like old files are being removed on the slave for me... actually I think this is related to the fact that I don&apos;t see old searchers being cleaned up... my slave currently has 4 open - one for each index version.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK, I found the bug that caused this one...&lt;br/&gt;
Line SnapPuller.java:172&lt;br/&gt;
  core.getSearcher().get()....&lt;br/&gt;
That pattern is almost always a bug... getSearcher() returns a RefCounted object that performs the reference counting on the SolrIndexSearcher.  It must be decremented (normally via a finally block).&lt;/p&gt;

&lt;p&gt;Oh... and more internal code comments would be welcome (I don&apos;t know if it&apos;s practical to add them after the fact... I find myself adding them for my own notes/thoughts as I develop).&lt;/p&gt;</comment>
                            <comment id="12614222" author="noble.paul" created="Thu, 17 Jul 2008 05:56:43 +0100"  >&lt;p&gt;Good catch . but it is not obvious that the refCount was incremented . Should we not have a method to return the searcher without&lt;br/&gt;
incrementing the refcount ? something like &lt;em&gt;SolrCore#getSearcherNoIncRef()&lt;/em&gt;&lt;br/&gt;
Anyone who is not using the IndexSearcher for searching will need that&lt;/p&gt;</comment>
                            <comment id="12614228" author="yseeley@gmail.com" created="Thu, 17 Jul 2008 06:25:33 +0100"  >&lt;blockquote&gt;&lt;p&gt;Because the file names are unique it did not matter if I used the index version (or does it).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, file names are unique since Lucene doesn&apos;t change existing files once they are written.  But, if I completely delete an index and start again, the same file name would be reused with different contents (and a different timestamp).&lt;/p&gt;

&lt;p&gt;But that&apos;s not the point I was trying to make...&lt;br/&gt;
If someone is replicating an older IndexCommit, then we want to extend the lease on it.  In order to do that, we need to know what IndexCommit the client is replicating.  The file name is not enough as a single file is normally part of more than one IndexCommit.&lt;/p&gt;</comment>
                            <comment id="12614230" author="noble.paul" created="Thu, 17 Jul 2008 06:49:48 +0100"  >&lt;blockquote&gt;&lt;p&gt;If someone is replicating an older IndexCommit, then we want to extend the lease on it. In order to do that, we need to know what IndexCommit the client is replicating. The file name is not enough as a single file is normally part of more than one IndexCommit.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Got the point. I assumed that the &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-617&quot; title=&quot;Allow configurable deletion policy&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-617&quot;&gt;&lt;del&gt;SOLR-617&lt;/del&gt;&lt;/a&gt; should have enough features to make people configure that. &lt;/p&gt;

&lt;p&gt;It is hard to drive it from the replication handler. The lease can be extended only when we get the onInit() onCommit() callback on &lt;em&gt;SolrIndexDeletionPolicy&lt;/em&gt;. We can&apos;t reliably expect it to happen during the time of downloading&lt;/p&gt;</comment>
                            <comment id="12614249" author="gsmet" created="Thu, 17 Jul 2008 07:56:17 +0100"  >&lt;p&gt;I read the patch quickly. I noticed a small typo in SnapPuller.DFAULT_CHUNK_SIZE (should be DEFAULT).&lt;/p&gt;

&lt;p&gt;I like the idea of configuration files replication (yeah, no more scp schema.xml everywhere).&lt;/p&gt;

&lt;p&gt;I usually replicate on optimize only but I wonder if people use the current ability to replicate on commit &lt;b&gt;and&lt;/b&gt; on optimize. It doesn&apos;t seem to be possible with your current patch.&lt;/p&gt;

&lt;p&gt;Anyway, really nice work.&lt;/p&gt;</comment>
                            <comment id="12614267" author="noble.paul" created="Thu, 17 Jul 2008 08:35:47 +0100"  >&lt;blockquote&gt;&lt;p&gt;I usually replicate on optimize only but I wonder if people use the current ability to replicate on commit and on optimize. It doesn&apos;t seem to be possible with your current patch.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;technically it is possible just add two entries for &lt;em&gt;replicateAfter&lt;/em&gt;. The code is not handling it because &lt;em&gt;NamedList&lt;/em&gt; did not have a &lt;em&gt;getAll()&lt;/em&gt; method at that time. The next patch will take care of it&lt;/p&gt;</comment>
                            <comment id="12614276" author="gsmet" created="Thu, 17 Jul 2008 10:04:52 +0100"  >&lt;blockquote&gt;&lt;p&gt;The next patch will take care of it&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Nice.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Noble Paul@06/Jun/08 09:59 AM&amp;gt; It&apos;s easy to implement with a wild card . But , very few files need to be replicated .Isn&apos;t it better to explicitly mention the names so that no file accidentally gets replicated.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m thinking of a use case: if you have a lot of synonym/stopwords dictionaries for different languages and field types, it might be a bit awkward to specify each file. A synonyms_&amp;#42;.txt, stopwords_&amp;#42;.txt would be welcome.&lt;/p&gt;

&lt;p&gt;Furthermore, I wonder if we shouldn&apos;t disable explicitely the replication of solrconfig.xml. Any opinion?&lt;/p&gt;</comment>
                            <comment id="12614336" author="shalinmangar" created="Thu, 17 Jul 2008 14:51:00 +0100"  >&lt;p&gt;Replication can be disabled by not registering the handler in solrconfig.xml and an HTTP API call should be added to disable replication on master/slave.&lt;/p&gt;</comment>
                            <comment id="12614348" author="yseeley@gmail.com" created="Thu, 17 Jul 2008 15:12:29 +0100"  >&lt;p&gt;Could you guys pull out all the changes to MultiCore, CoreDescriptor, SolrCore, etc (everything not related to replication) into a separate patch.  I think that will help things get committed.  Ryan also has a need to get the MultiCore and I think perhaps a getMultiCore() should just be added to the CoreDescriptor.&lt;/p&gt;</comment>
                            <comment id="12614374" author="shalinmangar" created="Thu, 17 Jul 2008 15:53:31 +0100"  >&lt;p&gt;Sure Yonik, we shall separate the changes in core classes into separate issues.&lt;/p&gt;</comment>
                            <comment id="12614378" author="noble.paul" created="Thu, 17 Jul 2008 16:00:17 +0100"  >&lt;p&gt;Actually there are a handful of other HTTP methods which can be invoked over HTTP. These can be used to control the feature from admin interface&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Abort copying snap from master to slave&lt;br/&gt;
&lt;tt&gt;command : &lt;a href=&quot;http://slave_host:port/solr/replication?command=abortsnappull&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://slave_host:port/solr/replication?command=abortsnappull&lt;/a&gt;&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;Force a snapshot on master&lt;br/&gt;
&lt;tt&gt;command : &lt;a href=&quot;http://master_host:port/solr/replication?command=snapshoot&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://master_host:port/solr/replication?command=snapshoot&lt;/a&gt;&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;Force a snap pull on slave from master&lt;br/&gt;
&lt;tt&gt;command : &lt;a href=&quot;http://slave_host:port/solr/replication?command=snappull&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://slave_host:port/solr/replication?command=snappull&lt;/a&gt;&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;Disable polling for snapshot from slave&lt;br/&gt;
&lt;tt&gt;ommand : &lt;a href=&quot;http://slave_host:port/solr/replication?command=disablepoll&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://slave_host:port/solr/replication?command=disablepoll&lt;/a&gt;&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;Enable polling for snapshot from slave&lt;br/&gt;
&lt;tt&gt;command : &lt;a href=&quot;http://slave_host:port/solr/replication?command=enablepoll&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://slave_host:port/solr/replication?command=enablepoll&lt;/a&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;

</comment>
                            <comment id="12614379" author="noble.paul" created="Thu, 17 Jul 2008 16:04:40 +0100"  >&lt;p&gt;Just the changes required to the core&lt;/p&gt;</comment>
                            <comment id="12614380" author="noble.paul" created="Thu, 17 Jul 2008 16:06:14 +0100"  >&lt;p&gt;new patch that takes care of the refcount. this is a complete patch &lt;/p&gt;</comment>
                            <comment id="12614760" author="ryantxu" created="Fri, 18 Jul 2008 16:35:32 +0100"  >&lt;p&gt;I just committed &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-638&quot; title=&quot;Enable access to MultiCore from SolrCore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-638&quot;&gt;&lt;del&gt;SOLR-638&lt;/del&gt;&lt;/a&gt; &amp;#8211; I think this patch depends on that&lt;/p&gt;</comment>
                            <comment id="12615169" author="noble.paul" created="Mon, 21 Jul 2008 10:08:09 +0100"  >&lt;p&gt;This patch is to &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;sync with the trunk (&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-638&quot; title=&quot;Enable access to MultiCore from SolrCore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-638&quot;&gt;&lt;del&gt;SOLR-638&lt;/del&gt;&lt;/a&gt; changes)&lt;/li&gt;
	&lt;li&gt;uses java1.4 &lt;em&gt;ScheduledExcecutorService&lt;/em&gt; instead of timer&lt;/li&gt;
	&lt;li&gt;&lt;em&gt;SolrCore.close()&lt;/em&gt; is done in a refcounted way&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12615241" author="yseeley@gmail.com" created="Mon, 21 Jul 2008 14:30:30 +0100"  >&lt;p&gt;I haven&apos;t had a chance to check out the latest patch, but it sounds like &quot;SolrCore.close() is done in a refcounted way&quot; is a generic multi-core change that is potentially sticky enough that it deserves it&apos;s own JIRA issue.&lt;/p&gt;</comment>
                            <comment id="12615256" author="noble.paul" created="Mon, 21 Jul 2008 15:27:59 +0100"  >&lt;p&gt;Yes , we may need another issue to track it. Directly calling &lt;em&gt;Solr.close()&lt;/em&gt;   can cause exceptions on in-flight requests&lt;/p&gt;</comment>
                            <comment id="12615953" author="noble.paul" created="Wed, 23 Jul 2008 11:59:11 +0100"  >&lt;p&gt;The core reload functionality has to close the old core .&lt;/p&gt;</comment>
                            <comment id="12618735" author="otis" created="Thu, 31 Jul 2008 16:58:11 +0100"  >&lt;p&gt;Comment about the solrconfig entry for replication on the &lt;b&gt;master&lt;/b&gt;:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt;

&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;requestHandler name=&lt;span class=&quot;code-quote&quot;&gt;&quot;/replication&quot;&lt;/span&gt; class=&lt;span class=&quot;code-quote&quot;&gt;&quot;solr.ReplicationHandler&quot;&lt;/span&gt; &amp;gt;&lt;/span&gt;
    &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;lst name=&lt;span class=&quot;code-quote&quot;&gt;&quot;master&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;code-tag&quot;&gt;&lt;span class=&quot;code-comment&quot;&gt;&amp;lt;!--Replicate on &apos;optimize&apos; it can also be  &apos;commit&apos; --&amp;gt;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;str name=&lt;span class=&quot;code-quote&quot;&gt;&quot;replicateAfter&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;commit&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;
         &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;str name=&lt;span class=&quot;code-quote&quot;&gt;&quot;confFiles&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;schema.xml,stopwords.txt,elevate.xml&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;          
    &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/lst&amp;gt;&lt;/span&gt;
&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/requestHandler&amp;gt;&lt;/span&gt;

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;Reading the above makes one think that it is the master that &lt;b&gt;does&lt;/b&gt; the actual replication.  In fact, the master only creates a snapshot of the index and other files after either commit or optimize.  It is the slaves that copy the snapshots.  So while we refer to the whole process as replication, I think the configuration elements&apos; names should reflect the actual actions to ease understanding and avoid confusion.&lt;/p&gt;

&lt;p&gt;Concretely, I think &quot;replicateAfter&quot; should be called &quot;snapshootAfter&quot; or some such.&lt;/p&gt;

&lt;p&gt;+1 for Hoss&apos; suggestion to decouple scheduling from the handler that can replicate/copy on-demand&lt;br/&gt;
+1 for Shalin&apos;s suggestion to expose an HTTP interface to enable/disable snapshooting on masters and copying/replication on slaves.&lt;/p&gt;</comment>
                            <comment id="12618775" author="noble.paul" created="Thu, 31 Jul 2008 18:49:28 +0100"  >&lt;blockquote&gt;&lt;p&gt;Reading the above makes one think that it is the master that does the actual replication. In fact, the master only creates a snapshot of the index &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The new replication does not create snapshots for replication. The replication is done from/to a live index. Hence the change in name&lt;/p&gt;</comment>
                            <comment id="12626079" author="shalinmangar" created="Wed, 27 Aug 2008 12:23:11 +0100"  >&lt;p&gt;This patch contains only replication related changes. It depends on &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-658&quot; title=&quot;Allow Solr to load index from arbitrary directory in dataDir&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-658&quot;&gt;&lt;del&gt;SOLR-658&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-617&quot; title=&quot;Allow configurable deletion policy&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-617&quot;&gt;&lt;del&gt;SOLR-617&lt;/del&gt;&lt;/a&gt; and must be applied after the patches in those issues.&lt;/p&gt;</comment>
                            <comment id="12626080" author="shalinmangar" created="Wed, 27 Aug 2008 12:28:10 +0100"  >&lt;p&gt;This patch contains all the replication related changes as well as changes in Solr itself. It contains the changes in &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-617&quot; title=&quot;Allow configurable deletion policy&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-617&quot;&gt;&lt;del&gt;SOLR-617&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-658&quot; title=&quot;Allow Solr to load index from arbitrary directory in dataDir&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-658&quot;&gt;&lt;del&gt;SOLR-658&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Un-tested version. I just compiled all the various patches and brought them up to trunk.&lt;/p&gt;</comment>
                            <comment id="12629123" author="akshay" created="Mon, 8 Sep 2008 11:46:19 +0100"  >&lt;p&gt;Patch in sync with the trunk, includes changes for &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-617&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;SOLR-617&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-658&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;SOLR-658&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="12630559" author="akshay" created="Fri, 12 Sep 2008 13:39:51 +0100"  >&lt;p&gt;Full patch with:&lt;br/&gt;
1. Support for reserving commit point. Configurable with commitReserveDuration configuration in ReplicationHandler section.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt;
&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;requestHandler name=&lt;span class=&quot;code-quote&quot;&gt;&quot;/replication&quot;&lt;/span&gt; class=&lt;span class=&quot;code-quote&quot;&gt;&quot;solr.ReplicationHandler&quot;&lt;/span&gt; &amp;gt;&lt;/span&gt;
    &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;lst name=&lt;span class=&quot;code-quote&quot;&gt;&quot;master&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;str name=&lt;span class=&quot;code-quote&quot;&gt;&quot;replicateAfter&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;commit&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;
         &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;str name=&lt;span class=&quot;code-quote&quot;&gt;&quot;confFiles&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;schema.xml,stopwords.txt,elevate.xml&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;
		 &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;str name=&lt;span class=&quot;code-quote&quot;&gt;&quot;commitReserveDuration&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;01:00:00&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/lst&amp;gt;&lt;/span&gt;
&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/requestHandler&amp;gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;2. Admin page for displaying replication details.&lt;br/&gt;
3. Combines changes for SOLR 617 and SOLR 658.&lt;/p&gt;</comment>
                            <comment id="12638511" author="akshay" created="Fri, 10 Oct 2008 10:02:52 +0100"  >&lt;p&gt;Patch includes changes for &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-658&quot; title=&quot;Allow Solr to load index from arbitrary directory in dataDir&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-658&quot;&gt;&lt;del&gt;SOLR-658&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-561&quot; title=&quot;Solr replication by Solr (for windows also)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-561&quot;&gt;&lt;del&gt;SOLR-561&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
Changes:&lt;br/&gt;
Abort command implementation in ReplicationHandler to abort ongoing replication.&lt;br/&gt;
More information displayed in the replication admin page, such as file being copied, time elapsed, time remaining, size of file downloaded and so on.&lt;/p&gt;</comment>
                            <comment id="12639406" author="yseeley@gmail.com" created="Tue, 14 Oct 2008 14:02:31 +0100"  >&lt;p&gt;Why are files downloaded to a temp directory first?  Since all index files are versioned, would it make sense to copy directly into the index dir (provided you copy segments_n last)?&lt;/p&gt;</comment>
                            <comment id="12639465" author="noble.paul" created="Tue, 14 Oct 2008 17:00:32 +0100"  >&lt;blockquote&gt;&lt;p&gt;Why are files downloaded to a temp directory first? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;If Solr crashes while downloading that will leave unnecessary/incomplete files in the index directory. We did not want the index directory to be polluted. The files are &apos;moved&apos; to index directory after they are downloaded . &lt;/p&gt;

&lt;p&gt;The segments_n file is copied in the end. from temp directory to index directory. &lt;br/&gt;
(OK , that patch is coming &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; )&lt;/p&gt;</comment>
                            <comment id="12639493" author="yseeley@gmail.com" created="Tue, 14 Oct 2008 18:05:15 +0100"  >&lt;blockquote&gt;&lt;p&gt;If Solr crashes while downloading that will leave unnecessary/incomplete files in the index directory.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If we don&apos;t want to try and pick up from where we left off, it seems like Lucene&apos;s deletion policy can clean up old index files that are unreferenced.&lt;/p&gt;
</comment>
                            <comment id="12639518" author="noble.paul" created="Tue, 14 Oct 2008 19:06:02 +0100"  >&lt;p&gt;If the files are not part of any indexcommit (this is true if the segments_n file didn&apos;t get downloaded) will it still clean it up?.  And when solr restarts ReplicationHandler will have difficulty in cleaning up those files if replication kicks off before Lucene cleans it up (If it actually does that)&lt;/p&gt;
</comment>
                            <comment id="12640119" author="akshay" created="Thu, 16 Oct 2008 10:53:26 +0100"  >&lt;p&gt;Patch with following changes:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;segments_ file moved in the end.&lt;/li&gt;
	&lt;li&gt;Some minor changes in replication admin page&lt;/li&gt;
	&lt;li&gt;Test case for index and config files replication.&lt;/li&gt;
	&lt;li&gt;Some minor bug fixes.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="12640450" author="shalinmangar" created="Fri, 17 Oct 2008 07:22:46 +0100"  >&lt;p&gt;Thanks Akshay.&lt;/p&gt;

&lt;p&gt;On a first glance, this is looking really good. I am planning to commit this in a few days. We can take up the enhancements or bug fixes through new issues.&lt;/p&gt;</comment>
                            <comment id="12640939" author="shalinmangar" created="Mon, 20 Oct 2008 08:06:32 +0100"  >&lt;p&gt;Updated patch with a couple of bug fixes related to closing connections and refcounted index searcher. Other cosmetic changes include code formatting and javadocs.&lt;/p&gt;

&lt;p&gt;Noble has put up a wiki page at &lt;a href=&quot;http://wiki.apache.org/solr/SolrReplication&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/solr/SolrReplication&lt;/a&gt; detailing the features and configuration.&lt;/p&gt;</comment>
                            <comment id="12640976" author="akshay" created="Mon, 20 Oct 2008 12:06:23 +0100"  >&lt;p&gt;Patch with minor fixes related to the admin page.&lt;/p&gt;</comment>
                            <comment id="12640999" author="shalinmangar" created="Mon, 20 Oct 2008 13:52:35 +0100"  >&lt;p&gt;Another iteration over Akshay&apos;s patch.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Made the collections used for keeping statistics synchronized to avoid concurrent modification exceptions.&lt;/li&gt;
	&lt;li&gt;Removed @author tags and put @version and @since 1.4 tags&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="12641295" author="akshay" created="Tue, 21 Oct 2008 07:57:12 +0100"  >&lt;p&gt;Again a minor fix in replication admin page&lt;/p&gt;</comment>
                            <comment id="12641321" author="shalinmangar" created="Tue, 21 Oct 2008 10:45:22 +0100"  >&lt;p&gt;Committed revision 706565.&lt;/p&gt;

&lt;p&gt;Thanks Noble, Yonik and Akshay!&lt;/p&gt;</comment>
                            <comment id="12641412" author="yseeley@gmail.com" created="Tue, 21 Oct 2008 16:43:39 +0100"  >&lt;p&gt;Snappuller should use getNewestSearcher() rather than getSearcher() to avoid pulling the same snapshot more than once if warming takes a long time.&lt;/p&gt;</comment>
                            <comment id="12641418" author="yseeley@gmail.com" created="Tue, 21 Oct 2008 17:06:26 +0100"  >&lt;p&gt;I didn&apos;t catch earlier how reservations were done: currently, the commit point is reserved for a certain time when the file list is initially fetched.  This requires that the user estimate how long a snap pull will last, and if they get it wrong things will fail.  On the other side, setting the time high requires more free disk space.&lt;/p&gt;

&lt;p&gt;It seems like renewing a lease (a short term reservation) whenever an access is done would solve both of these problems (and is what I initially had in mind).  All requests should indicate what commit point is being copied so that the lease can be extended.&lt;/p&gt;</comment>
                            <comment id="12641436" author="yseeley@gmail.com" created="Tue, 21 Oct 2008 18:03:18 +0100"  >&lt;p&gt;Files are downloaded in one HTTP request... the response is read and written one chunk at a time.  Has anyone tested this with a large files (say 5G or more) to ensure that:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the response is correctly streamed (not buffered) as it is written to the socket?&lt;/li&gt;
	&lt;li&gt;the servlet container can handle sending responses of that size&lt;/li&gt;
	&lt;li&gt;the servlet container won&apos;t time out (test big file over slow connection)&lt;/li&gt;
	&lt;li&gt;the client side (HTTPClient) doesn&apos;t buffer the response, can handle the big size, and won&apos;t time out.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The first 3 go through servlet container code and thus should probably be tested with tomcat, jetty, and resin.&lt;/p&gt;</comment>
                            <comment id="12641467" author="noble.paul" created="Tue, 21 Oct 2008 19:22:18 +0100"  >&lt;ul&gt;
	&lt;li&gt;we did extensive testing with very large index around 7GB with retries also (for failed connections)&lt;/li&gt;
	&lt;li&gt;Test was conducted on both on jetty and tomcat&lt;/li&gt;
	&lt;li&gt;Performance of new replication~= rsync based replication. The replication speed is largely network IO bound&lt;/li&gt;
&lt;/ul&gt;


&lt;blockquote&gt;&lt;p&gt;the servlet container can handle sending responses of that size&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The servlet container usually have a small chunk size by default(~8KB(in tomcat). It keeps flushing the stream after that size is crossed.&lt;/p&gt;


</comment>
                            <comment id="12641468" author="noble.paul" created="Tue, 21 Oct 2008 19:27:19 +0100"  >&lt;blockquote&gt;&lt;p&gt;All requests should indicate what commit point is being copied so that the lease can be extended.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is a good idea . But when the index is large it tends to have 1 very large file and a few other smaller files. It is that very large file that takes a lot of time(In our case a 6GB file across data centers took around 2 hrs) So we may also need to do call reserve even while download is going on.&lt;/p&gt;</comment>
                            <comment id="12641495" author="shalinmangar" created="Tue, 21 Oct 2008 19:49:05 +0100"  >&lt;p&gt;Thanks for going through this Yonik.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Snappuller should use getNewestSearcher() rather than getSearcher() to avoid pulling the same snapshot more than once if warming takes a long time.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The SnapPuller calls commit with waitSearcher=true, so the call will wait for the searcher to get registered and warmed. The reentrant lock in SnapPuller will be released only after the commit call returns. So it should be OK, right?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It seems like renewing a lease (a short term reservation) whenever an access is done would solve both of these problems (and is what I initially had in mind). All requests should indicate what commit point is being copied so that the lease can be extended.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Since files are transferred in one go, the master knows about the access time but it does not know if the transfer has ended so the lease may expire in between the transfer leading to a failure. We&apos;ll need to track the transfers individually as well. If the slave dies in between the transfer, we&apos;ll need to track that as well and time-out the lease appropriately. If I compare the state of things to the old way of replication, not sure if this feature is worth the effort. What do you think?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Has anyone tested this with a large files (say 5G or more)...&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We have been testing it with a large index (wikipedia articles, around 7-8GB index on disk) with Tomcat across networks (transfer rate between servers is around 700-800 KB/sec). We haven&apos;t seen any problem yet. We&apos;ll continue to test this with Tomcat and other containers and report performance numbers and problems, if any.&lt;/p&gt;</comment>
                            <comment id="12641543" author="yseeley@gmail.com" created="Tue, 21 Oct 2008 20:16:11 +0100"  >&lt;blockquote&gt;&lt;p&gt;The SnapPuller calls commit with waitSearcher=true, so the call will wait for the searcher to get registered and warmed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;A commit could come from somewhere else though, or we could be starting up and no searcher is yet registered.  It&apos;s always safe (and clearer) to just use the newest reader opened, right?&lt;/p&gt;

&lt;p&gt;Is there a reason that SnapPuller waits for the new searcher to be registered?&lt;br/&gt;
If not, I&apos;ll change this... I&apos;m currently creating a patch with some little thread-safety fixes.&lt;/p&gt;</comment>
                            <comment id="12641550" author="yseeley@gmail.com" created="Tue, 21 Oct 2008 20:30:12 +0100"  >&lt;blockquote&gt;&lt;p&gt;Since files are transferred in one go, the master knows about the access time but it does not know if the transfer has ended so the lease may expire in between the transfer leading to a failure.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, as Noble pointed out, lease extension will need to be done periodically during the download (every N blocks written to the socket).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We&apos;ll need to track the transfers individually as well.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Each file request can optionally specify the commit point it is copying.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If the slave dies in between the transfer, we&apos;ll need to track that as well and time-out the lease appropriately.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The lease is just the current reservation mechanism, but called more often and with a very short reservation (on the order of seconds, not minutes I would think), so I don&apos;t see a need to time them out.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We have been testing it with a large index (wikipedia articles, around 7-8GB index on disk)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Cool.  Hopefully one of the test indexes contain a single file greater than 4G to test that we don&apos;t hit any 32 bit overflow in the stack.  If not, re-doing your wikipedia test with compound index format and after an optimize should do the trick.&lt;/p&gt;</comment>
                            <comment id="12641712" author="akshay" created="Wed, 22 Oct 2008 05:26:30 +0100"  >&lt;blockquote&gt;&lt;p&gt;Cool. Hopefully one of the test indexes contain a single file greater than 4G to test that we don&apos;t hit any 32 bit overflow in the stack. If not, re-doing your wikipedia test with compound index format and after an optimize should do the trick.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, one of the files in the index is of size 6.3G, created on optimize.&lt;/p&gt;</comment>
                            <comment id="12641713" author="noble.paul" created="Wed, 22 Oct 2008 05:30:21 +0100"  >&lt;p&gt;patch contains changes for reserve being set for 10secs by default after  every 5 packets (5 MB) are written.&lt;/p&gt;

&lt;p&gt;The commitReserveDuration is now supposed to be a small value (default is 10 secs). If the network is particularly slow user can tweak it to set a bigger number.&lt;/p&gt;

&lt;p&gt;every command for fetching file content has an extra attribute indexversion , so that the master now knows which IndexCommit is being downloaded.&lt;/p&gt;</comment>
                            <comment id="12641976" author="yseeley@gmail.com" created="Wed, 22 Oct 2008 22:50:34 +0100"  >&lt;p&gt;Thanks Noble, reviewing now...&lt;/p&gt;</comment>
                            <comment id="12642026" author="yseeley@gmail.com" created="Thu, 23 Oct 2008 02:00:36 +0100"  >&lt;p&gt;Committed with 2 changes:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;getSearcher() isn&apos;t allowed in inform() so I changed to getNewestSearcher()&lt;/li&gt;
	&lt;li&gt;changed cleanReserves() to not collect ids to delete in a separate list (not needed for ConcurrentHashMap)&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12642050" author="noble.paul" created="Thu, 23 Oct 2008 05:24:09 +0100"  >&lt;p&gt;silly me. The packetsWriitten variable was not incremented&lt;/p&gt;</comment>
                            <comment id="12642204" author="yseeley@gmail.com" created="Thu, 23 Oct 2008 18:12:21 +0100"  >&lt;p&gt;Attaching some little thread safety fixes (mostly adding volatile to values modified and read from different threads).&lt;/p&gt;</comment>
                            <comment id="12642215" author="yseeley@gmail.com" created="Thu, 23 Oct 2008 18:54:18 +0100"  >&lt;p&gt;Updated the fixes patch with more thread safety fixes.&lt;/p&gt;

&lt;p&gt;Q: what is ReplicationHandler.getIndexVersion() supposed to return, and why?  It currently returns the version of the visible index (registered).  Should it be the most recent version of the index we have?  Any reason it isn&apos;t using ReplicationHandler.indexCommitPoint?&lt;/p&gt;

&lt;p&gt;Also, I think we should all work at adding more comments to code as it is written.  Lack of comments made this patch harder to review.&lt;/p&gt;</comment>
                            <comment id="12642217" author="yseeley@gmail.com" created="Thu, 23 Oct 2008 19:06:56 +0100"  >&lt;p&gt;I think there&apos;s an issue with SnapShooter in that it never does any reservations for the commit point it&apos;s trying to copy.&lt;/p&gt;</comment>
                            <comment id="12642359" author="yseeley@gmail.com" created="Fri, 24 Oct 2008 02:15:57 +0100"  >&lt;p&gt;Here&apos;s an update to the &quot;fixes&quot; patch that fixes an issue with setReserveDuration when called with different reserveTimes.  Previously, the new value overwrites the old, regardless of it&apos;s value.  The approach to fix is a basic spin loop (see below).  Anyone see issues with this approach?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void setReserveDuration(&lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; indexVersion, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; reserveTime) {
    &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; timeToSet = &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis() + reserveTime;
    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;(;;) {
      &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; previousTime = reserves.put(indexVersion, timeToSet);

      &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; is the common success &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt;: the older time didn&apos;t exist, or
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// came before the &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; time.
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (previousTime == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; || previousTime &amp;lt;= timeToSet) &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt;;

      &lt;span class=&quot;code-comment&quot;&gt;// At &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; point, we overwrote a longer reservation, so we want to restore the older one.
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// the problem is that an even longer reservation may come in concurrently
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// and we don&apos;t want to overwrite that one too.  We simply keep retrying in a loop
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// with the maximum time value we have seen.
&lt;/span&gt;      timeToSet = previousTime;      
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think this is also a great example of where comments explaining how things work are really needed.&lt;/p&gt;</comment>
                            <comment id="12642380" author="noble.paul" created="Fri, 24 Oct 2008 06:06:51 +0100"  >&lt;blockquote&gt;&lt;p&gt;what is ReplicationHandler.getIndexVersion() supposed to return, and why?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is the method called by the slaves. they must only see the current &quot;replicatable&quot; index version. For instance, if the &apos;replicateAfter&apos; is set to &apos;optimize&apos; then the slave should not see the index version that is a commit.&lt;/p&gt;

&lt;p&gt;The getDetails() ( command=details) method gives the actual current index version&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think there&apos;s an issue with SnapShooter in that it never does any reservations for the commit point it&apos;s trying to copy. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;right, Snaphsooter has to reserve.&lt;/p&gt;

&lt;p&gt;The new setReserveDuration() looks right. &lt;/p&gt;
</comment>
                            <comment id="12642389" author="noble.paul" created="Fri, 24 Oct 2008 07:31:58 +0100"  >&lt;p&gt;The SnapShooter is not written right (thread safety). soon after you commit the patch , I can give a patch . After I fix it I can update the wiki w/ proper documentation. &lt;/p&gt;

&lt;p&gt;Snapshoot is not a very important feature in  the current scheme of things. It is useful only if somebody wants to do periodic backups&lt;/p&gt;

&lt;p&gt;Should we try OS specific copy? &lt;br/&gt;
Hardlinks can be used in *nix and Windows can also do hardlinks if fsutils is present. If not ,we can do a proper copy&lt;/p&gt;</comment>
                            <comment id="12642449" author="noble.paul" created="Fri, 24 Oct 2008 12:48:11 +0100"  >&lt;p&gt;Yonik. If you can commit this patch I can give a patch with comments . The code badly needs some comments. &lt;/p&gt;</comment>
                            <comment id="12643172" author="noble.paul" created="Tue, 28 Oct 2008 09:57:55 +0000"  >&lt;p&gt;comments only&lt;/p&gt;</comment>
                            <comment id="12643214" author="yseeley@gmail.com" created="Tue, 28 Oct 2008 14:07:28 +0000"  >&lt;p&gt;Comments committed. Thanks!&lt;/p&gt;</comment>
                            <comment id="12645632" author="peger@automotive.com" created="Fri, 7 Nov 2008 00:17:49 +0000"  >&lt;p&gt;Hi, i have a couple comments about the implementation, specifically SnapShooter.java just pulled from TRUNK:&lt;/p&gt;

&lt;p&gt;-------------------------------------&lt;br/&gt;
createSnapshot() uses the following pattern, which seems unreliable to me, under the prospect of concurrent snapshot requests: &lt;/p&gt;

&lt;p&gt;lockFile = new File(snapDir, directoryName + &quot;.lock&quot;);&lt;br/&gt;
      if (lockFile.exists()) &lt;/p&gt;
{
        return;
      }

&lt;p&gt;... &amp;lt;1&amp;gt; ...&lt;/p&gt;

&lt;p&gt;lockFile.createNewFile();&lt;/p&gt;

&lt;p&gt;... &amp;lt;2&amp;gt; ...&lt;/p&gt;

&lt;p&gt;if (lockFile != null) &lt;/p&gt;
{
        lockFile.delete();
      }

&lt;p&gt;AFAIK, java.nio.channels.FileLock should be used for any type of file-based locking of the sort for cross-vm synchronization. If you are worried about in-vm synchronization, it might be best to just use j.u.c Locks or synchronized{} blocks. This would remove the possiblity of junk .lock files if, say the VM dies during &amp;lt;2&amp;gt;.&lt;/p&gt;

&lt;p&gt;-------------------------------------&lt;br/&gt;
Additionally, these lines seem suspect to me. transferTo() needs to be done in a loop for the full copy to work. &lt;/p&gt;

&lt;p&gt;      fis = new FileInputStream(file);&lt;br/&gt;
      File destFile = new File(toDir, file.getName());&lt;br/&gt;
      fos = new FileOutputStream(destFile);&lt;br/&gt;
      fis.getChannel().transferTo(0, fis.available(), fos.getChannel());&lt;br/&gt;
      destFile.setLastModified(file.lastModified());&lt;/p&gt;



&lt;p&gt;Am i crazy or are these real problems?&lt;/p&gt;</comment>
                            <comment id="12645647" author="yseeley@gmail.com" created="Fri, 7 Nov 2008 00:57:23 +0000"  >&lt;blockquote&gt;&lt;p&gt;Am i crazy or are these real problems?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, as Noble &amp;amp; I noted, there are still known problems with SnapShooter.  Luckily, it&apos;s not necessary in the current replication scheme which no longer relies on snapshots.&lt;/p&gt;</comment>
                            <comment id="12645650" author="peger@automotive.com" created="Fri, 7 Nov 2008 01:01:54 +0000"  >&lt;p&gt;Gotcha, i will focus efforts elsewhere then &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12645677" author="noblepaul" created="Fri, 7 Nov 2008 03:40:46 +0000"  >&lt;p&gt;We need to cleanup the SnapShooter. it was given low priority because&lt;br/&gt;
snapshoot is not at all necessary in the new replication&lt;br/&gt;
implementation. It is only useful for periodic backups&lt;/p&gt;




&lt;p&gt;&amp;#8211; &lt;br/&gt;
--Noble Paul&lt;/p&gt;</comment>
                            <comment id="12646968" author="otis" created="Wed, 12 Nov 2008 17:38:54 +0000"  >&lt;p&gt;I wonder if it might be useful to add copy throttle support to the replication.  See &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-849&quot; title=&quot;Add bwlimit support to snappuller&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-849&quot;&gt;&lt;del&gt;SOLR-849&lt;/del&gt;&lt;/a&gt; and the referenced email thread.&lt;/p&gt;</comment>
                            <comment id="12755894" author="billnbell" created="Wed, 16 Sep 2009 07:06:59 +0100"  >&lt;p&gt;I am not a huge fan of PollInterval. It would be great to add an option to get the Index based on exact time: PollTime=&quot;*/15 * * * *&quot; That would run at every 15 minutes based on the clock. i.e. 1:00pm, 1:15pm, 1:30pm, 1:45pm, etc.  All my slaves are sync&apos;d using NTP, so this would work better. Since each slave starts differently, we cannot set the PollInterval=&quot;00:15:00&quot; since they would get different indexes based on when they start. The other option would be to suspend polling - and start - which would be very manual I guess. Setting the PollInterval to 10 seconds would be getting a new index when the old one is still warming up. Even 10 seconds interval would not be good, since we get so many updates, each server would have different indexes. With Snap we don&apos;t have this issue.&lt;/p&gt;

&lt;p&gt;We get SOLR updates frequently and since they are large we cannot wait to do a commit at the 15 minute mark using cron. Optimize just takes too long.&lt;/p&gt;

&lt;p&gt;On our system we need to limit how often the slaves get the new index. We would like all slaves to get the index at the same time.&lt;/p&gt;

&lt;p&gt;Bill&lt;/p&gt;</comment>
                            <comment id="12755908" author="noble.paul" created="Wed, 16 Sep 2009 07:50:26 +0100"  >&lt;p&gt;The default pollInterval can behave the vway you want (so that the fetches are synchronized in time by the clock). Raise a separate issue and we can fix it&lt;/p&gt;</comment>
                            <comment id="12769584" author="koji" created="Sat, 24 Oct 2009 05:54:08 +0100"  >&lt;p&gt;change component from scripts to java&lt;/p&gt;</comment>
                            <comment id="12775510" author="gsingers" created="Tue, 10 Nov 2009 15:51:42 +0000"  >&lt;p&gt;Bulk close for Solr 1.4&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12400990">SOLR-658</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                            <outwardlinks description="incorporates">
                                        <issuelink>
            <issuekey id="12394773">SOLR-551</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12375335">SOLR-327</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12407422">SOLR-829</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12406913">SOLR-821</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12408257">SOLR-847</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12403052">SOLR-727</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12435904">SOLR-1439</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12406911">SOLR-820</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12400811">SOLR-647</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12399693">SOLR-617</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12399105">SOLR-605</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12400474">SOLR-638</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12386307" name="SOLR-561-core.patch" size="32937" author="noble.paul" created="Thu, 17 Jul 2008 16:04:40 +0100"/>
                            <attachment id="12392764" name="SOLR-561-fixes.patch" size="6955" author="yseeley@gmail.com" created="Fri, 24 Oct 2008 02:15:57 +0100"/>
                            <attachment id="12392742" name="SOLR-561-fixes.patch" size="6224" author="yseeley@gmail.com" created="Thu, 23 Oct 2008 18:54:18 +0100"/>
                            <attachment id="12392741" name="SOLR-561-fixes.patch" size="4620" author="yseeley@gmail.com" created="Thu, 23 Oct 2008 18:12:21 +0100"/>
                            <attachment id="12391871" name="SOLR-561-full.patch" size="96521" author="akshay" created="Fri, 10 Oct 2008 10:02:51 +0100"/>
                            <attachment id="12390003" name="SOLR-561-full.patch" size="99416" author="akshay" created="Fri, 12 Sep 2008 13:39:51 +0100"/>
                            <attachment id="12389665" name="SOLR-561-full.patch" size="109972" author="akshay" created="Mon, 8 Sep 2008 11:46:19 +0100"/>
                            <attachment id="12388993" name="SOLR-561-full.patch" size="76522" author="shalinmangar" created="Wed, 27 Aug 2008 12:28:10 +0100"/>
                            <attachment id="12392923" name="SOLR-561.patch" size="19693" author="noble.paul" created="Tue, 28 Oct 2008 09:57:55 +0000"/>
                            <attachment id="12392694" name="SOLR-561.patch" size="566" author="noble.paul" created="Thu, 23 Oct 2008 05:24:09 +0100"/>
                            <attachment id="12392627" name="SOLR-561.patch" size="11030" author="noble.paul" created="Wed, 22 Oct 2008 05:30:21 +0100"/>
                            <attachment id="12392554" name="SOLR-561.patch" size="176255" author="akshay" created="Tue, 21 Oct 2008 07:57:12 +0100"/>
                            <attachment id="12392476" name="SOLR-561.patch" size="173979" author="shalinmangar" created="Mon, 20 Oct 2008 13:52:35 +0100"/>
                            <attachment id="12392469" name="SOLR-561.patch" size="175757" author="akshay" created="Mon, 20 Oct 2008 12:06:23 +0100"/>
                            <attachment id="12392458" name="SOLR-561.patch" size="157325" author="shalinmangar" created="Mon, 20 Oct 2008 08:06:32 +0100"/>
                            <attachment id="12392232" name="SOLR-561.patch" size="175264" author="akshay" created="Thu, 16 Oct 2008 10:53:26 +0100"/>
                            <attachment id="12388992" name="SOLR-561.patch" size="52227" author="shalinmangar" created="Wed, 27 Aug 2008 12:23:11 +0100"/>
                            <attachment id="12386507" name="SOLR-561.patch" size="79486" author="noble.paul" created="Mon, 21 Jul 2008 10:08:09 +0100"/>
                            <attachment id="12386308" name="SOLR-561.patch" size="84094" author="noble.paul" created="Thu, 17 Jul 2008 16:06:14 +0100"/>
                            <attachment id="12385620" name="SOLR-561.patch" size="81356" author="noble.paul" created="Wed, 9 Jul 2008 12:29:46 +0100"/>
                            <attachment id="12383221" name="SOLR-561.patch" size="48072" author="noble.paul" created="Mon, 2 Jun 2008 12:55:25 +0100"/>
                            <attachment id="12383186" name="SOLR-561.patch" size="41532" author="noble.paul" created="Sun, 1 Jun 2008 08:42:29 +0100"/>
                            <attachment id="12383728" name="deletion_policy.patch" size="14661" author="yseeley@gmail.com" created="Tue, 10 Jun 2008 05:03:52 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 23 May 2008 19:17:06 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7047</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hxxql3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>20626</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>