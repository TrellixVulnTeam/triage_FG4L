<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 05:24:11 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/SOLR-284/SOLR-284.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[SOLR-284] Parsing Rich Document Types</title>
                <link>https://issues.apache.org/jira/browse/SOLR-284</link>
                <project id="12310230" key="SOLR">Solr</project>
                    <description>&lt;p&gt;I have developed a RichDocumentRequestHandler based on the CSVRequestHandler that supports streaming a PDF, Word, Powerpoint, Excel, or PDF document into Solr.&lt;/p&gt;


&lt;p&gt;There is a wiki page with information here: &lt;a href=&quot;http://wiki.apache.org/solr/UpdateRichDocuments&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/solr/UpdateRichDocuments&lt;/a&gt;&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12372848">SOLR-284</key>
            <summary>Parsing Rich Document Types</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gsingers">Grant Ingersoll</assignee>
                                    <reporter username="epugh">Eric Pugh</reporter>
                        <labels>
                    </labels>
                <created>Mon, 2 Jul 2007 21:54:02 +0100</created>
                <updated>Thu, 2 May 2013 03:29:26 +0100</updated>
                            <resolved>Tue, 15 Sep 2009 13:42:24 +0100</resolved>
                                                    <fixVersion>1.4</fixVersion>
                                    <component>update</component>
                        <due></due>
                            <votes>32</votes>
                                    <watches>15</watches>
                                                                <comments>
                            <comment id="12509667" author="epugh" created="Mon, 2 Jul 2007 22:01:14 +0100"  >&lt;p&gt;Patch file for adding new handler and test cases.&lt;/p&gt;</comment>
                            <comment id="12509673" author="epugh" created="Mon, 2 Jul 2007 22:11:10 +0100"  >&lt;p&gt;test files to go in test/test-files for unit testing.&lt;/p&gt;</comment>
                            <comment id="12509676" author="ryantxu" created="Mon, 2 Jul 2007 22:13:12 +0100"  >&lt;p&gt;I haven&apos;t run this patch, but have a few questions...&lt;/p&gt;

&lt;p&gt;What is the &lt;b&gt;general&lt;/b&gt; approach to extract a lucene document (list of fields) from a PDF? Word? Powerpoint?&lt;/p&gt;

&lt;p&gt;Is this just access to a few common fields like author, keywords, text, etc?  Is this something that realistically would need to be custom for each case?  &lt;/p&gt;

&lt;p&gt;Perhaps it makes sense to add a contrib section for this sort of stuff.  It seems weird to add 10 library dependencies to the core distribution.  How does nutch handle this?&lt;/p&gt;
</comment>
                            <comment id="12509679" author="epugh" created="Mon, 2 Jul 2007 22:15:41 +0100"  >&lt;p&gt;new jars to go in trunk/lib for pdf and office parsing...&lt;/p&gt;</comment>
                            <comment id="12509683" author="epugh" created="Mon, 2 Jul 2007 22:29:32 +0100"  >&lt;p&gt;So, I was not attempting to &quot;boil the ocean&quot; and provide the ultimate solution.  Our need was just to take all the raw text and index it in a field, and pass in a bunch of other data fields to be indexed.  &lt;/p&gt;

&lt;p&gt;We are parsing a large number of unstructured documents, that may or may not have common fields populated, but fortunately we don&apos;t really need them.  Our users aren&apos;t searching by author, but by content.  &lt;/p&gt;

&lt;p&gt;I think there are only 5 additional libraries, and one (poi-scratchpad) may be able to be removed...&lt;/p&gt;

&lt;p&gt;Yonik also mentioned using Tika, as a framework for creating a common interface to these types of rich documents, but Tika is still in incubation and has no code in it!&lt;/p&gt;

&lt;p&gt;I originally had separate handlers for each data type, and that was really icky, so I condensed it into the RichDocumentRequestHandler.  I could also merge in the CSVRequestHandler into it as well, by just taking out the logic for parsing CSV and putting it into a CSVParser.  However, the CSVRequestHandler has very complex and rich semantics that these unstructured documents don&apos;t really need.&lt;/p&gt;
</comment>
                            <comment id="12509905" author="epugh" created="Tue, 3 Jul 2007 16:18:36 +0100"  >&lt;p&gt;Updated patch file, properly handling missing stream.types, and cleaning up error messages a bit.&lt;/p&gt;</comment>
                            <comment id="12512497" author="epugh" created="Fri, 13 Jul 2007 15:29:24 +0100"  >&lt;p&gt;Updated to SVN revision 555996&lt;/p&gt;</comment>
                            <comment id="12524843" author="epugh" created="Tue, 4 Sep 2007 20:48:03 +0100"  >&lt;p&gt;Update patches for revision 572774&lt;/p&gt;</comment>
                            <comment id="12524851" author="epugh" created="Tue, 4 Sep 2007 21:10:48 +0100"  >&lt;p&gt;Java Source code for RichDocumentRequestHandler and friends.&lt;/p&gt;</comment>
                            <comment id="12524854" author="epugh" created="Tue, 4 Sep 2007 21:13:55 +0100"  >&lt;p&gt;add the test code for richdocumenthandler.&lt;/p&gt;</comment>
                            <comment id="12524856" author="epugh" created="Tue, 4 Sep 2007 21:14:33 +0100"  >&lt;p&gt;test code, this time with granted license!&lt;/p&gt;</comment>
                            <comment id="12525750" author="gsingers" created="Fri, 7 Sep 2007 16:41:37 +0100"  >&lt;p&gt;In regards to Tika not having any code, you may also find &lt;a href=&quot;http://aperture.sourceforge.net&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://aperture.sourceforge.net&lt;/a&gt; does many of the same things for handling different file formats, etc.&lt;/p&gt;</comment>
                            <comment id="12541535" author="jkuehn" created="Sat, 10 Nov 2007 11:22:37 +0000"  >&lt;p&gt;Hi Eric, thank you for this handler, works like a charm!&lt;br/&gt;
I need to use non-numeric ids which are fine with solr but are rejected by RichDocumentRequestHandler. I&apos;m not familiar with the solr-code, i patched RichDocumentRequestHandler.java to not to convert id to int, which didn&apos;t cause trouble so far:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;RichDocumentRequestHandler.java.patch&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Index: RichDocumentRequestHandler.java
===================================================================
--- RichDocumentRequestHandler.java	(revision 0)
+++ RichDocumentRequestHandler.java	(working copy)
@@ -133,7 +133,7 @@
 	&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; streamFieldname;
 	&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] fieldnames;
 	SchemaField[] fields;
-	&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; id;
+	&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; id;
 	  
 	&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; AddUpdateCommand templateAdd;
 
@@ -153,7 +153,7 @@
 	    &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; fn = params.get(FIELDNAMES);
 	    fieldnames = fn != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; ? commaSplit.split(fn,-1) : &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
 	    
-	    id = params.getInt(ID);
+	    id = params.get(ID);
 
 		templateAdd = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; AddUpdateCommand();
 		templateAdd.allowDups = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
@@ -202,7 +202,7 @@
 	 * @param desc
 	 *            TODO
 	 */
-	void doAdd(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; id, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; text, DocumentBuilder builder, AddUpdateCommand template)
+	void doAdd(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; id, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; text, DocumentBuilder builder, AddUpdateCommand template)
 	&lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
 
 	  &lt;span class=&quot;code-comment&quot;&gt;// first, create the lucene document
&lt;/span&gt;@@ -225,7 +225,7 @@
 	  handler.addDoc(template);
 	}
 
-	void addDoc(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; id, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; text) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
+	void addDoc(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; id, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; text) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
 		templateAdd.indexedId = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
 		doAdd(id, text, builder, templateAdd);
 	}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Tests were ok, maybe you can apply it to your sources.&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Juri&lt;/p&gt;</comment>
                            <comment id="12541879" author="epugh" created="Mon, 12 Nov 2007 18:23:04 +0000"  >&lt;p&gt;Juri,&lt;/p&gt;

&lt;p&gt;Thanks for the vote on the issue!  The next time I update this patch to work with the latest code, I&apos;ll apply your change.  Since this is still a pending patch, I am not actively maintaining it.  Thanks for voting for this patch, there is only one other patch with more votes, hopefully it will be added soon.  I&apos;d love to hear what the use case you have for this patch is.&lt;/p&gt;


&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR?report=com.atlassian.jira.plugin.system.project:popularissues-panel&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SOLR?report=com.atlassian.jira.plugin.system.project:popularissues-panel&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Eric&lt;/p&gt;</comment>
                            <comment id="12551506" author="jhipkiss" created="Thu, 13 Dec 2007 13:50:29 +0000"  >&lt;p&gt;This is crucial functionaility if Solr is to be accepted as a solution in any organisation.  A search engine that can&apos;t parse Microsoft or other closed formats is useless to most organisations.&lt;br/&gt;
This is a MUST!&lt;/p&gt;</comment>
                            <comment id="12569275" author="pompo" created="Fri, 15 Feb 2008 14:43:05 +0000"  >&lt;p&gt;I wrote a simple patch for RichDocumentUpdateHandler to accept multivalued fields. Just POST the same field name multiple times, e.g. category=TVs&amp;amp;category=Radios&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;RichDocumentRequestHandler.java.patch&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Index: RichDocumentRequestHandler.java
===================================================================
--- RichDocumentRequestHandler.java	(revision 0)
+++ RichDocumentRequestHandler.java	(working copy)
@@ -211,7 +211,10 @@
 	  &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i =0; i &amp;lt; fields.length;i++){
 	    &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; fieldName = fields[i].getName();
    
-  	    builder.addField(fieldName,params.get(fieldName),1.0f);
+           &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] values = params.getParams(fieldName);
+           &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; value : values) {
+             	    builder.addField(fieldName,value,1.0f);
+           }
 	      
 	  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Seems to work for me.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Pompo&lt;/p&gt;</comment>
                            <comment id="12582062" author="ryguasu" created="Tue, 25 Mar 2008 21:32:09 +0000"  >&lt;p&gt;I&apos;m thinking it would be handy if RichDocumentRequestHandler could support indexing text and HTML files, in addition to the fancier formats (pdf, doc, etc.). That way I could use RichDocumentRequestHandler for all my indexing needs (except commits and optimizes), rather than use it for for some doc types but still have to use XmlUpdateRequestHandler for text and HTML docs. Would anyone else find this useful?&lt;/p&gt;

&lt;p&gt;I skimmed the source, and adding support for text files looks trivial. (It&apos;s just a pass-through.) And if you had this, then I guess you&apos;d have at least one version of HTML support for free; in particular, you could upload your HTML file to RichDocumentRequestHandler, telling the handler that the document is in plain text format, and then strip off the HTML tags later by using the HTMLStripStandardTokenizer in your schema.xml.&lt;/p&gt;

&lt;p&gt;Alternatively, RichDocumentRequestHandler could provide its own explicit HTML to text conversion. There would probably be some advantages to this, but I&apos;m not sure exactly what they would be. One, I guess, would be that you could use tokenizers that didn&apos;t make use of HTMLStripReader.&lt;/p&gt;</comment>
                            <comment id="12583231" author="epugh" created="Fri, 28 Mar 2008 23:13:31 +0000"  >&lt;p&gt;Chris,  I like what you are thinking...  Really this is sort of becoming the AllDocumentsUnderTheSunRequestHandler, but what that highlights is that the current solution really doesn&apos;t do what we need, which is making it dirt simple to add new handlers...   &lt;/p&gt;

&lt;p&gt;While there are some efforts under way to do that, to provide the &quot;uber&quot; solution, I think adding another hack/method to RichDocumentRequestHandler is cool with me.  Since it&apos;s just a patch file, feel free to take it, munge it, and post it back as the &quot;current&quot; patch.  If you do, make sure to add to the docs on the wiki at &lt;a href=&quot;http://wiki.apache.org/solr/UpdateRichDocuments&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/solr/UpdateRichDocuments&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Heck, you may want to rip in Pompo&apos;s fix as well!&lt;/p&gt;</comment>
                            <comment id="12583233" author="epugh" created="Fri, 28 Mar 2008 23:14:59 +0000"  >&lt;p&gt;Oh, and don&apos;t forget to vote for it as well:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR?report=com.atlassian.jira.plugin.system.project:popularissues-panel&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SOLR?report=com.atlassian.jira.plugin.system.project:popularissues-panel&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It&apos;s the current leading vote getter!&lt;/p&gt;</comment>
                            <comment id="12586735" author="kristofd" created="Tue, 8 Apr 2008 11:05:08 +0100"  >&lt;p&gt;Very handy!&lt;/p&gt;

&lt;p&gt;It could be beneficial to have an option to save the extracted text as xml (so it can be stored) just before adding it to the Solr index. Thus, if the Solr schema needs to be changed (in a way that triggers a full reindex) the content can then be quickly re-fed from a &quot;near source&quot;.&lt;/p&gt;</comment>
                            <comment id="12587352" author="ryguasu" created="Wed, 9 Apr 2008 22:31:39 +0100"  >&lt;p&gt;Replacing rich.patch. The new one:&lt;/p&gt;

&lt;p&gt;1) Rolls together into one handy package all of these:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;the old rich.patch&lt;/li&gt;
	&lt;li&gt;the contents of source.zip and test.zip&lt;/li&gt;
	&lt;li&gt;Pompo&apos;s multivalued fields patch.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Note: It does &lt;b&gt;not&lt;/b&gt; include the contents of libs.zip or test-files.zip. I&apos;m not sure what the protocol is around those larger files.&lt;/p&gt;

&lt;p&gt;Note: The old rich.patch included a change to Config.java that  searched for an alternative config file in &quot;src/test/test-files/solr/conf/&quot;. I&apos;ve removed that change because I think it&apos;s debugging code that we don&apos;t want in an official patch. Let me know if I&apos;m wrong, though.&lt;/p&gt;

&lt;p&gt;2) Makes things work against the latest revision in trunk, r646483. (It had stopped working with the latest version.)&lt;/p&gt;

&lt;p&gt;I haven&apos;t added any new test cases, but the old ones all pass.&lt;/p&gt;

&lt;p&gt;I grant my modifications to ASF according to the Apache License. Someone might want to check that the underlying contributions have been appropriately licensed as well.&lt;/p&gt;</comment>
                            <comment id="12594730" author="beno" created="Tue, 6 May 2008 23:59:53 +0100"  >&lt;p&gt;Hi, just new here, I am working on Rich Document support for solr-ruby and acts_as_solr. If you are interested, see prelim results at: &lt;a href=&quot;http://wiki.apache.org/solr/solr-ruby/BrainStorming&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/solr/solr-ruby/BrainStorming&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For acts_as_solr I need the ID field to be a String, same as Juri Kuehn above who supplied the fix for this.&lt;/p&gt;

&lt;p&gt;Is there a specific reason it was not added to the latest rich.patch? I would appreciate it.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
MIchel&lt;/p&gt;</comment>
                            <comment id="12594987" author="ryguasu" created="Wed, 7 May 2008 19:17:13 +0100"  >&lt;p&gt;Here&apos;s a new version of rich.patch. My previous attempt didn&apos;t actually include all the necessary files! (Curses upon you, TortoiseSVN.) This one also includes preliminary support for plaintext and HTML files. (HTML support is done by running the input through the HTMLStripReader.)&lt;/p&gt;</comment>
                            <comment id="12594989" author="ryguasu" created="Wed, 7 May 2008 19:19:05 +0100"  >&lt;p&gt;New version of test-files.zip. Contains new file, simple.txt, that is used by a new unit test for plaintext files.&lt;/p&gt;</comment>
                            <comment id="12594992" author="gsingers" created="Wed, 7 May 2008 19:31:23 +0100"  >&lt;p&gt;Why not just use Tika (or Aperture, but it&apos;s license isn&apos;t as friendly)?  Doesn&apos;t make sense to reinvent the wheel here.&lt;/p&gt;</comment>
                            <comment id="12595007" author="ryguasu" created="Wed, 7 May 2008 20:15:00 +0100"  >&lt;p&gt;I&apos;m not sure this patch entirely reinvents the wheel, as it does most of the heavy lifting with preexisting components, namely PDFBox, POI, and Solr&apos;s own HTMLStripReader. It also has the advantage of already existing, whereas tying Solr to Tika or Aperture would take additional effort.&lt;/p&gt;

&lt;p&gt;Tika or Aperture do look really nice, though. The most obvious advantage these projects have over this patch is that they can already extract text from more file formats than this patch, and that the developers will probably continue to add more file formats over time. Are you thinking of additional advantages on top of this, Grant? Do you have any cool ideas about how Tika/Aperture&apos;s metadata extraction facilities might be integrated into Solr? Is there a potentially interesting interface between Aperture&apos;s crawling facilities and Solr?&lt;/p&gt;</comment>
                            <comment id="12595015" author="gsingers" created="Wed, 7 May 2008 20:46:56 +0100"  >


&lt;p&gt;I think Tika will actually take less effort, as you only need one  &lt;br/&gt;
interface, as I understand it.  You don&apos;t need separate handlers for  &lt;br/&gt;
each type, we just need to write the interface between Solr and Tika.&lt;/p&gt;

&lt;p&gt;Nutch is already using Tika.&lt;/p&gt;


&lt;p&gt;+1&lt;/p&gt;


&lt;p&gt;Yes, someone else maintains the code.  We just maintain the interface  &lt;br/&gt;
and upgrade when appropriate.&lt;/p&gt;


&lt;p&gt;well, metadata makes for nice fields to sort, filter and facet on,  &lt;br/&gt;
right?&lt;/p&gt;


&lt;p&gt;I think it is more likely that you will see Nutch integration w/ Solr  &lt;br/&gt;
(in fact, there is already a patch for it), but yeah, I think it makes  &lt;br/&gt;
sense to consider Solr as a sink for any crawler.&lt;/p&gt;

&lt;p&gt;Some of this also overlaps w/ the Data Import Request Handler on  &lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-469&quot; title=&quot;Data Import RequestHandler&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-469&quot;&gt;&lt;del&gt;SOLR-469&lt;/del&gt;&lt;/a&gt;.   I don&apos;t think we want to get Solr into the crawling game,  &lt;br/&gt;
but we also shouldn&apos;t prevent it from playing nicely with crawlers  &lt;br/&gt;
(not saying it doesn&apos;t already)&lt;/p&gt;


&lt;p&gt;--------------------------&lt;br/&gt;
Grant Ingersoll&lt;/p&gt;

&lt;p&gt;Lucene Helpful Hints:&lt;br/&gt;
&lt;a href=&quot;http://wiki.apache.org/lucene-java/BasicsOfPerformance&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/lucene-java/BasicsOfPerformance&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://wiki.apache.org/lucene-java/LuceneFAQ&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/lucene-java/LuceneFAQ&lt;/a&gt;&lt;/p&gt;





</comment>
                            <comment id="12595033" author="ryguasu" created="Wed, 7 May 2008 21:37:55 +0100"  >&lt;p&gt;Attaching another patch revision. I&apos;ve been totally asleep at the wheel today, and my previous one contained not only the feature described in this JIRA issue but also the Data Import RequestHandler patch (&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-469&quot; title=&quot;Data Import RequestHandler&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-469&quot;&gt;&lt;del&gt;SOLR-469&lt;/del&gt;&lt;/a&gt;). Hopefully I&apos;ve finally made a patch that&apos;s actually correct. I can at least promise that the unit tests pass when applied to r654253.&lt;/p&gt;</comment>
                            <comment id="12595360" author="otis" created="Thu, 8 May 2008 19:39:33 +0100"  >&lt;p&gt;+1 for Tika&lt;br/&gt;
But also +1 for committing this in the mean time &amp;#8211; wow, lots of watchers and voters!&lt;/p&gt;</comment>
                            <comment id="12595365" author="gsingers" created="Thu, 8 May 2008 19:59:10 +0100"  >&lt;p&gt;I don&apos;t agree on committing it.  If Tika is the right solution, then  &lt;br/&gt;
we should work towards Tika.  Not saying this isn&apos;t good, just saying  &lt;br/&gt;
it&apos;s going to create more maintenance than we want and then we just  &lt;br/&gt;
end up deprecating it in the near future.&lt;/p&gt;



</comment>
                            <comment id="12595372" author="ryguasu" created="Thu, 8 May 2008 20:44:11 +0100"  >&lt;p&gt;I&apos;m on the fence about whether this patch makes sense to include in Solr right now. One thing I&apos;m wondering, though: Can we assess the odds at this point whether it could make sense for a Tika-based handler to offer the same public interface that the handler in this patch presents? That is, even if the underlying implementation were switched to Tika at some point, could we avoid changing the URL schema and such that Solr clients would use to interact with it?&lt;/p&gt;

&lt;p&gt;If it&apos;s likely that the public interface could indeed remain the same for the first Tika-based handler release (or at least more or less the same), would this alleviate any of Grant&apos;s concerns?&lt;/p&gt;

&lt;p&gt;Also, would putting this handler into a contrib directory rather than in the main code base, as has been mentioned on the mailing list, make committing it any less problematic?&lt;/p&gt;</comment>
                            <comment id="12602831" author="klaasm" created="Thu, 5 Jun 2008 23:57:26 +0100"  >&lt;p&gt;Removing from 1.3.  No committer has taken ownership.&lt;/p&gt;

&lt;p&gt;(It might make sense as a contrib, but I can see the argument for not duplicating tika)&lt;/p&gt;</comment>
                            <comment id="12614992" author="ararog" created="Sat, 19 Jul 2008 14:50:14 +0100"  >&lt;p&gt;Who is working on tika based handler? The work on tika based handler can be started or it isn&apos;t mature enougth?&lt;/p&gt;</comment>
                            <comment id="12615057" author="otis" created="Sat, 19 Jul 2008 23:52:36 +0100"  >&lt;p&gt;I don&apos;t think anyone is working on it (publicly), so you are welcome to contribute it.&lt;/p&gt;</comment>
                            <comment id="12621989" author="ryguasu" created="Tue, 12 Aug 2008 22:27:52 +0100"  >&lt;p&gt;Trivial update to merge cleanly against r685275.&lt;/p&gt;</comment>
                            <comment id="12627082" author="ryguasu" created="Fri, 29 Aug 2008 20:34:41 +0100"  >&lt;p&gt;The patch, as currently stands, treats a field called &quot;id&quot; as a special case. First, it is a required field. Second, unlike any other field, you don&apos;t need to declare it in the fieldnames parameter. Finally, since the fieldSolrParams.getInt(), that field is required to be an int.&lt;/p&gt;

&lt;p&gt;This special-case treatment seems a little too particular to me; not everyone wants to have a field called &quot;id&quot;, and not everyone who does wants that field to be an int. So what I propose is to eliminate the special treatment of &quot;id&quot;. See un-hardcode-id.diff for what this might mean in particular. (That file is not complete; to correctly make this change, I&apos;d have to update the test cases.)&lt;/p&gt;

&lt;p&gt;This is a breaking change, because if you &lt;b&gt;are&lt;/b&gt; using an id field, you&apos;ll now have to specifically indicate that fact in the fieldnames parameter. Thus, instead of&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://localhost:8983/solr/update/rich?stream.file=myfile.doc&amp;amp;stream.type=doc&amp;amp;id=100&amp;amp;stream.fieldname=text&amp;amp;fieldnames=subject,author&amp;amp;subject=mysubject&amp;amp;author=eric&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://localhost:8983/solr/update/rich?stream.file=myfile.doc&amp;amp;stream.type=doc&amp;amp;id=100&amp;amp;stream.fieldname=text&amp;amp;fieldnames=subject,author&amp;amp;subject=mysubject&amp;amp;author=eric&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;you&apos;ll have to put&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://localhost:8983/solr/update/rich?stream.file=myfile.doc&amp;amp;stream.type=doc&amp;amp;id=100&amp;amp;stream.fieldname=text&amp;amp;fieldnames=id,subject,author&amp;amp;subject=mysubject&amp;amp;author=eric&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://localhost:8983/solr/update/rich?stream.file=myfile.doc&amp;amp;stream.type=doc&amp;amp;id=100&amp;amp;stream.fieldname=text&amp;amp;fieldnames=id,subject,author&amp;amp;subject=mysubject&amp;amp;author=eric&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think asking users of this patch to make this slight change in their client code is not an unreasonable burden, but I&apos;m curious what Eric and others have to say.&lt;/p&gt;</comment>
                            <comment id="12627309" author="epugh" created="Sun, 31 Aug 2008 14:22:40 +0100"  >&lt;p&gt;So, in typical open source fashion, I wrote the original patch to scratch my own itch.  Which meant that it was okay to make id be hardcoded.  However, even when I first posted the patch to this JIRA issue, I felt a little &quot;icky&quot; about the id field.  It seemed like a code smell to have this magic id!   So, from that standpoint, I think the changes that Chris has posted look great.  &lt;/p&gt;

&lt;p&gt;I think it&apos;s a good example of a patch getting better and better everytime someone else uses it!&lt;/p&gt;

&lt;p&gt;Now, if only this almost 14 month old patch could be applied!  With 28 votes, and 16 active watches, clearly somebody out there finds this useful!   &lt;/p&gt;

&lt;p&gt;And at this point it is miles better then what I first posted!  Keep up the great work and great contributions back!&lt;/p&gt;</comment>
                            <comment id="12627333" author="ryguasu" created="Sun, 31 Aug 2008 20:04:05 +0100"  >&lt;p&gt;While we&apos;re on the subject of breaking changes, I&apos;m now seeing some merit in replacing the fieldnames parameter with a field-specifying prefix.&lt;/p&gt;

&lt;p&gt;Currently when you want to set a non-body field, you introduce the field name in the fieldnames parameter and then specify its value in another parameter, like so:&lt;/p&gt;

&lt;p&gt;   /update/rich/...fieldnames=f1,f2,f3&amp;amp;f1=val1&amp;amp;f2=val2&amp;amp;f3=val3&lt;/p&gt;

&lt;p&gt;The alternative would be to to signal the fields f1, f2, and f3 by a field prefix, like so:&lt;/p&gt;

&lt;p&gt;  /update/rich/...f.f1=val1&amp;amp;f.f2=val2&amp;amp;f.f3=val3&lt;/p&gt;

&lt;p&gt;Because the f prefix says &quot;this is a field&quot;, there&apos;s no need for the fieldnames parameter.&lt;/p&gt;

&lt;p&gt;This isn&apos;t an Earth-shattering improvement, but there are three things I like about it:&lt;/p&gt;

&lt;p&gt;1. The URLs are shorter&lt;/p&gt;

&lt;p&gt;2. If you rename a field (e.g. rename f3 to g3), you can&apos;t accidentally half-update the URL in the client code, like this:&lt;/p&gt;

&lt;p&gt;  /update/rich/...fieldnames=f1,f2,g3&amp;amp;f1=val1&amp;amp;f2=val2&amp;amp;f3=val3&lt;/p&gt;

&lt;p&gt;3. Currently there are certain reserved words (e.g. &quot;fieldnames&quot;, &quot;commit&quot;) that you can&apos;t use, because they have special meaning to the handler. But with this change they become legitimate field names. For example, maybe I want each of my documents to have a &quot;commit&quot; field that describes who made the most recent relevant commit in a version control system.&lt;/p&gt;

&lt;p&gt;  /update/rich/...commit=true&amp;amp;f.commit=chris&lt;/p&gt;

&lt;p&gt;I can&apos;t think of any downsides right now, other than breaking people&apos;s code. (I do admit that is a downside.)&lt;/p&gt;

&lt;p&gt;Any comments?&lt;/p&gt;</comment>
                            <comment id="12627882" author="ryguasu" created="Wed, 3 Sep 2008 02:07:37 +0100"  >&lt;p&gt;A couple of Tika things:&lt;/p&gt;

&lt;p&gt;I glanced at Tika yesterday, and it looks like switching this patch over to it wouldn&apos;t be too hard. (The only thing half-worthy of note is that org.apache.tika.parser.Parser.parse outputs XHTML &lt;span class=&quot;error&quot;&gt;&amp;#91;via a SAX interface&amp;#93;&lt;/span&gt;, which we would probably then need to turn into plaintext.) I haven&apos;t yet looked into Eric&apos;s code to see if it does anything special that Tika doesn&apos;t do.&lt;/p&gt;

&lt;p&gt;I also noticed something else, though. Earlier comments say that Nutch uses Tika, but when I looked through Nutch trunk this seemed to only sort of be the case. In particular, Nutch definitely uses the stuff in the org.apache.tika.mime namepsace, to do things like auto-detect content types, but it doesn&apos;t seem to use the stuff in org.apache.tika.parser to do the actual document parsing; instead, it uses its own separate org.apache.nutch.parse.Parser class (and subclasses thereof). For example, org.apache.nutch.parse.html.HtmlParser does not delegate to org.apache.tika.parser.html.HtmlParser but rather does its own direct manipulation of the tagsoup and/or nekohtml libraries. (Things are similar with the Nutch PDF parser.) Nor does there seem to be an alternative class along the lines of org.apache.nutch.parse.TikaBasedParserThatCanParseLotsOfDifferentContentTypesIncludingHtml. And the string &quot;org.apache.tika.parser&quot; doesn&apos;t seem to occur in the Nutch source.&lt;/p&gt;

&lt;p&gt;I&apos;m wondering if anyone knows why Nutch does not seem to make use of all of Tika&apos;s functionality. Are they planning to switch everything over to Tika eventually?&lt;/p&gt;</comment>
                            <comment id="12628214" author="ryguasu" created="Thu, 4 Sep 2008 01:33:11 +0100"  >&lt;p&gt;This update is just to make a tiny refactoring, bringing all the handler&apos;s parsing classes under &lt;/p&gt;

&lt;p&gt;src\java\org\apache\solr\handler\rich&lt;/p&gt;

&lt;p&gt;and all the testing classes under &lt;/p&gt;

&lt;p&gt;src\test\org\apache\solr\handler\rich&lt;/p&gt;

&lt;p&gt;All tests pass.&lt;/p&gt;</comment>
                            <comment id="12628706" author="ryguasu" created="Fri, 5 Sep 2008 20:22:11 +0100"  >&lt;p&gt;THIS IS A BREAKING CHANGE TO RICH.PATCH! CLIENT URLs NEED TO BE UPDATED!&lt;/p&gt;

&lt;p&gt;All unit tests pass.&lt;/p&gt;

&lt;p&gt;Changes:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;As suggested earlier, the &quot;id&quot; parameter is no longer treated as a special case; it is not required, and it does not need to be an int. If you &lt;b&gt;do&lt;/b&gt; use a field called &quot;id&quot;, you &lt;b&gt;must&lt;/b&gt; now declare it in the fieldnames parameter, as you would any other field&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Do updates with with UpdateRequestProcessor and SolrInputDocument, rather than UpdateHandler and DocumentBuilder. (The latter pair appear to be obsolete.)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Previously if you declared a field in the fieldnames parameter but did not then did not specify a value for that field, you would get a NullPointerException. Now you can specify any nonnegative number of values for a declared field, including zero. (I&apos;ve added a unit test for this.)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;In SolrPDFParser, properly close PDDocument when PDF parsing throws an exception&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Log the stream type in the solr log, rather than on the console&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Some not-very-thorough conversion of tabs to spaces&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;As an aside, I&apos;ve noticed that I failed in my earlier efforts to incorporate Juri Kuehn&apos;s change to allow the id field to be non-integer. Sorry about that, Juri; that was not at all intentional.&lt;/p&gt;</comment>
                            <comment id="12646347" author="gsingers" created="Mon, 10 Nov 2008 20:13:15 +0000"  >&lt;p&gt;FYI, I intend to integrate Tika now that it has graduated from incubation and is a full-fledged Lucene sub-project.  I will do my best to be back-compatible with this patch, but make no guarantees as of know, since I have not reviewed this patch in a long time.&lt;/p&gt;</comment>
                            <comment id="12646947" author="gsingers" created="Wed, 12 Nov 2008 16:35:50 +0000"  >&lt;p&gt;Some initial thoughts on moving forward:&lt;/p&gt;

&lt;p&gt;I think we can add some generic functionality here via the request params:&lt;/p&gt;

&lt;p&gt;1. Tika can provide a lot of metadata about a document.  By metadata, I mean things like the actual author, pages, etc. as provided by the document, not the hardcoded metadata in the &lt;a href=&quot;http://wiki.apache.org/solr/UpdateRichDocuments&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/solr/UpdateRichDocuments&lt;/a&gt;.  The hardcoded metadata is also useful and should be retained.  With these, we then need a way to map fields from Tika&apos;s metadata to Solr fields.  If no mapping is specified, it tries to use the Tika metadata name as the field name.  If that doesn&apos;t exist, then we can rely on dynamic fields or we can allow for a param that passes in the name of a default field to map to.&lt;/p&gt;

&lt;p&gt;2.  We can auto detect the mime type or allow for it to be passed in.  Thus, stream.type becomes optional, but is still useful.&lt;/p&gt;

&lt;p&gt;3. Tika provides a mechanism for implementing your own SAX ContentHandler and passing that in.  I will likely make this pluggable such that people can provide there own.  I &lt;em&gt;think&lt;/em&gt; this would allow people to make even further refinements to the content (i.e. splitting on paragraphs or other things like that?????)&lt;/p&gt;

&lt;p&gt;I should have a start of a patch today or tomorrow.&lt;/p&gt;</comment>
                            <comment id="12646987" author="gsingers" created="Wed, 12 Nov 2008 18:13:48 +0000"  >&lt;blockquote&gt;
&lt;p&gt;3. Tika provides a mechanism for implementing your own SAX ContentHandler and passing that in. I will likely make this pluggable such that people can provide there own. I think this would allow people to make even further refinements to the content (i.e. splitting on paragraphs or other things like that?????)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Now that I&apos;m digging in more, this actually isn&apos;t needed.  The ProcessorChain can be used for this stuff&lt;/p&gt;</comment>
                            <comment id="12647003" author="epugh" created="Wed, 12 Nov 2008 19:07:34 +0000"  >&lt;p&gt;Grant,  I am really excited that you are looking at this patch!  &lt;/p&gt;

&lt;p&gt;While I am proud of it, and very proud of the number of organizations that have used it, and the people who have improved it (Thanks Chris!); it was just written to scratch an itch, and feel free to rip it apart to come up with a better solution for Solr.  The ability for Solr to injest more formats I think is key aspect, not how this patch works.&lt;/p&gt;

</comment>
                            <comment id="12647017" author="gsingers" created="Wed, 12 Nov 2008 19:29:05 +0000"  >&lt;p&gt;I&apos;ll separate out my two patches.&lt;/p&gt;</comment>
                            <comment id="12647618" author="gsingers" created="Fri, 14 Nov 2008 14:42:17 +0000"  >&lt;p&gt;Question for the people watching this:&lt;/p&gt;

&lt;p&gt;Would you prefer a new wiki page and keep the old one for those using Chris/Eric&apos;s patch, or would you rather I overwrite/edit the current one?&lt;/p&gt;

&lt;p&gt;FWIW, some of the parameters will be the same, but I&apos;m also adding in quite a bit more: boosting, XPath expression support (Tika returns everything as XHTML, so it then becomes possible to restrict down what parts you want to pay attention to), extraction only (i.e. no indexing), support for metadata extraction and indexing, support for sending in &quot;literals&quot; which are like the current fieldnames parameter and likely some other pieces.&lt;/p&gt;

&lt;p&gt;FYI: Out of the box, Tika has support for: &lt;a href=&quot;http://incubator.apache.org/tika/formats.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://incubator.apache.org/tika/formats.html&lt;/a&gt; and I know they are adding more things as well, like Flash, etc.&lt;/p&gt;

&lt;p&gt;It should also be noted, that if you are just indexing metadata about a file, it makes more sense to do the work on the client side.&lt;/p&gt;</comment>
                            <comment id="12647619" author="ehatcher" created="Fri, 14 Nov 2008 14:46:52 +0000"  >&lt;p&gt;I&apos;d rather see the old (err, current) wiki page replaced/renamed, and kept current with the latest patch/commit from this issue.  Nice work Grant!&lt;/p&gt;</comment>
                            <comment id="12647632" author="ryguasu" created="Fri, 14 Nov 2008 15:26:37 +0000"  >&lt;p&gt;Grant,&lt;/p&gt;

&lt;p&gt;I don&apos;t really care if you take over the old wiki page&apos;s name or start a new one; maybe it depends on if the updated handler is still going to have a similar name or be called something else. I do think, though, that it might be handy nice to have &lt;b&gt;some&lt;/b&gt; wiki page (and maybe some JIRA issue) to maintain the older patch on a temporary basis.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Chris&lt;/p&gt;</comment>
                            <comment id="12647670" author="gsingers" created="Fri, 14 Nov 2008 17:24:38 +0000"  >&lt;p&gt;OK, I&apos;ve created &lt;a href=&quot;http://wiki.apache.org/solr/ExtractingRequestHandler&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/solr/ExtractingRequestHandler&lt;/a&gt; and linked it from the old page.  I will have a preliminary patch up today.&lt;/p&gt;</comment>
                            <comment id="12647747" author="gsingers" created="Fri, 14 Nov 2008 22:59:40 +0000"  >&lt;p&gt;First crack at this.  You&apos;ll need to download &lt;a href=&quot;http://people.apache.org/~gsingers/extraction-libs.tar&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://people.apache.org/~gsingers/extraction-libs.tar&lt;/a&gt; as it is too big to fit in JIRA.&lt;/p&gt;

&lt;p&gt;There&apos;s probably lots wrong with it, so be gentle!  See &lt;a href=&quot;http://wiki.apache.org/solr/ExtractingRequestHandler&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/solr/ExtractingRequestHandler&lt;/a&gt; to get started.&lt;/p&gt;</comment>
                            <comment id="12647748" author="gsingers" created="Fri, 14 Nov 2008 23:01:43 +0000"  >&lt;p&gt;Things to do:&lt;/p&gt;

&lt;p&gt;1. Documentation&lt;br/&gt;
2. Way more testing, esp. unit tests of the various parameters&lt;br/&gt;
3. Update NOTICES and LICENSE.txt for the new dependencies.&lt;/p&gt;</comment>
                            <comment id="12647840" author="gsingers" created="Sat, 15 Nov 2008 13:03:13 +0000"  >&lt;p&gt;Captured fields weren&apos;t being indexed properly.&lt;/p&gt;</comment>
                            <comment id="12647846" author="gsingers" created="Sat, 15 Nov 2008 13:19:47 +0000"  >&lt;p&gt;Fix issue with literal mapping&lt;/p&gt;</comment>
                            <comment id="12647873" author="gsingers" created="Sat, 15 Nov 2008 16:45:12 +0000"  >&lt;p&gt;Separated out ID generation to make it easier to override.&lt;/p&gt;

&lt;p&gt;I think this is pretty close to being ready to commit, so please review.  I&apos;m wrapped up next week, so I probably won&apos;t commit until the end of next week (after 11/21) so please review and provide feedback.  Also, Tika is about to release 0.2, so I may just wait to add that in.&lt;/p&gt;

&lt;p&gt;Added in NOTICE and LICENSE information.&lt;/p&gt;</comment>
                            <comment id="12647875" author="gsingers" created="Sat, 15 Nov 2008 16:47:35 +0000"  >&lt;p&gt;Still to do:&lt;/p&gt;

&lt;p&gt;1. More unit tests&lt;/p&gt;

&lt;p&gt;2. We need to do the crypto notice for Solr once this is committed.   See &lt;a href=&quot;https://issues.apache.org/jira/browse/NUTCH-621&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/NUTCH-621&lt;/a&gt; for examples.  I will link a new issue for this so as not to hold up this patch from being committed.  It just needs to be done before releasing 1.4&lt;/p&gt;</comment>
                            <comment id="12647876" author="gsingers" created="Sat, 15 Nov 2008 16:52:23 +0000"  >&lt;p&gt;Let&apos;s name the patch right, eh?&lt;/p&gt;</comment>
                            <comment id="12647895" author="gsingers" created="Sat, 15 Nov 2008 21:12:58 +0000"  >&lt;p&gt;Fix an issue w/ XPath and extract only.  See &lt;a href=&quot;http://tika.markmail.org/message/kknu3hw7argwiqin&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://tika.markmail.org/message/kknu3hw7argwiqin&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12649542" author="ryguasu" created="Thu, 20 Nov 2008 23:45:57 +0000"  >&lt;p&gt;Is the latest patch supposed to contain a file &quot;solr-word.pdf&quot;? I don&apos;t see one, and my &quot;ant test&quot; is failing along these lines:&lt;/p&gt;

&lt;p&gt;        org.apache.solr.common.SolrException: java.io.FileNotFoundException: solr-word.pdf (The system cannot find the file specified)&lt;br/&gt;
	at org.apache.solr.handler.ExtractingDocumentLoader.load(ExtractingDocumentLoader.java:160)&lt;br/&gt;
	at org.apache.solr.handler.ContentStreamHandlerBase.handleRequestBody(ContentStreamHandlerBase.java:54)&lt;br/&gt;
	at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:131)&lt;br/&gt;
	at org.apache.solr.core.SolrCore.execute(SolrCore.java:1313)&lt;br/&gt;
	at org.apache.solr.util.TestHarness.queryAndResponse(TestHarness.java:331)&lt;br/&gt;
	at org.apache.solr.handler.ExtractingRequestHandlerTest.loadLocal(ExtractingRequestHandlerTest.java:97)&lt;br/&gt;
	at org.apache.solr.handler.ExtractingRequestHandlerTest.testExtraction(ExtractingRequestHandlerTest.java:27)&lt;/p&gt;</comment>
                            <comment id="12649551" author="ryguasu" created="Fri, 21 Nov 2008 00:11:53 +0000"  >&lt;p&gt;A few comment on the ExtractingDocumentLoader:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I think I like where this is going.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Currently the default is ext.ignore.und.fl (IGNORE_UNDECLARED_FIELDS) == false, which means that if Tika returns a metadata field and you haven&apos;t made an explicit mapping from the Tika fieldname to your Solr fieldname, then Solr will throw an exception and your document add will fail. This doesn&apos;t seem sound very robust for a production environment, unless Tika will only ever use a finite list of metadata field names. (That doesn&apos;t sound plausible, though I admit I haven&apos;t looked into it.) Even in that case, I think I&apos;d rather not have to set up a mapping for every possible field name in order to get started with this handler. Would true perhaps be a better default?&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;ext.capture / CAPTURE_FIELDS: Do you have a use case in mind for this feature, Grant? The example in the patch is of routing text from &amp;lt;div&amp;gt; tags to one Solr field while routing text from other tags to a different Solr field. I&apos;m kind of curious when this would be useful, especially keeping in mind that, in general, Tika source documents are not HTML, and so when &amp;lt;div&amp;gt; tags are generated they&apos;re as much artifacts of Tika as reflecting anything in the underlying document. (You could maybe ask a similar question about ext.inx.attr / INDEX_ATTRIBUTES.)&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12649985" author="gsingers" created="Sat, 22 Nov 2008 23:56:32 +0000"  >&lt;p&gt;Here&apos;s the solr-word PDF.&lt;/p&gt;</comment>
                            <comment id="12649986" author="gsingers" created="Sun, 23 Nov 2008 00:10:20 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I think I like where this is going.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Great!  I think the nice thing is as Tika grows, we&apos;ll get many more formats all for free.  For instance, I saw someone working on a Flash extractor.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Currently the default is ext.ignore.und.fl (IGNORE_UNDECLARED_FIELDS) == false, which means that if Tika returns a metadata field and you haven&apos;t made an explicit mapping from the Tika fieldname to your Solr fieldname, then Solr will throw an exception and your document add will fail. This doesn&apos;t seem sound very robust for a production environment, unless Tika will only ever use a finite list of metadata field names. (That doesn&apos;t sound plausible, though I admit I haven&apos;t looked into it.) Even in that case, I think I&apos;d rather not have to set up a mapping for every possible field name in order to get started with this handler. Would true perhaps be a better default?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I guess I was thinking that most people will probably start out with this by sending their docs through the engine and see what happens.  I think an exception helps them see sooner what they are missing.  That being said, I don&apos;t feel particularly strong about it.   It&apos;s easy enough to set it to true in the request handler mappings.    From what I see of Tika, though, the possible values for metadata is fixed within a version.  Perhaps the bigger issue is what happens when someone updates Tika to a newer version with newer Metadata options.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ext.capture / CAPTURE_FIELDS: Do you have a use case in mind for this feature, Grant? The example in the patch is of routing text from &amp;lt;div&amp;gt; tags to one Solr field while routing text from other tags to a different Solr field. I&apos;m kind of curious when this would be useful, especially keeping in mind that, in general, Tika source documents are not HTML, and so when &amp;lt;div&amp;gt; tags are generated they&apos;re as much artifacts of Tika as reflecting anything in the underlying document. (You could maybe ask a similar question about ext.inx.attr / INDEX_ATTRIBUTES.)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;For capture fields, it&apos;s similar to a copy field function.  Say, for example, you want a whole document in one field, but also to be able to search within paragraphs.  Then, you could use a capture field on a &amp;lt;p&amp;gt; tag to do that.  Thus, you get the best of both worlds.  The Tika output, is XHTML.&lt;/p&gt;

&lt;p&gt;Also, since extraction is happening on the server side, I want to make sure we have lots of options for dealing with the content.  I don&apos;t know where else one would have options to muck with the content post-extraction, but pre-indexing.  Hooking into the processor chain is too late, since then the Tika structure is gone.  That&apos;s my reasoning, anyway.  &lt;/p&gt;

&lt;p&gt;Similarly, for index attributes.  When extracting from an HTML file, and it comes across anchor tags (&amp;lt;a&amp;gt;) it will provide the attributes of the tags as XML attributes.  So, one may want to extract out the links separately from the main content and put them into a separate field.&lt;/p&gt;</comment>
                            <comment id="12650353" author="hossman" created="Mon, 24 Nov 2008 22:10:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;if Tika returns a metadata field and you haven&apos;t made an explicit mapping from the Tika fieldname to your Solr fieldname, then Solr will throw an exception and your document add will fail. This doesn&apos;t seem sound very robust for a production environment, unless Tika will only ever use a finite list of metadata field names.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m not familiar with the state of the patch, but i&apos;m assuming that (by default) all of the metadata fields produced by tika have a common naming convention &amp;#8211; either in terms of a common prefix or a common suffix.  in which case people can always make a dynamicField declaration to ignore all metadata fields not already explicitly declared.&lt;/p&gt;</comment>
                            <comment id="12650359" author="gsingers" created="Mon, 24 Nov 2008 22:24:39 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I&apos;m not familiar with the state of the patch, but i&apos;m assuming that (by default) all of the metadata fields produced by tika have a common naming convention - either in terms of a common prefix or a common suffix. in which case people can always make a dynamicField declaration to ignore all metadata fields not already explicitly declared.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No, they don&apos;t, but that is a good idea for Tika.&lt;/p&gt;</comment>
                            <comment id="12650363" author="ryguasu" created="Mon, 24 Nov 2008 22:31:38 +0000"  >&lt;p&gt;The 2008-11-15 01:12 PM version of &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-284&quot; title=&quot;Parsing Rich Document Types&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-284&quot;&gt;&lt;del&gt;SOLR-284&lt;/del&gt;&lt;/a&gt;.patch contains modifications to client/java/solrj/src/org/apache/solr/client/solrj/util/ClientUtils.java related to date handling. That&apos;s not intentional, is it?&lt;/p&gt;</comment>
                            <comment id="12650365" author="gsingers" created="Mon, 24 Nov 2008 22:52:26 +0000"  >&lt;blockquote&gt;
&lt;p&gt;The 2008-11-15 01:12 PM version of &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-284&quot; title=&quot;Parsing Rich Document Types&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-284&quot;&gt;&lt;del&gt;SOLR-284&lt;/del&gt;&lt;/a&gt;.patch contains modifications to client/java/solrj/src/org/apache/solr/client/solrj/util/ClientUtils.java related to date handling. That&apos;s not intentional, is it?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, it is intentional.  The user will need to be able to pass in/configure their own Date formats for their documents and the implementation has to be able to map those to Solr&apos;s canonical date format.  Thus, I moved the date handling stuff to a &quot;common&quot; DateUtils class (and deprecated it in ClientUtils) because it is needed on the server side too.  Unfortunately, it looks like I did some reformatting on the class as a whole, too.  Sorry &apos;bout that.&lt;/p&gt;</comment>
                            <comment id="12650368" author="gsingers" created="Mon, 24 Nov 2008 23:00:54 +0000"  >&lt;p&gt;I like how Erik has given names to contribs, etc.: Flare, Celeritas, etc.  So, I thought I would give one too:&lt;/p&gt;

&lt;p&gt;I was typing the javadocs and wrote &quot;Solr Content Extraction Library&quot;.   Which then lead me to &quot;Solr Cell&quot; as the project name?  &lt;a href=&quot;http://en.wikipedia.org/wiki/Solar_cell&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Solar_cell&lt;/a&gt;  It&apos;s also nice, b/c a Solar Cell&apos;s job is to convert the raw energy of the Sun to electricity, and this contrib&apos;s module is responsible for &quot;raw&quot; content of a document to something usable by Solr.&lt;/p&gt;

&lt;p&gt;I know, I know, get a life...  &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Still, it beats &quot;ExtractingRequestHandler&quot; as a name!&lt;/p&gt;</comment>
                            <comment id="12650431" author="ehatcher" created="Tue, 25 Nov 2008 01:08:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m not familiar with the state of the patch, but i&apos;m assuming that (by default) all of the metadata fields produced by tika have a common naming convention - either in terms of a common prefix or a common suffix. in which case people can always make a dynamicField declaration to ignore all metadata fields not already explicitly declared.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Tika doesn&apos;t need to do this explicitly.... you know all fields coming out of your call to the Tika API will be Tika fields.  Solar Cell (I&apos;m on board with that nickname, Grant - now you&apos;re catching on &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; - thus we could map all Tika output fields to tika_* where * is the Tika outputted field name.  And with field name mapping this default would be overridden, say tika_title mapped to &quot;title&quot;.   Just some off the cuff thoughts.&lt;/p&gt;</comment>
                            <comment id="12650634" author="gsingers" created="Tue, 25 Nov 2008 17:21:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;Tika doesn&apos;t need to do this explicitly.... you know all fields coming out of your call to the Tika API will be Tika fields. Solar Cell could map all Tika output fields to tika_* where * is the Tika outputted field name. And with field name mapping this default would be overridden, say tika_title mapped to &quot;title&quot;. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I can add in an option to have it do this mapping.&lt;/p&gt;</comment>
                            <comment id="12651066" author="ryguasu" created="Wed, 26 Nov 2008 17:18:19 +0000"  >&lt;p&gt;The 2008-11-15 01:12 PM &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-284&quot; title=&quot;Parsing Rich Document Types&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-284&quot;&gt;&lt;del&gt;SOLR-284&lt;/del&gt;&lt;/a&gt;.patch wasn&apos;t applying cleanly to trunk r720403 for me. (One of the hunks for client/java/solrj/src/org/apache/solr/client/solrj/util/ClientUtils.java wouldn&apos;t apply.) With this very small update, it does apply cleanly.&lt;/p&gt;</comment>
                            <comment id="12651073" author="ryguasu" created="Wed, 26 Nov 2008 17:42:28 +0000"  >&lt;p&gt;On r720403B, I&apos;m noticing that before I apply this patch tests pass, whereas after I apply this patch the following tests fail:&lt;/p&gt;

&lt;p&gt;solr.client.solrj.embedded.JettyWebappTest&lt;br/&gt;
solr.client.solrj.embedded.LargeVolumeJettyTest&lt;br/&gt;
solr.client.solrj.embedded.SolrExampleJettyTest&lt;br/&gt;
solr.client.solrj.response.TestSpellCheckResponse&lt;/p&gt;

&lt;p&gt;In each case Solr outputs this exception: &quot;On Solr startup: SEVERE: org.apache.solr.common.SolrException: Error loading class &apos;org.apache.solr.handler.ExtractingRequestHandler&apos;&quot;&lt;/p&gt;

&lt;p&gt;I&apos;m not sure the best way to get the ExtractingRequestHandler into the classpath here.&lt;/p&gt;

&lt;p&gt;Sort of related, I&apos;ve noticed that ExtractingRequestHandler doesn&apos;t currently get built into the .war file when you run &quot;ant example&quot;, in contrast to DataImportHandler, which &lt;b&gt;does&lt;/b&gt; get put into the .war by means of this target in its build.xml (among other targets):&lt;/p&gt;

&lt;p&gt;  &amp;lt;target name=&quot;dist&quot; depends=&quot;build&quot;&amp;gt;&lt;br/&gt;
  	&amp;lt;copy todir=&quot;../../build/web&quot;&amp;gt;&lt;br/&gt;
  		&amp;lt;fileset dir=&quot;src/main/webapp&quot; includes=&quot;**&quot; /&amp;gt;&lt;br/&gt;
  	&amp;lt;/copy&amp;gt;&lt;br/&gt;
  	&amp;lt;mkdir dir=&quot;../../build/web/WEB-INF/lib&quot;/&amp;gt;&lt;br/&gt;
  	&amp;lt;copy file=&quot;target/$&lt;/p&gt;
{fullnamever}.jar&quot; todir=&quot;${solr-path}/build/web/WEB-INF/lib&quot;&amp;gt;&amp;lt;/copy&amp;gt;&lt;br/&gt;
  	&amp;lt;copy file=&quot;target/${fullnamever}
&lt;p&gt;.jar&quot; todir=&quot;$&lt;/p&gt;
{solr-path}/dist&quot;&amp;gt;&amp;lt;/copy&amp;gt;&lt;br/&gt;
  &amp;lt;/target&amp;gt;&lt;br/&gt;
&lt;br/&gt;
Should ExtractingRequestHandler&apos;s build.xml perhaps have an analogous &quot;dist&quot; target, along these lines:&lt;br/&gt;
&lt;br/&gt;
  &amp;lt;target name=&quot;dist&quot; depends=&quot;build&quot;&amp;gt;&lt;br/&gt;
  	&amp;lt;mkdir dir=&quot;../../build/web/WEB-INF/lib&quot;/&amp;gt;&lt;br/&gt;
  	&amp;lt;copy file=&quot;build/${fullnamever}.jar&quot; todir=&quot;${solr-path}
&lt;p&gt;/build/web/WEB-INF/lib&quot;&amp;gt;&amp;lt;/copy&amp;gt;&lt;br/&gt;
  	&amp;lt;copy file=&quot;build/$&lt;/p&gt;
{fullnamever}
&lt;p&gt;.jar&quot; todir=&quot;$&lt;/p&gt;
{solr-path}
&lt;p&gt;/dist&quot;&amp;gt;&amp;lt;/copy&amp;gt;&lt;br/&gt;
  &amp;lt;/target&amp;gt;&lt;/p&gt;</comment>
                            <comment id="12651146" author="ryguasu" created="Wed, 26 Nov 2008 21:15:57 +0000"  >&lt;p&gt;Small change to the 2008-11-26 09:18 AM &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-284&quot; title=&quot;Parsing Rich Document Types&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-284&quot;&gt;&lt;del&gt;SOLR-284&lt;/del&gt;&lt;/a&gt;.patch (my previous one), this time adding an &quot;example&quot; ant target to contrib/javascript/build.xml. (Without this top-level &quot;ant example&quot; was failing.)&lt;/p&gt;</comment>
                            <comment id="12651212" author="ryguasu" created="Thu, 27 Nov 2008 01:23:18 +0000"  >&lt;p&gt;This should be the last change for today.&lt;/p&gt;

&lt;p&gt;This change adds a resource.name parameter that you can pass to the handler. (I&apos;m guessing you&apos;ll probably typically pass a filename, though Tika does use the more general term &quot;resource name&quot;.) If you provide it, Tika can take advantage of it when applying its heuristics to determine the MIME type.&lt;/p&gt;

&lt;p&gt;Affected files:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;ExtractingParams.java&lt;/li&gt;
	&lt;li&gt;ExtractingDocumentLoader.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12651813" author="gsingers" created="Sun, 30 Nov 2008 13:17:40 +0000"  >&lt;blockquote&gt;&lt;p&gt;Sort of related, I&apos;ve noticed that ExtractingRequestHandler doesn&apos;t currently get built into the .war file when you run &quot;ant example&quot;, in contrast to DataImportHandler, which does get put into the .war by means of this target in its build.xml (among other targets):&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, it does NOT get put into the WAR on purpose.  Unfortunately, I think the DIH does this wrong (but it&apos;s probably too late now).  A contrib should be optional, as not everyone wants it/needs it.  Solr Cell works solely by putting it into the Solr Home lib directory and then hooking it into the config.&lt;/p&gt;</comment>
                            <comment id="12652630" author="ryguasu" created="Wed, 3 Dec 2008 00:49:57 +0000"  >&lt;p&gt;Changes since my previous upload:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;sync CHANGES.txt with trunk&lt;/li&gt;
	&lt;li&gt;test cases for adding plain text data&lt;/li&gt;
	&lt;li&gt;you aren&apos;t forced to map a field if you use the resource.name parameter&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12652967" author="ryguasu" created="Wed, 3 Dec 2008 20:46:28 +0000"  >&lt;p&gt;As I mentioned before, tests for these &lt;/p&gt;

&lt;p&gt;  solr.client.solrj.embedded.JettyWebappTest&lt;br/&gt;
  solr.client.solrj.embedded.LargeVolumeJettyTest&lt;br/&gt;
  solr.client.solrj.embedded.SolrExampleJettyTest&lt;br/&gt;
  solr.client.solrj.embedded.TestSpellCheckResponse&lt;/p&gt;

&lt;p&gt;were failing, with Solr giving a classnotfoundexception for one of the extracting document loader (ie Solr Cell) classes.&lt;/p&gt;

&lt;p&gt;This revision fixes this by removing all references to this Tika handler from /trunk/example/conf/solrconfig.xml and /trunk/example/conf/schema.xml. Note that these references still exist (and are still used for testing) in /trunk/contrib/extraction/src/test/resources/solr/conf.&lt;/p&gt;

&lt;p&gt;There are probably other ways to make these tests pass, perhaps involving changing the setUp() methods for the above mentioned tests&apos; java files. (For example, maybe you could fiddle with the path parameter passed to the WebAppContext constructor in JettyWebappTest.java? I don&apos;t really know anything about this embedded stuff.) I like the current approach, though, because it avoids further changes to code that&apos;s logically independent of this handler.&lt;/p&gt;</comment>
                            <comment id="12652993" author="ryguasu" created="Wed, 3 Dec 2008 22:01:27 +0000"  >&lt;p&gt;Currently this patch deploys the Tika libs to /trunk/example/solr/lib. I&apos;m curious where the Tika handler&apos;s lib/ directory is supposed to go in a multicore deployment. I created my own multicore setup more or less like this:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;ant example&lt;/li&gt;
	&lt;li&gt;Copy /trunk/example to /trunk/solr-10000&lt;/li&gt;
	&lt;li&gt;Copy /trunk/solr-10000/multicore/* to /trunk/solr-10000/solr.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;(Solr-10000 means &quot;copy of Solr I plan to run on port 10000.&quot;)&lt;/p&gt;

&lt;p&gt;This seems to be the easiest way to set things up so that I can cd to /trunk/solr-10000 and run start.jar to get multicore Solr running.&lt;/p&gt;

&lt;p&gt;Or rather, that &lt;b&gt;would&lt;/b&gt; get multicore Solr running, except that Solr gets a can&apos;t-find-the-Tika-classes exception. So I guess /trunk/solr-10000/solr/lib is not where the lib directory goes for multicore deployment.&lt;/p&gt;

&lt;p&gt;So I tried putting Tika libs instead in /trunk/solr-10000/solr/core0/lib, and that loaded fine. That doesn&apos;t seem like the right place for the directory, though; it seems like each core shouldn&apos;t have to have its own separate copy of the Tika libs.&lt;/p&gt;

&lt;p&gt;So where &lt;b&gt;do&lt;/b&gt; the Tika libs go?&lt;/p&gt;</comment>
                            <comment id="12653137" author="gsingers" created="Thu, 4 Dec 2008 02:30:23 +0000"  >&lt;p&gt;I think in multicore you can specify a shared library in the solr.xml directory, so you could put the tika stuff in that dir.&lt;/p&gt;


&lt;p&gt;As for the tests, I didn&apos;t know the tests had a dependency on the example directory.  That doesn&apos;t seem good.  I&apos;m with a client all this week, but will try to get to it this weekend.&lt;/p&gt;</comment>
                            <comment id="12654063" author="gsingers" created="Sat, 6 Dec 2008 13:06:49 +0000"  >&lt;p&gt;Committed revision 723977.&lt;/p&gt;

&lt;p&gt;Committed Chris&apos; patch, w/ the modification that I put the ext prefix on the resource.name and stream.type.&lt;/p&gt;

&lt;p&gt;I also added a ext.metadata.prefix option, which can be used to map the Tika metadata to a dynamic Field, as Erik described above.&lt;/p&gt;

&lt;p&gt;See the Wiki page for details: &lt;a href=&quot;http://wiki.apache.org/solr/ExtractingRequestHandler&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/solr/ExtractingRequestHandler&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks for everyone&apos;s input and work!&lt;/p&gt;</comment>
                            <comment id="12654234" author="ryantxu" created="Sun, 7 Dec 2008 19:34:32 +0000"  >&lt;p&gt;Looks like there are a bunch of duplicate .jar files in lib.  You could remove these and use the ones that are already in /lib&lt;/p&gt;

&lt;div class=&quot;panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;panelContent&quot;&gt;
&lt;p&gt;Index: contrib/extraction/lib/commons-io-1.4.jar&lt;br/&gt;
Index: contrib/extraction/lib/commons-codec-1.3.jar&lt;br/&gt;
Index: contrib/extraction/lib/commons-lang-2.1.jar&lt;br/&gt;
Index: contrib/extraction/lib/commons-logging-1.0.4.jar&lt;br/&gt;
Index: contrib/extraction/lib/junit-3.8.1.jar&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12654235" author="gsingers" created="Sun, 7 Dec 2008 19:59:54 +0000"  >&lt;p&gt;Thanks, Ryan, I will remove them.&lt;/p&gt;</comment>
                            <comment id="12656018" author="gsingers" created="Fri, 12 Dec 2008 14:08:12 +0000"  >&lt;p&gt;Forgot a couple of things on this:&lt;/p&gt;

&lt;p&gt;1. To hook into the release/javadoc mechanism.&lt;br/&gt;
2. In order to facilitate separation of the javadocs and other things, I&apos;m going to move the code to o.a.s.handler.extraction package.&lt;br/&gt;
3. Need to publish the Maven artifacts.&lt;/p&gt;</comment>
                            <comment id="12656023" author="ararog" created="Fri, 12 Dec 2008 14:38:36 +0000"  >&lt;p&gt;Grant, lemme know how can I help.&lt;/p&gt;</comment>
                            <comment id="12656032" author="gsingers" created="Fri, 12 Dec 2008 15:22:04 +0000"  >&lt;p&gt;OK, I just committed:&lt;/p&gt;

&lt;p&gt;1. Upgraded to Tika 0.2 official release&lt;br/&gt;
2. Put in POM support&lt;br/&gt;
3. Hooked in various other build things.&lt;/p&gt;</comment>
                            <comment id="12662616" author="lancenorskog" created="Sat, 10 Jan 2009 04:02:45 +0000"  >&lt;p&gt;The ExtractingRequestHandler has its own UUID generation code. &lt;/p&gt;

&lt;p&gt;Should the schema designer just use the UUID field type or decide to have no unique key field?  This seems more modular and follows other aspects of the design.&lt;/p&gt;
</comment>
                            <comment id="12662660" author="gsingers" created="Sat, 10 Jan 2009 14:11:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;Should the schema designer just use the UUID field type or decide to have no unique key field? This seems more modular and follows other aspects of the design.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I guess I usually prefer having a unique key field, as it always gives you that one last handle to grab on to to find a specific document.  However, I&apos;m not sure I follow what you mean by having no uniq. field being more modular.&lt;/p&gt;

&lt;p&gt;I put in the code b/c I figured it was better to generate an ID than to outright reject the document, since unlike when adding XML, sending large files can be really expensive, so I wanted it to handle as many edge cases as possible and still accept a document.&lt;/p&gt;

&lt;p&gt;Here&apos;s the code:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
SchemaField uniqueField = schema.getUniqueKeyField();
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (uniqueField != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; uniqueFieldName = uniqueField.getName();
      SolrInputField uniqFld = document.getField(uniqueFieldName);
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (uniqFld == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
        &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; uniqId = generateId(uniqueField);
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (uniqId != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
          document.addField(uniqueFieldName, uniqId);
        }
      }
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12662696" author="hossman" created="Sat, 10 Jan 2009 21:36:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;I put in the code b/c I figured it was better to generate an ID than to outright reject the document,&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmmm ... that means that if i have a schema with a uniqueKey field, and i forget to specify a uniqueKey value when indexing my document, the handler will &quot;silently succeed&quot; in adding a document with a key i have no control over instead of failing in a way that will make me aware of my mistake &amp;#8211; and i have no way of configuring solr to prevent that kind of &quot;silent success&quot;&lt;/p&gt;

&lt;p&gt;If i wanted that behavior, i could configure the schema with a UUIDFIeld as the uniqueKey and take advantage of the default.  but as it is now i have no way to prevent it.&lt;/p&gt;

&lt;p&gt;I would think consistency and flexibility is more important, and remove that &quot;generateId&quot; functionality along the lines of Lance&apos;s suggestion.&lt;/p&gt;</comment>
                            <comment id="12662793" author="gsingers" created="Sun, 11 Jan 2009 15:44:05 +0000"  >&lt;blockquote&gt;&lt;p&gt;Hmmm ... that means that if i have a schema with a uniqueKey field, and i forget to specify a uniqueKey value when indexing my document, the handler will &quot;silently succeed&quot; in adding a document with a key i have no control over instead of failing in a way that will make me aware of my mistake - and i have no way of configuring solr to prevent that kind of &quot;silent success&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually, there is a mechanism for avoiding it, and it is documented on in &lt;a href=&quot;http://wiki.apache.org/solr/ExtractingRequestHandler#head-6cda7b8832bb2ccaf6b0b57a6ef524b553db489e&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/solr/ExtractingRequestHandler#head-6cda7b8832bb2ccaf6b0b57a6ef524b553db489e&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I could, however, see adding a flag to specify whether one wants &quot;silent success&quot; or not.  I think the use case for content extraction is different than the normal XML message path.  Often times, these files are quite large and the cost of sending them to the system is significant.  &lt;/p&gt;

&lt;p&gt;Another thing that might be interesting to do is to actually return in the the response the generated id.&lt;/p&gt;</comment>
                            <comment id="12663150" author="ryguasu" created="Tue, 13 Jan 2009 00:01:11 +0000"  >&lt;blockquote&gt;&lt;p&gt;I could, however, see adding a flag to specify whether one wants &quot;silent success&quot; or not. I think the use case for content extraction is different than the normal XML message path. Often times, these files are quite large and the cost of sending them to the system is significant.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;In my own use case of the handler, I imagine the fail-on-missing-key policy would be the more helpful policy. This is because I want to be in control of my own key, and if Solr fails as soon as I don&apos;t provide one, that&apos;s going to help me find the bug in my indexing code right away, whereas &quot;silent success&quot; will allow that bug to fester. I&apos;m not sure there would be significant countervailing advantages to the other policy. It&apos;s true that transferring a large file when you&apos;re just going to get an error message wastes some time, but I feel like in debugging there&apos;s potential to waste a lot more time.&lt;/p&gt;

&lt;p&gt;My first choice would be for fail-on-missing-key to be the default, followed by having an easy-to-set flag. In any case, though, it would be nice not to have to create a custom SolrContentHandler just to get this one sanity check.&lt;/p&gt;</comment>
                            <comment id="12663186" author="gsingers" created="Tue, 13 Jan 2009 02:03:44 +0000"  >&lt;p&gt;I guess I&apos;m fine with it.  So, should we remove key generation all together?&lt;/p&gt;</comment>
                            <comment id="12671482" author="gsingers" created="Sat, 7 Feb 2009 16:01:44 +0000"  >&lt;p&gt;Remove Key Generation.  Will commit shortly&lt;/p&gt;</comment>
                            <comment id="12671483" author="gsingers" created="Sat, 7 Feb 2009 16:03:27 +0000"  >&lt;p&gt;I removed the auto key generation: Committed revision 741907.  I think this can officially close out this patch.&lt;/p&gt;</comment>
                            <comment id="12724855" author="yseeley@gmail.com" created="Sat, 27 Jun 2009 15:09:58 +0100"  >&lt;p&gt;Not sure if I should open a new issue or keep improvements here.&lt;br/&gt;
I think we need to improve the OOTB experience with this...&lt;br/&gt;
&lt;a href=&quot;http://search.lucidimagination.com/search/document/302440b8a2451908/solr_cell&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://search.lucidimagination.com/search/document/302440b8a2451908/solr_cell&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Ideas for improvement:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;auto-mapping names of the form Last-Modified to a more solrish field name like last_modified&lt;/li&gt;
	&lt;li&gt;drop &quot;ext.&quot; from parameter names, and revisit naming to try and unify with other update handlers like CSV&lt;br/&gt;
  note: in the future, one could see generic functionality like boosting fields, setting field value defaults, etc, being handled by a generic component or update processor... all the better reason to drop the ext prefix.&lt;/li&gt;
	&lt;li&gt;I imagine that metadata is normally useful, so we should&lt;br/&gt;
  1. predefine commonly used metadata fields in the example schema... there&apos;s really no cost to this&lt;br/&gt;
  2. use mappings to normalize any metadata names (if such normalization isn&apos;t already done in Tika)&lt;br/&gt;
  3. ignore or drop fields that have little use&lt;br/&gt;
  4. provide a way to handle new attributes w/o dropping them or throwing an error&lt;/li&gt;
	&lt;li&gt;enable the handler by default - lazy to avoid a dependency on having all the tika libs available&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12724856" author="epugh" created="Sat, 27 Jun 2009 15:11:50 +0100"  >&lt;p&gt;I am out of the office 6/29 - 6/30.  For urgent issues, please contact&lt;br/&gt;
Jason Hull at jhull@opensourceconnections.com or phone at (434)&lt;br/&gt;
409-8451.&lt;/p&gt;</comment>
                            <comment id="12724858" author="yseeley@gmail.com" created="Sat, 27 Jun 2009 15:33:04 +0100"  >&lt;p&gt;Oops, there is a &quot;ext.metadata.prefix&quot; that I missed on the first pass.  This should be defaulted to handle unknown attributes.&lt;/p&gt;</comment>
                            <comment id="12724859" author="yseeley@gmail.com" created="Sat, 27 Jun 2009 15:36:01 +0100"  >&lt;p&gt;ext.capture seems problematic in that one needs a separate ext.map statement to move what you capture... but it doesn&apos;t seem to work well if you already have fieldnames that might match something you are trying to capture.&lt;/p&gt;

&lt;p&gt;perhaps something of the form&lt;br/&gt;
capture.targetfield=expression&lt;br/&gt;
would work better?&lt;/p&gt;</comment>
                            <comment id="12724862" author="yseeley@gmail.com" created="Sat, 27 Jun 2009 15:58:44 +0100"  >&lt;p&gt;I just tried setting ext.idx.attr=false, and I didn&apos;t see any change after indexing a PDF.&lt;br/&gt;
Perhaps we don&apos;t even need this option if we map attributes to an ignored_ field that is ignored?&lt;br/&gt;
In any case, the default seems like it should generate / index attributes.&lt;/p&gt;</comment>
                            <comment id="12724863" author="yseeley@gmail.com" created="Sat, 27 Jun 2009 16:11:19 +0100"  >&lt;p&gt;Another comment on parameter naming: period is more like a scoping operator, and less like a word separator.  Hence ext.ignore.und.fl is more readable as ext.ignore_undefined or something.&lt;/p&gt;</comment>
                            <comment id="12724871" author="yseeley@gmail.com" created="Sat, 27 Jun 2009 17:58:28 +0100"  >&lt;p&gt;Apologies for not reviewing this sooner after it was committed - but this is the last/best chance to improve the interface before 1.4 is released (and this is very important new functionality).&lt;/p&gt;

&lt;p&gt;Since the &quot;ext.&quot; seems unnecessary and removing is already a name change, we might as well revisit the names themselves anyway.  Here are my first thoughts on it:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;//////// &lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt; type stuff that could be reused by other update handlers
&lt;/span&gt;boost.myfield=2.3
literal.myfield=Hello
map.origfield=newfield
uprefix=attr_ 
  &lt;span class=&quot;code-comment&quot;&gt;// map any unknown fields using a standard prefix... good &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// dynamic field mapping.
&lt;/span&gt;
&lt;span class=&quot;code-comment&quot;&gt;//////// more solr cell specific
&lt;/span&gt;capture.target_field=div
  &lt;span class=&quot;code-comment&quot;&gt;// does capture + field-map in single step... avoids name clashes
&lt;/span&gt;xpath=xpath_expr
  &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt;: could &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; xpath.targetfield=xpath_expr
&lt;/span&gt;extract_only=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// period&apos;s aren&apos;t word separators, but scoping operators
&lt;/span&gt; &lt;span class=&quot;code-comment&quot;&gt;// in the &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; could be replaced with a &lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt; update operation
&lt;/span&gt; &lt;span class=&quot;code-comment&quot;&gt;// to &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; the document(s) instead of indexing them.
&lt;/span&gt;resource.name=test.pdf

New idea:
  nicenames=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;code-comment&quot;&gt;// Last-Modified -&amp;gt; last_modified
&lt;/span&gt;

REMOVED:
ext.ignore.und.fl 
  &lt;span class=&quot;code-comment&quot;&gt;// throwing an exception when a field-type doesn&apos;t exist is &lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// and not needed.  we should never silently ignore.
&lt;/span&gt;ext.idx.attr
  &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; we ever want &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; to be &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;?  we can ignore all attributes
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// with field mappings &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; we want to
&lt;/span&gt;ext.metadata.prefix
  &lt;span class=&quot;code-comment&quot;&gt;// seems like we only want to map unknown fields, not all fields
&lt;/span&gt;ext.def.fl 
  &lt;span class=&quot;code-comment&quot;&gt;// we can use a standard field name &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; indexing main content
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// and use map to move it &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; desired. &lt;span class=&quot;code-quote&quot;&gt;&quot;content&quot;&lt;/span&gt;? &lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Do people view this as an improvement?&lt;/p&gt;</comment>
                            <comment id="12724937" author="gsingers" created="Sun, 28 Jun 2009 11:41:00 +0100"  >&lt;blockquote&gt;&lt;p&gt;I just tried setting ext.idx.attr=false, and I didn&apos;t see any change after indexing a PDF.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is often needed for HTML, where it is used to index the attributes of tags.  Same would go for XML.&lt;/p&gt;</comment>
                            <comment id="12724938" author="gsingers" created="Sun, 28 Jun 2009 11:41:31 +0100"  >&lt;p&gt;I will review your comments more tomorrow.  Still waist deep in boxes from the move!&lt;/p&gt;</comment>
                            <comment id="12725237" author="ryguasu" created="Mon, 29 Jun 2009 17:35:35 +0100"  >&lt;blockquote&gt;&lt;p&gt;Apologies for not reviewing this sooner after it was committed - but this is the last/best chance to improve the interface before 1.4 is released (and this is very important new functionality).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;My only request is that, if you&apos;re changing how field mapping works and maybe removing ext.ignore.und.fl, you make sure it stays easy to say, &quot;Tika, I don&apos;t care about any of your parsed metadata. Please leave it out of my Solr index.&quot; In my current use case I already know all the metadata I want, and including the Tika-parsed fields would result in index bloat. (My temptation would be to make excluding Tika-parsed fields the default, though it sounds like other people have the opposite inclination.)&lt;/p&gt;</comment>
                            <comment id="12725355" author="gsingers" created="Mon, 29 Jun 2009 22:18:08 +0100"  >&lt;blockquote&gt;&lt;p&gt;ext.ignore.und.fl&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think this should be kept and this is a case where we should silently ignore.  Parsing rich data is a different beast than normal Solr XML or other structured content.  There are a lot of times where you only want to get specific fields and there can be a large number of fields.  It is burdensome to have to add the ignores for all the metadata.  Not to mention different types may have different metadata.  So, -1 on removing.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;ext.idx.attr&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, we may want it to be false.  That&apos;s why I put it in!  &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  It can be used to extract things like HREF into other fields or not.  Think faceting.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;ext.metadata.prefix&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is not a mapping thing so much as a way to separately handle metadata fields from the main text fields.  I&apos;m not sure if it differs from the uprefix approach you are proposing except you can know exactly what is metadata and what isn&apos;t.&lt;/p&gt;


&lt;p&gt;Other questions that Yonik brought up:&lt;/p&gt;

&lt;p&gt;1. I don&apos;t think trying to auto map is a good idea.  New file formats will have new ways of doing them, it&apos;s better to have the user handle it.  &lt;br/&gt;
2. Fine with dropping ext for common names&lt;br/&gt;
3. Metadata is often not useful and I don&apos;t think we need to do work as suggested.  See Eric&apos;s comment above.&lt;br/&gt;
4. Enabling by default is fine.&lt;/p&gt;
</comment>
                            <comment id="12726113" author="yseeley@gmail.com" created="Wed, 1 Jul 2009 16:42:44 +0100"  >&lt;blockquote&gt;&lt;p&gt;My only request is that, if you&apos;re changing how field mapping works and maybe removing ext.ignore.und.fl, you make sure it stays easy to say, &quot;Tika, I don&apos;t care about any of your parsed metadata.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Map unknown fields to an ignored fieldtype.&lt;br/&gt;
uprefix=ignored_&lt;/p&gt;</comment>
                            <comment id="12726115" author="epugh" created="Wed, 1 Jul 2009 16:47:48 +0100"  >&lt;p&gt;I am out of the office 6/29 - 6/30.  For urgent issues, please contact&lt;br/&gt;
Jason Hull at jhull@opensourceconnections.com or phone at (434)&lt;br/&gt;
409-8451.&lt;/p&gt;</comment>
                            <comment id="12726116" author="yseeley@gmail.com" created="Wed, 1 Jul 2009 16:49:34 +0100"  >&lt;blockquote&gt;&lt;p&gt;It is burdensome to have to add the ignores for all the metadata.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It would be easy to change the default from index to ignore:&lt;br/&gt;
uprefix=ignored_    // ignored_ will be defined in the schema as indexed=false, stored=false&lt;br/&gt;
uprefix=attr_&lt;/p&gt;

&lt;p&gt;Actually, that brings up another random question... when we get the metadata back from Tika, is it typed (can we tell that number of pages is an integer?)&lt;/p&gt;</comment>
                            <comment id="12726122" author="yseeley@gmail.com" created="Wed, 1 Jul 2009 17:03:06 +0100"  >&lt;p&gt;&amp;gt;&amp;gt; I just tried setting ext.idx.attr=false, and I didn&apos;t see any change after indexing a PDF.&lt;br/&gt;
&amp;gt; This is often needed for HTML, where it is used to index the attributes of tags. Same would go for XML.&lt;/p&gt;

&lt;p&gt;That&apos;s confusing given that the examples on the wiki show PDFs being indexed with ext.idx.attr=true&lt;/p&gt;

&lt;p&gt;It also confused me since the docs say &quot;Index the Tika XHTML attributes into separate fields, named after the attribute.&quot; and the docs also say &quot;Tika does everything by producing an XHTML stream that it feeds to a SAX ContentHandler&quot;.&lt;br/&gt;
That led me to believe that ext.idx.attr was for all tika generated metadata (or maybe it is, but tika doesn&apos;t generally use attributes?)&lt;/p&gt;

&lt;p&gt;It&apos;s also rather confusing just what rules can be applied to what.  For example, does ext.metadata.prefix work on stuff produced by ext.idx.attr?&lt;br/&gt;
edit: nope, I just tried, and that does not work.&lt;/p&gt;</comment>
                            <comment id="12726123" author="ryguasu" created="Wed, 1 Jul 2009 17:04:21 +0100"  >&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;My only request is that, if you&apos;re changing how field mapping works and maybe removing ext.ignore.und.fl, you make sure it stays easy to say, &quot;Tika, I don&apos;t care about any of your parsed metadata.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Map unknown fields to an ignored fieldtype.&lt;br/&gt;
uprefix=ignored_&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That seems fine.&lt;/p&gt;

&lt;p&gt;Tangentially, I wonder how fast Tika&apos;s metadata extraction is, compared to its main body text extraction. If the latter doesn&apos;t dwarf the former, there might be value in adding a &quot;Solr, don&apos;t even ask Tika to calculate for metadata at all; just have it extract the body text&quot; flag; this could potentially speed things up for people that don&apos;t need the metadata. Maybe it would make sense to benchmark things before adding such a flag, though. I also don&apos;t have a good sense of how many people will want to use the metadata feature vs how many don&apos;t.&lt;/p&gt;</comment>
                            <comment id="12728144" author="yseeley@gmail.com" created="Tue, 7 Jul 2009 16:19:00 +0100"  >&lt;p&gt;The current ext.metadata.prefix parameter adds the prefix to all attributes, even those that have already been mapped (so last_modified appears instead as attr_last_modified).  Seems like one really wants a prefix appended only for those params that are not explicitly mapped (or don&apos;t appear in the schema)... this is what the proposed &quot;uprefix&quot; (unknown field prefix) would do.&lt;/p&gt;</comment>
                            <comment id="12728303" author="yseeley@gmail.com" created="Tue, 7 Jul 2009 20:10:32 +0100"  >&lt;p&gt;The date.format thing is interesting.... but shouldn&apos;t that really be part of a Date fieldType that can accept all those formats?&lt;br/&gt;
Transforming in the update handler only means that you could add a literal.mydate=date1 via the update handler, and then fail to query it (because the date parsing was specific to the update handler.)&lt;/p&gt;

&lt;p&gt;Perhaps we could add this to the new trie field for dates?&lt;/p&gt;</comment>
                            <comment id="12728636" author="gsingers" created="Wed, 8 Jul 2009 12:40:43 +0100"  >&lt;blockquote&gt;&lt;p&gt;The date.format thing is interesting.... but shouldn&apos;t that really be part of a Date fieldType that can accept all those formats?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agreed, I was just wanting more Date Field Type capabilities the other day.  It would be nice to be able to specify two things on the Date fieldType:&lt;br/&gt;
1. Input formats accepted like what the ExtractingRequestHandler offers&lt;br/&gt;
2. Output granularity.  That is, may not want to store seconds, etc. so Solr should drop the precision.  Note, this is different from Trie in that it is only indexing one token.&lt;/p&gt;

&lt;p&gt;Probably should handle on a separate issue.&lt;/p&gt;</comment>
                            <comment id="12730516" author="yseeley@gmail.com" created="Mon, 13 Jul 2009 22:21:05 +0100"  >&lt;p&gt;OK, here&apos;s my first crack at cleaning things up a little before release.  Changes:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;there were no tests for XML attribute indexing.&lt;/li&gt;
	&lt;li&gt;capture had no unit tests&lt;/li&gt;
	&lt;li&gt;boost has no unit tests&lt;/li&gt;
	&lt;li&gt;ignoring unknown fields had no unit test&lt;/li&gt;
	&lt;li&gt;metadata prefix had no unit test&lt;/li&gt;
	&lt;li&gt;logging ignored fields at the INFO level for each document loaded is too verbose&lt;/li&gt;
	&lt;li&gt;removed handling of undeclared fields and let downstream components&lt;br/&gt;
  handle this.&lt;/li&gt;
	&lt;li&gt;avoid the String catenation code for single valued fields when Tika only&lt;br/&gt;
  produces a single value (for performance)&lt;/li&gt;
	&lt;li&gt;remove multiple literal detection handling for single valued fields - let a downstream component handle it&lt;/li&gt;
	&lt;li&gt;map literal values just as one would with generated metadata, since the user may be just supplying the extra metadata.  also apply transforms (date formatting currently)&lt;/li&gt;
	&lt;li&gt;fixed a bug where null field values were being added (and later dropped by Solr... hence it was never caught).&lt;/li&gt;
	&lt;li&gt;avoid catching previously thrown SolrExceptions... let them fly through&lt;/li&gt;
	&lt;li&gt;removed some unused code (id generation, etc)&lt;/li&gt;
	&lt;li&gt;added lowernames option to map field names to lowercase/underscores&lt;/li&gt;
	&lt;li&gt;switched builderStack from synchronized Stack to LinkedList&lt;/li&gt;
	&lt;li&gt;fixed a bug that caused content to be appended with no whitespace in between&lt;/li&gt;
	&lt;li&gt;made extracting request handler lazy loading in example config&lt;/li&gt;
	&lt;li&gt;added ignored_ and attr_ dynamic fields in example schema&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Interface:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
The &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; field is always &lt;span class=&quot;code-quote&quot;&gt;&quot;content&quot;&lt;/span&gt; - use map to change it to something &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;
lowernames=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;/&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, map names like Content-Type to content_type
&lt;/span&gt;map.&amp;lt;fname&amp;gt;=&amp;lt;target_field&amp;gt;
boost.&amp;lt;fname&amp;gt;=&amp;lt;boost&amp;gt;
literal.&amp;lt;fname&amp;gt;=&amp;lt;literal_value&amp;gt;
xpath=&amp;lt;xpath_expr&amp;gt;  - only generate content &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the matching xpath expr
extractOnly=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;/&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; - &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, just &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; the extracted content
capture=&amp;lt;xml_element_name&amp;gt;  &lt;span class=&quot;code-comment&quot;&gt;// separate out these elements 
&lt;/span&gt;captureAttr=&amp;lt;xml_element_name&amp;gt;   &lt;span class=&quot;code-comment&quot;&gt;// separate out the attributes &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; these elements
&lt;/span&gt;uprefix=&amp;lt;prefix&amp;gt;  &lt;span class=&quot;code-comment&quot;&gt;// unknown field prefix - any unknown fields will be prepended with &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; value
&lt;/span&gt;stream.type
resource.name
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To try and make things more uniform, all fields, whether &quot;content&quot; or metadata or attributes or literals, all go through the same process.&lt;br/&gt;
1) map to lowercase if lowernames=true&lt;br/&gt;
2) apply map.field rules&lt;br/&gt;
3) if the resulting field is unknown, prefix it with uprefix&lt;/p&gt;

&lt;p&gt;Hopefully people will agree that this is an improvement in general.  I think in the future we&apos;ll need more advanced options, esp around dealing with links in HTML and more powerful xpath constructs, but that&apos;s for after 1.4 IMO.&lt;/p&gt;</comment>
                            <comment id="12730929" author="yseeley@gmail.com" created="Tue, 14 Jul 2009 16:54:39 +0100"  >&lt;p&gt;OK, I&apos;ve committed the above.  I&apos;ll work on updating the wiki, including clarifying things that didn&apos;t make sense the first time I looked at this.&lt;/p&gt;</comment>
                            <comment id="12753865" author="yseeley@gmail.com" created="Thu, 10 Sep 2009 23:31:32 +0100"  >&lt;p&gt;Attaching a schema update to define some common useful metadata fields to improve the OOTB experience.&lt;br/&gt;
Any concerns or suggestions for improvements?  I&apos;d like to commit shortly to get it into 1.4&lt;/p&gt;
</comment>
                            <comment id="12754626" author="gsingers" created="Sat, 12 Sep 2009 23:16:44 +0100"  >&lt;p&gt;I don&apos;t think we should drop ext.def.fl (the name can change, but the functionality is useful) and am going to reopen this.  Namely, it is often the case where one wants all values that aren&apos;t explicitly mapped to go into a default field and I don&apos;t think that is possible using uprefix.  Since all metadata fields aren&apos;t knowable up front, there is currently no way to express this in the ExtractingRequestHandler.&lt;/p&gt;</comment>
                            <comment id="12754635" author="gsingers" created="Sun, 13 Sep 2009 00:01:56 +0100"  >&lt;p&gt;Adds in defaultField parameter and tests.&lt;/p&gt;</comment>
                            <comment id="12754644" author="yseeley@gmail.com" created="Sun, 13 Sep 2009 01:25:48 +0100"  >&lt;blockquote&gt;&lt;p&gt;it is often the case where one wants all values that aren&apos;t explicitly mapped to go into a default field&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What&apos;s the real use-case, to be able to search all metadata?  One could use a dynamic copyField into a single indexed field.  That also helps if one sttill wants to keep all of the stored values for the metadata in separate fields.&lt;/p&gt;</comment>
                            <comment id="12754646" author="gsingers" created="Sun, 13 Sep 2009 02:17:25 +0100"  >&lt;blockquote&gt;&lt;p&gt;What&apos;s the real use-case, to be able to search all metadata? One could use a dynamic copyField into a single indexed field. That also helps if one sttill wants to keep all of the stored values for the metadata in separate fields.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, that works too, but it is convoluted and I may not care about storing the attributes nor want to deal with copyFields and the extra performance costs.  It just seems easier to have a default field capability.  Then one can just have everything go to it.&lt;/p&gt;</comment>
                            <comment id="12755008" author="gsingers" created="Mon, 14 Sep 2009 15:52:54 +0100"  >&lt;p&gt;Yonik, any objections to me committing the current patch given your concerns?&lt;/p&gt;</comment>
                            <comment id="12755053" author="dsmiley" created="Mon, 14 Sep 2009 17:12:14 +0100"  >&lt;p&gt;Grant, your response confuses me.  How does a copyField &lt;em&gt;necessitate&lt;/em&gt; storing the fields?  And how is the copyField slower than this feature mapping to a common attribute which ends up with an equivalent outcome?&lt;/p&gt;</comment>
                            <comment id="12755058" author="gsingers" created="Mon, 14 Sep 2009 17:22:31 +0100"  >&lt;blockquote&gt;&lt;p&gt;How does a copyField necessitate storing the fields?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yonik suggested his approach helps with stored values for the metadata.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;And how is the copyField slower than this feature mapping to a common attribute which ends up with an equivalent outcome? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As I understand Yonik&apos;s response, he was suggesting that I use the uprefix combined with copy fields.  That involves two field entries, when I only care about the one catch all.  copyFields do have a cost, especially when you don&apos;t need them.&lt;/p&gt;

&lt;p&gt;At any rate, with the patch I put up, you have the option of doing it either way.&lt;/p&gt;</comment>
                            <comment id="12755468" author="gsingers" created="Tue, 15 Sep 2009 13:42:24 +0100"  >&lt;p&gt;Committed revision 815293.&lt;/p&gt;</comment>
                            <comment id="12756154" author="ryguasu" created="Wed, 16 Sep 2009 19:25:52 +0100"  >&lt;p&gt;This caught me by surprise, so I&apos;m noting it here in case it helps anyone else:&lt;/p&gt;

&lt;p&gt;In SVN r815830 (September 16, 2009), Grant renamed the field name mapping argument &quot;map&quot; to &quot;fmap&quot;. The reason was to make naming more consistent with the CSV handler. For more info on this see the following thread:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.nabble.com/Fwd%3A-CSV-Update---Need-help-mapping-csv-field-to-schema%27s-ID-td25463942.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.nabble.com/Fwd%3A-CSV-Update---Need-help-mapping-csv-field-to-schema%27s-ID-td25463942.html&lt;/a&gt;&lt;/p&gt;
</comment>
                            <comment id="12756259" author="ryguasu" created="Wed, 16 Sep 2009 23:27:45 +0100"  >&lt;p&gt;Grant and company: I just noticed that the example solrconfig.xml at the head of SVN trunk still uses map, not fmap. (In particular, there&apos;s &quot;map.content&quot;, &quot;map.a&quot;, and &quot;map.div&quot;.) I assume this should be fixed for the 1.4 release. Interestingly, this doesn&apos;t seem to make any unit tests fail.&lt;/p&gt;</comment>
                            <comment id="12756266" author="yseeley@gmail.com" created="Wed, 16 Sep 2009 23:43:36 +0100"  >&lt;blockquote&gt;&lt;p&gt;example solrconfig.xml at the head of SVN trunk still uses map, not fmap.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks, I just fixed this.&lt;/p&gt;</comment>
                            <comment id="12775499" author="gsingers" created="Tue, 10 Nov 2009 15:51:42 +0000"  >&lt;p&gt;Bulk close for Solr 1.4&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12408366">SOLR-852</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12408569">SOLR-862</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12430269">SOLR-1274</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12399726" name="SOLR-284-no-key-gen.patch" size="6389" author="gsingers" created="Sat, 7 Feb 2009 16:01:44 +0000"/>
                            <attachment id="12419404" name="SOLR-284.patch" size="5437" author="gsingers" created="Sun, 13 Sep 2009 00:01:55 +0100"/>
                            <attachment id="12413344" name="SOLR-284.patch" size="34139" author="yseeley@gmail.com" created="Mon, 13 Jul 2009 22:21:05 +0100"/>
                            <attachment id="12395210" name="SOLR-284.patch" size="126587" author="ryguasu" created="Wed, 3 Dec 2008 20:46:28 +0000"/>
                            <attachment id="12395150" name="SOLR-284.patch" size="130534" author="ryguasu" created="Wed, 3 Dec 2008 00:49:56 +0000"/>
                            <attachment id="12394799" name="SOLR-284.patch" size="127132" author="ryguasu" created="Thu, 27 Nov 2008 01:23:18 +0000"/>
                            <attachment id="12394777" name="SOLR-284.patch" size="126403" author="ryguasu" created="Wed, 26 Nov 2008 21:15:57 +0000"/>
                            <attachment id="12394765" name="SOLR-284.patch" size="126017" author="ryguasu" created="Wed, 26 Nov 2008 17:18:19 +0000"/>
                            <attachment id="12393993" name="SOLR-284.patch" size="137669" author="gsingers" created="Sat, 15 Nov 2008 21:12:58 +0000"/>
                            <attachment id="12393987" name="SOLR-284.patch" size="130047" author="gsingers" created="Sat, 15 Nov 2008 16:52:23 +0000"/>
                            <attachment id="12360970" name="libs.zip" size="5014466" author="epugh" created="Mon, 2 Jul 2007 22:15:41 +0100"/>
                            <attachment id="12389580" name="rich.patch" size="83146" author="ryguasu" created="Fri, 5 Sep 2008 20:22:11 +0100"/>
                            <attachment id="12389472" name="rich.patch" size="81030" author="ryguasu" created="Thu, 4 Sep 2008 01:33:11 +0100"/>
                            <attachment id="12388086" name="rich.patch" size="80555" author="ryguasu" created="Tue, 12 Aug 2008 22:27:52 +0100"/>
                            <attachment id="12381628" name="rich.patch" size="81044" author="ryguasu" created="Wed, 7 May 2008 21:37:55 +0100"/>
                            <attachment id="12381611" name="rich.patch" size="414111" author="ryguasu" created="Wed, 7 May 2008 19:17:13 +0100"/>
                            <attachment id="12379772" name="rich.patch" size="69678" author="ryguasu" created="Wed, 9 Apr 2008 22:31:39 +0100"/>
                            <attachment id="12365107" name="rich.patch" size="3627" author="epugh" created="Tue, 4 Sep 2007 20:48:02 +0100"/>
                            <attachment id="12419229" name="schema_update.patch" size="2657" author="yseeley@gmail.com" created="Thu, 10 Sep 2009 23:31:32 +0100"/>
                            <attachment id="12394495" name="solr-word.pdf" size="21052" author="gsingers" created="Sat, 22 Nov 2008 23:56:32 +0000"/>
                            <attachment id="12365110" name="source.zip" size="17346" author="epugh" created="Tue, 4 Sep 2007 21:10:48 +0100"/>
                            <attachment id="12381612" name="test-files.zip" size="1046109" author="ryguasu" created="Wed, 7 May 2008 19:19:05 +0100"/>
                            <attachment id="12360969" name="test-files.zip" size="1058261" author="epugh" created="Mon, 2 Jul 2007 22:11:10 +0100"/>
                            <attachment id="12365113" name="test.zip" size="8447" author="epugh" created="Tue, 4 Sep 2007 21:14:33 +0100"/>
                            <attachment id="12389188" name="un-hardcode-id.diff" size="3724" author="ryguasu" created="Fri, 29 Aug 2008 20:34:41 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 2 Jul 2007 21:13:12 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7306</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hxxs9z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>20900</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>