<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 05:09:41 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/PIG-1518/PIG-1518.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[PIG-1518] multi file input format for loaders</title>
                <link>https://issues.apache.org/jira/browse/PIG-1518</link>
                <project id="12310730" key="PIG">Pig</project>
                    <description>&lt;p&gt;We frequently run in the situation where Pig needs to deal with small files in the input. In this case a separate map is created for each file which could be very inefficient. &lt;/p&gt;

&lt;p&gt;It would be greate to have an umbrella input format that can take multiple files and use them in a single split. We would like to see this working with different data formats if possible.&lt;/p&gt;

&lt;p&gt;There are already a couple of input formats doing similar thing: MultifileInputFormat as well as CombinedInputFormat; howevere, neither works with ne Hadoop 20 API. &lt;/p&gt;

&lt;p&gt;We at least want to do a feasibility study for Pig 0.8.0.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12470197">PIG-1518</key>
            <summary>multi file input format for loaders</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yanz">Yan Zhou</assignee>
                                    <reporter username="olgan">Olga Natkovich</reporter>
                        <labels>
                    </labels>
                <created>Mon, 26 Jul 2010 21:53:35 +0100</created>
                <updated>Tue, 10 Jan 2012 07:30:18 +0000</updated>
                            <resolved>Thu, 26 Aug 2010 18:59:18 +0100</resolved>
                                                    <fixVersion>0.8.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="12894205" author="yanz" created="Sat, 31 Jul 2010 00:46:52 +0100"  >&lt;p&gt;CombinedInputFormat, in lieu of the deprecated MultiFileInputFomrat,  batches small files on the basis of block locality. For PIG, this umbrella input format will have to work with the generic input formats for which the block info is not available but the data node and size info are present to let the M/R make scheduling decisions.&lt;/p&gt;

&lt;p&gt;CombinedInputFormat, in lieu of the deprecated MultiFileInputFomrat,  batches small files on the basis of block locality. For PIG, this umbrella input format will have to work with the generic input formats for which the block info is unavailable but the data node and size info are present to let the M/R make scheduling decisions. In other words, PIG can not&lt;br/&gt;
break the original splits to &quot;work inside&quot; but can just use the original splits as building block for the combined input splits.&lt;/p&gt;

&lt;p&gt;Consequently, this combine input format will be holding multiple generic input splits so that each combined split&apos;s size is bound by a configured limit of, say, pig.maxsplitsize, with the default value of the HDFS block size of the file system the load source sits in.&lt;/p&gt;

&lt;p&gt;However, due to the constrains of sortness in the tables in merge join, the split combination will not be used for any loads that will be used in merge join. For mapside cogroup or mapside group by, though, the splits can be combined because the splits are only required to contain the all duplicate keys per instance and combination of splits will still preserve that invariant.&lt;/p&gt;

&lt;p&gt;During combination, the splits on the same data nodes will be merged as much as possible. Leftovers will be merged without regarding to the data localities. Of all the used data nodes, those of less splits will be merged before considering those of more splits so as to minimize the leftovers on the data nodes of less splits. On each data node,  a greedy approach is adopted so that largest splits are tried to be merged before smaller ones. This is because smaller splits are easier merged later among themselves. &lt;br/&gt;
As result, in implementation, a sorted list of data hosts (on the number of splits) of sorted lists (on the split size) of the original splits will be maintained to efficiently perform the above operations. The complexity should be linear with the number of the original splits.&lt;/p&gt;

&lt;p&gt;Note that for data locality, we just honor whatever the generic input split&apos;s getLocations() method produces. Any particular input split&apos;s implementation actually may or may not hold that property. For instance, CombinedInputFormat will combine &lt;br/&gt;
node-local or rack-local blocks into a split. Essentially, this PIG container input split works on whatever data locality perception the underlying loader provides.&lt;/p&gt;

&lt;p&gt;On the implementation side, PigSplit will not hold a single wrapped InputSplit instance but a new CombinedInputSplit instance. Accordingly, PigRecordReader will hold a list&lt;br/&gt;
of wrapped record readers and not just a single one. Correspondingly PigRecordReader&apos;s nextKeyValue() will use the wrapped record reader in order to fetch the next values.&lt;/p&gt;

&lt;p&gt;Risks include 1) the test verifications may need major changes since this optimization may cause major ordering changes in results; 2) since LoadFunc.prepareRead() takes a PigSplit argument, there might be a backward compatibility issue as PigSplit changes its wrapped input split to the combined input split. But this should be very unlikely as the only known&lt;br/&gt;
use of the PigSplit argument is the internal  &quot;index loader&quot; for the right table in merge join.&lt;/p&gt;</comment>
                            <comment id="12894778" author="yanz" created="Tue, 3 Aug 2010 02:43:12 +0100"  >&lt;p&gt;In contrast with Hive, where the CombineFileInputFormat is used to generate input splits on the underlying storage formats, this PIG&apos;s combined splits work on top of the splits generated by the underlying loaders. In other words, Hive&apos;s input splits are CombineFileSplits that create record readers of underlying storage formats; while Pig&apos;s combined input splits contain underlying storage&apos;s splits.&lt;/p&gt;

&lt;p&gt;CombineFileRecordReader would have been reusable if not for its support only in 0.18 and the need of  CombineFIleSplit as an argument to its constructor instead of InputSplit (&lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-955&quot; title=&quot;CombineFileRecordReader should pass a InputSplit in the constructor instead of CombineFileSplit&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-955&quot;&gt;MAPREDUCE-955&lt;/a&gt;).&lt;/p&gt;</comment>
                            <comment id="12895335" author="yanz" created="Wed, 4 Aug 2010 18:56:29 +0100"  >&lt;p&gt;The combination algorithm currently does not consider rack-locality as the generic underlying input splits do not carry the rack info. For more specific input splits like FileSplit, the rack info is available, thus allowing for generation of combined splits with consideration of rack-locality. But this might be out of scope for 0.8 and a seperate JIRA, &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-1535&quot; title=&quot;Combined input splits need to consider rack-locality for the underlying splits of rack info.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-1535&quot;&gt;PIG-1535&lt;/a&gt;, has been filed for that purpose.&lt;/p&gt;</comment>
                            <comment id="12895338" author="yanz" created="Wed, 4 Aug 2010 19:02:55 +0100"  >&lt;p&gt;To provide a safe valve for any input fomats that might dislike the combination of their splits, a boolean property of pig.splitcombinaton is to be provided to allow for disabling this feature. The default value will be true.&lt;/p&gt;</comment>
                            <comment id="12897085" author="yanz" created="Wed, 11 Aug 2010 00:38:01 +0100"  >&lt;p&gt;The pseudo code of the combination op is as follows:&lt;/p&gt;

&lt;p&gt;for each node of the nodes (sorted in the order of ascending sizes) {&lt;br/&gt;
while the node&apos;s split list (sorted in the order of descending sizes) is not empty {&lt;br/&gt;
find the biggest splits that can be combined with the first split of the list of the splits;&lt;br/&gt;
if  the accumulated split size is &amp;gt;= half of the limit &lt;/p&gt;
{
  generate a combined split;
  remove the accumulated splits from the node&apos;s split list;
  clear the accumulated split list;
}
&lt;p&gt; else &lt;/p&gt;
{
  break;
}
&lt;p&gt;}&lt;br/&gt;
}&lt;/p&gt;

&lt;p&gt;// leftover combination&lt;br/&gt;
for each node of the nodes {&lt;br/&gt;
for each split of the node&apos;s split list &lt;/p&gt;
{
  add the split to a leftover list;
}
&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;for each split in the leftover list {&lt;br/&gt;
if accumulated split size is &amp;gt;= limit &lt;/p&gt;
{
   generate a combined split;
   remove the accumulated splits from the node&apos;s split list;
   clear the accumulated split list;
}
&lt;p&gt;if it is the last split in the leftover list &lt;/p&gt;
{
  try to see if it can be added with an existing combined split;
  if not, generate a combined split on the accumulated splits;
}
&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;The complexity is n*log&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; with n being the number of original splits that are smaller than the limit.&lt;/p&gt;</comment>
                            <comment id="12897368" author="alangates" created="Wed, 11 Aug 2010 19:27:10 +0100"  >&lt;blockquote&gt;&lt;p&gt;For mapside cogroup or mapside group by, though, the splits can be combined because the splits are only required to contain the all duplicate keys per instance and combination of splits will still preserve that invariant.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You are correct for mapside group, but not mapside cogroup.  Mapside cogroup does require all files being grouped to be processed in an ordered fashion.  &lt;/p&gt;</comment>
                            <comment id="12897493" author="yanz" created="Wed, 11 Aug 2010 23:30:32 +0100"  >&lt;p&gt;Right, map side cogroup needs the sortness of the input, but just the &quot;side inputs&quot; need the feature to be able to seek on a key; the &quot;base input&quot; will only need presence of all duplicate keys in a mapper. I&apos;ll mark the &quot;side inputs&quot; as non-combinable.&lt;/p&gt;</comment>
                            <comment id="12897887" author="yanz" created="Thu, 12 Aug 2010 19:35:36 +0100"  >&lt;p&gt;During the merge process, any empty splits will be skipped. Currently empty splits will be generated on empty files, which is not necessary at the first place.&lt;/p&gt;</comment>
                            <comment id="12898490" author="yanz" created="Sat, 14 Aug 2010 02:05:28 +0100"  >&lt;p&gt;There is a bigger question at hand. The semantics of OrderedLoadFunc is that the splits are totally ordered. And BinStorage, InterStorage and PigStorage all implement that interface through FileInputLoadFunc. Since the combination of splits as conceived here will definitely destroy the split ordering, if the combination is disabled for these storages, the feature would be virtually useless for a majority of use cases.&lt;/p&gt;

&lt;p&gt;On the other hand, I&apos;m seeing no use of the comparison capability except for MergeJoinIndexer&apos;s getNext() method, which makes me wonder if the OrderedLoadFunc can be removed from the FileInputLoadFunc.  Semantically, FileInputLoadFunc should not support the ordering of splits, as Hadoop&apos;s FileInputFormat doesn&apos;t. When a need arises like in MergeJoinIndexer, we can add that extension on. But the change may incur some backward compatibility issues.&lt;br/&gt;
I&apos;m now soliciting comments in this area.&lt;/p&gt;</comment>
                            <comment id="12898648" author="ashutoshc" created="Sat, 14 Aug 2010 22:56:06 +0100"  >&lt;p&gt;This feature of combining multiple splits should honor OrderedLoadFunc interface. If loadfunc is implementing that interface, then splits generated by it should not be combined. However, its not clear why FileInputLoadFunc implements this interface. AFAIK, split[] returned by getsplits() on FileInputFormat makes no guarantees that underlying splits will be returned in ordered fashion. Though, it is a default behavior right now and thus making it implement OrderedLoadFunc doesnt result in any problem in current implementation. But it seems there is no real benefit of FileInputLoadFunc needing to implement it (there is one exception to which I will come later on). So, I will argue that FileInputLoadFunc stop implementing OrderedLoadFunc. This will result in immediate benefit of making this change useful to all the fundamental storage mechanisms of Pig like PigStorage, BinStorage, InterStorage etc. Dropping of an interface by an implementing class  can be seen as backward incompatible change, but I really doubt if any one cares if PigStorage is reading splits in an ordered fashion. &lt;br/&gt;
Only real victim of this change will be MergeJoin which will stop working with PigStorage by default. But we have not seen MergeJoin being used with PigStorage at many places. Second, its anyway is based on assumption of FileInputFormat which may choose to change behavior in future. Third, solution of this problem will be straight forward that having other Loader which extends PigStorage and implements OrderedLoadFunc which can be used to load data for merge join. &lt;/p&gt;

&lt;p&gt;In essence I am arguing to drop OrderedLoadFunc interface from FileInputLoadFunc so that this feature is useful for large number of usecases.&lt;/p&gt;

&lt;p&gt;Yan, you also need to watch out for ReadToEndLoader which is also making assumptions which may break in presence of this feature.&lt;/p&gt;</comment>
                            <comment id="12899445" author="yanz" created="Tue, 17 Aug 2010 17:03:23 +0100"  >&lt;p&gt;Another approach is to mark splits as uncombinable only when necessary. Specifically, MergeJoinIndexer and the base load in mapside cogroup need to be excluded from the split combination. &lt;/p&gt;

&lt;p&gt;Breaking backward compatinility is probably too much a risk to take. In the meanwhile, OrderedLoadFunc has a notion of &quot;being evolving&quot; that will leave some headroom for future semantic polishes.&lt;/p&gt;</comment>
                            <comment id="12899605" author="yanz" created="Tue, 17 Aug 2010 22:43:05 +0100"  >&lt;p&gt;One experimental result on a 15-node cluster of 2 x Xeon L5420 2.50GHz/16G RAM boxes is as follows:&lt;/p&gt;

&lt;p&gt;Query:&lt;/p&gt;

&lt;p&gt;register pigperf.jar;&lt;br/&gt;
A = load &apos;/user/pig/tests/data/pigmix/page_views&apos; using org.apache.pig.test.udf.storefunc.PigPerformanceLoader()&lt;br/&gt;
    as (user, action, timespent, query_term, ip_addr, timestamp,&lt;br/&gt;
        estimated_revenue, page_info, page_links);&lt;br/&gt;
B = foreach A generate user, (double)estimated_revenue;&lt;br/&gt;
B1 = distinct B;&lt;br/&gt;
alpha = load &apos;/user/pig/tests/data/pigmix/users&apos; using PigStorage(&apos;\u0001&apos;) as (name, phone, address,&lt;br/&gt;
        city, state, zip);&lt;br/&gt;
beta = foreach alpha generate name;&lt;br/&gt;
C = join beta by name, B1 by user parallel 300;&lt;br/&gt;
D = group C by $0 parallel 40;&lt;br/&gt;
E = foreach D generate group, SUM(C.estimated_revenue);&lt;br/&gt;
store E into &apos;spliCombo2.out&apos;;&lt;/p&gt;

&lt;p&gt;It creates 3 map/reduce jobs.&lt;/p&gt;

&lt;p&gt;No Split Combination:&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Mappers&lt;/th&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Reducers&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;number&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;120&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;300&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;elapsed time&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;24s&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2m43s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;number&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;301&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;300&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;elapsed time&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;46s&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3m11s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;number&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;300&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;40&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;elapsed time&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;38s&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;53s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Total elapsed time&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7m36s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;



&lt;p&gt;With Split Combination:&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;mappers&lt;/th&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Reducers&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;number&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;120&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;300&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;elapsed time&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;22s&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2m49s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;number&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;300&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;elapsed time&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;27s&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2m46s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;number&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;40&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;elapsed time&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;17s&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;24s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Total elapsed time&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7m5s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
</comment>
                            <comment id="12899609" author="yanz" created="Tue, 17 Aug 2010 22:45:15 +0100"  >&lt;p&gt;The formatting of the table of the last comment is a bit off: both headers should be be right-shifted by one column.&lt;/p&gt;</comment>
                            <comment id="12899888" author="yanz" created="Wed, 18 Aug 2010 17:16:29 +0100"  >&lt;p&gt;In summary, the split combination&apos;s controllables are through the following jvm properties:&lt;/p&gt;

&lt;p&gt;pig.maxCombinedSplitSize: by default, it is the load filesystem&apos;s default block size. This specifies the maximum combined split size in unit of bytes;&lt;/p&gt;

&lt;p&gt;pig.splitCombination: takes values of &quot;false&quot; and &quot;true&quot;. The default is &quot;true&quot;. &quot;false&quot; will disable the split combination.&lt;/p&gt;</comment>
                            <comment id="12900002" author="mridul" created="Wed, 18 Aug 2010 20:58:48 +0100"  >&lt;p&gt;if optimizer is turned off, does this also get turned off ? (pig.splitCombination= false).&lt;/p&gt;</comment>
                            <comment id="12900123" author="yanz" created="Thu, 19 Aug 2010 01:37:12 +0100"  >&lt;p&gt;No. It does not work inside an optimizer as logical/physical plans are not changed as the other optimizers do.&lt;/p&gt;</comment>
                            <comment id="12900908" author="yanz" created="Sat, 21 Aug 2010 00:07:34 +0100"  >&lt;p&gt;Style changes, Hudson pass, plus other minor changes. Internal Hudson results:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; -1 overall.&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;     +1 @author.  The patch does not contain any @author tags.&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;     +1 tests included.  The patch appears to include 3 new or modified tests.&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;     +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;     +1 findbugs.  The patch does not introduce any new Findbugs warnings.&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;     -1 release audit.  The applied patch generated 427 release audit warnings (more than the trunk&apos;s current 425 warnings).&lt;/p&gt;


&lt;p&gt;The release audit warnings are on two html files: PigInputFormat.html and PiRecordReader.html&lt;/p&gt;</comment>
                            <comment id="12901600" author="rding" created="Mon, 23 Aug 2010 22:36:12 +0100"  >&lt;p&gt;+1. The patch looks good.&lt;/p&gt;

&lt;p&gt;A few of minor points:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;In PigSplit, the method add(InputSplit split) is not used and can be removed&lt;/li&gt;
	&lt;li&gt;In MapRedUtil, it would be better to not leave the debug verification code in the source code&lt;/li&gt;
	&lt;li&gt;In PigRecordReader, the code can be simplified if the initNextRecordReader() from constructor to initialize() method&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12901636" author="yanz" created="Mon, 23 Aug 2010 23:34:07 +0100"  >&lt;p&gt;The add method if PigSplit is removed. The debug code is left to facilitate future debugging work. The use of initNextRecordReader is pretty cloned from org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader and I&apos;ll leave it as is too.&lt;/p&gt;</comment>
                            <comment id="12901681" author="yanz" created="Tue, 24 Aug 2010 01:17:49 +0100"  >&lt;p&gt;Fix a typo; rebase on the latest trunk.&lt;/p&gt;</comment>
                            <comment id="12902295" author="yanz" created="Wed, 25 Aug 2010 05:53:01 +0100"  >&lt;p&gt;Minor polish of a debugging code inside comments&lt;/p&gt;</comment>
                            <comment id="12902350" author="mridul" created="Wed, 25 Aug 2010 10:05:20 +0100"  >&lt;p&gt;Might be a good idea to contact aruniyer who maintains the FISH implementation.&lt;br/&gt;
It is essentially built upon pig split and custom loader.&lt;/p&gt;</comment>
                            <comment id="12902726" author="yanz" created="Thu, 26 Aug 2010 01:24:03 +0100"  >&lt;p&gt;Improvement on logging info.&lt;/p&gt;</comment>
                            <comment id="12902946" author="yanz" created="Thu, 26 Aug 2010 18:35:28 +0100"  >&lt;p&gt;rebased on the latest trunk&lt;/p&gt;</comment>
                            <comment id="12902957" author="rding" created="Thu, 26 Aug 2010 18:59:18 +0100"  >&lt;p&gt;Patch is committed to trunk. Thanks Yan.&lt;/p&gt;</comment>
                            <comment id="12903031" author="dvryaboy" created="Thu, 26 Aug 2010 21:31:31 +0100"  >&lt;p&gt;This is a great feature, thanks Yan.&lt;/p&gt;

&lt;p&gt;Could you comment on what the final solution was as far as PigStorage and OrderedLoadFunc? I see two ideas (yours and Ashutosh&apos;s) in the discussion, but not what the ultimate direction you took was.&lt;/p&gt;</comment>
                            <comment id="12903102" author="yanz" created="Thu, 26 Aug 2010 23:08:21 +0100"  >&lt;p&gt;It is not combinable if the loader is a CollectableLoadFunc AND a OrderedLoadFunc. Since PigStorage is a CollectableLoadFunc  but not a OrderedLoadFunc, it is combinable.&lt;/p&gt;</comment>
                            <comment id="12903283" author="ashutoshc" created="Fri, 27 Aug 2010 08:56:50 +0100"  >&lt;p&gt;Yan, &lt;br/&gt;
Sorry for being late on this now thats its committed. But I think you have gotten it other way around. A CollectableLoadFunc is combinable but OrderedLoadFunc is not. Lets go over all three interfaces:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;h4&gt;&lt;a name=&quot;CollectableLoadFunc%3AAloaderimplementingitmustmakesurethatallinstancesofaparticularkeyispresentinonesplit.Ifyoucombinesplitsofsuchaloader%2C...&quot;&gt;&lt;/a&gt;CollectableLoadFunc: A loader implementing it must make sure that all instances of a particular key is present in one split. If you combine splits of such a loader, it will still remain CollectableLoadFunc because all instances of keys will still be in same split after combination. It is dictating a property &lt;b&gt;within&lt;/b&gt; a split. Thus, its combinable.&lt;/h4&gt;&lt;/li&gt;
	&lt;li&gt;&lt;h4&gt;&lt;a name=&quot;OrderedLoadFunc%3AOrderedLoadFuncinsiststhatloaderimplementingitmustreadsplitsinawelldefinedorder.Ifyoucombinethesplits%2Cthatordermaynothold.Youcantcombinesplitsforthisloader.Itsdefiningapropertyacrossmultiplesplits.&quot;&gt;&lt;/a&gt;OrderedLoadFunc: OrderedLoadFunc insists that loader implementing it must read splits in a well defined order. If you combine the splits, that order may not hold. You cant combine splits for this loader. Its defining a property &lt;b&gt;across&lt;/b&gt; multiple splits.&lt;/h4&gt;&lt;/li&gt;
	&lt;li&gt;&lt;h4&gt;&lt;a name=&quot;IndexableLoadFunc%3ASaysthatloaderisindexablemeaninggivenakeyitwillgetyouascloseaspossibletothatkey.Itinherentlyassumesdataissortedandindexisbuiltforit.Yourcombinedsplitsmaynotremainsortedanymore....&quot;&gt;&lt;/a&gt;IndexableLoadFunc: Says that loader is indexable meaning given a key it will get you as close as possible to that key. It inherently assumes data is sorted and index is built for it. Your combined splits may not remain sorted anymore. You cant combine splits for this interface either. Its defining a property &lt;b&gt;across&lt;/b&gt; multiple splits.&lt;/h4&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;If you agree with above then PigStorage isnt combinable because &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class PigStorage &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; FileInputLoadFunc &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; StoreFuncInterface,  LoadPushDown{}
and 
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;abstract&lt;/span&gt; class FileInputLoadFunc &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; LoadFunc &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; OrderedLoadFunc  {}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I also didnt get your logic for &lt;b&gt;CollectableLoadFunc AND a OrderedLoadFunc&lt;/b&gt; It will help if you can explain that a bit.&lt;/p&gt;</comment>
                            <comment id="12903423" author="yanz" created="Fri, 27 Aug 2010 15:17:11 +0100"  >&lt;p&gt;MergeJoinIndexer and IndexableLoadFunc are both not combinable.&lt;/p&gt;

&lt;p&gt;Regarding orderedLoadFunc, the story is a bit more complex. First of all, it&apos;s only non-overriden method, getSplitComparable, is only used in MergeJoinIndexer which is already not combinable. &lt;/p&gt;

&lt;p&gt;The big issue is FileInputLoadFunc which is extended by BinStorage, PigStorage and InterStorage. Semantically, I agree OrderedLoadFunc should not be combinable. However, FileInputFormat&apos;s implementation of OrderedLoadFunc makes little sense in that its ordering is based on the  (path, offset) pair. This is an ordering but just an arbitrary ordering. Mathematically one can establish any arbitrary ordering over a discrete set of data. But the point is how is the ordering used. For our purpose, the ordering should be related to some keys used in data manipulation for which (path, offset) does not serve the purpose. Or implicitly a FileInputLoadFunc still requires the storage gives out splits in some key ordering. If that storage ordering does not actually exist, FileInputLoadFunc as an OrderedLoadFunc will have no use of its &quot;sortness&quot;&lt;br/&gt;
because the ordering is just, well, arbitray. The three extensions of FileInputLoadFunc work on generic data storage. Unless they work on sorted data in general, they should not be an OrderedLoadFunc.&lt;/p&gt;

&lt;p&gt;The other use of OrderedLoadFunc, not its non-overriden method, getSplitComparable, is by map-side cogroup. But it does not check if the sort key is the join key which is critical for correctness.  It also requires to be a CollectableLoadFunc to work properly.&lt;/p&gt;

&lt;p&gt;Since we do not want to break backward compatibility, and the only use of OrderLoadFunc in Pig, except for MergeJinIndexer which is already excluded from combining, is in map side cogroup with CollectableLoadFunc, I mark &quot;CollectableLoadFunc AND an OrderedLoadFunc&quot; as non-combinable.&lt;/p&gt;

&lt;p&gt;In the future, we should really clean up the the OrderedLoadFunc from FileInputLoadFunc and let the getSplitComparable method provide key-related info and not the (path, offset) pair. Backward compatibility may need to be addressed too. Only then will the water become clearer and I be ok to adjust the noncombinable setting accordingly.&lt;/p&gt;</comment>
                            <comment id="12903501" author="olgan" created="Fri, 27 Aug 2010 19:08:40 +0100"  >&lt;p&gt;After discussion with Ashutosh and Yan tha agreement is that in addition to checking interfaces we also need to check if we are taking advantage of the loader properties before deciding whether to combine or not.&lt;/p&gt;

&lt;p&gt;For instance, even if the loader implements OrderLoadFunc but there is no merge join in the script, we can still combine.&lt;/p&gt;

&lt;p&gt;Yan, please, compile the list of valid combinations and update the patch, thanks.&lt;/p&gt;</comment>
                            <comment id="12903525" author="yanz" created="Fri, 27 Aug 2010 19:46:32 +0100"  >&lt;p&gt;In summary, the following functionalities won&apos;t see splits combined on loads:&lt;/p&gt;

&lt;p&gt;1) map-side cogroup;&lt;br/&gt;
2) merge join;&lt;/p&gt;</comment>
                            <comment id="12903528" author="yanz" created="Fri, 27 Aug 2010 19:51:49 +0100"  >&lt;p&gt;All other functionalities except for the two mentioned in the previous comment will see splits combined by default, if necessary.&lt;/p&gt;</comment>
                            <comment id="12906536" author="justinjas" created="Mon, 6 Sep 2010 17:36:58 +0100"  >&lt;p&gt;Backported &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-1518&quot; title=&quot;multi file input format for loaders&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-1518&quot;&gt;&lt;del&gt;PIG-1518&lt;/del&gt;&lt;/a&gt; to the 0.7.0 branch and wanted to share incase anyone else was trying to do the same thing.&lt;/p&gt;</comment>
                            <comment id="12907805" author="olgan" created="Thu, 9 Sep 2010 23:35:17 +0100"  >&lt;p&gt;Hi Justin, thanks for the patch!&lt;/p&gt;

&lt;p&gt;I don&apos;t think we can commit it to 0.7 patch because we have already done the official 0.7 release and we can&apos;t introduce non-backward compatible changes to this branch.&lt;/p&gt;

&lt;p&gt;However, I think it is great to have the patch on the JIRA so that anybody who is interested in this patch can apply it to their own tree and run with it. We have done similar things in the past (with hadoop versions) and it worked fine.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12537799">PIG-2462</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12453951" name="PIG-1518-0.7.0.patch" size="58544" author="justinjas" created="Mon, 6 Sep 2010 17:36:58 +0100"/>
                            <attachment id="12453150" name="PIG-1518.patch" size="59181" author="yanz" created="Thu, 26 Aug 2010 18:35:28 +0100"/>
                            <attachment id="12453135" name="PIG-1518.patch" size="59181" author="yanz" created="Thu, 26 Aug 2010 16:17:12 +0100"/>
                            <attachment id="12453092" name="PIG-1518.patch" size="59209" author="yanz" created="Thu, 26 Aug 2010 01:24:03 +0100"/>
                            <attachment id="12453008" name="PIG-1518.patch" size="59271" author="yanz" created="Wed, 25 Aug 2010 05:53:01 +0100"/>
                            <attachment id="12452879" name="PIG-1518.patch" size="59378" author="yanz" created="Tue, 24 Aug 2010 01:17:49 +0100"/>
                            <attachment id="12452873" name="PIG-1518.patch" size="59377" author="yanz" created="Mon, 23 Aug 2010 23:34:06 +0100"/>
                            <attachment id="12452679" name="PIG-1518.patch" size="59836" author="yanz" created="Sat, 21 Aug 2010 00:07:34 +0100"/>
                            <attachment id="12452408" name="PIG-1518.patch" size="53435" author="yanz" created="Wed, 18 Aug 2010 17:02:47 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 30 Jul 2010 23:46:52 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>165001</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hyar9z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>96730</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Feature: combine splits of sizes smaller than the value of property &amp;quot;pig.maxCombinedSplitSize&amp;quot; or, if the property of &amp;quot;pig.maxCombinedSplitSize&amp;quot; is not set, the file system default block size of the load&amp;#39;s location. This feature can be turned off through setting the property &amp;quot;pig.splitCombination&amp;quot; to &amp;quot;false&amp;quot;. When such a combination is performed, a log message like &amp;quot;Total input paths (combined) to process : 7&amp;quot; will be logged. &lt;br/&gt;
&lt;br/&gt;
This feature will be applicable if a user input, or an intermediate input, has many small files to be loaded that would otherwise cause many more &amp;quot;under-fed&amp;quot; mappers to be launched and potentially slowdown of the execution.&lt;br/&gt;
&lt;br/&gt;
This change will not cause any backward compatibility issue except if a loader implementation makes use of the PigSplit object passed through the prepareToRead method where a rebuild of the loader might be necessary as PigSplit&amp;#39;s definition has been modified. However, currently we know of no external use of the object.&lt;br/&gt;
&lt;br/&gt;
This change also requires the loader to be stateless across the invocations to the prepareToRead method. That is, the method should reset any internal states that are not affected by the RecordReader argument.&lt;br/&gt;
Otherwise, this feature should be disabled.&lt;br/&gt;
&lt;br/&gt;
In addition, if a loader implements IndexableLoadFunc, or implements OrderedLoadFunc and CollectableLoadFunc, its input splits won&amp;#39;t be subject to possible combinations.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>