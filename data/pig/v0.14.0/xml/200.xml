<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:55:35 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/PIG-200/PIG-200.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[PIG-200] Pig Performance Benchmarks</title>
                <link>https://issues.apache.org/jira/browse/PIG-200</link>
                <project id="12310730" key="PIG">Pig</project>
                    <description>&lt;p&gt;To benchmark Pig performance, we need to have a TPC-H like Large Data Set plus Script Collection. This is used in comparison of different Pig releases, Pig vs. other systems (e.g. Pig + Hadoop vs. Hadoop Only).&lt;/p&gt;

&lt;p&gt;Here is Wiki for small tests: &lt;a href=&quot;http://wiki.apache.org/pig/PigPerformance&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/pig/PigPerformance&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I am currently running long-running Pig scripts over data-sets in the order of tens of TBs. Next step is hundreds of TBs.&lt;/p&gt;

&lt;p&gt;We need to have an open large-data set (open source scripts which generate data-set) and detailed scripts for important operations such as ORDER, AGGREGATION etc.&lt;/p&gt;

&lt;p&gt;We can call those the Pig Workouts: Cardio (short processing), Marathon (long running scripts) and Triathlon (Mix). &lt;/p&gt;

&lt;p&gt;I will update this JIRA with more details of current activities soon.&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12393604">PIG-200</key>
            <summary>Pig Performance Benchmarks</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/task.png">Task</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="alangates">Alan Gates</assignee>
                                    <reporter username="amirhyoussefi">Amir Youssefi</reporter>
                        <labels>
                    </labels>
                <created>Thu, 10 Apr 2008 02:12:55 +0100</created>
                <updated>Wed, 2 Oct 2013 22:50:34 +0100</updated>
                            <resolved>Mon, 26 Jan 2009 20:21:08 +0000</resolved>
                                                    <fixVersion>0.2.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>11</watches>
                                                                <comments>
                            <comment id="12587661" author="alangates" created="Thu, 10 Apr 2008 15:49:36 +0100"  >&lt;p&gt;Amir,&lt;/p&gt;

&lt;p&gt;I have a perl script that I use to generate data for pig testing.  It can generate different types of data and different sizes.  For a given type and size, it always produces the same set.  However, for data of the same type and different sizes, the smaller is not a subset of the larger.  This allows it to produce good data for testing joins.  If you&apos;re interested in using this for your benchmarking, let me know.&lt;/p&gt;</comment>
                            <comment id="12587674" author="acmurthy" created="Thu, 10 Apr 2008 16:31:13 +0100"  >&lt;blockquote&gt;&lt;p&gt;I have a perl script that I use to generate data for pig testing. &lt;span class=&quot;error&quot;&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I managed to use the same script via a Pig-Streaming job to generate large amounts of data in a parallel manner, the only change I needed was to edit it to switch off the sql generation...&lt;/p&gt;</comment>
                            <comment id="12602627" author="pi_song" created="Thu, 5 Jun 2008 13:10:23 +0100"  >&lt;p&gt;To move this forward, I propose that we should have:-&lt;/p&gt;

&lt;p&gt;1) Small dataset test. Just a set of simple benchmarks for running on development box. For a common machine, it shouldn&apos;t take longer than 30 minutes in total.&lt;br/&gt;
2) Large dataset test. For real benchmarking.&lt;/p&gt;

&lt;p&gt;I think the test cases in &lt;a href=&quot;http://wiki.apache.org/pig/PigPerformance&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/pig/PigPerformance&lt;/a&gt; should already provide good coverage. We will have to do another review once query optimizer is in place.&lt;/p&gt;

&lt;p&gt;Alan,  could you please attach the perl script so that I can see what it does?&lt;/p&gt;
</comment>
                            <comment id="12603887" author="alangates" created="Tue, 10 Jun 2008 15:25:49 +0100"  >&lt;p&gt;Pi, here&apos;s the perl script I use to generate data for end-to-end testing, large and small.&lt;/p&gt;</comment>
                            <comment id="12653533" author="alangates" created="Thu, 4 Dec 2008 22:52:02 +0000"  >&lt;p&gt;The following attached patch takes a different approach to providing a set of benchmarks for pig.  It contains a set of 14 queries which are designed to try to cover a range of ways users use pig.  It also includes implementations of the same queries in java code for map reduce, so that developers can compare pig performance against map reduce performance.  See &lt;a href=&quot;http://wiki.apache.org/pig/PigMix&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/pig/PigMix&lt;/a&gt; for information on how the queries were chosen, how the data is constructed, and data from an initial run of 0.1.0 pig versus soon to be 0.2.0 pig.&lt;/p&gt;

&lt;p&gt;This attachment is not ready for inclusion in the code.  It has several issues.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;The library used to generate the zipf distributions in the data is under the GNU public license, and thus cannot be included.  The library can be obtained at &lt;a href=&quot;http://www.eli.sdsu.edu/java-SDSU/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.eli.sdsu.edu/java-SDSU/&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;The data generation script is single threaded because the zipf distribution generator is.  This means to generate 10m rows of data (about 15G) takes ~48 hours.  I&apos;d like to be able to generate larger data sets, but first I need to find a parallel zipf distribution generator that has a compatible license (or write one, which I don&apos;t really want to do).&lt;/li&gt;
	&lt;li&gt;There are places in the code (particularly the map reduce code) where path names etc. are hard wired to locations in my test setup.  These need to be generalized.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="12667397" author="olgan" created="Mon, 26 Jan 2009 20:21:08 +0000"  >&lt;p&gt;PigMix is out set of benchmarks going forward. &lt;/p&gt;</comment>
                            <comment id="12721959" author="zshao" created="Fri, 19 Jun 2009 20:45:48 +0100"  >&lt;p&gt;We made a benchmark for Hive based on the queries from the SIGMOD 2009 paper.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-396&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-396&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We also spent a lot of time in writing pig programs for those queries, and we have some preliminary results.&lt;br/&gt;
Will somebody from the pig team take a look and help improve the pig queries?&lt;/p&gt;</comment>
                            <comment id="12738556" author="yinghe" created="Mon, 3 Aug 2009 21:25:04 +0100"  >&lt;p&gt;perf.hadoop.patch is used to support running DataGenerator in hadoop mode. It should be installed on top of perf.patch. &lt;/p&gt;</comment>
                            <comment id="12738609" author="yinghe" created="Mon, 3 Aug 2009 22:25:50 +0100"  >&lt;p&gt;doc for DataGenerator in hadoop mode is here: &lt;a href=&quot;http://wiki.apache.org/pig/DataGeneratorHadoop&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/pig/DataGeneratorHadoop&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12844831" author="d_y_k_w" created="Sat, 13 Mar 2010 08:24:13 +0000"  >&lt;p&gt;How can I run the perf.patch? do I need the generate_data.sh in order to run those 14 queries?&lt;/p&gt;</comment>
                            <comment id="12844947" author="daijy" created="Sat, 13 Mar 2010 19:35:15 +0000"  >&lt;p&gt;Yes, as the name suggests, generate_data.sh will generate the input file for the queries.&lt;/p&gt;</comment>
                            <comment id="12845174" author="d_y_k_w" created="Mon, 15 Mar 2010 03:46:15 +0000"  >&lt;p&gt;Hi Daniel,&lt;/p&gt;

&lt;p&gt;How can I run the perf.patch? I saw a lot of different things in the perf.patch.&lt;br/&gt;
I want to generate data set and use those 14 pig queries for benchmarking.&lt;/p&gt;

&lt;p&gt;Would you mind telling me more on how to use the perf.patch?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;

&lt;p&gt;Duncan&lt;/p&gt;</comment>
                            <comment id="12845579" author="daijy" created="Mon, 15 Mar 2010 22:50:35 +0000"  >&lt;p&gt;Hi, Duncan,&lt;br/&gt;
perf.patch is a little bit old. I attach new perf-0.6.patch. Instruction to generate input data for Pigmix is:&lt;br/&gt;
1. apply perf-0.6.patch on pig 0.6 release&lt;br/&gt;
2. ant jar compile-test&lt;br/&gt;
3. export PIG_HOME=.&lt;br/&gt;
4. test/utils/pigmix/datagen/generate_data.sh&lt;/p&gt;</comment>
                            <comment id="12845581" author="daijy" created="Mon, 15 Mar 2010 22:51:51 +0000"  >&lt;p&gt;Miss one step, before you build, get &lt;a href=&quot;http://www.eli.sdsu.edu/java-SDSU/sdsuLibJKD12.jar&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.eli.sdsu.edu/java-SDSU/sdsuLibJKD12.jar&lt;/a&gt;, and put in your lib&lt;/p&gt;</comment>
                            <comment id="12846782" author="d_y_k_w" created="Thu, 18 Mar 2010 07:31:20 +0000"  >&lt;p&gt;Thank you very Daniel~&lt;/p&gt;</comment>
                            <comment id="12850795" author="d_y_k_w" created="Mon, 29 Mar 2010 06:39:50 +0100"  >&lt;p&gt;Hi ,&lt;/p&gt;

&lt;p&gt;I encountered build fail when I executed this command &quot;ant jar compile-test&quot;.&lt;br/&gt;
What do I need to installed before I execute this command?&lt;br/&gt;
Thanks&lt;/p&gt;

&lt;p&gt;Duncan&lt;/p&gt;</comment>
                            <comment id="12851293" author="daijy" created="Tue, 30 Mar 2010 08:09:26 +0100"  >&lt;p&gt;Hi, duncan,&lt;br/&gt;
I tried and I didn&apos;t see errors. Are you using pig 0.6 release? What error message did you see?&lt;/p&gt;</comment>
                            <comment id="12879256" author="daijy" created="Wed, 16 Jun 2010 07:03:39 +0100"  >&lt;p&gt;pigmix2.patch include all queries for PigMix2. It contains original 12 PigMix queries plus 5 new queries. New queries is to measure the performance of new Pig features. This patch also contains map-reduce version of data-generator. To use it:&lt;br/&gt;
1. Download pig 0.7 release&lt;br/&gt;
2. Apply the patch&lt;br/&gt;
3. copy &lt;a href=&quot;http://www.eli.sdsu.edu/java-SDSU/sdsuLibJKD12.jar&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.eli.sdsu.edu/java-SDSU/sdsuLibJKD12.jar&lt;/a&gt; to lib&lt;br/&gt;
4. ant jar pigperf&lt;br/&gt;
5. You will use pig.jar, pigperf.jar. Scripts is in test/utils/pigmix/scripts. To generate data, use generate_data.sh. To run PigMix2, use runpigmix-adhoc.pl.&lt;/p&gt;</comment>
                            <comment id="13039754" author="mead" created="Thu, 26 May 2011 17:10:11 +0100"  >&lt;p&gt;Hello Daniel,&lt;/p&gt;

&lt;p&gt;I am using pigmix2.patch now. It generates 625m records for the pages table, which is too large compared to the available disk space on my cluster. I would like to generate only 100m records of pages. Is there a ratio I should maintain between the size of the pages table and the other tables; users and power users?&lt;/p&gt;

&lt;p&gt;Thanks.&lt;br/&gt;
Mostafa Ead&lt;/p&gt;</comment>
                            <comment id="13042331" author="daijy" created="Wed, 1 Jun 2011 19:08:10 +0100"  >&lt;p&gt;All other table will derive data from pages. If you resize pages, other table will change automatically to maintain the proper ratio.&lt;/p&gt;</comment>
                            <comment id="13042335" author="aaa" created="Wed, 1 Jun 2011 19:11:47 +0100"  >&lt;p&gt;I am out of office on a business trip for next couple of days. I will&lt;br/&gt;
be slower than usual in responding to emails. If this is urgent then&lt;br/&gt;
please call my cell phone (or send an SMS), otherwise I will reply to&lt;br/&gt;
your email when I get back.&lt;/p&gt;

&lt;p&gt;Thanks for your patience,&lt;/p&gt;

&lt;p&gt;&amp;#8211; amr&lt;/p&gt;</comment>
                            <comment id="13140303" author="tlipcon" created="Mon, 31 Oct 2011 16:50:59 +0000"  >&lt;p&gt;To run in 0.9, I had to make some changes:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the new signature of bytesToMap in PigPerformanceLoader.Caster has to delegate to the old implementation (not through UnsupportedOperationException)&lt;/li&gt;
	&lt;li&gt;the loader script should really have a &quot;set -e&quot;, and ideally figure out which generation steps have already been completed successfully (mine failed several hours in due to OOME trying to load a giant lookaside map)&lt;/li&gt;
	&lt;li&gt;above Daniel says that you only need to resize &quot;pages&quot; in order to change the other datasets. But, the script has a variable defined for &quot;widerowcnt&quot; which implies otherwise. Do we need to manually adjust that or is it ignored? If ignored it should be set to 0 with a comment explaining that&lt;/li&gt;
	&lt;li&gt;cat $powerusers/* will try to cat a _logs directory - should probably only try to cat the data files&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13140428" author="daijy" created="Mon, 31 Oct 2011 18:41:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;above Daniel says that you only need to resize &quot;pages&quot; in order to change the other datasets. But, the script has a variable defined for &quot;widerowcnt&quot; which implies otherwise. Do we need to manually adjust that or is it ignored? If ignored it should be set to 0 with a comment explaining that&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;widerows is one exception you also need to specify the size. This is only used in L11. It should increase proportionally with the pageviews.&lt;/p&gt;</comment>
                            <comment id="13169599" author="dvryaboy" created="Wed, 14 Dec 2011 19:26:56 +0000"  >&lt;p&gt;Attaching a patch that works with pig 0.11 (current trunk).&lt;/p&gt;

&lt;p&gt;A few changes:&lt;/p&gt;

&lt;p&gt;1) Removed explicit hardcoded parallelism inside the pig scripts to let them scale automatically.&lt;/p&gt;

&lt;p&gt;2) All scripts respect the PIGMIX_DIR environment variable (so you don&apos;t have to have /user/pig on your cluster &amp;#8211; set $PIGMIX_DIR and use your own paths)&lt;/p&gt;

&lt;p&gt;3) Made the shell scripts respect $HADOOP_CLASSPATH &lt;/p&gt;

&lt;p&gt;4) PigPerformanceLoader is now part of e2e, so removed it from this patch. Fixed the e2e one to proxy bytesToMap to its caster instead of throwing an exception&lt;/p&gt;

&lt;p&gt;5) use /usr/bin/env to find perl, as not everyone has it in the same place. Use strict and warnings in perl.&lt;/p&gt;</comment>
                            <comment id="13169626" author="dvryaboy" created="Wed, 14 Dec 2011 19:48:22 +0000"  >&lt;p&gt;btw getting rid of the hardcoded &quot;parallel 40&quot; is a suggestion, feel free to push back. I haven&apos;t looked at what this does to multi-terabyte-sized loads. I do think we should consider measuring sum of task times instead of overall wall clock time &amp;#8211; it&apos;s a better measure of performance.&lt;/p&gt;</comment>
                            <comment id="13169851" author="jay23jack" created="Thu, 15 Dec 2011 00:15:42 +0000"  >&lt;p&gt;&quot;To benchmark Pig performance, we need to have a TPC-H like Large Data Set plus Script Collection.&quot;&lt;/p&gt;

&lt;p&gt;Now we have the TPC-H benchmark available for Pig (&lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-2397&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;PIG-2397&lt;/a&gt;)!! It can be used to measure the performance of Pig&apos;s relational operators, like projection, group, join, etc. Also, the complex workloads can help enrich Pig&apos;s multi-query optimization. More importantly, we can use it to compare Pig with Hive and many other systems to see what we can learn from them, and get a more intuitive understanding of Pig&apos;s performance.&lt;/p&gt;

&lt;p&gt;So I propose to include the TPC-H as part of the PigMix. &lt;/p&gt;</comment>
                            <comment id="13260155" author="jay23jack" created="Tue, 24 Apr 2012 03:22:34 +0100"  >&lt;p&gt;Did anyone notice that pig-0.9.0 uses an extra job for L9 than pig-0.8.1?&lt;/p&gt;

&lt;p&gt;L9 is very simple: (slightly changed for setting the default_parallel)&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
SET default_parallel $factor

register ../pigperf.jar;
A = load &apos;$input/pigmix_page_views&apos; using org.apache.pig.test.udf.storefunc.PigPerformanceLoader()
    as (user, action, timespent, query_term, ip_addr, timestamp,
        estimated_revenue, page_info, page_links);
B = order A by query_term;
store B into &apos;$output/L9out&apos;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;div class=&quot;panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;Output information of 0.8.1&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;panelContent&quot;&gt;
&lt;p&gt;JobId   Maps    Reduces MaxMapTime      MinMapTIme      AvgMapTime      MaxReduceTime   MinReduceTime   AvgReduceTime   Alias   Feature Outputs&lt;br/&gt;
job_201204222028_0192   60      1       33      12      20      102     102     102     B       SAMPLER &lt;br/&gt;
job_201204222028_0193   60      17      78      39      57      533     147     360     B       ORDER_BY        /tmp/10m-0.8.1/L9out,&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;Output information of 0.9.0&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;panelContent&quot;&gt;
&lt;p&gt;JobId   Maps    Reduces MaxMapTime      MinMapTIme      AvgMapTime      MaxReduceTime   MinReduceTime   AvgReduceTime   Alias&lt;br/&gt;
   Feature Outputs&lt;br/&gt;
job_201204222028_0269   60      0       171     27      116     0       0       0       A       MAP_ONLY        &lt;br/&gt;
job_201204222028_0270   60      1       63      9       26      136     136     136     B       SAMPLER &lt;br/&gt;
job_201204222028_0271   60      17      183     30      66      657     262     446     B       ORDER_BY        /tmp/10m-0.9.0/L9out,&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We can see, 0.9.0 uses a MAP_ONLY job to load the data, which is almost as expensive as the ORDER_BY job. In my environment with 4 slave nodes processing 10m records, it increases time from 1021 seconds (0.8.1) to 1921 seconds (0.9.0)!&lt;/p&gt;

&lt;p&gt;Does anybody know what happened?&lt;/p&gt;</comment>
                            <comment id="13260170" author="dvryaboy" created="Tue, 24 Apr 2012 04:01:27 +0100"  >&lt;p&gt;Funny, was just looking at the same thing. It&apos;s pig being silly about what projections do &amp;#8211; try loading without a schema, and ordering by the field ordinal. The extra MR job will go away.&lt;/p&gt;

&lt;p&gt;Seems like a serious performance regression that we should fix asap.&lt;/p&gt;</comment>
                            <comment id="13260174" author="jay23jack" created="Tue, 24 Apr 2012 04:16:54 +0100"  >&lt;p&gt;Agree! Created a jira &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-2661&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;PIG-2661&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13263275" author="jay23jack" created="Fri, 27 Apr 2012 01:38:58 +0100"  >&lt;p&gt;Attached the complete results in case anybody is interested.&lt;/p&gt;</comment>
                            <comment id="13615074" author="shaw" created="Wed, 27 Mar 2013 09:49:31 +0000"  >&lt;p&gt;Does anyone run pigmix succeed on pig-0.11 and hadoop-2.0.x  ?&lt;/p&gt;</comment>
                            <comment id="13616643" author="daijy" created="Thu, 28 Mar 2013 21:00:16 +0000"  >&lt;p&gt;Hi, Shaw, it cannot run directly with pig-0.11 yet. I will attach another patch shortly.&lt;/p&gt;</comment>
                            <comment id="13619036" author="daijy" created="Mon, 1 Apr 2013 19:45:46 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-200&quot; title=&quot;Pig Performance Benchmarks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-200&quot;&gt;&lt;del&gt;PIG-200&lt;/del&gt;&lt;/a&gt;-0.12.patch works with trunk (0.12). I tested both hadoop 1.0.4 and 2.0.3. The patch is ready to review and commit.&lt;/p&gt;</comment>
                            <comment id="13619041" author="daijy" created="Mon, 1 Apr 2013 19:50:00 +0100"  >&lt;p&gt;To run it:&lt;br/&gt;
ant -Dharness.hadoop.home=$HADOOP_HOME pigmix-deploy&lt;br/&gt;
ant -Dharness.hadoop.home=$HADOOP_HOME pigmix&lt;/p&gt;</comment>
                            <comment id="13632338" author="alangates" created="Mon, 15 Apr 2013 23:58:11 +0100"  >&lt;p&gt;+1.  Latest patch changes look good.  I think it would be good to get this checked in and maintained going forward.&lt;/p&gt;</comment>
                            <comment id="13632346" author="daijy" created="Tue, 16 Apr 2013 00:14:13 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-200&quot; title=&quot;Pig Performance Benchmarks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-200&quot;&gt;&lt;del&gt;PIG-200&lt;/del&gt;&lt;/a&gt;-0.12.patch committed to trunk.&lt;/p&gt;</comment>
                            <comment id="13632351" author="amirhyoussefi" created="Tue, 16 Apr 2013 00:21:59 +0100"  >&lt;p&gt;Thanks Daniel. I second Alan&apos;s &quot;I think it would be good to get this checked in and maintained going forward.&quot;&lt;/p&gt;</comment>
                            <comment id="13632357" author="daijy" created="Tue, 16 Apr 2013 00:23:53 +0100"  >&lt;p&gt;Documentation is in &lt;a href=&quot;https://cwiki.apache.org/confluence/display/PIG/PigMix&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/PIG/PigMix&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13695628" author="anlilin" created="Fri, 28 Jun 2013 19:22:42 +0100"  >&lt;p&gt;Hi Danie, it seems that test/perf/pigmix/lib/sdsuLibJKD12.jar is missing in trunk, can you check it in?&lt;/p&gt;</comment>
                            <comment id="13784487" author="daijy" created="Wed, 2 Oct 2013 22:50:34 +0100"  >&lt;p&gt;Professor Roger Whitney is kindly agree to change license of sdsuLibJKD12 to Apache. Commit it to Pig codebase. Get rid of the manual step. Thanks Professor Roger!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12552236">PIG-2661</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12576726" name="PIG-200-0.12.patch" size="223171" author="daijy" created="Wed, 3 Apr 2013 06:48:33 +0100"/>
                            <attachment id="12383751" name="generate_data.pl" size="10534" author="alangates" created="Tue, 10 Jun 2008 15:25:49 +0100"/>
                            <attachment id="12438872" name="perf-0.6.patch" size="155140" author="daijy" created="Mon, 15 Mar 2010 22:50:35 +0000"/>
                            <attachment id="12415402" name="perf.hadoop.patch" size="33425" author="yinghe" created="Mon, 3 Aug 2009 21:25:04 +0100"/>
                            <attachment id="12395343" name="perf.patch" size="157010" author="alangates" created="Thu, 4 Dec 2008 22:52:02 +0000"/>
                            <attachment id="12524797" name="pig-0.8.1-vs-0.9.0.png" size="7790" author="jay23jack" created="Fri, 27 Apr 2012 01:38:58 +0100"/>
                            <attachment id="12448820" name="pigmix2.patch" size="204654" author="daijy" created="Tue, 6 Jul 2010 22:19:19 +0100"/>
                            <attachment id="12507399" name="pigmix_pig0.11.patch" size="199046" author="dvryaboy" created="Wed, 14 Dec 2011 19:26:56 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 10 Apr 2008 14:49:36 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72308</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hyabvz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>94237</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>