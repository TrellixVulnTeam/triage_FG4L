<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:58:38 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/PIG-1205/PIG-1205.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[PIG-1205] Enhance HBaseStorage-- Make it support loading row key and implement StoreFunc</title>
                <link>https://issues.apache.org/jira/browse/PIG-1205</link>
                <project id="12310730" key="PIG">Pig</project>
                    <description></description>
                <environment></environment>
        <key id="12446785">PIG-1205</key>
            <summary>Enhance HBaseStorage-- Make it support loading row key and implement StoreFunc</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12436093">PIG-966</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dvryaboy">Dmitriy V. Ryaboy</assignee>
                                    <reporter username="zjffdu">Jeff Zhang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 27 Jan 2010 09:00:23 +0000</created>
                <updated>Fri, 17 Dec 2010 22:43:17 +0000</updated>
                            <resolved>Mon, 30 Aug 2010 22:29:18 +0100</resolved>
                                    <version>0.7.0</version>
                                    <fixVersion>0.8.0</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>9</watches>
                                                                <comments>
                            <comment id="12805435" author="zjffdu" created="Wed, 27 Jan 2010 09:26:50 +0000"  >&lt;p&gt;This issue is about enhance the features of HBaseStorage.&lt;br/&gt;
1. make it support loading key.  Add a constructor for HBaseStorage , the second argument can have value &quot;true&quot; or &quot;false&quot; which indicate whether you want to load the row key as the first field of Tuple&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; HBaseStorage(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; columnList, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; loadRowKey){
...
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;2. Make the HBaseStorage implements interface StoreFunc, you can store the Tuple to HBase. One thing to be noticed is that if you use HBaseStorage, the type of  of each field stored in HBase is String no matter what its type in Tuple. That means if you use HBaseStorage to load it again, you have to convert the type by yourself. The HBaseStorage do not do the type conversion for you.&lt;/p&gt;</comment>
                            <comment id="12805438" author="hadoopqa" created="Wed, 27 Jan 2010 09:36:41 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12431541/PIG_1205.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12431541/PIG_1205.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision 903030.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 patch.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/179/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/179/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12838524" author="pkamath" created="Thu, 25 Feb 2010 20:24:47 +0000"  >&lt;p&gt;Jeff, the patch no longer applies cleanly on trunk - looks like we missed reviewing this earlier - sorry about that - can you regenerate this patch against trunk?&lt;/p&gt;</comment>
                            <comment id="12839537" author="zjffdu" created="Mon, 1 Mar 2010 02:52:40 +0000"  >&lt;p&gt;Submit the patch for trunk&lt;/p&gt;</comment>
                            <comment id="12839660" author="hadoopqa" created="Mon, 1 Mar 2010 12:23:00 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12437440/PIG_1205_2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12437440/PIG_1205_2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision 916793.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated 1 warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 99 javac compiler warnings (more than the trunk&apos;s current 98 warnings).&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/230/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/230/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/230/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/230/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/230/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/230/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12841937" author="pkamath" created="Fri, 5 Mar 2010 17:14:16 +0000"  >&lt;p&gt;Review comments:&lt;br/&gt;
1) The top level comment in HBaseStorage reads - &quot;A Hbase loader&quot; - am wondering if it is worth keeping it a loader (maybe change the name to HBaseLoader) and create a separate Storer which extends StoreFunc rather than have HBaseStorage implement StoreFuncInterface - by extending the StoreFunc, if new functions with default implementations are added then the Storer will not need to change. The disadvantage is if we call the loader HBaseLoader, existing users of HBaseStorage would have to change their scripts to use HBaseLoader instead. This is just a suggestion - I am fine if HBaseStorage does both load and store and implements StoreFuncInterface - Jeff I will let you decide which is better. If you choose to do both load and store in HBaseStorage change the top level comment accordingly.&lt;br/&gt;
2) The following method implementation should change from:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      @Override                                                                                                                                                                                                                            
      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; relToAbsPathForStoreLocation(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; location, Path curDir)                                                                                                                                                             
              &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {                                                                                                                                                                                                         
          &lt;span class=&quot;code-comment&quot;&gt;// TODO Auto-generated method stub                                                                                                                                                                                               
&lt;/span&gt;          &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;                                                                                                                                                                                                                     
      }               
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;to&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      @Override                                                                                                                                                                                                                            
      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; relToAbsPathForStoreLocation(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; location, Path curDir)                                                                                                                                                             
              &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {                                                                                                                                                                                                         
          &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; location;                                                                                                                                                                                                                     
      }               
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Also, do address the javadoc/javac issues reported above.&lt;/p&gt;

&lt;p&gt;If the above are addressed, +1 for the patch (I don&apos;t have enough HBase knowledge to review the HBase specific code - I have only reviewed the use of load/store API).&lt;/p&gt;</comment>
                            <comment id="12842680" author="zjffdu" created="Mon, 8 Mar 2010 14:47:51 +0000"  >&lt;p&gt;Pradeep, thanks for your review. I&apos;ve updated patch. I choose to put the loadfunc and storefunc together into HBaseStorage, make it like PigStorage&lt;/p&gt;</comment>
                            <comment id="12842779" author="hadoopqa" created="Mon, 8 Mar 2010 19:23:09 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12438187/PIG_1205_3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12438187/PIG_1205_3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision 919634.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 99 javac compiler warnings (more than the trunk&apos;s current 98 warnings).&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/227/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/227/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/227/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/227/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/227/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/227/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12842783" author="pkamath" created="Mon, 8 Mar 2010 19:29:13 +0000"  >&lt;p&gt;New patch looks good - i had one question - cleanupOnFailure() is implemented as an empty body method - wondering if there should be some cleanup of the hbase data which was written out since this method is called when the job fails? If so, please add the the clean up code in that method. &lt;/p&gt;

&lt;p&gt;If the above comment and the extra javac warning reported by Hadoop QA in the previous comment are address, the patch is good to be committed (again, if someone else who has hbase knowledge can review the hbase portion that would be good, since I have not reviewed that part).&lt;/p&gt;</comment>
                            <comment id="12842806" author="dvryaboy" created="Mon, 8 Mar 2010 20:26:54 +0000"  >&lt;p&gt;Jeff, thanks for all your work on this!&lt;br/&gt;
It occurs to me that the constructor with position-dependent arguments is not a scalable pattern. We may have many options we might want to set for Hbase in the future (only load certain column-families, minimum record date, interpret stored data as strings or bytes, etc), and having to set them by adding on a third, fourth, fifth argument to the constructor is not really great.&lt;/p&gt;

&lt;p&gt;We could instead use commons-cli (already used by Hadoop, so no new dependencies) or args4j to parse a command-line style argument. So invocation would look like this instead:&lt;/p&gt;

&lt;p&gt;load &apos;hdfs://blah&quot; using HBaseStorage(&quot;-columns=col1,col2 -loadRowKey=true -castUsing=Utf8StorageConverter&quot;)&lt;/p&gt;

&lt;p&gt;What do you think? &lt;/p&gt;</comment>
                            <comment id="12842882" author="zjffdu" created="Tue, 9 Mar 2010 02:18:49 +0000"  >&lt;p&gt;Response to Pradeep,&lt;br/&gt;
1. HBase support multi-version values, so the failure won&apos;t affect the next rerun. another concern is that cleanOnFailure is called on client side, so if the number of result rows is very large, the cost of deletion will be high.&lt;br/&gt;
2. I check the test report here &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/227/artifact/trunk/patchprocess/trunkJavacWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/227/artifact/trunk/patchprocess/trunkJavacWarnings.txt&lt;/a&gt;  and it weird that is shows there are only 98 warnings which is not the 99 warnings.  Do you know the reason ? Thanks.&lt;/p&gt;</comment>
                            <comment id="12842884" author="zjffdu" created="Tue, 9 Mar 2010 02:22:09 +0000"  >&lt;p&gt;Response to Dmitriy,&lt;/p&gt;

&lt;p&gt;Thanks for your great idea, it really has better extensibility. But one problem is that this will sacrifice the incompatibility with previous version of HBaseStorage. I have not rich experience on hbase, do you think it is often required by users to specify other arguments ?&lt;/p&gt;
</comment>
                            <comment id="12842885" author="dvryaboy" created="Tue, 9 Mar 2010 02:29:43 +0000"  >&lt;p&gt;First, I have to give credit to Ciemo for the idea, he mentioned it a while back on the SchemaStorage ticket. &lt;/p&gt;

&lt;p&gt;You raise a good point, although I doubt there are many users of the old LoadFunc.&lt;/p&gt;

&lt;p&gt;How about making the LoadFunc take an optional second parameter, which has all the options, and maintain the first one as the list of columns to pull?&lt;/p&gt;</comment>
                            <comment id="12843547" author="hadoopqa" created="Wed, 10 Mar 2010 12:24:26 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12438187/PIG_1205_3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12438187/PIG_1205_3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision 921185.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 99 javac compiler warnings (more than the trunk&apos;s current 98 warnings).&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/237/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/237/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/237/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/237/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/237/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/237/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12843946" author="zjffdu" created="Thu, 11 Mar 2010 06:53:04 +0000"  >&lt;p&gt;Dmitriy, &lt;br/&gt;
Thanks for your suggestion, I adopt your idea to let the second argument have all the options and let the first one as the columns argument.&lt;/p&gt;

&lt;p&gt;Pradeep,&lt;br/&gt;
I check the test report, It seems that the new generated javac warning is acceptable, this warning is the same as the another one warning in PigStorage. And does this need the build engineer to do some extra configuration ?&lt;/p&gt;
</comment>
                            <comment id="12843949" author="pkamath" created="Thu, 11 Mar 2010 07:10:07 +0000"  >&lt;p&gt;Jeff, unless the warning is due to use of deprecated hadoop API, we should fix it - if it is due to deprecated hadoop API then its ok to ignore.&lt;/p&gt;</comment>
                            <comment id="12844094" author="hadoopqa" created="Thu, 11 Mar 2010 15:18:40 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12438486/PIG_1205_4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12438486/PIG_1205_4.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision 921585.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 99 javac compiler warnings (more than the trunk&apos;s current 98 warnings).&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/234/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/234/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/234/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/234/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/234/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/234/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12846224" author="pkamath" created="Wed, 17 Mar 2010 00:07:41 +0000"  >&lt;p&gt;Jeff, if the only issue blocking the commit is javac warning - unless the warning is due to use of deprecated hadoop API, we should fix it - if it is due to deprecated hadoop API then its ok to ignore. Very soon trunk will be branched for Pig 0.7.0 - so if this feature is useful to feature in Pig 0.7.0, we should get this committed soon.&lt;/p&gt;</comment>
                            <comment id="12846267" author="zjffdu" created="Wed, 17 Mar 2010 02:40:58 +0000"  >&lt;p&gt;Thanks, Pradeep. I am sorry for no time to fix the javac warning. It seems this is &quot;unchecked&quot; javac warning which is the same as the one in PigStorage.&lt;/p&gt;</comment>
                            <comment id="12846273" author="dvryaboy" created="Wed, 17 Mar 2010 03:06:31 +0000"  >&lt;p&gt;You can suppress the unchecked warning with @SuppresWarnings(&quot;unchecked&quot;), and comment why it&apos;s ok to suppress the warning&lt;/p&gt;

&lt;p&gt;I&apos;ve been playing with using HBase through pig using the 0.6 loader, and I must say, it&apos;s very far from being ready from prime-time. I don&apos;t know whether we need to exert too much effort to get this under the wire when it won&apos;t really be usable anyway until much further love is applied.&lt;/p&gt;

&lt;p&gt;-D&lt;/p&gt;</comment>
                            <comment id="12846327" author="zjffdu" created="Wed, 17 Mar 2010 07:36:46 +0000"  >&lt;p&gt;Dmitriy, do you mean the HBaseStorage&apos;s performance is far from expected ? There&apos;s some discussion on &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-1209&quot; title=&quot;Port POJoinPackage to proactively spill&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-1209&quot;&gt;&lt;del&gt;PIG-1209&lt;/del&gt;&lt;/a&gt;, some extra options should been set to improve the performance.&lt;br/&gt;
With this task, the second parameter can been extended to support other parameters.&lt;/p&gt;</comment>
                            <comment id="12846442" author="dvryaboy" created="Wed, 17 Mar 2010 15:29:29 +0000"  >&lt;p&gt;Jeff,&lt;br/&gt;
A brief list of issues that come to mind (these apply to the 0.6 version, but I think things are substantially the same in 0.7):&lt;/p&gt;

&lt;p&gt;1) extending Utf8Converter means data in HBase is expected to be stored as strings. Conversion using the Hbase Bytes class should be supported instead (or at least in addition).&lt;br/&gt;
2) No projection push-down. For some reason even though it is clear what columns to pull, this client pulls everything, and filters out the right columns when constructing a tuple. The columns should be pushed into the Scan.&lt;br/&gt;
3) No filter push-down. HBase has a number of efficient filters available, none of which are used. At a minimum, range constraints on the row key should be supported.&lt;br/&gt;
4) No way to pull out the row key (but you are adding that in this ticket, so that&apos;s good).&lt;br/&gt;
5) No way to control row version / timestamp&lt;/p&gt;

&lt;p&gt;None of this is rocket science, and in fact I am making good progress on all of them for 0.6, but it&apos;s unlikely to get done and ported for 0.7 by Monday.&lt;/p&gt;

&lt;p&gt;-D&lt;/p&gt;</comment>
                            <comment id="12847470" author="olgan" created="Fri, 19 Mar 2010 17:51:11 +0000"  >&lt;p&gt;Jeff, are you still planning to get this into Pig 0.7.0 by Monday or should we move this to Pig 0.8.0?&lt;/p&gt;</comment>
                            <comment id="12847473" author="dvryaboy" created="Fri, 19 Mar 2010 17:55:55 +0000"  >&lt;p&gt;fwiw &amp;#8211; I have an implementation for 0.6 that does most of what I outlined above; could probably port to 0.7 and make apache-friendly within the next couple of weeks.&lt;/p&gt;</comment>
                            <comment id="12847476" author="olgan" created="Fri, 19 Mar 2010 17:59:28 +0000"  >&lt;p&gt;Sounds good. Then I will mark it for inclusion in 0.8.0.&lt;/p&gt;</comment>
                            <comment id="12891858" author="olgan" created="Sat, 24 Jul 2010 00:22:33 +0100"  >&lt;p&gt;Jeff and Dmitry - are you still planning to finish this for Pig 0.8.0 release&lt;/p&gt;</comment>
                            <comment id="12891864" author="dvryaboy" created="Sat, 24 Jul 2010 00:35:25 +0100"  >&lt;p&gt;When is the cut-off date for that?&lt;/p&gt;</comment>
                            <comment id="12892374" author="olgan" created="Mon, 26 Jul 2010 18:16:15 +0100"  >&lt;p&gt;The proposal is to cut the branch on 8/30 so the code needs to be committed by then.&lt;/p&gt;</comment>
                            <comment id="12892376" author="dvryaboy" created="Mon, 26 Jul 2010 18:18:54 +0100"  >&lt;p&gt;I can integrate my changes by then. &lt;/p&gt;</comment>
                            <comment id="12899220" author="dvryaboy" created="Tue, 17 Aug 2010 01:53:39 +0100"  >&lt;p&gt;This patch (not really review-ready yet) introduces the Elephant-Bird improvements.&lt;/p&gt;

&lt;p&gt;You can use -gt, -gte, -lt, -lte flags to filter out row ranges, specify caching and per-region row limits, and you can specify the caster to use (interpret Strings, as before, or use bytes directly for more eficient storage and communication).&lt;/p&gt;

&lt;p&gt;The filtering is a bit off because it still spins up all the map tasks, the ones whose keys are filtered out just finish extremely fast. &lt;/p&gt;

&lt;p&gt;The progress reporting is a bit jittery, but better than nothing.&lt;/p&gt;

&lt;p&gt;TODO: fix up filtering, add projection pushdown, add filter pushdown, and write better tests.&lt;/p&gt;
</comment>
                            <comment id="12899691" author="zjffdu" created="Wed, 18 Aug 2010 02:23:54 +0100"  >&lt;p&gt;I am reviewing this patch.&lt;/p&gt;</comment>
                            <comment id="12899718" author="zjffdu" created="Wed, 18 Aug 2010 04:26:00 +0100"  >&lt;p&gt;Several comments:&lt;/p&gt;

&lt;p&gt;1. Is it possible to specify min_row_key and max_row_key in parameters, in the current implementation, hbase will create split covering the whole table. But sometimes we do not need to scan all the table.  Some regions can been ignored. This can improve the performance.&lt;/p&gt;

&lt;p&gt;2. One small suggestion: move line 206 to if block (only one time setting is enough)&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
       &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (scanFilter == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
            scanFilter = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; FilterList();
            scan.setFilter(scanFilter);
       }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;3. It&apos;s better to add warning log in HBaseBinaryConverter when the bytes is cut off for type conversion &lt;/p&gt;

&lt;p&gt;4. The parameter &quot;Per-region limit&quot; is a bit confusing for me, I think users would like to the set the limit on the whole table not per region. What do you think ?&lt;/p&gt;</comment>
                            <comment id="12899722" author="dvryaboy" created="Wed, 18 Aug 2010 05:00:48 +0100"  >&lt;blockquote&gt;&lt;p&gt;1. Is it possible to specify min_row_key and max_row_key in parameters&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Even better than that &amp;#8211; you can specify lt, lte, gt, and gte. It&apos;s true that as written splits will be created for the whole table, but the filters will cause most of those splits to immediately exit. Not creating the splits is on my todo list (I already do this in the elephantbird version for 0.6)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;2. One small suggestion: move line 206 to if block (only one time setting is enough)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Good idea.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;3. It&apos;s better to add warning log in HBaseBinaryConverter when the bytes is cut off for type conversion &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Will do. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;4. The parameter &quot;Per-region limit&quot; is a bit confusing for me, I think users would like to the set the limit on the whole table not per region. What do you think ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Trouble is, you can&apos;t enforce a total limit without post-processing. In practice, I use -limit when I am experimenting and want to get just a few rows from HBase; if I want a specific number of rows, I use both -limit (to speed up the tasks, since the scanners will exit early), and Pig&apos;s LIMIT operator (to get the exact number of rows I need).&lt;/p&gt;
</comment>
                            <comment id="12900140" author="zjffdu" created="Thu, 19 Aug 2010 02:16:36 +0100"  >&lt;p&gt;Dimitiy,&lt;/p&gt;

&lt;p&gt;One suggestion of Point 1:&lt;br/&gt;
You can set the StartRow and EndRow to Scan if user specify gt, lt, lte and gte parameters, one thing should been noticed is StartRow is inclusive and EndRow is exclusive. So when users specify lte, you can add 1 to the EndRow key.   In this way, TableInputFormat will create fewer InputSplit which means fewer mapper task.&lt;/p&gt;
</comment>
                            <comment id="12900995" author="dvryaboy" created="Sat, 21 Aug 2010 10:19:38 +0100"  >&lt;p&gt;Fixed test (but did not add new tests).&lt;br/&gt;
Made default caster configurable by setting pig.hbase.caster property. &lt;br/&gt;
Made rowKey filters (gt, lt, gte, lte) filter out regions when possible. Tested manually.&lt;/p&gt;

&lt;p&gt;Jeff, to your comments about shifting to cut off regions &amp;#8211;  I think it&apos;s better to have the loader think about region sizes, and let the user only worry about key values. If they are intimate enough with their tables to know region boundaries, they should know which end of a region is inclusive and which is exclusive, and provide the correct filters.&lt;/p&gt;</comment>
                            <comment id="12901142" author="dvryaboy" created="Sun, 22 Aug 2010 08:59:45 +0100"  >&lt;p&gt;Implemented LoadPushDown (NOTE: this involved a slight backwards-compatible refactoring of Utf8StorageConverter).&lt;br/&gt;
Refactored the tests a bit.&lt;/p&gt;

&lt;p&gt;At this point I think we are good except for further testing and documentation.&lt;/p&gt;</comment>
                            <comment id="12901784" author="zjffdu" created="Tue, 24 Aug 2010 10:04:29 +0100"  >&lt;p&gt;Several updates continue Dmitriy&apos;s work.&lt;/p&gt;

&lt;p&gt;1. Add unit test to HBaseStorage&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;code refactoring of TestHBaseStorage&lt;/li&gt;
	&lt;li&gt;add unit test for parameters: gt lt gte let limit and HBaseBinaryConverter.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;2.  Update hbase 0.20 to hbase 0.20.6 (Dimitry, I found HBaseStorage do not work on hbase 0.20, do you also manul test on hbase 0.20.6 rather than 0.20.0 ?)&lt;/p&gt;

&lt;p&gt;3.  I think we need more document for HBaseStorage especially the LoadCaster, if user specify the wrong LoadCast, he will get confusing result.&lt;/p&gt;

</comment>
                            <comment id="12901787" author="dvryaboy" created="Tue, 24 Aug 2010 10:16:13 +0100"  >&lt;p&gt;Jeff,&lt;br/&gt;
Thanks a lot for pitching in with the tests!&lt;/p&gt;

&lt;p&gt;I was using 0.20.0 and the old tests passed. I&apos;ve only tested the binary conversion stuff and other new features  on the Twitter machines, and they do run a later HBase version &amp;#8211; perhaps the incompatibility is in the filters or binary casters code?&lt;br/&gt;
Do you know which tests fail with 0.20.0?&lt;/p&gt;

&lt;p&gt;I will definitely add a bunch of documentation.&lt;/p&gt;</comment>
                            <comment id="12901799" author="zjffdu" created="Tue, 24 Aug 2010 10:42:39 +0100"  >&lt;p&gt;Dmitriy,&lt;/p&gt;

&lt;p&gt;The testcase of testLoadWithParameters_1 and testLoadWithParameters_2 failed when using hbase 0.20  &lt;br/&gt;
I think TableInputFormat has some update (maybe bug fixing) from hbase 0.20. to hbase 0.20.6&lt;/p&gt;



&lt;p&gt;The following is log:&lt;br/&gt;
10/08/24 17:28:00 ERROR mapReduceLayer.Launcher: Backend error message during job submission&lt;br/&gt;
org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Unable to create input splits for: hbase://pigtable_1&lt;br/&gt;
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:269)&lt;br/&gt;
	at org.apache.hadoop.mapred.JobClient.writeNewSplits(JobClient.java:885)&lt;br/&gt;
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:779)&lt;br/&gt;
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:730)&lt;br/&gt;
	at org.apache.hadoop.mapred.jobcontrol.Job.submit(Job.java:378)&lt;br/&gt;
	at org.apache.hadoop.mapred.jobcontrol.JobControl.startReadyJobs(JobControl.java:247)&lt;br/&gt;
	at org.apache.hadoop.mapred.jobcontrol.JobControl.run(JobControl.java:279)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:619)&lt;br/&gt;
Caused by: java.lang.NullPointerException&lt;br/&gt;
	at org.apache.hadoop.hbase.io.HbaseObjectWritable.readObject(HbaseObjectWritable.java:365)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.HbaseObjectWritable.readObject(HbaseObjectWritable.java:347)&lt;br/&gt;
	at org.apache.hadoop.hbase.filter.CompareFilter.readFields(CompareFilter.java:132)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.HbaseObjectWritable.readObject(HbaseObjectWritable.java:418)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.HbaseObjectWritable.readObject(HbaseObjectWritable.java:347)&lt;br/&gt;
	at org.apache.hadoop.hbase.filter.FilterList.readFields(FilterList.java:204)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.Scan.readFields(Scan.java:523)&lt;br/&gt;
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.convertStringToScan(TableMapReduceUtil.java:94)&lt;br/&gt;
	at org.apache.hadoop.hbase.mapreduce.TableInputFormat.setConf(TableInputFormat.java:79)&lt;br/&gt;
	at org.apache.pig.backend.hadoop.hbase.HBaseTableInputFormat$HBaseTableIFBuilder.build(HBaseTableInputFormat.java:77)&lt;br/&gt;
	at org.apache.pig.backend.hadoop.hbase.HBaseStorage.getInputFormat(HBaseStorage.java:268)&lt;br/&gt;
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:257)&lt;br/&gt;
	... 7 more&lt;/p&gt;

&lt;p&gt;10/08/24 17:28:00 ERROR pigstats.PigStats: ERROR 2118: Unable to create input splits for: hbase://pigtable_1&lt;br/&gt;
10/08/24 17:28:00 ERROR pigstats.PigStatsUtil: 1 map reduce job(s) failed!&lt;br/&gt;
10/08/24 17:28:00 INFO pigstats.PigStats: Script Statistics: &lt;/p&gt;</comment>
                            <comment id="12901924" author="zjffdu" created="Tue, 24 Aug 2010 16:35:59 +0100"  >&lt;p&gt;Dmitriy, &lt;/p&gt;

&lt;p&gt;I found the problem. This is really a bug of hbase 0.20.0 about the serialization of filter (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1830&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-1830&lt;/a&gt;)&lt;br/&gt;
I think we should update hbase to 0.20.6 in pig, and 0.20.6 is compatible with 0.20.0&lt;/p&gt;
</comment>
                            <comment id="12902008" author="dvryaboy" created="Tue, 24 Aug 2010 19:40:29 +0100"  >&lt;p&gt;Ok, let&apos;s upgrade to 20.6 then. We could work around by serializing the filters ourselves, and applying them to the scan when reading the UDFContext, but seems a bit overboard, and folks should be upgrading anyway. &lt;/p&gt;

&lt;p&gt;&lt;b&gt;Commiters&lt;/b&gt;: this is ready for review.&lt;/p&gt;
</comment>
                            <comment id="12903043" author="alangates" created="Thu, 26 Aug 2010 21:57:47 +0100"  >&lt;p&gt;Comments&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;As discussed previously, LoadStoreCaster should be changed so that there is a StoreCaster interface that has the toByte methods, and LoadStoreCaster is a convenience interface that extends LoadCaster and StoreCaster.&lt;/li&gt;
	&lt;li&gt;It looks like with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1933&quot; title=&quot;Upload Hbase jars to a public maven repository&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1933&quot;&gt;&lt;del&gt;HBASE-1933&lt;/del&gt;&lt;/a&gt; Hbase is now available via Maven.  Can we pull it from Maven rather than check in the jar to our lib directory?&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Since I know little about Hbase I focussed my review on the Pig side.&lt;/p&gt;</comment>
                            <comment id="12904050" author="dvryaboy" created="Mon, 30 Aug 2010 00:17:36 +0100"  >&lt;p&gt;Attaching the hbase-0.20.6 jars&lt;/p&gt;

&lt;p&gt;HBase is an apache project, so no license issues.&lt;/p&gt;</comment>
                            <comment id="12904322" author="dvryaboy" created="Mon, 30 Aug 2010 21:25:35 +0100"  >&lt;p&gt;Patch with the StoreCaster changes as suggested by Alan. With +1s from Alan and Jeff, committing.&lt;/p&gt;</comment>
                            <comment id="12904325" author="dvryaboy" created="Mon, 30 Aug 2010 21:28:52 +0100"  >&lt;p&gt;Re &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1933&quot; title=&quot;Upload Hbase jars to a public maven repository&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1933&quot;&gt;&lt;del&gt;HBASE-1933&lt;/del&gt;&lt;/a&gt;, they are publishing snapshots of current trunk, not the 0.20 branch. We&apos;ll be able to start using maven to pull down hbase when we upgrade to their 0.9 release (which iirc depends on hdfs appends...)&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12431541" name="PIG_1205.patch" size="13804" author="zjffdu" created="Wed, 27 Jan 2010 09:27:37 +0000"/>
                            <attachment id="12437440" name="PIG_1205_2.patch" size="13644" author="zjffdu" created="Mon, 1 Mar 2010 02:52:40 +0000"/>
                            <attachment id="12438187" name="PIG_1205_3.patch" size="14123" author="zjffdu" created="Mon, 8 Mar 2010 14:46:30 +0000"/>
                            <attachment id="12438486" name="PIG_1205_4.patch" size="15585" author="zjffdu" created="Thu, 11 Mar 2010 06:48:31 +0000"/>
                            <attachment id="12452239" name="PIG_1205_5.path" size="32673" author="dvryaboy" created="Tue, 17 Aug 2010 01:53:39 +0100"/>
                            <attachment id="12452704" name="PIG_1205_6.patch" size="35379" author="dvryaboy" created="Sat, 21 Aug 2010 10:19:38 +0100"/>
                            <attachment id="12452731" name="PIG_1205_7.patch" size="53420" author="dvryaboy" created="Sun, 22 Aug 2010 08:59:45 +0100"/>
                            <attachment id="12452913" name="PIG_1205_8.patch" size="67753" author="zjffdu" created="Tue, 24 Aug 2010 10:04:29 +0100"/>
                            <attachment id="12453458" name="PIG_1205_9.patch" size="76566" author="dvryaboy" created="Mon, 30 Aug 2010 21:25:35 +0100"/>
                            <attachment id="12453394" name="hbase-0.20.6-test.jar" size="2031357" author="dvryaboy" created="Mon, 30 Aug 2010 00:17:36 +0100"/>
                            <attachment id="12453393" name="hbase-0.20.6.jar" size="1574100" author="dvryaboy" created="Mon, 30 Aug 2010 00:17:35 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 27 Jan 2010 09:36:41 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>41721</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hyanrj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>96161</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>HBaseStorage has been significantly reworked with this release.&lt;br/&gt;
&lt;br/&gt;
Usage:&lt;br/&gt;
{code}&lt;br/&gt;
my_data = LOAD &amp;#39;&lt;a href=&quot;hbase://table_name&amp;#39;&quot;&gt;hbase://table_name&amp;amp;#39;&lt;/a&gt; USING org.apache.pig.backend.hadoop.hbase.HBaseStorage(&amp;#39;colfamily:col1 colfamily:col2&amp;#39;, &amp;#39;-caching 100&amp;#39;) as (col1:int, col2:chararray);&lt;br/&gt;
&lt;br/&gt;
STORE my_date INTO &amp;#39;hbaseL//other_table&amp;#39; USING org.apache.pig.backend.hadoop.hbase.HBaseStorage(&amp;#39;colfamily:col1 colfamily:col2&amp;#39;);&lt;br/&gt;
{code}&lt;br/&gt;
&lt;br/&gt;
HBaseStorage can now write data into HBase as well as read it. The first argument is a space-delimited list of columns to be loaded (or stored). Columns are specified as columnfamily:column_name. The second argument is an optional set of key-value pairs used to control HBaseStorage behavior. Available arguments are:&lt;br/&gt;
&lt;br/&gt;
* {{monospaced}}-loadKey{{monospaced}} Used to load the row key; false by default. If true, the first field in the returned tuple will be the value of the row key.&lt;br/&gt;
* {{monospaced}}-gt, -gte, -lt, and -lte{{monospaced}} Used to specify bounds on row keys to be scanned. The keys are specified as binary data, using the hex representation. Any slashes have to be double-escaped (two slashes per single &amp;quot;real&amp;quot; slash) to be parsed correctly.&lt;br/&gt;
* {{monospaced}}-caching{{monospaced}} Used to specify the number of rows to be cached per HBase RPC call. See &lt;a href=&quot;http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/HTable.html#setScannerCaching%28int%29&quot;&gt;http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/HTable.html#setScannerCaching%28int%29&lt;/a&gt; for more information about this HBase feature.&lt;br/&gt;
* {{monospaced}}-limit{{monospaced}} Used to control how many rows *per scanned region* will be retrieved. This can of course speed up processing if you just want a few rows. The total number of rows returned will be up to number of regions * limit. The limit is applied after any -gt, -lt, etc filters. Pig&amp;#39;s LIMIT operator can be used in conjunction with this argument.&lt;br/&gt;
* {{monospaced}}-caster{{monospaced}} Used to specify a LoadCaster (or LoadStoreCaster, for storage) used to convert the data stored in HBase into Pig data. By default, the Utf8StorageConverter is used, which stores all data as its string representation. The string &amp;quot;HBaseBinaryConverter&amp;quot; can be used to specify that data is stored in HBase&amp;#39;s native binary format. Note that the HBaseBinary converter does not work with complex data types such as maps, tuples, and bags. You can also specify a full class path such as org.apache.pig.backend.hadoop.hbase.HBaseBinaryConverter to use your own Caster. The default caster can be changed by setting the pig.hbase.caster property in pig,properties&lt;br/&gt;
&lt;br/&gt;
HBaseStorage matches column arguments to tuple fields based on their ordinal position. When storing, the first field is expected to be the key value.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>hbase</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>