<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:56:22 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/PIG-833/PIG-833.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[PIG-833] Storage access layer</title>
                <link>https://issues.apache.org/jira/browse/PIG-833</link>
                <project id="12310730" key="PIG">Pig</project>
                    <description>&lt;p&gt;A layer is needed to provide a high level data access abstraction and a tabular view of data in Hadoop, and could free Pig users from implementing their own data storage/retrieval code.  This layer should also include a columnar storage format in order to provide fast data projection, CPU/space-efficient data serialization, and a schema language to manage physical storage metadata.  Eventually it could also support predicate pushdown for further performance improvement.  Initially, this layer could be a contrib project in Pig and become a hadoop subproject later on.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12427140">PIG-833</key>
            <summary>Storage access layer</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rangadi">Raghu Angadi</assignee>
                                    <reporter username="jaytang">Jay Tang</reporter>
                        <labels>
                    </labels>
                <created>Thu, 4 Jun 2009 19:27:24 +0100</created>
                <updated>Wed, 24 Mar 2010 22:13:06 +0000</updated>
                            <resolved>Tue, 8 Sep 2009 22:06:24 +0100</resolved>
                                                    <fixVersion>0.4.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>20</watches>
                                                                <comments>
                            <comment id="12716462" author="hammer" created="Fri, 5 Jun 2009 01:20:27 +0100"  >&lt;p&gt;You may want to see the Hive project, where a columnar storage format has been developed and benchmarked: &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-352&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-352&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="12716470" author="hong.tang" created="Fri, 5 Jun 2009 01:55:42 +0100"  >&lt;p&gt;Jeff, just like the SQL effort, the space of columnar storage is also wide open, and I think it is more beneficial to the overall healthy of the hadoop ecosystem.&lt;/p&gt;

&lt;p&gt;With that being said, I also looked at the patch attached with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-352&quot; title=&quot;Make Hive support column based storage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-352&quot;&gt;&lt;del&gt;HIVE-352&lt;/del&gt;&lt;/a&gt;. It appears that what the patch does is a level below our stated objectives. Specifically, the guts of the implementation (RCFile) is very close in spirit to TFile as described &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-3315&quot; title=&quot;New binary file format&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-3315&quot;&gt;&lt;del&gt;HADOOP-3315&lt;/del&gt;&lt;/a&gt;, which seems to have its first comprehensive patch back in December 2008. &lt;/p&gt;</comment>
                            <comment id="12716471" author="hammer" created="Fri, 5 Jun 2009 02:03:54 +0100"  >&lt;p&gt;Hey Hong,&lt;/p&gt;

&lt;p&gt;I never mentioned SQL or an ecosystem in my comment, but thanks for your observation. I was simply referring to the existence of a fairly detailed discussion in a related subproject that the Pig team may not have been following. I&apos;ll add an additional one here: &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-279&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-279&lt;/a&gt; addresses the predicate pushdown feature.&lt;/p&gt;

&lt;p&gt;Regards,&lt;br/&gt;
Jeff &lt;/p&gt;</comment>
                            <comment id="12716578" author="hong.tang" created="Fri, 5 Jun 2009 11:57:07 +0100"  >&lt;p&gt;@Jeff, I might have read a bit too much into the lines. I was referring to your comments on &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-824&quot; title=&quot;SQL interface for Pig&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-824&quot;&gt;&lt;del&gt;PIG-824&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I also took a look at &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-279&quot; title=&quot;Implement predicate push down for hive queries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-279&quot;&gt;&lt;del&gt;HIVE-279&lt;/del&gt;&lt;/a&gt;, the predicate push down mentioned there is actually a bit different from what we plan to do. &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-279&quot; title=&quot;Implement predicate push down for hive queries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-279&quot;&gt;&lt;del&gt;HIVE-279&lt;/del&gt;&lt;/a&gt; pushes predicates to map phase, whereby we would like to implement a storage layer where we can filter out bytes while reading data from disk.&lt;/p&gt;</comment>
                            <comment id="12736379" author="rangadi" created="Wed, 29 Jul 2009 01:27:32 +0100"  >&lt;p&gt;Attaching hadoop20.jar that needs to be placed under lib/ directory under the top level PIG directory. will included specific instructions later in the jira.&lt;/p&gt;</comment>
                            <comment id="12736405" author="zshao" created="Wed, 29 Jul 2009 02:08:51 +0100"  >&lt;p&gt;Hive has such a storage access layer. It consists of Hadoop File Format (which provides row-level access via RecordReader), and SerDe and ObjectInspector (which get the column values from the row).&lt;br/&gt;
Because of that, we were able to integrate RCFile (the columnar storage file format) fair easily (NOTE: in the columnar storage case, the row is just a handle).  We did look at TFile at that time, but it was not complete yet so we implemented RCFile by modifying SequenceFile instead of TFile.&lt;/p&gt;

&lt;p&gt;Experiments have shown that Hive SerDe/ObjectInspector has a pretty good performance because we always reuse the same objects for different rows. &lt;/p&gt;

&lt;p&gt;Most of the SerDe/ObjectInspector code is in hive/trunk/serde. There is a set of slides on &lt;a href=&quot;http://www.slideshare.net/zshao/hive-object-model&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.slideshare.net/zshao/hive-object-model&lt;/a&gt;&lt;br/&gt;
If the Pig team is interested in taking a deeper look at Hive&apos;s SerDe/ObjectInspector infrastructure, I am happy to provide more information.&lt;/p&gt;</comment>
                            <comment id="12736424" author="rangadi" created="Wed, 29 Jul 2009 03:55:18 +0100"  >
&lt;p&gt;Will surely look at Hive&apos;s storage layer and SerDe. I will be able to better comment on specifics  once I get better handle. In the mean while I will attach the work that is already been done on Zebra. &lt;/p&gt;

&lt;p&gt;This is currently a contrib in PIG. Based on these experiences we could probably provide a common storage layer more widely suitable for multiple Hadoop related projects.&lt;/p&gt;</comment>
                            <comment id="12736425" author="rangadi" created="Wed, 29 Jul 2009 03:58:38 +0100"  >&lt;p&gt;The first cut of contrib/zebra. The patch is very large and should probably compress the subsequent versions of it.&lt;/p&gt;

&lt;p&gt;More documentation on design and usage will be added to the jira.&lt;/p&gt;

&lt;p&gt;How to compile :&lt;br/&gt;
----------------------&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;check out latest PIG trunk&lt;/li&gt;
	&lt;li&gt;Apply the latest patch from &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-660&quot; title=&quot;Integration with Hadoop 0.20&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-660&quot;&gt;&lt;del&gt;PIG-660&lt;/del&gt;&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;copy attached hadoop20.jar to ./lib&lt;/li&gt;
	&lt;li&gt;run &apos;&lt;tt&gt;ant jar&lt;/tt&gt;&apos; (and &lt;tt&gt;&apos;ant -Dtestcase=none test-core&apos;&lt;/tt&gt; for zebra tests).&lt;/li&gt;
	&lt;li&gt;cd contrib/zebra&lt;/li&gt;
	&lt;li&gt;ant jar&lt;/li&gt;
	&lt;li&gt;ant test (for tests).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Currently there are compile time deprecation warnings related to use of deprecated mapred API (JobConf). There is will be fixed later.&lt;/p&gt;</comment>
                            <comment id="12736964" author="hammer" created="Thu, 30 Jul 2009 03:33:01 +0100"  >&lt;p&gt;Hey Raghu,&lt;/p&gt;

&lt;p&gt;Good stuff! Do you guys have any internal benchmarks that you could add to the docs on design and usage?&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Jeff&lt;/p&gt;</comment>
                            <comment id="12736998" author="rangadi" created="Thu, 30 Jul 2009 06:23:39 +0100"  >&lt;p&gt;There will be benchmark results either attached to this jira or to a subsequent jira.&lt;/p&gt;

&lt;p&gt;I would like to compare to SequenceFiles and the new format in Hive. Should to see on par performance.&lt;/p&gt;

&lt;p&gt;Major performance benefits come from commonly used projections (through column groups) and map side joins of sorted tables. An important part of motivation is some features like column security, ability to delete entire columns. &lt;/p&gt;

&lt;p&gt;We are running some larger scale benchmarks internally.. but these run on Yahoo&apos;s internal data sources.&lt;/p&gt;</comment>
                            <comment id="12742018" author="rangadi" created="Tue, 11 Aug 2009 20:04:49 +0100"  >&lt;p&gt;Updated patch. Only change is that ant prints a descriptive error to user if hadoop20.jar does not exist in top level lib directory. It lists basic steps to get this built until &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-660&quot; title=&quot;Integration with Hadoop 0.20&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-660&quot;&gt;&lt;del&gt;PIG-660&lt;/del&gt;&lt;/a&gt; is committed.&lt;/p&gt;</comment>
                            <comment id="12742064" author="alangates" created="Tue, 11 Aug 2009 22:20:15 +0100"  >&lt;p&gt;When I run ant test in contrib/zebra, I get failures.  I&apos;ve attached the output of the command.&lt;/p&gt;</comment>
                            <comment id="12742069" author="rangadi" created="Tue, 11 Aug 2009 22:28:17 +0100"  >&lt;p&gt;Alan, in order to run unit tests you need to build pig test-core.&lt;/p&gt;

&lt;p&gt;As mentioned in the instructions above please run &lt;tt&gt;&apos;ant -Dtestcase=none test-core&apos;&lt;/tt&gt; under top level directory before running &apos;ant test&apos; under contrib/zebra.&lt;/p&gt;</comment>
                            <comment id="12742081" author="alangates" created="Tue, 11 Aug 2009 22:53:57 +0100"  >&lt;p&gt;Okay, now that I&apos;ve first built Pig&apos;s test, I run the tests and I get:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 [delete] Deleting directory /Users/gates/src/pig/apache/top/zebra/trunk/build/contrib/zebra/test/logs
    [mkdir] Created dir: /Users/gates/src/pig/apache/top/zebra/trunk/build/contrib/zebra/test/logs
    [junit] Running org.apache.hadoop.zebra.io.TestCheckin
    [junit] Tests run: 125, Failures: 0, Errors: 0, Time elapsed: 16.894 sec
    [junit] Running org.apache.hadoop.zebra.mapred.TestCheckin
    [junit] Tests run: 2, Failures: 0, Errors: 0, Time elapsed: 158.741 sec
    [junit] Running org.apache.hadoop.zebra.pig.TestCheckin1
    [junit] Tests run: 0, Failures: 0, Errors: 2, Time elapsed: 0.13 sec
    [junit] Test org.apache.hadoop.zebra.pig.TestCheckin1 FAILED
    [junit] Running org.apache.hadoop.zebra.pig.TestCheckin2
    [junit] Tests run: 0, Failures: 0, Errors: 2, Time elapsed: 0.131 sec
    [junit] Test org.apache.hadoop.zebra.pig.TestCheckin2 FAILED
    [junit] Running org.apache.hadoop.zebra.pig.TestCheckin3
    [junit] Tests run: 0, Failures: 0, Errors: 2, Time elapsed: 0.133 sec
    [junit] Test org.apache.hadoop.zebra.pig.TestCheckin3 FAILED
    [junit] Running org.apache.hadoop.zebra.pig.TestCheckin4
    [junit] Tests run: 0, Failures: 0, Errors: 2, Time elapsed: 0.128 sec
    [junit] Test org.apache.hadoop.zebra.pig.TestCheckin4 FAILED
    [junit] Running org.apache.hadoop.zebra.pig.TestCheckin5
    [junit] Tests run: 0, Failures: 0, Errors: 2, Time elapsed: 0.128 sec
    [junit] Test org.apache.hadoop.zebra.pig.TestCheckin5 FAILED
    [junit] Running org.apache.hadoop.zebra.types.TestCheckin
    [junit] Tests run: 45, Failures: 0, Errors: 0, Time elapsed: 0.253 sec
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;ve attached the output from one of the tests.&lt;/p&gt;</comment>
                            <comment id="12742083" author="dvryaboy" created="Tue, 11 Aug 2009 22:56:21 +0100"  >&lt;p&gt;Alan &amp;#8211; if it&apos;s not finding .dfs , it&apos;s probably not linking hadoop20.jar&lt;/p&gt;

&lt;p&gt;Try my patch in 660 &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12742093" author="alangates" created="Tue, 11 Aug 2009 23:14:40 +0100"  >&lt;p&gt;My bad.  I missed the line in the instructions where it said to apply the &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-660&quot; title=&quot;Integration with Hadoop 0.20&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-660&quot;&gt;&lt;del&gt;PIG-660&lt;/del&gt;&lt;/a&gt; patch.  I applied that and am trying again.&lt;/p&gt;</comment>
                            <comment id="12742100" author="alangates" created="Tue, 11 Aug 2009 23:28:06 +0100"  >&lt;p&gt;Patch checked in.  All the unit tests passed.&lt;/p&gt;</comment>
                            <comment id="12742170" author="dvryaboy" created="Wed, 12 Aug 2009 02:24:07 +0100"  >&lt;p&gt;Alan, this means Pig contrib/ is no longer compatible with Hadoop 18.&lt;br/&gt;
Which probably means that you need to either rolls this back or roll 660 in (and add the hadoop20.jar file to lib/ )&lt;br/&gt;
Otherwise the build is broken.&lt;/p&gt;</comment>
                            <comment id="12742201" author="jaytang" created="Wed, 12 Aug 2009 04:44:39 +0100"  >&lt;p&gt;Zebra has a dependency on TFile that is available in Hadoop 20; that&apos;s why the compilation instruction is more complicated.  A new wiki at &lt;a href=&quot;http://wiki.apache.org/pig/zebra&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/pig/zebra&lt;/a&gt; will provide more information on Zebra.&lt;/p&gt;</comment>
                            <comment id="12742318" author="hudson" created="Wed, 12 Aug 2009 13:30:39 +0100"  >&lt;p&gt;Integrated in Pig-trunk #520 (See &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-trunk/520/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-trunk/520/&lt;/a&gt;)&lt;br/&gt;
    : Added Zebra, new columnar storage mechanism for HDFS.&lt;/p&gt;</comment>
                            <comment id="12742321" author="aaa" created="Wed, 12 Aug 2009 13:41:21 +0100"  >&lt;p&gt;I am out of office until Aug 14th. I will be checking my email&lt;br/&gt;
intermittently. If this is urgent then please call my cell phone,&lt;br/&gt;
otherwise I will reply to your email when I get back.&lt;/p&gt;

&lt;p&gt;Thanks for your patience,&lt;/p&gt;

&lt;p&gt;&amp;#8211; amr&lt;/p&gt;</comment>
                            <comment id="12742435" author="rangadi" created="Wed, 12 Aug 2009 17:25:47 +0100"  >&lt;p&gt;&amp;gt;  this means Pig contrib/ is no longer compatible with Hadoop 18.&lt;/p&gt;

&lt;p&gt;This is not desirable and expected to be temporary until &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-660&quot; title=&quot;Integration with Hadoop 0.20&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-660&quot;&gt;&lt;del&gt;PIG-660&lt;/del&gt;&lt;/a&gt; is committed. &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-660&quot; title=&quot;Integration with Hadoop 0.20&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-660&quot;&gt;&lt;del&gt;PIG-660&lt;/del&gt;&lt;/a&gt; has other dependencies different schedule. We thought committing zebra will make zebra builds and subsequent patches easier if it is committed. &lt;/p&gt;

&lt;p&gt;As such PIG does not build contrib from top level (&apos;ant test-contrib&apos; is a no-op). So each contrib project needs to be build explicitly anyway. This is different from Hadoop build. This this patch should not fail existing automated builds.&lt;/p&gt;</comment>
                            <comment id="12744323" author="hammer" created="Tue, 18 Aug 2009 02:28:11 +0100"  >&lt;p&gt;Hey,&lt;/p&gt;

&lt;p&gt;Raghu, you mention that a design document is forthcoming. It would be great to have a PDF design document, like Matei&apos;s for the fair scheduler, in addition to the Javadoc and wiki page. Any progress on that front? I&apos;m quite interested in learning more about Zebra&apos;s use and implementation.&lt;/p&gt;

&lt;p&gt;On a larger note, it would be great if Pig moved to the Hadoop model for new features, where a design document and test plan is required to commit. See &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-5587&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HADOOP-5587&lt;/a&gt;. It&apos;s tough to digest the bulk dumps of Owl, Zebra, and Giraffe, though we certainly appreciate the work Yahoo has done on these projects!&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Jeff&lt;/p&gt;</comment>
                            <comment id="12744361" author="rangadi" created="Tue, 18 Aug 2009 05:54:04 +0100"  >
&lt;p&gt;will try to get some initial docs attached to this jira asap. I think the current plan is to have proper wiki pages (and attached here). This is part of the reason by we would like to keep this jira open.&lt;/p&gt;

&lt;p&gt;The bulk initial dump is certainly not desirable but has been fairly common for many contrib projects in Hadoop. A bit of rush to get this committed to contrib is in part to avoid such large changes going again. The longer we delay larger the patch is going to get. We want to get the subsequent patches and discussions to public jira asap and we are already doing that.&lt;/p&gt;

&lt;p&gt;I would like to clarify that this is not a PIG feature but rather a contrib project. We would not want this commit to be generalized for PIG commits. All the responsibility is with Zebra team. This patch is the initial verion. It does include many tests. &lt;/p&gt;



</comment>
                            <comment id="12745049" author="he yongqiang" created="Wed, 19 Aug 2009 14:23:46 +0100"  >&lt;p&gt;Can add more description/explain in this jira or wiki page about usage etc, such as schma format, storage format, projection, and partition?&lt;/p&gt;</comment>
                            <comment id="12745052" author="he yongqiang" created="Wed, 19 Aug 2009 14:31:29 +0100"  >&lt;p&gt;By schema format, i mean the string used to define column names and column types. What kind of data type zebra support? what&apos;s the format? It will be great if there are some example and explaination.&lt;br/&gt;
By storage format, i mean the string used to define column groups, such as &quot;[r.f12, f1, m#&lt;/p&gt;
{b}
&lt;p&gt;]; [m#&lt;/p&gt;
{a}
&lt;p&gt;, r.f11]&quot; in TestBasicTableMapSplits.java.&lt;/p&gt;</comment>
                            <comment id="12745125" author="jing1234" created="Wed, 19 Aug 2009 18:01:12 +0100"  >&lt;p&gt;Zebra supports int, long, float, double, bool, collection (equivalent to Pig Bag), map, record (equivalent to Pig Tuple), string, bytes (equivalent to Pig Bytearray)&lt;/p&gt;</comment>
                            <comment id="12745140" author="jing1234" created="Wed, 19 Aug 2009 18:24:22 +0100"  >&lt;p&gt;Here is an example for different data types:&lt;br/&gt;
final static String STR_SCHEMA = &quot;s1:bool, s2:int, s3:long, s4:float, s5:string, s6:bytes, r1:record(f1:int, f2:long), r2:record(r3:record(f3:float, f4)), m1:map(string),m2:map(map(int)), c:collection(f13:double, f14:float, f15:bytes)&quot;;&lt;/p&gt;

&lt;p&gt;final static String STR_STORAGE = &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;s1, s2&amp;#93;&lt;/span&gt;; [m1#&lt;/p&gt;
{a}]; &lt;span class=&quot;error&quot;&gt;&amp;#91;r1.f1&amp;#93;&lt;/span&gt;; &lt;span class=&quot;error&quot;&gt;&amp;#91;s3, s4, r2.r3.f3&amp;#93;&lt;/span&gt;; &lt;a href=&quot;#{x|y}&quot;&gt;s5, s6, m2#{x|y}&lt;/a&gt;; &lt;a href=&quot;#{b}&quot;&gt;r1.f2, m1#{b}&lt;/a&gt;; &lt;a href=&quot;#{z}&quot;&gt;r2.r3.f4, m2#{z}&lt;/a&gt;&quot;;&lt;br/&gt;
  &lt;br/&gt;
On schema side, s1, s2....s6 are simple data type.   m2:map(map(int)): meaning m2 is a map of map. m2&apos;s value is a map and this inner map&apos;s value is a int type.   (key is always string type)&lt;br/&gt;
 r2:record(r3:record(f3:float, f4)): meaning r2 is a record with one field which is a record (r3). r3 is a record with two fields: f3: float and f4: default type bytes.&lt;br/&gt;
&lt;br/&gt;
On storage side, i.e  [m1#{a}
&lt;p&gt;] meaning map m1 with key &apos;a&apos; in this column group.  [s5, s6, m2#&lt;/p&gt;
{x|y}
&lt;p&gt;] meaning s5, s6 and map m2 with key &apos;x&apos; or &apos;y&apos; in this column group. [r2.r3.f4, m2#&lt;/p&gt;
{z}
&lt;p&gt;] meaning record r2&apos;s record r3 with field f4 and map m2 2ith key &apos;z&apos; in this column group.&lt;/p&gt;

</comment>
                            <comment id="12745219" author="rangadi" created="Wed, 19 Aug 2009 22:39:32 +0100"  >&lt;p&gt;Thanks Jing. There are some PIG examples listed at the bottom of Zebra wiki : &lt;a href=&quot;http://wiki.apache.org/pig/zebra&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/pig/zebra&lt;/a&gt; (wiki is still under construction).&lt;/p&gt;

&lt;p&gt;Just listing java strings in Jing&apos;s comment with out Jira formatting :&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;final static String STR_SCHEMA = 
     &quot;s1:bool, s2:int, s3:long, s4:float, s5:string, s6:bytes, &quot; +
     &quot;r1:record(f1:int, f2:long), r2:record(r3:record(f3:float, f4)), &quot; +
     &quot;m1:map(string),m2:map(map(int)), c:collection(f13:double, f14:float, f15:bytes)&quot;;

final static String STR_STORAGE = 
      &quot;[s1, s2]; [m1#{a}]; [r1.f1]; [s3, s4, r2.r3.f3]; [s5, s6, m2#{x|y}];  &quot; +
      &quot;[r1.f2, m1#{b}]; [r2.r3.f4, m2#{z}]&quot;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12745250" author="he yongqiang" created="Thu, 20 Aug 2009 01:24:39 +0100"  >&lt;p&gt;Thanks Jing.&lt;br/&gt;
I now have a better understand of schema and columngroups.&lt;br/&gt;
What the projection and partition are used for?&lt;/p&gt;</comment>
                            <comment id="12745758" author="jing1234" created="Fri, 21 Aug 2009 02:04:38 +0100"  >&lt;p&gt;Zebra supports vertical partition, meaning the rows of table can be splitted into columns and according to user specification(i.e. STR_STORAGE), Zebra will store columns into column groups.   Column Group is written in Tfile.&lt;br/&gt;
For excample, &lt;br/&gt;
final static String STR_STORAGE = &lt;br/&gt;
      &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;s1, s2&amp;#93;&lt;/span&gt;; [m1#&lt;/p&gt;
{a}
&lt;p&gt;]; &lt;span class=&quot;error&quot;&gt;&amp;#91;r1.f1&amp;#93;&lt;/span&gt;; &lt;span class=&quot;error&quot;&gt;&amp;#91;s3, s4, r2.r3.f3&amp;#93;&lt;/span&gt;; [s5, s6, m2#&lt;/p&gt;
{x|y}
&lt;p&gt;];  &quot; +&lt;br/&gt;
      &quot;[r1.f2, m1#&lt;/p&gt;
{b}
&lt;p&gt;]; [r2.r3.f4, m2#&lt;/p&gt;
{z}
&lt;p&gt;]&quot;;&lt;/p&gt;

&lt;p&gt;each [ ] is a column group. so, in this case, column group 0 will contain s1 and s2. &lt;/p&gt;

&lt;p&gt;Projection is  a view of table. Say, if your projection is something like:&lt;br/&gt;
 String projection = new String(&quot;s1,s3&quot;);&lt;br/&gt;
Zebra will load you date of s1 s3 (in this case, stitch ColumnGroup0 and ColumnGroup3 )&lt;/p&gt;

&lt;p&gt;This design is mainly for performance improvement. This is specially useful for the users who are only interested in certain columns of the data instead of the whole row. &lt;/p&gt;</comment>
                            <comment id="12745770" author="he yongqiang" created="Fri, 21 Aug 2009 03:22:54 +0100"  >&lt;p&gt;Thanks Jing.&lt;br/&gt;
Yeah, i know the design of column groups and projection.&lt;br/&gt;
The reason i was asking is that i saw an usage in line 251 TestBasicTable.java:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;doReadWrite(path, 2, 100, &quot;SF_a,SF_b,SF_c,SF_d,SF_e&quot;, &quot;[SF_a,SF_b,SF_c];[SF_d,SF_e]&quot;, &quot;SF_f,SF_a,SF_c,SF_d&quot;, true, false);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;where  &quot;SF_f,SF_a,SF_c,SF_d&quot; is passed as projection, but is there a column &quot;SF_f&quot; defined?&lt;/p&gt;

&lt;p&gt;btw, can you give more detail about the design of Partition? ColumnGroup is much like projection in C-Store, so it can be more easily to be understood.&lt;/p&gt;</comment>
                            <comment id="12750093" author="jing1234" created="Tue, 1 Sep 2009 21:55:37 +0100"  >&lt;p&gt;Hi Yongqiang, &lt;br/&gt;
Sorry for the late reply. I was out of town last week. &lt;br/&gt;
Right, SF_F is not defined in the schema, query a none-existing column is allowed and it will return null.&lt;/p&gt;</comment>
                            <comment id="12752745" author="alangates" created="Tue, 8 Sep 2009 22:06:24 +0100"  >&lt;p&gt;Patch was checked in a while ago.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12394260">PIG-210</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12414837" name="PIG-833-zebra.patch" size="1170753" author="rangadi" created="Wed, 29 Jul 2009 03:58:38 +0100"/>
                            <attachment id="12416234" name="PIG-833-zebra.patch.bz2" size="112891" author="rangadi" created="Tue, 11 Aug 2009 20:06:42 +0100"/>
                            <attachment id="12416233" name="PIG-833-zebra.patch.bz2" size="112600" author="rangadi" created="Tue, 11 Aug 2009 20:04:49 +0100"/>
                            <attachment id="12416252" name="TEST-org.apache.hadoop.zebra.pig.TestCheckin1.txt" size="1554" author="alangates" created="Tue, 11 Aug 2009 22:53:57 +0100"/>
                            <attachment id="12414823" name="hadoop20.jar.bz2" size="10233989" author="rangadi" created="Wed, 29 Jul 2009 01:27:32 +0100"/>
                            <attachment id="12416246" name="test.out" size="13902" author="alangates" created="Tue, 11 Aug 2009 22:20:15 +0100"/>
                            <attachment id="12414838" name="zebra-javadoc.tgz" size="87297" author="rangadi" created="Wed, 29 Jul 2009 04:03:57 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 5 Jun 2009 00:20:27 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>164386</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hyajfj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>95459</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>