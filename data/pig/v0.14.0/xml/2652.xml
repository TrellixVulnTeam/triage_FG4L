<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 05:07:10 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/PIG-2652/PIG-2652.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[PIG-2652] Skew join and order by don&apos;t trigger reducer estimation</title>
                <link>https://issues.apache.org/jira/browse/PIG-2652</link>
                <project id="12310730" key="PIG">Pig</project>
                    <description>&lt;p&gt;If neither PARALLEL, default parallel or &lt;tt&gt;mapred.reduce.tasks&lt;/tt&gt; are set, the number of reducers is not estimated based on input size for skew joins or order by. Instead, these jobs get only 1 reducer.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12550904">PIG-2652</key>
            <summary>Skew join and order by don&apos;t trigger reducer estimation</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dvryaboy">Dmitriy V. Ryaboy</assignee>
                                    <reporter username="billgraham">Bill Graham</reporter>
                        <labels>
                    </labels>
                <created>Sat, 14 Apr 2012 00:43:45 +0100</created>
                <updated>Fri, 22 Feb 2013 04:53:35 +0000</updated>
                            <resolved>Thu, 28 Jun 2012 21:51:36 +0100</resolved>
                                                    <fixVersion>0.11</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13253884" author="billgraham" created="Sat, 14 Apr 2012 00:54:35 +0100"  >&lt;p&gt;Here&apos;s a patch that sets the number of reducers to -1 in &lt;tt&gt;MRController&lt;/tt&gt; for sampled operations if it hasn&apos;t been set larger than 1. This will then trigger the reducer estimator in &lt;tt&gt;JobControlCompiler&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;A related fix would be to not do the sampling  if someone has set number of reducers explicitly to 1.&lt;/p&gt;</comment>
                            <comment id="13253890" author="dvryaboy" created="Sat, 14 Apr 2012 00:57:22 +0100"  >&lt;p&gt;+1.&lt;br/&gt;
This code is quite the mess. At some point we need to refactor it.&lt;/p&gt;

&lt;p&gt;Not running sampling for skewed / merge / order jobs when parallelism is set to 1 should be a separate ticket (I think I filed it already? Maybe just meant to).&lt;/p&gt;

&lt;p&gt;Please commit to 10 and 11.&lt;/p&gt;</comment>
                            <comment id="13253898" author="dvryaboy" created="Sat, 14 Apr 2012 01:08:59 +0100"  >&lt;p&gt;Committed to 0.9.3, 0.10.0, 0.11&lt;/p&gt;</comment>
                            <comment id="13254187" author="daijy" created="Sat, 14 Apr 2012 21:02:54 +0100"  >&lt;p&gt;Get couple of unit test failures:&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test org.apache.pig.test.TestCounters FAILED&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test org.apache.pig.test.TestEvalPipeline2 FAILED&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test org.apache.pig.test.TestFRJoin FAILED&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test org.apache.pig.test.TestGrunt FAILED&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test org.apache.pig.test.TestJobSubmission FAILED&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test org.apache.pig.test.TestJoin FAILED&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test org.apache.pig.test.TestLimitVariable FAILED&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test org.apache.pig.test.TestMultiQueryLocal FAILED&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test org.apache.pig.test.TestPigRunner FAILED&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test org.apache.pig.test.TestPigSplit FAILED&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test org.apache.pig.test.TestSampleOptimizer FAILED&lt;/p&gt;</comment>
                            <comment id="13254195" author="dvryaboy" created="Sat, 14 Apr 2012 21:43:52 +0100"  >&lt;p&gt;I am guessing the tests need to be adjusted. Sorry we rushed this out. Looking.&lt;/p&gt;</comment>
                            <comment id="13254197" author="dvryaboy" created="Sat, 14 Apr 2012 21:49:48 +0100"  >&lt;p&gt;These tests take forever. While I am waiting, Daniel, do you mind attaching the error logs?&lt;/p&gt;</comment>
                            <comment id="13254202" author="dvryaboy" created="Sat, 14 Apr 2012 22:09:29 +0100"  >&lt;p&gt;Ok, TestCounters appears to have a problem rooted in this exception:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

12/04/14 13:50:10 INFO mapred.TaskInProgress: Error from attempt_20120414134535045_0008_m_000000_0: java.lang.RuntimeException: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.partitioners.WeightedRangePartitioner.setConf(WeightedRangePartitioner.java:157)
        at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:62)
        at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)
        at org.apache.hadoop.mapred.MapTask$NewOutputCollector.&amp;lt;init&amp;gt;(MapTask.java:677)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:756)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:370)
        at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1083)
        at org.apache.hadoop.mapred.Child.main(Child.java:249)
Caused by: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0
        at java.util.ArrayList.RangeCheck(ArrayList.java:547)
        at java.util.ArrayList.get(ArrayList.java:322)
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.partitioners.WeightedRangePartitioner.convertToArray(WeightedRangePartitioner.java:199)
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.partitioners.WeightedRangePartitioner.setConf(WeightedRangePartitioner.java:142)
        ... 10 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13254251" author="dvryaboy" created="Sun, 15 Apr 2012 03:26:27 +0100"  >&lt;p&gt;Figured it out. &lt;br/&gt;
The parallelism from MRCompiler is used to set the number of quantiles that FindQuantiles needs to produce. If we set it to -1, nothing gets generated. We need to somehow do the proper, stat-guided estimation prior to getSamplingJob getting called (or fix it up in JobControlCompiler).&lt;/p&gt;</comment>
                            <comment id="13254253" author="dvryaboy" created="Sun, 15 Apr 2012 03:43:44 +0100"  >&lt;p&gt;Patching things up in JobControlCompiler, or getting JCC to run before MRCompiler appears to require a significant rewrite.&lt;/p&gt;

&lt;p&gt;Alternate proposal: &lt;br/&gt;
If parallelism is not set explicitly, and no default is specified, set the number of quantiles to pig.exec.reducers.max. WeightedPartitioner will then need to look at its actual parallelism and evenly distribute the (up to max-reducers) quantiles among partitions.  We&apos;d need to do something like that anyway if we used LoadFunc-reported histograms, or existing samples, to do the weighted partitioning, instead of running a sampling job every time.&lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;</comment>
                            <comment id="13254296" author="daijy" created="Sun, 15 Apr 2012 11:02:03 +0100"  >&lt;p&gt;In which context do you see the issue stated in the Jira? Seems order by with PigStorage set the right #reduce even before the patch. Sample job get initial value 1, but get reset in SampleOptimizer with the right value.&lt;/p&gt;</comment>
                            <comment id="13254361" author="dvryaboy" created="Sun, 15 Apr 2012 17:15:42 +0100"  >&lt;p&gt;Rolled back for 0.9.3 and 0.10.&lt;/p&gt;

&lt;p&gt;Thanks for the pointer to SampleOptimizer. &lt;/p&gt;

&lt;p&gt;I&apos;ll produce a reproducible test case.&lt;/p&gt;</comment>
                            <comment id="13254388" author="dvryaboy" created="Sun, 15 Apr 2012 18:59:35 +0100"  >&lt;p&gt;Ok, I have a test case. Estimation isn&apos;t triggered when the skewed join is preceded by another join (and perhaps anything else that has a reduce phase?).&lt;/p&gt;

&lt;p&gt;Try this script:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-- lower &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; so that multiple reducers are forced
set pig.exec.reducers.bytes.per.reducer 118024;

x = load &apos;tmp/camac10/part*&apos; as (foo:chararray);
y = load &apos;tmp/camac10/part*&apos; as (foo:chararray);
x2 = load &apos;tmp/camac10/part*&apos; as (bar:chararray);
x = join x by $0, x2 by $0;
z = join x by $0, y by $0;
store z into &apos;tmp/x11&apos;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With both joins being regular hash joins, the stats look like this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
JobId	Maps	Reduces	MaxMapTime	MinMapTIme	AvgMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	Alias	Feature	Outputs
job_201204041958_154682	2	12	6	6	6	19	19	19	x2,x	HASH_JOIN	
job_201204041958_154690	2	9	6	6	6	19	19	19	y,z	HASH_JOIN	hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hadoop-nn/user/dmitriy/tmp/x11,&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that &lt;b&gt;9 reducers&lt;/b&gt; were used by the second join.&lt;/p&gt;

&lt;p&gt;Now let&apos;s make the second join skewed (just add &quot;using &apos;skewed&apos;&quot; to the second join statement).&lt;br/&gt;
New stats:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
JobId	Maps	Reduces	MaxMapTime	MinMapTIme	AvgMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	Alias	Feature	Outputs
job_201204041958_154662	2	12	6	6	6	26	19	23	x2,x	HASH_JOIN	
job_201204041958_154664	1	1	6	6	6	19	19	19		SAMPLER	
job_201204041958_154667	2	1	6	6	6	19	19	19	y	SKEWED_JOIN	hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hadoop-nn/user/dmitriy/tmp/x10,&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(by the way &amp;#8211; I now notice that the z alias doesn&apos;t show up..).&lt;/p&gt;

&lt;p&gt;Note a single reducer being used for the skewed join job.&lt;/p&gt;

&lt;p&gt;Here&apos;s the plan:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
#--------------------------------------------------
# Map Reduce Plan                                  
#--------------------------------------------------
MapReduce node scope-32
Map Plan
Union[tuple] - scope-33
|
|---x: Local Rearrange[tuple]{chararray}(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) - scope-14
|   |   |
|   |   Project[chararray][0] - scope-15
|   |
|   |---x: New For Each(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)[bag] - scope-4
|       |   |
|       |   Cast[chararray] - scope-2
|       |   |
|       |   |---Project[bytearray][0] - scope-1
|       |
|       |---x: Load(hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hadoop-nn/user/dmitriy/tmp/camac10/part*:org.apache.pig.builtin.PigStorage) - scope-0
&lt;/span&gt;|
|---x: Local Rearrange[tuple]{chararray}(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) - scope-16
    |   |
    |   Project[chararray][0] - scope-17
    |
    |---x2: New For Each(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)[bag] - scope-9
        |   |
        |   Cast[chararray] - scope-7
        |   |
        |   |---Project[bytearray][0] - scope-6
        |
        |---x2: Load(hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hadoop-dw-nn.smf1.twitter.com/user/dmitriy/tmp/camac10/part*:org.apache.pig.builtin.PigStorage) - scope-5--------
&lt;/span&gt;Reduce Plan
Store(hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hadoop-nn/tmp/temp1728845767/tmp973408893:org.apache.pig.impl.io.InterStorage) - scope-35
&lt;/span&gt;|
|---POJoinPackage(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;,&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)[tuple] - scope-64--------
Global sort: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
----------------

MapReduce node scope-39
Map Plan
Local Rearrange[tuple]{tuple}(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) - scope-42
|   |
|   Constant(all) - scope-41
|
|---New For Each(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;,&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)[tuple] - scope-40
    |   |
    |   Project[chararray][0] - scope-26
    |   |
    |   POUserFunc(org.apache.pig.impl.builtin.GetMemNumRows)[tuple] - scope-37
    |   |
    |   |---Project[tuple][*] - scope-36
    |
    |---Load(hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hadoop-nn/tmp/temp1728845767/tmp973408893:org.apache.pig.impl.builtin.PoissonSampleLoader(&apos;org.apache.pig.impl.io.InterStorage&apos;,&apos;100&apos;)) - scope-38--------
&lt;/span&gt;Reduce Plan
Store(hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hadoop-nn/tmp/temp1728845767/tmp-1828327704:org.apache.pig.impl.io.InterStorage) - scope-51
&lt;/span&gt;|
|---New For Each(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)[tuple] - scope-50
    |   |
    |   POUserFunc(org.apache.pig.impl.builtin.PartitionSkewedKeys)[tuple] - scope-49
    |   |
    |   |---Project[tuple][*] - scope-48
    |
    |---New For Each(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;,&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)[tuple] - scope-47
        |   |
        |   Constant(1) - scope-46
        |   |
        |   Project[bag][1] - scope-44
        |
        |---Package[tuple]{chararray} - scope-43--------
Global sort: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
Secondary sort: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
----------------

MapReduce node scope-57
Map Plan
Union[tuple] - scope-58
|
|---Local Rearrange[tuple]{chararray}(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) - scope-54
|   |   |
|   |   Project[chararray][0] - scope-26
|   |
|   |---Load(hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hadoop-nn/tmp/temp1728845767/tmp973408893:org.apache.pig.impl.io.InterStorage) - scope-52
&lt;/span&gt;|
|---Partition rearrange [bag]{chararray}(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) - scope-55
    |   |
    |   Project[chararray][0] - scope-27
    |
    |---y: New For Each(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)[bag] - scope-25
        |   |
        |   Cast[chararray] - scope-23
        |   |
        |   |---Project[bytearray][0] - scope-22
        |
        |---y: Load(hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hadoop-nn/user/dmitriy/tmp/camac10/part*:org.apache.pig.builtin.PigStorage) - scope-21--------
&lt;/span&gt;Reduce Plan
z: Store(hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hadoop-nn/user/dmitriy/tmp/x11:org.apache.pig.builtin.PigStorage) - scope-29
&lt;/span&gt;|
|---POJoinPackage(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;,&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)[tuple] - scope-66--------
Global sort: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
----------------
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Daniel, what do you think about fixing this in SampleOptimizer vs making the multi-partition change I proposed (make it unnecessary to push the constant around, always generate stats for a large number of partitions and distributed them in WeightedPartitioner)?&lt;/p&gt;</comment>
                            <comment id="13254394" author="billgraham" created="Sun, 15 Apr 2012 19:23:05 +0100"  >&lt;p&gt;I was able to reproduce with a similar script that didn&apos;t have a reducer in the first MR job. The code in questions is this block in &lt;tt&gt;SampleOptimizer&lt;/tt&gt;. It returns in the second conditional with &lt;tt&gt;Predecessor should be a root of the plan&lt;/tt&gt; before reducers can be estimated.&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;noformat&lt;/tt&gt;&lt;br/&gt;
// Get this job&apos;s predecessor.  There should be exactly one.;&lt;br/&gt;
List&amp;lt;MapReduceOper&amp;gt; preds = mPlan.getPredecessors(mr);&lt;br/&gt;
if (preds.size() != 1) &lt;/p&gt;
{
    log.debug(&quot;Too many predecessors to sampling job.&quot;);
    return;
}
&lt;p&gt;MapReduceOper pred = preds.get(0);&lt;/p&gt;

&lt;p&gt;// The predecessor should be a root.&lt;br/&gt;
List&amp;lt;MapReduceOper&amp;gt; predPreds = mPlan.getPredecessors(pred);&lt;br/&gt;
if (predPreds != null &amp;amp;&amp;amp; predPreds.size() &amp;gt; 0) &lt;/p&gt;
{
    log.debug(&quot;Predecessor should be a root of the plan&quot;);
    return; 
}

&lt;p&gt;// The predecessor should have just a load and store in the map, and nothing&lt;br/&gt;
// in the combine or reduce.&lt;br/&gt;
if ( !(pred.reducePlan.isEmpty() &amp;amp;&amp;amp; pred.combinePlan.isEmpty())) &lt;/p&gt;
{
    log.debug(&quot;Predecessor has a combine or reduce plan&quot;);
    return;
}
&lt;p&gt;&lt;tt&gt;noformat&lt;/tt&gt;&lt;/p&gt;</comment>
                            <comment id="13254397" author="billgraham" created="Sun, 15 Apr 2012 19:30:54 +0100"  >&lt;p&gt;FYI, here&apos;s my script that reproduces with an initial Map-only job:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;L = LOAD &apos;data1.txt&apos; AS (owner:chararray,pet:chararray,age:int,phone:chararray);
R = LOAD &apos;data2.txt&apos; AS (owner:chararray,pet:chararray,age:int,phone:chararray);

L2 = FILTER L BY ((int)age &amp;gt; 0);
UNIONED = UNION L, L2;
JOINED = JOIN UNIONED BY owner, R BY owner USING &apos;skewed&apos;;

STORE JOINED INTO &apos;tmp/skew_join_union&apos;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13254431" author="dvryaboy" created="Sun, 15 Apr 2012 21:57:33 +0100"  >&lt;p&gt;Looks like the third rule isn&apos;t correct either.&lt;/p&gt;

&lt;p&gt;The problems seems to be that the SampleOptimizer used to do one thing, but now does (at least) two things. It used to remove an unnecessary MR job, as described in the class javadoc. As of &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-1642&quot; title=&quot;Order by doesn&amp;#39;t use estimation to determine the parallelism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-1642&quot;&gt;&lt;del&gt;PIG-1642&lt;/del&gt;&lt;/a&gt;, though, it&apos;s also responsible for reducer estimation. However, that optimization is not always possible &amp;#8211; which means reducer estimation also doesn&apos;t happen.&lt;/p&gt;

&lt;p&gt;I think we should separate the two functionalities, either by reworking the SampleOptimizer code, or changing how WeightedPartitioner works. The former is less intrusive, the latter is probably a more architecturally sound solution.&lt;/p&gt;

&lt;p&gt;Opinions?&lt;/p&gt;</comment>
                            <comment id="13254443" author="daijy" created="Sun, 15 Apr 2012 23:44:25 +0100"  >&lt;p&gt;I agree SampleOptimizer did more than it suppose to be, better to separate into two rule. &lt;/p&gt;

&lt;p&gt;As Bill observes, the rule does not proceed because some precondition fail. For now we can adjust the precondition check to solve some problem. I attach a patch for it. It solves Dmitriy&apos;s test case, however, Bill&apos;s test case is more involved. It is also related to plan merge of MultQuery. If I rewrite the query to get rid of the alias reuse, I can make it work:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
L = LOAD &apos;1.txt&apos; AS (owner:chararray,pet:chararray,age:&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,phone:chararray);
LN = LOAD &apos;1.txt&apos; AS (owner:chararray,pet:chararray,age:&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,phone:chararray);
R = LOAD &apos;2.txt&apos; AS (owner:chararray,pet:chararray,age:&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,phone:chararray);

L2 = FILTER L BY ((&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)age &amp;gt; 0);
UNIONED = UNION LN, L2;
JOINED = JOIN UNIONED BY owner, R BY owner USING &apos;skewed&apos;;

dump JOINED;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13254468" author="daijy" created="Mon, 16 Apr 2012 01:20:47 +0100"  >&lt;p&gt;SampleOptimizer is not a good place to do #reducer adjust. It is done once before the job launch, intermediate file is not yet generated, there is no way to get the size of job input. We shall move this logic to JobControlCompiler. Attach &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-2652&quot; title=&quot;Skew join and order by don&amp;#39;t trigger reducer estimation&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-2652&quot;&gt;&lt;del&gt;PIG-2652&lt;/del&gt;&lt;/a&gt;_3.patch.&lt;/p&gt;</comment>
                            <comment id="13254469" author="dvryaboy" created="Mon, 16 Apr 2012 01:28:44 +0100"  >&lt;p&gt;oh yeah.. we should reopen this &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13254471" author="dvryaboy" created="Mon, 16 Apr 2012 01:34:00 +0100"  >&lt;p&gt;Awesome, Daniel, thanks.&lt;br/&gt;
This last version looks much less fragile, and more easy to understand.&lt;/p&gt;

&lt;p&gt;I will test (more thoroughly this time, maybe add a test case or two even..).&lt;/p&gt;

&lt;p&gt;Stylistically, I&apos;d prefer the code that specifically deals with sampling jobs to be moved out into its own function called from adjustNumReducers. I&apos;ll post my version once I&apos;m done with tests (and taxes...).&lt;/p&gt;</comment>
                            <comment id="13254473" author="daijy" created="Mon, 16 Apr 2012 01:44:33 +0100"  >&lt;p&gt;The same patch for 0.10 branch. One side affect is explain will see different number of reducer cuz intermediate file is not available at explain time.&lt;/p&gt;</comment>
                            <comment id="13255363" author="dvryaboy" created="Tue, 17 Apr 2012 07:37:17 +0100"  >&lt;p&gt;Spent some time debugging my refactoring and decided maybe there&apos;s a bug in your patch, Daniel. As written, we look at the inputs to the sampling job and estimating reducers for the successor based on those inputs. However, the successor actually has two inputs &amp;#8211; the sampled dataset, and the second joined relation. That means the earlier estimate is incorrect.&lt;/p&gt;

&lt;p&gt;I tried running the estimator on the post-sample job, but there doesn&apos;t seem to be a way to connect the plan to its predecessor &amp;#8211; the plan passed in is already trimmed at the top. I&apos;ll try the following instead: identify a sampling job&apos;s children, and set them aside somewhere; then check against the saved list of known post-sample jobs and re-run the estimator for them if parallelism is set to 1.&lt;/p&gt;</comment>
                            <comment id="13255405" author="dvryaboy" created="Tue, 17 Apr 2012 09:02:43 +0100"  >&lt;p&gt;I&apos;ve verified that the same bug (undercounting the input when estimating reducers) is in effect on trunk, when SampleOptimizer is able to estimate reducers.&lt;/p&gt;

&lt;p&gt;Starting to uncover quite a few issues in skewed join implementation.. for example even if I explicitly set parallelism to 56, and have a half-dozen unique values in the skewed relation, the output is only split across 16 reducers.&lt;/p&gt;</comment>
                            <comment id="13255406" author="daijy" created="Tue, 17 Apr 2012 09:03:27 +0100"  >&lt;p&gt;Do you mean in skewed join, we only estimate the size based on the big table? I can see that, and it happens even before the patch. But since usually the skewed side is larger, so this might be acceptable.&lt;/p&gt;

&lt;p&gt;I find another issue however, some rules such as LimitAdjuster depends on the right #reducer, and those rules are triggered before job launch. Seems we need a hook to adjust plan after finishing one job.&lt;/p&gt;</comment>
                            <comment id="13255407" author="daijy" created="Tue, 17 Apr 2012 09:05:17 +0100"  >&lt;p&gt;Also, I try to starting rolling 0.10.0 tomorrow, may we unlink it from 0.10.0?&lt;/p&gt;</comment>
                            <comment id="13255408" author="dvryaboy" created="Tue, 17 Apr 2012 09:14:00 +0100"  >&lt;p&gt;Agreed with unlinking from 0.10, this is clearly becoming a major patch rather than a minor one. 0.10.1, maybe.. crossing fingers. We should document this for 0.10, at least.&lt;/p&gt;

&lt;p&gt;Interesting about LimitAdjuster. Separate jira or do you think we can kill both birds with one stone?&lt;/p&gt;

&lt;p&gt;I really think avoiding having to know # of reducers in any optimizers will serve us better in the long term. Can LimitAdjuster be done without this knowledge?&lt;/p&gt;

&lt;p&gt;Re: size estimation for skewed join, yes, I mean the &quot;big&quot; table &amp;#8211; except it&apos;s not the big table, it&apos;s the one with data skew. The other table might be the same size, or even bigger!&lt;/p&gt;
</comment>
                            <comment id="13255815" author="daijy" created="Tue, 17 Apr 2012 19:31:54 +0100"  >&lt;p&gt;Here is LimitAdjuster does: If the last job has more than 1 reducer, and it contains a limit, we will add a final MR job with 1 reducer. Otherwise we get N records per reducer rather than N records total. LimitAdjuster depends on #reducer of the MR Job.&lt;/p&gt;</comment>
                            <comment id="13255833" author="dvryaboy" created="Tue, 17 Apr 2012 20:01:21 +0100"  >&lt;p&gt;Could we make the Limit job a special case of MapReduce job (extends basemr) that, prior to kicking off, checks the number of input files and quietly returns if there is only a single file? Then we can always add it without performance overhead.&lt;/p&gt;</comment>
                            <comment id="13256871" author="dvryaboy" created="Wed, 18 Apr 2012 20:27:55 +0100"  >&lt;p&gt;Ok I have a much cleaner version of the patch, but it still suffers from a critical flaw &amp;#8211; the sampler needs to know the number of buckets to get samples for, and if it&apos;s not explicitly specified, and the SampleOptimizer stuff doesn&apos;t kick in, it still gets a single bucket to &quot;distribute&quot; skewed keys between.&lt;/p&gt;

&lt;p&gt;I think we have to go ahead with the approach of always sampling for a large number of buckets (10000?), and distributing them evenly in the partitioner. &lt;/p&gt;

&lt;p&gt;Daniel &amp;#8211; comments? Will attach my work-in-progress patch.&lt;/p&gt;</comment>
                            <comment id="13256875" author="dvryaboy" created="Wed, 18 Apr 2012 20:30:08 +0100"  >&lt;p&gt;note that I completely yanked that visitor. Don&apos;t think we need it anymore.&lt;/p&gt;</comment>
                            <comment id="13257010" author="dvryaboy" created="Wed, 18 Apr 2012 22:54:34 +0100"  >&lt;p&gt;Visitor is back in &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. Duh. Patch coming.&lt;/p&gt;</comment>
                            <comment id="13257034" author="dvryaboy" created="Wed, 18 Apr 2012 23:29:03 +0100"  >&lt;p&gt;Ok this works, I think. TestSampleOptimizer passes. I don&apos;t have the infra set up at the moment to run the rest (currently running TestFRJoin on my laptop..). Manual skewed join job run did the right thing.&lt;/p&gt;

&lt;p&gt;Still estimating based on the left side only, but running using an estimate for both left and right for skewed joins. &lt;/p&gt;</comment>
                            <comment id="13258089" author="daijy" created="Fri, 20 Apr 2012 09:44:49 +0100"  >&lt;p&gt;Seems it still does not solve the LimitAdjuster issue. Imagine the following script:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
A = load &apos;1.txt&apos;;
B = order A by a0;
C = limit B 100;
dump C;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It will generate 2 jobs, sampler job and order by job. When we launch the first job, we check the size of input file, and realize we need N&amp;gt;1 reducer, so we adjust both jobs to set #reducer to N. But since there is a limit operator beneath, it then needs to add a third job with #reducer=1 to impose the limit 100. LimitAdjuster is assumed to add the third job, but it runs before JobControlCompiler, so it cannot see #reducers=N. &lt;/p&gt;

&lt;p&gt;There is a testcase TestEvalPipeline2.testLimitAutoReducer, and it fails because of the above reason.&lt;/p&gt;</comment>
                            <comment id="13258091" author="dvryaboy" created="Fri, 20 Apr 2012 09:51:34 +0100"  >&lt;p&gt;I see.&lt;br/&gt;
I think the way to solve this is to always produce the third job in physical compilation, and remove it if it&apos;s not necessary in LimitAdjuster as not running this is an optimization (correctness won&apos;t suffer from running the extra MR). Agreed?&lt;/p&gt;</comment>
                            <comment id="13258719" author="daijy" created="Sat, 21 Apr 2012 02:25:21 +0100"  >&lt;p&gt;Yes, it&apos;s doable. We can mark the job SKIP when we find the job is no longer needed. When JobControlCompiler see a SKIP job, simply discard. &lt;/p&gt;</comment>
                            <comment id="13259324" author="dvryaboy" created="Mon, 23 Apr 2012 01:53:56 +0100"  >&lt;p&gt;Ok, not that simple. The adjuster messes with the inputs / outputs of the limiting job in pretty complex ways, so one would have to unroll all of that before running the pre-limit job.&lt;/p&gt;

&lt;p&gt;Also, apparently one can&apos;t simply run the adjuster inside the JobControlCompiler &amp;#8211; it does correctly add a new job, but that job fails with &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;12/04/22 17:27:31 INFO mapred.TaskInProgress: Error from attempt_20120422172532429_0004_m_000000_0: org.apache.pig.backend.executionengine.ExecException: ERROR 2044: The type &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; cannot be collected as a Key type
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; &lt;/p&gt;

&lt;p&gt;Moreover, the extra job is not accounted for in stats, progress, etc. &lt;/p&gt;

&lt;p&gt;Looking at how we can do this better.&lt;/p&gt;</comment>
                            <comment id="13259743" author="dvryaboy" created="Mon, 23 Apr 2012 18:22:06 +0100"  >&lt;p&gt;Ok, attaching latest.&lt;/p&gt;

&lt;p&gt;This always adds the limiting MR job, even though it&apos;s not always strictly necessary. I feel that getting number of reducers estimated well for big jobs is more important than saving a tiny MR job (and this job will be tiny &amp;#8211; if it&apos;s unnecessary, by definition all that it does is read a LIMIT-ed number of rows, and output them back out).&lt;/p&gt;

&lt;p&gt;We will create a separate ticket to apply an optimization that eliminates this extra limit job when possible.&lt;/p&gt;</comment>
                            <comment id="13259936" author="daijy" created="Mon, 23 Apr 2012 21:46:34 +0100"  >&lt;p&gt;Agree it&apos;s more important to fix big job. Did you run through unit test? I am afraid some tests will fail due to the extra job.&lt;/p&gt;</comment>
                            <comment id="13260079" author="dvryaboy" created="Tue, 24 Apr 2012 00:33:33 +0100"  >&lt;p&gt;I haven&apos;t had any luck getting hudson to actually finish a full unit test run.. but let me try to set that up again. &lt;/p&gt;</comment>
                            <comment id="13260143" author="dvryaboy" created="Tue, 24 Apr 2012 02:53:14 +0100"  >&lt;p&gt;Unsurprisingly, org.apache.pig.test.TestLimitAdjuster failed. I&apos;ll adjust tests as appropriate.&lt;/p&gt;</comment>
                            <comment id="13260214" author="dvryaboy" created="Tue, 24 Apr 2012 05:44:27 +0100"  >&lt;p&gt;Actually, it passes if I clean the environment. TestSkewedJoin also passed. I spot-checked a few others and they pass as well. A grep through tests and golden files didn&apos;t show anything that&apos;s specifically testing the added (or not-added) limiter job, just that the results are correct.&lt;/p&gt;

&lt;p&gt;Currently test-commit fails on trunk for me on hudson (org.apache.pig.test.TestStore.testSuccessFileCreation1 fails), so running the whole test suite doesn&apos;t seem possible.. do you have a more stable testing environment you could try this on?&lt;/p&gt;</comment>
                            <comment id="13260309" author="daijy" created="Tue, 24 Apr 2012 08:11:21 +0100"  >&lt;p&gt;Yes, I will run the test.&lt;/p&gt;</comment>
                            <comment id="13261211" author="dvryaboy" created="Wed, 25 Apr 2012 02:46:50 +0100"  >&lt;p&gt;Daniel, did you get a chance to run this?&lt;/p&gt;</comment>
                            <comment id="13261344" author="daijy" created="Wed, 25 Apr 2012 07:47:46 +0100"  >&lt;p&gt;Yes, I get the following failures, most are not surprising:&lt;br/&gt;
TestExampleGenerator.testLimit&lt;br/&gt;
TestJobSubmission.testReducerNumEstimationForOrderBy&lt;br/&gt;
TestPigRunner.orderByTest&lt;br/&gt;
TestPigStats.testPigStatsAlias&lt;/p&gt;</comment>
                            <comment id="13262457" author="dvryaboy" created="Thu, 26 Apr 2012 09:19:47 +0100"  >&lt;p&gt;Fixed tests. Please try again.&lt;/p&gt;</comment>
                            <comment id="13263863" author="daijy" created="Fri, 27 Apr 2012 19:15:05 +0100"  >&lt;p&gt;Unit tests pass. +1 for commit. But we need to fix the extra job issue before next release.&lt;/p&gt;</comment>
                            <comment id="13264113" author="dvryaboy" created="Sat, 28 Apr 2012 00:34:56 +0100"  >&lt;p&gt;Committed to 0.11&lt;/p&gt;

&lt;p&gt;Can I commit to 0.10.1 or do you feel the extra MR job is too much?&lt;/p&gt;</comment>
                            <comment id="13264145" author="daijy" created="Sat, 28 Apr 2012 01:16:06 +0100"  >&lt;p&gt;If we can fix the extra job before 0.10.1 release, I am fine to commit it.&lt;/p&gt;</comment>
                            <comment id="13264152" author="dvryaboy" created="Sat, 28 Apr 2012 01:24:48 +0100"  >&lt;p&gt;Created &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-2675&quot; title=&quot;Optimization: Remove unnecessary Limit jobs from plan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-2675&quot;&gt;PIG-2675&lt;/a&gt;.&lt;br/&gt;
I am not sure I want to commit to doing that as a blocker for 0.10.1. It&apos;s a very small job, there are more fundamental improvements to be had for the same amount of effort, I think. But we should still do it at some point.&lt;/p&gt;</comment>
                            <comment id="13264154" author="daijy" created="Sat, 28 Apr 2012 01:26:59 +0100"  >&lt;p&gt;I don&apos;t feel it&apos;s too hard to fix. I can take a look.&lt;/p&gt;</comment>
                            <comment id="13414192" author="jay23jack" created="Sat, 14 Jul 2012 01:22:34 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Still estimating based on the left side only, but running using an estimate for both left and right for skewed joins.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Does this means the skew join will allocate more reducers than what the sampler assumes, and those extra reducers will have nothing to do?&lt;/p&gt;</comment>
                            <comment id="13414210" author="dvryaboy" created="Sat, 14 Jul 2012 01:38:08 +0100"  >&lt;p&gt;I believe the non-skewed keys will get hashed to all reducers, not just those used for sampling.&lt;/p&gt;</comment>
                            <comment id="13415459" author="jay23jack" created="Mon, 16 Jul 2012 19:03:14 +0100"  >&lt;p&gt;Then the skewed keys will only go to some of the reducers, and ideally we want to distribute them across all reducers right? I can fix it in &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-2779&quot; title=&quot;Refactoring the code for setting number of reducers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-2779&quot;&gt;&lt;del&gt;PIG-2779&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13490251" author="rohini" created="Sun, 4 Nov 2012 18:44:57 +0000"  >&lt;p&gt;Correcting the fixed version. Removing 0.9.3 and 0.10.1&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12596346">PIG-2779</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12522639" name="PIG-2652_1.patch" size="864" author="billgraham" created="Sat, 14 Apr 2012 00:54:35 +0100"/>
                            <attachment id="12522727" name="PIG-2652_2.patch" size="2276" author="daijy" created="Sun, 15 Apr 2012 23:44:25 +0100"/>
                            <attachment id="12522729" name="PIG-2652_3.patch" size="10506" author="daijy" created="Mon, 16 Apr 2012 01:20:47 +0100"/>
                            <attachment id="12522731" name="PIG-2652_3_10.patch" size="9398" author="daijy" created="Mon, 16 Apr 2012 01:44:32 +0100"/>
                            <attachment id="12523239" name="PIG-2652_4.patch" size="9592" author="dvryaboy" created="Wed, 18 Apr 2012 20:30:08 +0100"/>
                            <attachment id="12523267" name="PIG-2652_5.patch" size="11235" author="dvryaboy" created="Wed, 18 Apr 2012 23:29:03 +0100"/>
                            <attachment id="12523824" name="PIG-2652_6.patch" size="15712" author="dvryaboy" created="Mon, 23 Apr 2012 18:22:06 +0100"/>
                            <attachment id="12524406" name="PIG-2652_7.patch" size="24999" author="dvryaboy" created="Thu, 26 Apr 2012 09:19:46 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 13 Apr 2012 23:57:22 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>235768</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy8k73:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>83915</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fix how reducers are estimated for skew join and order operators.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>