<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:55:14 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/PIG-1229/PIG-1229.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[PIG-1229] allow pig to write output into a JDBC db</title>
                <link>https://issues.apache.org/jira/browse/PIG-1229</link>
                <project id="12310730" key="PIG">Pig</project>
                    <description>&lt;p&gt;UDF to store data into a DB&lt;/p&gt;</description>
                <environment></environment>
        <key id="12455602">PIG-1229</key>
            <summary>allow pig to write output into a JDBC db</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ankur">Ankur</assignee>
                                    <reporter username="iholsman">Ian Holsman</reporter>
                        <labels>
                    </labels>
                <created>Mon, 8 Feb 2010 08:01:33 +0000</created>
                <updated>Fri, 17 Dec 2010 22:43:19 +0000</updated>
                            <resolved>Wed, 28 Jul 2010 01:45:38 +0100</resolved>
                                                    <fixVersion>0.8.0</fixVersion>
                                    <component>impl</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="12831052" author="kimballa" created="Mon, 8 Feb 2010 19:06:22 +0000"  >&lt;p&gt;Ian, &lt;/p&gt;

&lt;p&gt;This class looks reasonable to me. You&apos;ll probably need to format this as a patch to get it accepted into the project though.&lt;/p&gt;

&lt;p&gt;Is there a test plan for this code and/or unit tests?&lt;/p&gt;

&lt;p&gt;Some database-specific things I&apos;ve noticed: &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;You create a PreparedStatement, and call its executeUpdate() method several times then call close() on the statement. This assumes you&apos;re in Auto-commit mode; I think you should configure the commit mode explicitly when creating the connection. Also, you&apos;ll probably get a lot better performance if you use addBatch() / executeBatch() for your batch size rather than individual executeUpdate() statements. You should then call connection.commit() and ps.clear() rather than closing the prepared statement and compiling a new one.&lt;/li&gt;
	&lt;li&gt;If user and pass are null, I think you may need to use DriverManager.getConnection(jdbcUrl) instead of DriverManager.getConnection(jdbcUrl, null, null). Worth a unit test.&lt;/li&gt;
	&lt;li&gt;See org.apache.hadoop.mapreduce.lib.db.DBOutputFormat in the MapReduce project for some similar code to take inspiration from.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12831337" author="ankur" created="Tue, 9 Feb 2010 07:46:52 +0000"  >&lt;p&gt;Aaron, Thanks for the suggestions.&lt;br/&gt;
I&apos;ll have an updated patch coming soon.&lt;/p&gt;</comment>
                            <comment id="12833837" author="ankur" created="Mon, 15 Feb 2010 15:21:29 +0000"  >&lt;p&gt;Updated code with added test case using HSQLDB (binary part of the patch).&lt;/p&gt;</comment>
                            <comment id="12833949" author="hadoopqa" created="Mon, 15 Feb 2010 19:59:46 +0000"  >&lt;p&gt;+1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12435875/jira-1229.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12435875/jira-1229.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision 909921.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 4 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/211/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/211/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/211/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/211/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/211/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/211/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12833998" author="kimballa" created="Mon, 15 Feb 2010 22:00:31 +0000"  >&lt;p&gt;Looks much better - thanks for adding the test case too. Including hsqldb.jar in your patch didn&apos;t work, by the way &amp;#8211; you&apos;ll need to attach that jar separately to the issue I think.&lt;/p&gt;</comment>
                            <comment id="12834071" author="ankur" created="Tue, 16 Feb 2010 04:05:49 +0000"  >&lt;p&gt;Attaching hsqldb.jar separately as including it in the patch does not work&lt;/p&gt;</comment>
                            <comment id="12834375" author="olgan" created="Tue, 16 Feb 2010 18:49:21 +0000"  >&lt;p&gt;Updated version number since it is not a blocker for 0.6.0 that has been out for a while&lt;/p&gt;</comment>
                            <comment id="12840963" author="olgan" created="Thu, 4 Mar 2010 00:12:18 +0000"  >&lt;p&gt;Ashutosh, please, review and see if we can pull the jar from IVY.&lt;/p&gt;</comment>
                            <comment id="12841003" author="ashutoshc" created="Thu, 4 Mar 2010 02:25:08 +0000"  >&lt;p&gt;Ankur,&lt;/p&gt;

&lt;p&gt;With recent Load-Store interface changes, the patch doesn&apos;t compile. Can you regenerate it? And while you are at it, can you also make changes in ivy.xml so that hsqldb.jar is pulled over internet instead of needing it to be bundled with pig distribution.&lt;/p&gt;</comment>
                            <comment id="12841049" author="ankur" created="Thu, 4 Mar 2010 04:08:04 +0000"  >&lt;p&gt;Sure, I&apos;ll do that. Give me a couple days of time.&lt;/p&gt;</comment>
                            <comment id="12841391" author="ashutoshc" created="Thu, 4 Mar 2010 17:16:31 +0000"  >&lt;p&gt;Sure. By the way, I am not sure if hsqldb license &lt;a href=&quot;http://hsqldb.org/web/hsqlLicense.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hsqldb.org/web/hsqlLicense.html&lt;/a&gt; is compatible with Apache or not. Though, I think if we are pulling it through ivy, we will be fine. Am I correct ?&lt;/p&gt;</comment>
                            <comment id="12847483" author="olgan" created="Fri, 19 Mar 2010 18:06:05 +0000"  >&lt;p&gt;Is this issue going to be resolved by Monday or should we move the release to Pig 0.8.0?&lt;/p&gt;</comment>
                            <comment id="12847909" author="ankur" created="Sun, 21 Mar 2010 10:21:01 +0000"  >&lt;p&gt;@Ashtosh Chauhan &lt;br/&gt;
I read the HSQLDB license and it looked ok to me but I am not a lawyer &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; . Besides that apache cocoon uses it. I think we should be ok pulling it through ivy.&lt;/p&gt;

&lt;p&gt;I&apos;ll make the ivy and load-store related changes and submit a new patch on Monday.&lt;/p&gt;

&lt;p&gt;Sorry for the delay.&lt;/p&gt;
</comment>
                            <comment id="12848258" author="olgan" created="Mon, 22 Mar 2010 18:13:05 +0000"  >&lt;p&gt;Moving to Pig 0.8.0 release since we are branching today.&lt;/p&gt;</comment>
                            <comment id="12851454" author="ankur" created="Tue, 30 Mar 2010 17:22:54 +0100"  >&lt;p&gt;Here is the updated patch that compiles against pig 0.7 branch and implements new load/store APIs. &lt;/p&gt;

&lt;p&gt;Note:- that I haven&apos;t used hadoop&apos;s DBOutputFormat as the code is not yet moved to o.p.h.mapreduce.lib and hence there are compatibility issues.&lt;/p&gt;</comment>
                            <comment id="12851455" author="olgan" created="Tue, 30 Mar 2010 17:27:09 +0100"  >&lt;p&gt;Since we already branched, this feature will not go into 0.7.0 branch but would instead be committed to trunk and released as part of 0.8.0 release. I think this patch should work just fine against trunk since we have noit deviated much.&lt;/p&gt;</comment>
                            <comment id="12851665" author="hadoopqa" created="Wed, 31 Mar 2010 01:05:42 +0100"  >&lt;p&gt;+1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12440249/jira-1229-v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12440249/jira-1229-v2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision 928950.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 4 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/260/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/260/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/260/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/260/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/260/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/260/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12852190" author="ashutoshc" created="Thu, 1 Apr 2010 01:16:22 +0100"  >&lt;p&gt;Few suggestions:&lt;/p&gt;

&lt;p&gt;Reading from test case, currently store statements look like:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 b = store a into &apos;dummy&apos; using org.apache.pig.piggybank.storage.DBStorage(&apos;org.hsqldb.jdbcDriver&apos;,&apos;jdbc:hsqldb:file:/tmp/batchtest;hsqldb.default_table_type=cached;hsqldb.cache_rows=100&apos;,&apos;insert into a...&apos;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;here &apos;dummy&apos; is totally ignored. while this works, from a user experience following might be better:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 b = store a into &apos;jdbc:hsqldb:file:/tmp/batchtest&apos; using org.apache.pig.piggybank.storage.DBStorage(&apos;org.hsqldb.jdbcDriver&apos;,&apos;hsqldb.default_table_type=cached;hsqldb.cache_rows=100&apos;,&apos;insert into a&apos;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;that is, have db url as store location and second param of store func as db params. you can use setStoreLocation() to store url. Apart from more intuitive store stmt, this will also allow you to check whether DB is reachable or not at compile time itself, instead of at runtime. You can do that via checkOutputSpecs(). &lt;/p&gt;

&lt;p&gt;Doing DataType.findType() on every element of every tuple will be expensive. I am wondering if you can get hold of schema in your store func and use that to map pig types to sql types.&lt;/p&gt;

&lt;p&gt;All of these suggestions may come in as later patches. So, if you want to get this committed and track these separately I think that also will work as this patch is functionally complete. &lt;/p&gt;</comment>
                            <comment id="12852243" author="ankur" created="Thu, 1 Apr 2010 05:13:11 +0100"  >&lt;p&gt;Ashutosh,&lt;br/&gt;
   Thanks for the review comments. Accepting the store location via setStoreLocation() definitely makes sense. However I am not sure about checking database reachability in checkOutputSepcs() &lt;br/&gt;
since that may be called on the client side as well and the DB machine may not be reachable from the client machine. Isn&apos;t OutputFormat&apos;s setupTask()  a better place to do a DB availability checks ?&lt;br/&gt;
This sounds like a reasonable ask before a commit. I will incorporate this and submit a new patch &lt;/p&gt;

&lt;p&gt;&amp;gt; Doing DataType.find() ....&lt;br/&gt;
I assume this is what you have in mind :-&lt;br/&gt;
    1. Getting DB Schema information for the table we are writing to.&lt;br/&gt;
    2. Use checkSchema() API to validate this with Pig supplied schema and cache it.&lt;br/&gt;
    3. Use the cached information in the putNext() method.&lt;/p&gt;

&lt;p&gt;This is more of a performance enhancement and looks like more work. So I would prefer if we track this as a JIRA for DBStorage.&lt;/p&gt;</comment>
                            <comment id="12853843" author="ankur" created="Tue, 6 Apr 2010 11:34:46 +0100"  >&lt;p&gt;So accepting the JDBC URL in setStoreLocation() exposes a flaw in Hadoop&apos;s Path class and it causes test case to fail with following exception&lt;/p&gt;

&lt;p&gt;java.net.URISyntaxException: Relative path in absolute URI: jdbc:hsqldb:&lt;a href=&quot;file:/tmp/batchtest;hsqldb.default_table_type=cached;hsqldb.cache_rows=100&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/tmp/batchtest;hsqldb.default_table_type=cached;hsqldb.cache_rows=100&lt;/a&gt;&lt;br/&gt;
java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: jdbc:hsqldb:&lt;a href=&quot;file:/tmp/batchtest;hsqldb.default_table_type=cached;hsqldb.cache_rows=100&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/tmp/batchtest;hsqldb.default_table_type=cached;hsqldb.cache_rows=100&lt;/a&gt;&lt;br/&gt;
        at org.apache.hadoop.fs.Path.initialize(Path.java:140)&lt;br/&gt;
        at org.apache.hadoop.fs.Path.&amp;lt;init&amp;gt;(Path.java:126)&lt;br/&gt;
        at org.apache.pig.LoadFunc.getAbsolutePath(LoadFunc.java:238)&lt;br/&gt;
        at org.apache.pig.StoreFunc.relToAbsPathForStoreLocation(StoreFunc.java:60)&lt;br/&gt;
        at org.apache.pig.impl.logicalLayer.parser.QueryParser.StoreClause(QueryParser.java:3587)&lt;br/&gt;
...&lt;br/&gt;
...&lt;br/&gt;
Caused by: java.net.URISyntaxException: Relative path in absolute URI: jdbc:hsqldb:&lt;a href=&quot;file:/tmp/batchtest;hsqldb.default_table_type=cached;hsqldb.cache_rows=100&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/tmp/batchtest;hsqldb.default_table_type=cached;hsqldb.cache_rows=100&lt;/a&gt;&lt;br/&gt;
        at java.net.URI.checkPath(URI.java:1787)&lt;br/&gt;
        at java.net.URI.&amp;lt;init&amp;gt;(URI.java:735)&lt;br/&gt;
        at org.apache.hadoop.fs.Path.initialize(Path.java:137)&lt;/p&gt;

&lt;p&gt;Looking at the code of Path.java it seems like it extracts scheme based on the first occurrence of &apos;:&apos;, this causes authority and path to be extracted incorrectly resulting in the above exception thrown java.net.URI. &lt;br/&gt;
However if I try to initialize URI directly with the URL string, no exception is thrown.&lt;/p&gt;

&lt;p&gt;As for DB reachability check, I think it is ok to check the availability at the runtime an fail if its available. We do this prepareToWrite(). &lt;br/&gt;
For performance enhancement, I think we can track that via separate issue.&lt;/p&gt;

&lt;p&gt;This patch has taken quite a while now and I wouldn&apos;t want to delay it further by depending on a hadoop fix.&lt;/p&gt;

&lt;p&gt;So If a reviewer does not find any blocking issues then my suggestion is to go ahead with the commit. &lt;/p&gt;</comment>
                            <comment id="12854740" author="ashutoshc" created="Thu, 8 Apr 2010 01:08:28 +0100"  >&lt;p&gt;You  can get rid of this stack-trace by overriding relToAbsPathForStoreLocation() of StoreFunc which DBStorage extends and turning it into no-op. Since, DB location is always absolute, there is no need of default behavior which is there in StoreFunc.  &lt;/p&gt;

&lt;p&gt;For DataType.find() I found even PigStorage does the same, so this patch is no worse then PigStorage in that way.&lt;/p&gt;</comment>
                            <comment id="12855835" author="ankur" created="Mon, 12 Apr 2010 05:52:18 +0100"  >&lt;ul&gt;
	&lt;li&gt;Sigh *&lt;br/&gt;
The problem is with hadoop&apos;s Path implementation that has problems understanding JDBC URLs correctly. So turning relToAbsPathForStoreFunction() does NOT help. &lt;br/&gt;
The URI SyntaxException is now propagated to the point of setting output path for the job. Here is the new trace from the text execution failure with suggested workaround&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;org.apache.pig.backend.executionengine.ExecException: ERROR 2043: Unexpected error during execution.&lt;br/&gt;
        at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.execute(HExecutionEngine.java:332)&lt;br/&gt;
        at org.apache.pig.PigServer.executeCompiledLogicalPlan(PigServer.java:835)&lt;br/&gt;
        at org.apache.pig.PigServer.execute(PigServer.java:828)&lt;br/&gt;
        at org.apache.pig.PigServer.access$100(PigServer.java:105)&lt;br/&gt;
        at org.apache.pig.PigServer$Graph.execute(PigServer.java:1080)&lt;br/&gt;
        at org.apache.pig.PigServer.executeBatch(PigServer.java:288)&lt;br/&gt;
        at org.apache.pig.piggybank.test.storage.TestDBStorage.testWriteToDB(Unknown Source)&lt;br/&gt;
Caused by: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobCreationException: ERROR 2017: Internal error creating job configuration.&lt;br/&gt;
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler.getJob(JobControlCompiler.java:624)&lt;br/&gt;
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler.compile(JobControlCompiler.java:246)&lt;br/&gt;
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.launchPig(MapReduceLauncher.java:131)&lt;br/&gt;
        at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.execute(HExecutionEngine.java:308)&lt;br/&gt;
Caused by: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: jdbc:hsqldb:&lt;a href=&quot;file:/tmp/batchtest;hsqldb.default_table_type=cached;hsqldb.cache_rows=100&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/tmp/batchtest;hsqldb.default_table_type=cached;hsqldb.cache_rows=100&lt;/a&gt;&lt;br/&gt;
        at org.apache.hadoop.fs.Path.initialize(Path.java:140)&lt;br/&gt;
        at org.apache.hadoop.fs.Path.&amp;lt;init&amp;gt;(Path.java:126)&lt;br/&gt;
        at org.apache.hadoop.fs.Path.&amp;lt;init&amp;gt;(Path.java:45)&lt;br/&gt;
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler.getJob(JobControlCompiler.java:459)&lt;br/&gt;
Caused by: java.net.URISyntaxException: Relative path in absolute URI: jdbc:hsqldb:&lt;a href=&quot;file:/tmp/batchtest;hsqldb.default_table_type=cached;hsqldb.cache_rows=100&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/tmp/batchtest;hsqldb.default_table_type=cached;hsqldb.cache_rows=100&lt;/a&gt;&lt;br/&gt;
        at java.net.URI.checkPath(URI.java:1787)&lt;br/&gt;
        at java.net.URI.&amp;lt;init&amp;gt;(URI.java:735)&lt;br/&gt;
        at org.apache.hadoop.fs.Path.initialize(Path.java:137)&lt;/p&gt;


</comment>
                            <comment id="12856761" author="ankur" created="Wed, 14 Apr 2010 06:43:19 +0100"  >&lt;p&gt;Any updates ? &lt;/p&gt;</comment>
                            <comment id="12857154" author="ashutoshc" created="Thu, 15 Apr 2010 01:05:00 +0100"  >&lt;p&gt;As per &lt;a href=&quot;http://www.mail-archive.com/pig-user@hadoop.apache.org/msg02257.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.mail-archive.com/pig-user@hadoop.apache.org/msg02257.html&lt;/a&gt; thread I am wondering if it will be safe and possible to make sure that job using this storage has speculative execution turned-off.  Otherwise, with S.E. turned on, there are too many scenarios we would have to handle. What do you think?&lt;/p&gt;</comment>
                            <comment id="12857253" author="ankur" created="Thu, 15 Apr 2010 10:56:06 +0100"  >&lt;p&gt;So I read the complete thread and here are my thoughts:-&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Speculative execution issue : With recent changes of moving to Hadoop&apos;s I/O format in Load/Store, DBStorage has been modified to commit the data to DB in OutputCommitter&apos;s&lt;br/&gt;
commitTask() method.   Hadoop itself gaurantees that the method will be called only for first successful attempt so it shouldn&apos;t matter whether or not speculative execution is on. &lt;br/&gt;
BUT this does NOT solve the problem where certain tasks finished successfully but the JOB itself failed in which case the data from successful attempts should be rolled back.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Writing to Temporary Table: Even this does not handle the case the above case since some of the tasks would have moved their data to the actual table.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Bulk loading : This is the most suitable option in my opinion if the data is large. However for small to medium data size (like aggregate summaries), I found DBStorage UDF to be most helpful.&lt;br/&gt;
It just eliminates one more layer of processing from the application. In fact this was precisely the reason it was written for.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So in a nutshell, using a single mapper/reducer with this patch should be good regardless of speculative execution being off/on. In case of multiple mappers/reducers writing to DB it should be application&apos;s&lt;br/&gt;
responsibility to cleanup data ONLY IN CASE of job failure.&lt;/p&gt;</comment>
                            <comment id="12861177" author="ashutoshc" created="Tue, 27 Apr 2010 01:05:50 +0100"  >&lt;p&gt;Ankur,&lt;/p&gt;

&lt;p&gt;The stack trace above is out of sync with trunk. Can you upload the patch with this alternative approach that you are trying. I think it might be possible to get this working.&lt;/p&gt;</comment>
                            <comment id="12861246" author="ankur" created="Tue, 27 Apr 2010 06:06:49 +0100"  >&lt;p&gt;Here you go ...&lt;/p&gt;</comment>
                            <comment id="12867285" author="ashutoshc" created="Thu, 13 May 2010 23:21:18 +0100"  >&lt;p&gt;Ankur,&lt;/p&gt;

&lt;p&gt;Sorry for getting back late on this. I fiddled with your latest patch and was able to make some progress on it. I am able to get rid of those Path problems (looks like Pig itself is not dealing with it correctly at one place). I think with the patch that I attached should work but I am not able to get test case to pass because of hsqldb problem which I am not able to resolve. I keep getting this error from it:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Caused by: java.sql.SQLException: The database is already in use by another process: org.hsqldb.persist.NIOLockFile@4abea04e[file =/private/tmp/batchtest.lck, exists=true, locked=false, valid=false, fl =null]: java.lang.Exception: checkHeartbeat(): lock file [/private/tmp/batchtest.lck] is presumably locked by another process.
        at org.hsqldb.jdbc.Util.sqlException(Unknown Source)
        at org.hsqldb.jdbc.jdbcConnection.&amp;lt;init&amp;gt;(Unknown Source)
        at org.hsqldb.jdbcDriver.getConnection(Unknown Source)
        at org.hsqldb.jdbcDriver.connect(Unknown Source)
        at java.sql.DriverManager.getConnection(DriverManager.java:582)
        at java.sql.DriverManager.getConnection(DriverManager.java:185)
        at org.apache.pig.piggybank.storage.DBStorage.prepareToWrite(DBStorage.java:274)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Anyways here are the changes I made:&lt;br/&gt;
1.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Index:src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
===================================================================
-                conf.set(&lt;span class=&quot;code-quote&quot;&gt;&quot;pig.streaming.log.dir&quot;&lt;/span&gt;, 
-                            &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Path(outputPath, LOG_DIR).toString());
+&lt;span class=&quot;code-comment&quot;&gt;//                conf.set(&lt;span class=&quot;code-quote&quot;&gt;&quot;pig.streaming.log.dir&quot;&lt;/span&gt;, 
&lt;/span&gt;+&lt;span class=&quot;code-comment&quot;&gt;//                            &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Path(outputPath, LOG_DIR).toString());
&lt;/span&gt;                 conf.set(&lt;span class=&quot;code-quote&quot;&gt;&quot;pig.streaming.task.output.dir&quot;&lt;/span&gt;, outputPath);
             }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This looks like a problem in Pig. Here Pig is incorrectly assuming that it can put logs generated during stream command in output location which is incorrect if output location is something like DB. Since this needs changes in main Pig code, I will suggest to open new jira for it and track it there.&lt;/p&gt;

&lt;p&gt;2. Then in DBStorage.java&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
@Override
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void setStoreLocation(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; location, Job job) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
	  job.getConfiguration().set(&lt;span class=&quot;code-quote&quot;&gt;&quot;pig.db.conn.string&quot;&lt;/span&gt;, location);
}
@Override
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; RecordWriter&amp;lt;NullWritable, NullWritable&amp;gt; getRecordWriter(
    TaskAttemptContext context) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException, InterruptedException {
  jdbcURL = context.getConfiguration().get(&lt;span class=&quot;code-quote&quot;&gt;&quot;pig.db.conn.string&quot;&lt;/span&gt;);
  &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 
&lt;p&gt;Need to save db connection string in job in setStoreLocation() and then retrieve it in backend in getRecordWriter(). &lt;/p&gt;

&lt;p&gt;3. In DBStorage.java&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
@Override
	&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void cleanupOnFailure(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; location, Job job) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
	  log.error(&lt;span class=&quot;code-quote&quot;&gt;&quot;Job has failed.&quot;&lt;/span&gt;);
	}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;You need to necessarily override this function of StoreFunc() as default implementation assumes FileSystem as the output location. Currently, I left it as no-op but it can be improved to do rollbacks, release db connections etc. &lt;/p&gt;</comment>
                            <comment id="12869552" author="ankur" created="Thu, 20 May 2010 11:24:12 +0100"  >&lt;p&gt;Hi Ashutosh,&lt;br/&gt;
                   Thanks for helping out here. The error that you see - &quot;...The database is already in use by another process&quot; is due to locking issues in hsqldb 1.8.0.7. Upgrading to 1.8.0.10 &lt;br/&gt;
alleviates the problem and the test passes successfully. Few changes that I did&lt;/p&gt;

&lt;p&gt;1. Added a placeholder record-writer as PigOutputFormat calls close() on it throwing null pointer exception if we return null from our output format.&lt;br/&gt;
2. Looks like you missed the ivy.xml and build.xml changes to pull the correct hsqldb jar.&lt;/p&gt;
</comment>
                            <comment id="12869692" author="ashutoshc" created="Thu, 20 May 2010 18:41:22 +0100"  >&lt;p&gt;Cool. I created &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-1424&quot; title=&quot;Error logs of streaming should not be placed in output location&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-1424&quot;&gt;PIG-1424&lt;/a&gt; to track the Pig issue.&lt;/p&gt;</comment>
                            <comment id="12892378" author="ashutoshc" created="Mon, 26 Jul 2010 18:21:36 +0100"  >&lt;p&gt;Since fix to &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-1424&quot; title=&quot;Error logs of streaming should not be placed in output location&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-1424&quot;&gt;PIG-1424&lt;/a&gt; doesnt look straight forward and I dont think anyone is working on it, I will suggest to unblock this useful piggy bank functionality from Pig&apos;s issues. We can take the original approach suggested in the first patch of passing jdbc url string as constructor argument instead of store location. &lt;br/&gt;
Ankur, do you have cycles to generate the patch which we will commit now so it makes into 0.8.&lt;/p&gt;</comment>
                            <comment id="12892718" author="ankur" created="Tue, 27 Jul 2010 11:54:17 +0100"  >&lt;p&gt;Hope this one finally goes in .&lt;/p&gt;</comment>
                            <comment id="12892719" author="ankur" created="Tue, 27 Jul 2010 11:55:30 +0100"  >&lt;p&gt;Regenerated the patch as per Ashutosh&apos;s suggestion.&lt;/p&gt;</comment>
                            <comment id="12892999" author="hadoopqa" created="Wed, 28 Jul 2010 01:17:40 +0100"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12450586/jira-1229-final.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12450586/jira-1229-final.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision 979781.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 4 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    -1 core tests.  The patch failed core unit tests.&lt;/p&gt;

&lt;p&gt;    -1 contrib tests.  The patch failed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/360/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/360/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/360/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/360/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/360/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/360/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12893006" author="ashutoshc" created="Wed, 28 Jul 2010 01:45:38 +0100"  >&lt;p&gt;Changes look good. Core test failures looks irrelevant as there are no changes in main src/ tree of Pig only in contrib. Thanks Ian for your initial work. Thanks, Ankur for your persistence in getting this committed . &lt;/p&gt;</comment>
                            <comment id="12894839" author="ankur" created="Tue, 3 Aug 2010 08:47:25 +0100"  >&lt;p&gt;Attaching the patch with fixes to the test case.&lt;br/&gt;
1. Starting the HsqlDB server manually - dbServer.start().&lt;br/&gt;
2. Supplying user name and password when initializing DBStorage.&lt;/p&gt;</comment>
                            <comment id="12894963" author="ashutoshc" created="Tue, 3 Aug 2010 19:03:23 +0100"  >&lt;p&gt;I am still getting the same exception &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
java.io.IOException: JDBC Error
        at org.apache.pig.piggybank.storage.DBStorage.prepareToWrite(DBStorage.java:291)
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat$PigRecordWriter.&amp;lt;init&amp;gt;(PigOutputFormat.java:124)
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat.getRecordWriter(PigOutputFormat.java:85)
        at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.&amp;lt;init&amp;gt;(MapTask.java:488)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:610)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:305)
        at org.apache.hadoop.mapred.Child.main(Child.java:170)
Caused by: java.sql.SQLException: Table not found in statement [insert into ttt (id, name, ratio) values (?,?,?)]
        at org.hsqldb.jdbc.Util.throwError(Unknown Source)
        at org.hsqldb.jdbc.jdbcPreparedStatement.&amp;lt;init&amp;gt;(Unknown Source)
        at org.hsqldb.jdbc.jdbcConnection.prepareStatement(Unknown Source)
        at org.apache.pig.piggybank.storage.DBStorage.prepareToWrite(DBStorage.java:288)
        ... 6 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Reading through few internet forums it seems that there are subtle differences in &quot;stand-alone&quot; mode Vs &quot;server&quot; mode of hsqldb . May be starting hsqldb instance in server mode would alleviate the problem.&lt;/p&gt;</comment>
                            <comment id="12894975" author="kimballa" created="Tue, 3 Aug 2010 19:24:35 +0100"  >&lt;p&gt;Haven&apos;t looked at how you&apos;re using hsqldb in this patch, but I&apos;ve got a lot of experience using HSQLDB for testing.&lt;/p&gt;

&lt;p&gt;If you&apos;re running one or more tests in a single process that requires an HSQLDB-backed database, you do not need to create a new instance of Server. You can just set your JDBC connect string to &lt;tt&gt;jdbc:hsqldb:mem:foodbname&lt;/tt&gt; and get a &lt;tt&gt;Connection&lt;/tt&gt; instance to a memory-backed single-process database called &lt;tt&gt;foodbname&lt;/tt&gt;. This database will exist for the lifetime of the Java process. You can have multiple &lt;tt&gt;Connection&lt;/tt&gt; instances (concurrently or serially) open to this database and it will function like you expect a database to work like. The advantage of not using a server is that this does not require binding a port; therefore you can run multiple tests concurrently without worrying about collisions. Similarly, there&apos;s no need to use the &lt;tt&gt;jdbc:hsqldb:file&lt;/tt&gt; protocol unless you want to restore the contents of the database in a subsequent process. When your Java process ends, you won&apos;t have a bonus file to clean up with &lt;tt&gt;jdbc:hsqldb:mem&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Of course, if you&apos;re testing with &lt;tt&gt;MiniMRCluster&lt;/tt&gt; or something, you&apos;ll want to start a Server so that the external mapper processes can connect to the same database via &lt;tt&gt;jdbc:hsqldb:hsql://server:port/dbname&lt;/tt&gt;. &lt;/p&gt;
</comment>
                            <comment id="12895158" author="ankur" created="Wed, 4 Aug 2010 07:05:33 +0100"  >&lt;p&gt;Here is my understanding of what happens&lt;/p&gt;

&lt;p&gt;1. The main thread in the JVM executing the test initializes MiniDFSCluster,  MiniMRCluster and HSQLDB server all in different threads.&lt;br/&gt;
2. The test setUp() method then executed to create table &apos;ttt&apos; to which data will be written by DBStorage() in the test.&lt;br/&gt;
3. Pig statements are then executed that spawn M/R job as a separate process that tries to get a connection to the database and create a preparedStatement for table &apos;ttt&apos;. This fails sometimes as DB thread does NOT get a chance to fully persist the table information and the exception is thrown from the map-tasks as noted by Ashutosh.&lt;/p&gt;

&lt;p&gt;The fix for this is to add a 5 sec sleep in setUp() method to give DB a chance to persist table information. This alleviates the problem and test passes for repeated multiple runs. &lt;/p&gt;

&lt;p&gt;Note that Ideal fix would have been to do a busy wait for table creation completion but i don&apos;t see a method in HSqlDB to do that. &lt;/p&gt;</comment>
                            <comment id="12895171" author="kimballa" created="Wed, 4 Aug 2010 08:30:23 +0100"  >&lt;p&gt;I&apos;m pretty confused by what you mean here. HSQLDB is fully SQL-92 compliant and provides ACID transactional semantics. If you execute a &lt;tt&gt;CREATE TABLE&lt;/tt&gt; statement in a &lt;tt&gt;Statement&lt;/tt&gt; or &lt;tt&gt;PreparedStatement&lt;/tt&gt; created in a given &lt;tt&gt;Connection&lt;/tt&gt; and then call &lt;tt&gt;Connection.commit()&lt;/tt&gt;, this commit statement will either throw a &lt;tt&gt;SQLException&lt;/tt&gt; indicating failure, or return silently, indicating that the results have been made durable and are visible to all subsequent transactions of concurrent clients.&lt;/p&gt;

&lt;p&gt;This version of HSQLDB has been available for several years at this point. It is quite stable. If sleeping for a random timeout interval fixes your issue, then you have most likely misconfigured something. You might want to double-check; have you called &lt;tt&gt;Connection.setAutoCommit()&lt;/tt&gt;? If this is configured to false, do you call &lt;tt&gt;commit()&lt;/tt&gt; after making an update?&lt;/p&gt;

&lt;p&gt;Note that if you are using separate processes to connect to HSQLDB, then you should start a single &lt;tt&gt;Server&lt;/tt&gt; instance that should connect to the underlying database resource with &lt;tt&gt;file:&lt;/tt&gt; or &lt;tt&gt;mem:&lt;/tt&gt; to operate on a file-backed or memory-backed database, but the child processes should then connect to the server using &lt;tt&gt;jdbc:hsqldb:hsql://&amp;lt;server&amp;gt;:&amp;lt;port&amp;gt;/&amp;lt;dbname&amp;gt;&lt;/tt&gt; so they actually serialize through the server. Concurrent clients in separate processes should not access the same database via &lt;tt&gt;jdbc:hsqldb:&lt;a href=&quot;file://&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file://&lt;/a&gt;&lt;/tt&gt; resources.&lt;/p&gt;</comment>
                            <comment id="12895178" author="ankur" created="Wed, 4 Aug 2010 09:27:34 +0100"  >&lt;p&gt;Aaron,&lt;br/&gt;
         Autocommit() was not the issue.  It was the usage of &quot;jdbc:hsqldb:file:&quot; url in the STORE function that was the problem. Replacing it with &quot;jdbc:hsqldb:hsql://localhost/dbname&quot; solved the issue. Attaching the updated patch with the test case modification.&lt;/p&gt;

&lt;p&gt;Really appreciate your help here. Thanks a lot &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12895182" author="kimballa" created="Wed, 4 Aug 2010 09:33:31 +0100"  >&lt;p&gt;Glad you got it working!&lt;/p&gt;</comment>
                            <comment id="12895330" author="ashutoshc" created="Wed, 4 Aug 2010 18:40:16 +0100"  >&lt;p&gt;Tested and it worked. Committed. Thanks Aaron and Ankur for help in fixing the issue.&lt;/p&gt;</comment>
                            <comment id="12910331" author="scouredimage" created="Thu, 16 Sep 2010 22:39:28 +0100"  >&lt;p&gt;I upgraded to 0.7 and tried the updated patch. However, I don&apos;t see any entries in the database.&lt;br/&gt;
Upon further investigation, I noticed that in my particular case, the batch size was 100 and the number of output records that ended up at every reducer was below this threshold.&lt;br/&gt;
I added a debug statement to the OuputComitter&apos;s commitTask method and found that count was 0.&lt;br/&gt;
Any ideas why this might be happening?&lt;/p&gt;</comment>
                            <comment id="12910441" author="ankur" created="Fri, 17 Sep 2010 05:25:42 +0100"  >&lt;p&gt;In the putNext() method, count is reset to 0 every time the number of tuples added to the batch exceed &apos;batchSize&apos;. The batch is then executed and its parameters cleared. There is currently &lt;br/&gt;
an ExecException in the putNext() method that is being ignored. Can you try adding some debugging System.outs and check the stdout/stderr of your reducers to see if that is the problem ?&lt;/p&gt;</comment>
                            <comment id="12910629" author="scouredimage" created="Fri, 17 Sep 2010 16:23:31 +0100"  >&lt;p&gt;I narrowed down the problem to org.apache.hadoop.mapred.Task.java lines 411-418.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;org.apache.hadoop.mapred.Task.java&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (useNewApi) {
  LOG.debug(&lt;span class=&quot;code-quote&quot;&gt;&quot;using &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; api &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; output committer&quot;&lt;/span&gt;);
  outputFormat =
        ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), job);
  committer = outputFormat.getOutputCommitter(taskContext);
} &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
  committer = conf.getOutputCommitter();
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But DBStorage UDF assumes that the OutputFormat is in a closure.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12465047">PIG-1424</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12450586" name="jira-1229-final.patch" size="17971" author="ankur" created="Tue, 27 Jul 2010 11:54:17 +0100"/>
                            <attachment id="12451206" name="jira-1229-final.test-fix.patch" size="18291" author="ankur" created="Wed, 4 Aug 2010 09:27:34 +0100"/>
                            <attachment id="12440249" name="jira-1229-v2.patch" size="17642" author="ankur" created="Tue, 30 Mar 2010 17:22:54 +0100"/>
                            <attachment id="12442925" name="jira-1229-v3.patch" size="17817" author="ankur" created="Tue, 27 Apr 2010 06:06:49 +0100"/>
                            <attachment id="12445048" name="pig-1229.2.patch" size="19534" author="ankur" created="Thu, 20 May 2010 11:24:44 +0100"/>
                            <attachment id="12444430" name="pig-1229.patch" size="17180" author="ashutoshc" created="Thu, 13 May 2010 23:21:18 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 8 Feb 2010 19:06:22 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>164742</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310041" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Patch Info</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10042"><![CDATA[Patch Available]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy40t3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>57287</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>