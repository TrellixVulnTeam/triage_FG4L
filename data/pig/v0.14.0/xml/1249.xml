<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 05:06:27 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/PIG-1249/PIG-1249.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[PIG-1249] Safe-guards against misconfigured Pig scripts without PARALLEL keyword</title>
                <link>https://issues.apache.org/jira/browse/PIG-1249</link>
                <project id="12310730" key="PIG">Pig</project>
                    <description>&lt;p&gt;It would be &lt;b&gt;very&lt;/b&gt; useful for Pig to have safe-guards against naive scripts which process a &lt;b&gt;lot&lt;/b&gt; of data without the use of PARALLEL keyword.&lt;/p&gt;

&lt;p&gt;We&apos;ve seen a fair number of instances where naive users process huge data-sets (&amp;gt;10TB) with badly mis-configured #reduces e.g. 1 reduce. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12457055">PIG-1249</key>
            <summary>Safe-guards against misconfigured Pig scripts without PARALLEL keyword</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zjffdu">Jeff Zhang</assignee>
                                    <reporter username="acmurthy">Arun C Murthy</reporter>
                        <labels>
                    </labels>
                <created>Mon, 22 Feb 2010 18:20:24 +0000</created>
                <updated>Wed, 19 Jan 2011 09:01:15 +0000</updated>
                            <resolved>Thu, 29 Jul 2010 01:25:52 +0100</resolved>
                                    <version>0.8.0</version>
                                    <fixVersion>0.8.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="12838227" author="zjffdu" created="Thu, 25 Feb 2010 07:47:13 +0000"  >&lt;p&gt;+1, And I  find that hive can estimate the reducer number according the input size. This is a really useful feature.&lt;/p&gt;</comment>
                            <comment id="12868260" author="zjffdu" created="Mon, 17 May 2010 17:00:23 +0100"  >&lt;p&gt;The current idea is borrowed from hive, use the input file size to estimate the reducer number.&lt;br/&gt;
Two parameters can been set for this purpose&lt;br/&gt;
pig.exec.reducers.bytes.per.reducer  // the number of bytes of input for each reducer&lt;br/&gt;
pig.exec.reducers.max                          // the max number of reducer number&lt;/p&gt;

&lt;p&gt;This only work for hdfs, won&apos;t work for other data source such as hbase or cassandra.&lt;/p&gt;
</comment>
                            <comment id="12868893" author="thejas" created="Wed, 19 May 2010 00:25:07 +0100"  >&lt;p&gt;If default_parallel has not been set, the patch sets a new default number of reducers based on input file sizes.&lt;br/&gt;
If the &apos;input&apos; specified in the load statement is not an hdfs file, it fail to find the file size and default of 1 reduce will be used.&lt;/p&gt;

&lt;p&gt;The next steps in automatically determining number of reducers (which can be addressed in separate jiras) are -&lt;br/&gt;
1. Determining different number of reducers for each MR job of a pig-query, based on the input size for the MR job.&lt;br/&gt;
2. Extending this functionality to load functions that don&apos;t take hdfs files as input. We can look at using LoadMetaData.getStatistics() .&lt;/p&gt;

&lt;p&gt;Comments on the patch -&lt;br/&gt;
If default_parallel is specified, the number of reducers doesn&apos;t need to be determined.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

estimateNumberOfReducers(conf,mro);
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (pigContext.defaultParallel &amp;gt; 0)
       conf.set(&lt;span class=&quot;code-quote&quot;&gt;&quot;mapred.reduce.tasks&quot;&lt;/span&gt;, &quot;&quot;+pigContext.defaultParallel);

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;can be changed to &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (pigContext.defaultParallel &amp;gt; 0)
     conf.set(&lt;span class=&quot;code-quote&quot;&gt;&quot;mapred.reduce.tasks&quot;&lt;/span&gt;, &quot;&quot;+pigContext.defaultParallel);
&lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;
     estimateNumberOfReducers(conf,mro);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Everything else looks good.&lt;/p&gt;

&lt;p&gt;Hudson still seems to be having problems. I am currently running unit tests with this patch.&lt;/p&gt;
</comment>
                            <comment id="12868905" author="alangates" created="Wed, 19 May 2010 00:38:51 +0100"  >&lt;p&gt;One thing we want to be sure of is that if users explicitly set parallel to 1, we don&apos;t override it.  From reviewing the above code it isn&apos;t clear to me whether that&apos;s the case here or not.&lt;/p&gt;</comment>
                            <comment id="12868931" author="dvryaboy" created="Wed, 19 May 2010 01:22:40 +0100"  >&lt;p&gt;This is a good spot to leverage pinning options that were added to operators a while back. The parser would pin the parallel option if it encounters the PARALLEL keyword, and the code in this patch wouldn&apos;t get invoked unless parallelism is not pinned.&lt;/p&gt;</comment>
                            <comment id="12870637" author="zjffdu" created="Mon, 24 May 2010 16:18:11 +0100"  >&lt;p&gt;Clear the logic. &lt;br/&gt;
first check the PARALLE in query, &lt;br/&gt;
if not set, then check the defaultParallel in PigContext, &lt;br/&gt;
if not set, do estimation of reducer number.&lt;/p&gt;</comment>
                            <comment id="12870896" author="alangates" created="Mon, 24 May 2010 23:58:16 +0100"  >&lt;p&gt;Questions/Comments:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;In this code, what happens if a loader is not loading from a file (like an HBase loader)?  It looks to me like it will end up throwing an IOException when it tries to stat the &apos;file&apos; which won&apos;t exist and that will cause Pig to die.  Ideally in this case it should decide that it cannot make a rational estimate and not try to estimate.&lt;/li&gt;
	&lt;li&gt;I&apos;m curious where the values of ~1GB per reducer and 999 reducers came from.&lt;/li&gt;
	&lt;li&gt;Does this estimate apply only to the first job or to all jobs?&lt;/li&gt;
	&lt;li&gt;How does this work in the case of joins, where there are multiple inputs to a job?&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="12870948" author="zjffdu" created="Tue, 25 May 2010 03:07:02 +0100"  >&lt;p&gt;Response to Alan&apos;s questions,&lt;/p&gt;

&lt;p&gt;   1.  In this code, what happens if a loader is not loading from a file (like an HBase loader)? It looks to me like it will end up throwing an IOException when it tries to stat the &apos;file&apos; which won&apos;t exist and that will cause Pig to die. Ideally in this case it should decide that it cannot make a rational estimate and not try to estimate.&lt;br/&gt;
   &lt;font color=&quot;blue&quot;&gt;&lt;br/&gt;
             It won&apos;t throw IOException when file doesn&apos;t exit,  getTotalInputFileSize will return 0 if not loading from file or file doesn&apos;t exit. And the final estimated reducer number will be 1.&lt;br/&gt;
   &lt;/font&gt;&lt;br/&gt;
   2. I&apos;m curious where the values of ~1GB per reducer and 999 reducers came from.&lt;br/&gt;
   &lt;font color=&quot;blue&quot;&gt;&lt;br/&gt;
            These two numbers is what Hive use, I&apos;m not sure how they came from. Maybe from their experience.&lt;br/&gt;
   &lt;/font&gt;&lt;br/&gt;
   3. Does this estimate apply only to the first job or to all jobs?&lt;br/&gt;
   &lt;font color=&quot;blue&quot;&gt;&lt;br/&gt;
   It will apply to all the jobs&lt;br/&gt;
   &lt;/font&gt;&lt;br/&gt;
   4. How does this work in the case of joins, where there are multiple inputs to a job?&lt;br/&gt;
   &lt;font color=&quot;blue&quot;&gt;&lt;br/&gt;
   it will estimate the reducer number according the all the inputs files&apos; size &lt;br/&gt;
   &lt;/font&gt;&lt;/p&gt;</comment>
                            <comment id="12871358" author="alangates" created="Tue, 25 May 2010 21:57:54 +0100"  >&lt;p&gt;1. In this code, what happens if a loader is not loading from a file (like an HBase loader)? It looks to me like it will end up throwing an IOException when it tries to stat the &apos;file&apos; which won&apos;t exist and that will cause Pig to die. Ideally in this case it should decide that it cannot make a rational estimate and not try to estimate.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;blue&quot;&gt;&lt;br/&gt;
It won&apos;t throw IOException when file doesn&apos;t exit, getTotalInputFileSize will return 0 if not loading from file or file doesn&apos;t exit. And the final estimated reducer number will be 1.&lt;br/&gt;
&lt;/font&gt;&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;&lt;br/&gt;
Could we add a test to test this?  I think it would be good to assure it works in this situation.  Maybe you could take one of the tests that uses the Hbase loader.&lt;/font&gt;&lt;/p&gt;

&lt;p&gt;2. I&apos;m curious where the values of ~1GB per reducer and 999 reducers came from.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;blue&quot;&gt;&lt;br/&gt;
These two numbers is what Hive use, I&apos;m not sure how they came from. Maybe from their experience.&lt;/font&gt;&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;&lt;br/&gt;
ok, good enough.  We can adjust them later if we need to.&lt;/font&gt;&lt;/p&gt;

&lt;p&gt;3. Does this estimate apply only to the first job or to all jobs?&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;blue&quot;&gt;&lt;br/&gt;
It will apply to all the jobs&lt;/font&gt;&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;&lt;br/&gt;
Eventually we should change this to do the estimation on the fly in the JobControlCompiler.  Since most queries tend to aggregate data down after a number of steps I suspect that using the initial input to estimate the entire query will mean that the final results are parallelized too widely.  But this is better than the current situation where they aren&apos;t parallelized at all.&lt;/font&gt;&lt;/p&gt;

&lt;p&gt;4. How does this work in the case of joins, where there are multiple inputs to a job?&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;blue&quot;&gt;&lt;br/&gt;
it will estimate the reducer number according the all the inputs files&apos; size&lt;/font&gt;&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;&lt;br/&gt;
cool&lt;/font&gt;&lt;/p&gt;

&lt;p&gt;So other than testing the non-file case I&apos;m +1 on this patch.&lt;/p&gt;</comment>
                            <comment id="12871797" author="zjffdu" created="Wed, 26 May 2010 17:39:51 +0100"  >&lt;p&gt;Update the patch, including testcase of non-dfs input and do path checking when doing estimation&lt;/p&gt;
</comment>
                            <comment id="12872196" author="hadoopqa" created="Thu, 27 May 2010 13:28:49 +0100"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12445559/PIG_1249_3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12445559/PIG_1249_3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision 948526.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 5 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 patch.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h1.grid.sp2.yahoo.net/6/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h1.grid.sp2.yahoo.net/6/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12872322" author="alangates" created="Thu, 27 May 2010 19:53:40 +0100"  >&lt;p&gt;+1, new test looks good.&lt;/p&gt;

&lt;p&gt;Hudson is still having troubles.  We should run the &quot;ant test&quot; and &quot;ant test-patch&quot; directives manually.&lt;/p&gt;</comment>
                            <comment id="12874787" author="alangates" created="Wed, 2 Jun 2010 21:43:04 +0100"  >&lt;p&gt;The latest patch doesn&apos;t apply because of a merge conflict.  I&apos;ll attach a patch that addresses this.&lt;/p&gt;</comment>
                            <comment id="12874788" author="alangates" created="Wed, 2 Jun 2010 21:43:50 +0100"  >&lt;p&gt;Patch with merge conflict resolution.&lt;/p&gt;</comment>
                            <comment id="12874903" author="zjffdu" created="Thu, 3 Jun 2010 02:14:21 +0100"  >&lt;p&gt;Alan,Thanks for your help.&lt;/p&gt;</comment>
                            <comment id="12875551" author="hadoopqa" created="Fri, 4 Jun 2010 11:22:33 +0100"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12446173/PIG-1249-4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12446173/PIG-1249-4.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision 951229.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 5 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    -1 core tests.  The patch failed core unit tests.&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/329/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/329/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/329/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/329/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/329/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h7.grid.sp2.yahoo.net/329/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12887283" author="ashutoshc" created="Mon, 12 Jul 2010 07:50:24 +0100"  >&lt;p&gt;Map-reduce framework has a jira related to this issue.  &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/MAPREDUCE-1521&lt;/a&gt; It has two implications for Pig:&lt;/p&gt;

&lt;p&gt;1) We need to reconsider whether we still want Pig to set number of reducers on user&apos;s behalf. We can choose not to &quot;intelligently&quot; choose # of reducers and let framework fail the  job which doesn&apos;t &quot;correctly&quot; specify # of reducers. Then, Pig is out of this guessing game and users are forced by framework to correctly specify # of reducers. &lt;/p&gt;

&lt;p&gt;2) Now that MR framework will fail the job based on configured limits, operators where Pig does compute and set number of reducers (like skewed join etc.) should now be aware of those limits so that # of reducers computed by them fall within those limits.&lt;/p&gt;</comment>
                            <comment id="12891788" author="olgan" created="Fri, 23 Jul 2010 21:49:49 +0100"  >&lt;p&gt;Ashutosh,&lt;/p&gt;

&lt;p&gt;First, the changes are not going to be in framework till Hadoop 22 and I don&apos;t think we want to wait that far as we are seeing quite a few problems on our cluster. Second, I think we want to take a direction with pig of setting things up for users. Of course, we don&apos;t have stats right now to do so accurately but I think this is a step in the right direction&lt;/p&gt;</comment>
                            <comment id="12891789" author="olgan" created="Fri, 23 Jul 2010 21:53:29 +0100"  >&lt;p&gt;Jeff, sorry this patch did not get much attention in a while. Can I ask you to do the following:&lt;/p&gt;

&lt;p&gt;(1) Regenrate the patch for the latest trunk and make sure that the tests are passing and we get no additional warnings&lt;br/&gt;
(2) Add a docs comment that describes in one place what are the exact heuristics, when they are applied and how they can be influenced. I will ask our doc writer to incorporate this information in Pig 0.8.0 documentation&lt;br/&gt;
(3) If it is not already done, can we log the value that will be used so that the user knows what is happenning&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;</comment>
                            <comment id="12892697" author="zjffdu" created="Tue, 27 Jul 2010 10:08:36 +0100"  >&lt;p&gt;Olga, I generated the patch for the latest trunk. And add doc for in method estimateNumberOfReducers in JobControlCompiler. If you need anything else, feel free to tell me.&lt;/p&gt;
</comment>
                            <comment id="12892871" author="olgan" created="Tue, 27 Jul 2010 18:43:10 +0100"  >&lt;p&gt;Hi Jeff, &lt;/p&gt;

&lt;p&gt;Thanks for the quick response. I will review and commit the patch. I am going to add a log statement for the reduce value that has been computed. I will also copy your doc comment from the src to the JIRA to assist our doc writer&lt;/p&gt;</comment>
                            <comment id="12892873" author="hadoopqa" created="Tue, 27 Jul 2010 18:55:45 +0100"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12450579/PIG-1249_5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12450579/PIG-1249_5.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision 979503.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 5 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    -1 core tests.  The patch failed core unit tests.&lt;/p&gt;

&lt;p&gt;    -1 contrib tests.  The patch failed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/359/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/359/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/359/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/359/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/359/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Pig-Patch-h8.grid.sp2.yahoo.net/359/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12893445" author="olgan" created="Thu, 29 Jul 2010 01:25:52 +0100"  >&lt;p&gt;Patch committed. Thanks Jeff!&lt;/p&gt;</comment>
                            <comment id="12893446" author="olgan" created="Thu, 29 Jul 2010 01:27:00 +0100"  >&lt;p&gt;Comments for the documentation:&lt;/p&gt;

&lt;p&gt;+    /**&lt;br/&gt;
+     * Currently the estimation of reducer number is only applied to HDFS, The estimation is based on the input size of data storage on HDFS.&lt;br/&gt;
+     * Two parameters can been configured for the estimation, one is pig.exec.reducers.max which constrain the maximum number of reducer task (default is 999). The other&lt;br/&gt;
+     * is pig.exec.reducers.bytes.per.reducer(default value is 1000*1000*1000) which means the how much data can been handled for each reducer.&lt;br/&gt;
+     * e.g. the following is your pig script&lt;br/&gt;
+     * a = load &apos;/data/a&apos;;&lt;br/&gt;
+     * b = load &apos;/data/b&apos;;&lt;br/&gt;
+     * c = join a by $0, b by $0;&lt;br/&gt;
+     * store c into &apos;/tmp&apos;;&lt;br/&gt;
+     *&lt;br/&gt;
+     * The size of /data/a is 1000*1000*1000, and size of /data/b is 2*1000*1000*1000.&lt;br/&gt;
+     * Then the estimated reducer number is (1000*1000*1000+2*1000*1000*1000)/(1000*1000*1000)=3&lt;/p&gt;</comment>
                            <comment id="12983462" author="anupgoyal" created="Wed, 19 Jan 2011 00:46:36 +0000"  >&lt;p&gt;one thing that we didn&apos;t take care is the use of the hadoop parameter &quot;mapred.reduce.tasks&quot;.&lt;br/&gt;
If I specify the hadoop parameter -Dmapred.reduce.tasks=450 for all the MR jobs , it is overwritten by   estimateNumberOfReducers(conf,mro), which in my case is 15.&lt;br/&gt;
I am not specifying any default_parallel and PARALLEL statements.&lt;/p&gt;

&lt;p&gt;Ideally, the number of reducer should be 450. &lt;/p&gt;

&lt;p&gt;I think we should prioritize this parameter above the estimate reducers calculations.&lt;br/&gt;
The priority list should be&lt;/p&gt;

&lt;p&gt;1. PARALLEL statement&lt;br/&gt;
2. default_parallel statement&lt;br/&gt;
3. mapred.reduce.task  hadoop parameter&lt;br/&gt;
4. estimateNumberOfreducers();&lt;/p&gt;</comment>
                            <comment id="12983470" author="daijy" created="Wed, 19 Jan 2011 01:01:00 +0000"  >&lt;p&gt;Agreed, &quot;mapred.reduce.task&quot; should have higher priority than estimateNumberOfreducers(). If not, then it&apos;s a bug. &lt;/p&gt;</comment>
                            <comment id="12983620" author="zjffdu" created="Wed, 19 Jan 2011 09:01:15 +0000"  >&lt;p&gt;I&apos;ve created a ticket for this issue &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-1810&quot; title=&quot;Prioritize hadoop parameter &amp;quot;mapred.reduce.task&amp;quot; above estimation of reducer number&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-1810&quot;&gt;PIG-1810&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12457041">MAPREDUCE-1521</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12446173" name="PIG-1249-4.patch" size="9255" author="alangates" created="Wed, 2 Jun 2010 21:43:50 +0100"/>
                            <attachment id="12444699" name="PIG-1249.patch" size="6892" author="zjffdu" created="Mon, 17 May 2010 17:00:23 +0100"/>
                            <attachment id="12450579" name="PIG-1249_5.patch" size="10134" author="zjffdu" created="Tue, 27 Jul 2010 10:06:35 +0100"/>
                            <attachment id="12445332" name="PIG_1249_2.patch" size="7971" author="zjffdu" created="Mon, 24 May 2010 16:18:11 +0100"/>
                            <attachment id="12445559" name="PIG_1249_3.patch" size="9306" author="zjffdu" created="Wed, 26 May 2010 17:39:50 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 25 Feb 2010 07:47:13 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>164758</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hyao9j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>96242</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>In the previous versions of Pig, if the number of reducers was not specified (via PARALLEL or default_parallel), the value of 1 was used which in many cases was not a good choice and caused severe performance problems.&lt;br/&gt;
&lt;br/&gt;
In Pig 0.8.0, a simple heuristic is used to come up with a better number based on the size of the input data. There are several parameters that the user can control:&lt;br/&gt;
&lt;br/&gt;
pig.exec.reducers.bytes.per.reducer - define number of input bytes per reduce; default value is 1000*1000*1000 (1GB)&lt;br/&gt;
pig.exec.reducers.max - defines the upper bound on the number of reducers; default is 999&lt;br/&gt;
&lt;br/&gt;
The formula is very simple:&lt;br/&gt;
&lt;br/&gt;
#reducers = MIN (pig.exec.reducers.max, total input size (in bytes) / bytes per reducer.&lt;br/&gt;
&lt;br/&gt;
This is a very simplistic formula that we would need to improve over time. Note, that the computed value takes all inputs within the script into account and applies the computed value to all the jobs within Pig script.&lt;br/&gt;
&lt;br/&gt;
Note that this is not a backward compatible change and set default_parallel to restore the value to 1</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>