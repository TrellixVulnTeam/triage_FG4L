<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:56:42 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/PIG-3002/PIG-3002.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[PIG-3002] Pig client should handle CountersExceededException</title>
                <link>https://issues.apache.org/jira/browse/PIG-3002</link>
                <project id="12310730" key="PIG">Pig</project>
                    <description>&lt;p&gt;Running a pig job that uses more than 120 counters will succeed, but a grunt exception will occur when trying to output counter info to the console. This exception should be caught and handled with friendly messaging:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.pig.backend.executionengine.ExecException: ERROR 2043: Unexpected error during execution.
        at org.apache.pig.PigServer.launchPlan(PigServer.java:1275)
        at org.apache.pig.PigServer.executeCompiledLogicalPlan(PigServer.java:1249)
        at org.apache.pig.PigServer.execute(PigServer.java:1239)
        at org.apache.pig.PigServer.executeBatch(PigServer.java:333)
        at org.apache.pig.tools.grunt.GruntParser.executeBatch(GruntParser.java:136)
        at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:197)
        at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:169)
        at org.apache.pig.tools.grunt.Grunt.exec(Grunt.java:84)
        at org.apache.pig.Main.run(Main.java:604)
        at org.apache.pig.Main.main(Main.java:154)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:186)
Caused by: org.apache.hadoop.mapred.Counters$CountersExceededException: Error: Exceeded limits on number of counters - Counters=120 Limit=120
        at org.apache.hadoop.mapred.Counters$Group.getCounterForName(Counters.java:312)
        at org.apache.hadoop.mapred.Counters.findCounter(Counters.java:431)
        at org.apache.hadoop.mapred.Counters.getCounter(Counters.java:495)
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.computeWarningAggregate(MapReduceLauncher.java:707)
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.launchPig(MapReduceLauncher.java:442)
        at org.apache.pig.PigServer.launchPlan(PigServer.java:1264)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12613305">PIG-3002</key>
            <summary>Pig client should handle CountersExceededException</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jarcec">Jarek Jarcec Cecho</assignee>
                                    <reporter username="billgraham">Bill Graham</reporter>
                        <labels>
                            <label>newbie</label>
                            <label>simple</label>
                    </labels>
                <created>Wed, 24 Oct 2012 18:51:49 +0100</created>
                <updated>Mon, 14 Oct 2013 17:46:13 +0100</updated>
                            <resolved>Fri, 1 Mar 2013 06:21:39 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13548620" author="jarcec" created="Wed, 9 Jan 2013 16:10:48 +0000"  >&lt;p&gt;I&apos;ve tried to fix this issue by moving code that is responsible for getting counter value to shim layer. By doing this I can properly catch CountersExceededException only for Hadoop 0.23 and higher.&lt;/p&gt;

&lt;p&gt;My current patch do not include any tests as I&apos;m not sure where to put shim related tests. I did however verified the functionality on real clusters with Hadoop 1.x and Hadoop 2.x.&lt;/p&gt;</comment>
                            <comment id="13548668" author="billgraham" created="Wed, 9 Jan 2013 16:45:25 +0000"  >&lt;p&gt;Thanks for digging into this one Jarek.&lt;/p&gt;

&lt;p&gt;If we swallow the exception in the shim and return 0 it would be misleading to the user.&lt;br/&gt;
Instead what if we catch the exception during the call to computeWarningAggregate in MapReduceLauncher and log a message about how the counters could not be fetched for this job. Likewise the messaging in CompilationMessageCollector.logAggregate should be updated as well to indicate that aggregates might be off.&lt;/p&gt;</comment>
                            <comment id="13549013" author="jarcec" created="Wed, 9 Jan 2013 21:17:47 +0000"  >&lt;p&gt;Hi Bill,&lt;br/&gt;
thank you very much for your review, I appreciate your time. My first implementation actually took the way you&apos;ve proposed. But after that I dig into the logic and realized that it might not be necessary. As far as I understand purpose of the method computeWarningAggregate() is to aggregate existing counters from predefined Enum PigWarning. Therefore this method should not create any new counters. However the method call Counters.getCounter(Enum) will create new counter in case that it&apos;s not there (as side effect) and throw CountersExceededException in case that it can&apos;t create it.&lt;/p&gt;

&lt;p&gt;That&apos;s why I&apos;ve introduced getCounterValue() method on the shim layer that silently ignore this exception. The purpose of this method is only to get the value, not create the counter. And if we got the exception, than it means that the counter is not there (and can&apos;t be created) and thus it seems to me that returning 0 should be valid operation at this point.&lt;/p&gt;

&lt;p&gt;I believe that overall aggregates should be valid.&lt;/p&gt;

&lt;p&gt;Does this reasoning make any sense?&lt;/p&gt;

&lt;p&gt;Jarcec&lt;/p&gt;</comment>
                            <comment id="13552087" author="billgraham" created="Sat, 12 Jan 2013 22:45:41 +0000"  >&lt;p&gt;This exception gets thrown when a job creates more than 120 counters and we then go to check on expected counters at the conclusion of the job. Each call to getCounter will throw CountersExceededException. Your patch will swallow that exception and result in the user being messaged that the counter exists and has a value of 0. We don&apos;t want to do that in this case. Instead we want to message the user that we couldn&apos;t access counters due to the limit issue and that we don&apos;t know what the counter values are.&lt;/p&gt;

&lt;p&gt;Also, the logic behind getCounterValue shouldn&apos;t be driven my just this one caller. Other callers who want to get a counter value wouldn&apos;t (and shouldn&apos;t) expect that the method swallows exceptions and returns 0.&lt;/p&gt;</comment>
                            <comment id="13552261" author="jarcec" created="Sun, 13 Jan 2013 17:50:29 +0000"  >&lt;p&gt;Hi Bill,&lt;br/&gt;
again thank you for your comment. I appreciate your input. Please do not understand me wrong, I&apos;ll be more than happy to change my patch by including your suggestions. However I would like to make sure that we&apos;re on the same page first.&lt;/p&gt;

&lt;p&gt;I&apos;ve dug into Hadoop source code and the call getCounter(Enum) is defined in &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;. This call is just forwarded to findCounter(Enum) defined in AbstractCounters in &lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt;. This method will firstly check if the counter exists in object &quot;cache&quot;, if so, then this object is returned without any exception being raised. If the object is not present, then it call method findCounter(String, String) that will eventually create the counter and throw CountersExceededException exception if needed. &lt;/p&gt;

&lt;p&gt;Let&apos;s assume for example that we have following counters with maximal counter limit set to 2:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;A =&amp;gt; 1&lt;/li&gt;
	&lt;li&gt;B =&amp;gt; 2&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;If we try to call method getCounter(Enum) with values A, B and C, then we will get:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;A =&amp;gt; 1&lt;/li&gt;
	&lt;li&gt;B =&amp;gt; 2&lt;/li&gt;
	&lt;li&gt;C =&amp;gt; CountersExceededException, because C is not in map &quot;cache&quot; and thus the code will try to create new counter and fail on configured limitation.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;By this example, I&apos;m trying to explain that the method getCounter(Enum) won&apos;t throw CountersExceededException for all subsequent calls after the Counters gets full, but just for those that do not yet exists. I&apos;m also trying to show that the method computeWarningAggregate by itself won&apos;t affect generated aggregates.&lt;/p&gt;

&lt;p&gt;You&apos;re definitely right that newly introduced function getCounterValue() is driven by single caller and that it&apos;s not the best way to do it. I&apos;ve tried to put the code directly inside computeWarningAggregate(), but I failed on compilation error as CountersExceededException is not available in Hadoop 1.0. Therefore I&apos;ve moved the code into the shim layer.&lt;/p&gt;

&lt;p&gt;I&apos;ve defined the method getCounterValue() to return long instead of Counter object to narrow down the purpose to just get the long value of the counters, not the counter object itself. I believe that in such case, swallowing the exception is reasonable, because in such case the counter do not exists there and thus it&apos;s value is 0. Maybe providing descriptive javadoc to method getCounterValue() would help here?&lt;/p&gt;

&lt;p&gt;Jarcec&lt;/p&gt;

&lt;p&gt;Links:&lt;br/&gt;
1: &lt;a href=&quot;https://github.com/apache/hadoop-common/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Counters.java#L516&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hadoop-common/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Counters.java#L516&lt;/a&gt;&lt;br/&gt;
2: &lt;a href=&quot;https://github.com/apache/hadoop-common/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/counters/AbstractCounters.java#L163&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hadoop-common/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/counters/AbstractCounters.java#L163&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13561770" author="jarcec" created="Thu, 24 Jan 2013 17:15:15 +0000"  >&lt;p&gt;Hi Bill,&lt;br/&gt;
did you by any chance have a time to look at my explanation?&lt;/p&gt;

&lt;p&gt;I&apos;ll be more than happy to refactore my code if needed, I just wanted to be sure that we&apos;re on the same page first.&lt;/p&gt;

&lt;p&gt;Jarcec&lt;/p&gt;</comment>
                            <comment id="13562053" author="billgraham" created="Thu, 24 Jan 2013 22:17:33 +0000"  >&lt;p&gt;Sorry for the delay Jarcec. I actually read your explanation after you wrote it and had concerns that we might be thinking of two different uses cases. I wrote a test script that uses a UDF to produce 100 counters. The script runs and the jobs complete successfully, but grunt outputs an error message.&lt;/p&gt;

&lt;p&gt;I wanted to dig in more before replying but I got pulled away onto something else. I want to asset what the behavior becomes with your patch to see how it changes the behavior. Will report back.&lt;/p&gt;</comment>
                            <comment id="13562228" author="jarcec" created="Fri, 25 Jan 2013 00:49:03 +0000"  >&lt;p&gt;Thank you very much for your feedback Bill, I appreciate your time and effort to verify my suggestion. Please take your time, I&apos;m not in hurry for this.&lt;/p&gt;

&lt;p&gt;Jarcec&lt;/p&gt;</comment>
                            <comment id="13585189" author="jarcec" created="Sat, 23 Feb 2013 18:35:54 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=billgraham&quot; class=&quot;user-hover&quot; rel=&quot;billgraham&quot;&gt;Bill Graham&lt;/a&gt;,&lt;br/&gt;
I know that you are super busy with driving the pig release and all other things. I just wanted to check whether you had by any chance time to take a look into my proposed patch?&lt;/p&gt;

&lt;p&gt;Jarcec&lt;/p&gt;</comment>
                            <comment id="13585678" author="billgraham" created="Mon, 25 Feb 2013 07:19:18 +0000"  >&lt;p&gt;I was able to run some tests using both the patched and unpatched version and both behave the same w.r.t. what&apos;s output to the console.&lt;/p&gt;

&lt;p&gt;The behavior of &lt;tt&gt;MapReduceLauncher.computeWarningAggregate()&lt;/tt&gt; is  already to catch &lt;tt&gt;IOException&lt;/tt&gt; and log a warning, so it would be aceptable to catch &lt;tt&gt;Exception&lt;/tt&gt; around the iterator on the &lt;tt&gt;PigWarning&lt;/tt&gt; enum and just &lt;tt&gt;log.warn&lt;/tt&gt; there as well. No need to modify the shim code. Just log the error and move on. This will cause the console output to show the success state of the jobs, along with the exception with the counters.&lt;/p&gt;</comment>
                            <comment id="13587246" author="jarcec" created="Tue, 26 Feb 2013 16:46:41 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=billgraham&quot; class=&quot;user-hover&quot; rel=&quot;billgraham&quot;&gt;Bill Graham&lt;/a&gt;, &lt;br/&gt;
thank you very much for taking a look on this Jira and my patch. I was considering similar solution as you proposed in my early work, but I&apos;ve notice one side effect during experiments with my early patches.&lt;/p&gt;

&lt;p&gt;I&apos;ve created quite pathological case when my cluster was using default configuration, but I&apos;ve limit the number of allowed counters to 3 on machine where I&apos;ve executed pig. I&apos;ve noticed that with similar fix, pig will print out couple of counters and than bail out on exception on first non existing Counter. As a result not all the counters will be printed out even though they are available in the &lt;tt&gt;Couter&lt;/tt&gt; object.&lt;/p&gt;

&lt;p&gt;My experiment is obviously not entirely real as it&apos;s unlikely that users will have different hadoop configuration. However I believe that it model the edge situation when mapreduce job will create almost all available counters, but because client is iterating over predefined set, not all of them will be printed out.&lt;/p&gt;

&lt;p&gt;I&apos;ve also did one step further and put the &lt;tt&gt;try-catch&lt;/tt&gt; block inside the &lt;tt&gt;for&lt;/tt&gt; iteration. I&apos;ve noticed that in this situation we might print out the error message several times, which is kind of distracting. This lead me to the idea of doing the changes on the shim layer that I&apos;ve submitted.&lt;/p&gt;

&lt;p&gt;Jarcec&lt;/p&gt;</comment>
                            <comment id="13589284" author="billgraham" created="Thu, 28 Feb 2013 07:23:54 +0000"  >&lt;p&gt;I don&apos;t think we should be modifying the shims code in this way for the contrived case. Swallowing exceptions and returning 0 doesn&apos;t seem like the right thing to do for the reasons I&apos;ve described above. If Hadoop is throwing exceptions because we&apos;ve used too many counters, let&apos;s catch it and log it and move on. Surfacing the exception to a user in the console is better than trying to print some of them. Any counters captured by Hadoop will still be reported in the JT and the job history. &lt;/p&gt;</comment>
                            <comment id="13589842" author="jarcec" created="Thu, 28 Feb 2013 19:32:45 +0000"  >&lt;p&gt;Understood. Thank you for your time &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=billgraham&quot; class=&quot;user-hover&quot; rel=&quot;billgraham&quot;&gt;Bill Graham&lt;/a&gt;, I appreciate your help and support.&lt;/p&gt;

&lt;p&gt;I&apos;m +1 on the patch &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-3002&quot; title=&quot;Pig client should handle CountersExceededException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-3002&quot;&gt;&lt;del&gt;PIG-3002&lt;/del&gt;&lt;/a&gt;.2.patch&quot; (non-binding).&lt;/p&gt;

&lt;p&gt;Jarcec&lt;/p&gt;</comment>
                            <comment id="13590279" author="billgraham" created="Fri, 1 Mar 2013 06:21:39 +0000"  >&lt;p&gt;Committed. Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jarcec&quot; class=&quot;user-hover&quot; rel=&quot;jarcec&quot;&gt;Jarek Jarcec Cecho&lt;/a&gt; for digging into this one and sorry for the delay.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12570736" name="PIG-3002.2.patch" size="2760" author="billgraham" created="Mon, 25 Feb 2013 07:19:18 +0000"/>
                            <attachment id="12563951" name="PIG-3002.patch" size="3701" author="jarcec" created="Wed, 9 Jan 2013 16:10:48 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 9 Jan 2013 16:10:48 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>250795</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy4w3b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>62360</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>