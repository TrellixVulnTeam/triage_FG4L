<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:57:35 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/PIG-2550/PIG-2550.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[PIG-2550] Custom tuple results in &quot;Unexpected datatype 110 while reading tuplefrom binary file&quot; while spilling</title>
                <link>https://issues.apache.org/jira/browse/PIG-2550</link>
                <project id="12310730" key="PIG">Pig</project>
                    <description>&lt;p&gt;In the below script ;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
a = load &apos;gen_data/&apos; AS (f1,f2);
b = load &apos;gen_data_02/&apos; AS (f1,f2);
c = cogroup a by f1,b by f1;
d = foreach c generate group,flatten(a),COUNT(b),flatten(UDFReturningMyCustomTuple(b,a));
store d into &apos;test006&apos;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The udf (UDFReturningMyCustomTuple) returns a bag which contains custom tuples.&lt;br/&gt;
The script execution fails at the reducer side with the below exception while reading back the spilled data,&lt;/p&gt;

&lt;p&gt;2012-02-23 10:37:16,840 FATAL org.apache.pig.data.DefaultDataBag: Unable to read our spill file.&lt;br/&gt;
org.apache.pig.backend.executionengine.ExecException: ERROR 2112: Unexpected datatype 110 while reading tuple from binary file.&lt;br/&gt;
	at org.apache.pig.data.BinInterSedes.getTupleSize(BinInterSedes.java:133)&lt;br/&gt;
	at org.apache.pig.data.BinInterSedes.addColsToTuple(BinInterSedes.java:556)&lt;br/&gt;
	at org.apache.pig.data.BinSedesTuple.readFields(BinSedesTuple.java:66)&lt;br/&gt;
	at org.apache.pig.data.DefaultDataBag$DefaultDataBagIterator.next(DefaultDataBag.java:215)&lt;br/&gt;
	at org.apache.pig.data.DefaultDataBag$DefaultDataBagIterator.hasNext(DefaultDataBag.java:158)&lt;br/&gt;
	at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.processPlan(POForEach.java:301)&lt;br/&gt;
	at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.getNext(POForEach.java:208)&lt;br/&gt;
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Reduce.runPipeline(PigGenericMapReduce.java:459)&lt;br/&gt;
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Reduce.processOnePackageOutput(PigGenericMapReduce.java:427)&lt;br/&gt;
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Reduce.reduce(PigGenericMapReduce.java:407)&lt;br/&gt;
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Reduce.reduce(PigGenericMapReduce.java:261)&lt;br/&gt;
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:176)&lt;br/&gt;
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:649)&lt;br/&gt;
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:417)&lt;br/&gt;
	at org.apache.hadoop.mapred.Child$4.run(Child.java:255)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:396)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1082)&lt;br/&gt;
	at org.apache.hadoop.mapred.Child.main(Child.java:249)&lt;/p&gt;

&lt;p&gt;It looks like while spilling we do MyCustomTuple.write(DataOutput out) which writes the type as DataType.TUPLE (110),&lt;br/&gt;
but while reading back we always use BinSedesTuple.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12543829">PIG-2550</key>
            <summary>Custom tuple results in &quot;Unexpected datatype 110 while reading tuplefrom binary file&quot; while spilling</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="daijy">Daniel Dai</assignee>
                                    <reporter username="vivekp">Vivek Padmanabhan</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Feb 2012 12:31:19 +0000</created>
                <updated>Thu, 26 Apr 2012 21:32:54 +0100</updated>
                            <resolved>Fri, 23 Mar 2012 23:59:24 +0000</resolved>
                                    <version>0.8.1</version>
                    <version>0.9.1</version>
                    <version>0.10.0</version>
                                    <fixVersion>0.10.0</fixVersion>
                    <fixVersion>0.9.3</fixVersion>
                    <fixVersion>0.11</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13214580" author="vivekp" created="Thu, 23 Feb 2012 12:37:53 +0000"  >&lt;p&gt;Attaching the artifacts used to reproduce this issue.&lt;/p&gt;

&lt;p&gt;-Dmapred.reduce.child.java.opts=&quot;-Xmx512M&quot;&lt;/p&gt;

&lt;p&gt;It looks like this job runs fine with Pig 0.7&lt;/p&gt;</comment>
                            <comment id="13214831" author="vivekp" created="Thu, 23 Feb 2012 16:21:42 +0000"  >&lt;p&gt;I got the script running after overriding read and write methods in the custom tuple&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class MyCustomTuple &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; DefaultTuple {
    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; serialVersionUID = 8156382697467819543L;
    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; InterSedes sedes = InterSedesFactory.getInterSedesInstance();
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; MyCustomTuple() {
        &lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;();
    }
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; MyCustomTuple(&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; t) {
        &lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;();
        append(t);
    }
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void write(DataOutput out) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
        sedes.writeDatum(out, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;);
    }
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void readFields(DataInput in) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
        &lt;span class=&quot;code-comment&quot;&gt;// Clear our fields, in &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; we&apos;re being reused.
&lt;/span&gt;        mFields.clear();
        sedes.addColsToTuple(in, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;);
    } 

}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I am not sure whether overriding write() will have any other impacts. Could this be considered as a workaround ?&lt;/p&gt;</comment>
                            <comment id="13217418" author="daijy" created="Mon, 27 Feb 2012 19:24:01 +0000"  >&lt;p&gt;I follow your instructions but not able to reproduce it. In step 2, you mention how gen_data_02 is generated, but how gen_data is generated? Is that reproducible in local mode?&lt;/p&gt;</comment>
                            <comment id="13218083" author="vivekp" created="Tue, 28 Feb 2012 11:49:05 +0000"  >&lt;p&gt;For the error to happen DefaultDataBag should be spilling data on reduce side. This test was run on MR mode.&lt;/p&gt;

&lt;p&gt;gen_data is same as asgen_data_02 but with a smaller value.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.io.BufferedWriter;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.io.File;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.io.FileWriter;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.io.IOException;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class Gen {

    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void main(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] args) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
        BufferedWriter bw = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BufferedWriter( &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; FileWriter( &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; File (&lt;span class=&quot;code-quote&quot;&gt;&quot;tmp_data&quot;&lt;/span&gt;)));

        &lt;span class=&quot;code-object&quot;&gt;StringBuffer&lt;/span&gt; sb = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;StringBuffer&lt;/span&gt; ();
        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i=0;i &amp;lt; 200; i ++)
            sb.append(i);
        bw.write(sb.toString());
        bw.write(&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;);
        
	&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i=0;i &amp;lt; 5*1000 ; i ++)
            bw.write(&quot;&quot;+i%10);
        bw.close();        
    }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;BTW I tried to set pig.data.tuple.factory.name to org.apache.pig.data.DefaultTupleFactory but the property is not picked up in the map/reduce tasks.&lt;/p&gt;</comment>
                            <comment id="13220549" author="amolkekre" created="Fri, 2 Mar 2012 00:49:00 +0000"  >&lt;p&gt;Any updates on when we can get a fix?&lt;/p&gt;</comment>
                            <comment id="13220649" author="daijy" created="Fri, 2 Mar 2012 03:35:03 +0000"  >&lt;p&gt;I was able to reproduce now. The problem is we spill data using custom tuple&apos;s serializer, but when we read it back, we use BinInterSedes. I try to make a fix tomorrow. &lt;/p&gt;</comment>
                            <comment id="13220758" author="daijy" created="Fri, 2 Mar 2012 08:02:40 +0000"  >&lt;p&gt;Vivek, can you try the patch?&lt;/p&gt;</comment>
                            <comment id="13222260" author="vivekp" created="Mon, 5 Mar 2012 10:37:09 +0000"  >&lt;p&gt;Thanks Daniel, the script goes through fine with the patch&lt;/p&gt;</comment>
                            <comment id="13222478" author="dvryaboy" created="Mon, 5 Mar 2012 18:03:18 +0000"  >&lt;p&gt;That only fixes the spilling behavior. It does not fix the fact that custom tuples whose serialization does not match BinInterSedes can&apos;t be used across the Map-Reduce boundary.&lt;/p&gt;</comment>
                            <comment id="13222502" author="daijy" created="Mon, 5 Mar 2012 18:58:25 +0000"  >&lt;p&gt;That&apos;s true. After serialization/deserialization, you will get BinSedesTuple instead of custom tuple. &lt;/p&gt;</comment>
                            <comment id="13230741" author="thejas" created="Fri, 16 Mar 2012 00:17:12 +0000"  >&lt;blockquote&gt;&lt;p&gt;That only fixes the spilling behavior. It does not fix the fact that custom tuples whose serialization does not match BinInterSedes can&apos;t be used across the Map-Reduce boundary.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, the tuples will be serialized using the BinInterSedes format at the map-reduce boundary, and BinInterTuples will be created after the boundary. I don&apos;t see a bug there.&lt;/p&gt;

&lt;p&gt;+1 for the patch.&lt;/p&gt;
</comment>
                            <comment id="13237300" author="amolkekre" created="Fri, 23 Mar 2012 23:40:26 +0000"  >&lt;p&gt;Daniel, Thejas,&lt;br/&gt;
Can this patch be committed. We are looking to launch it on grids asap.&lt;/p&gt;</comment>
                            <comment id="13237320" author="daijy" created="Fri, 23 Mar 2012 23:59:24 +0000"  >&lt;p&gt;Committed to 0.9/0.10/trunk. For trunk, it is actually fixed in &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-2359&quot; title=&quot;Support more efficient Tuples when schemas are known&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-2359&quot;&gt;&lt;del&gt;PIG-2359&lt;/del&gt;&lt;/a&gt;. Only commit the test case to trunk.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12531275">PIG-2359</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12516799" name="PIG-2550-1.patch" size="2473" author="daijy" created="Fri, 2 Mar 2012 08:02:33 +0000"/>
                            <attachment id="12515746" name="REPRODUCING_SPILL_ERROR.txt" size="2740" author="vivekp" created="Thu, 23 Feb 2012 12:37:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 27 Feb 2012 19:24:01 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>229068</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy3t3z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>56040</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>