<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 05:10:16 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/PIG-2495/PIG-2495.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[PIG-2495] Using merge JOIN from a HBaseStorage produces an error</title>
                <link>https://issues.apache.org/jira/browse/PIG-2495</link>
                <project id="12310730" key="PIG">Pig</project>
                    <description>&lt;p&gt;To increase performance of my computation, I would like to use a merge join between two tables to increase speed computation but it produces an error.&lt;/p&gt;

&lt;p&gt;Here is the script:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;start_sessions = LOAD &apos;hbase://startSession.bea000000.dev.ubithere.com&apos; USING org.apache.pig.backend.hadoop.hbase.HBaseStorage(&apos;meta:infoid meta:imei meta:timestamp&apos;, &apos;-loadKey&apos;) AS (sid:chararray, infoid:chararray, imei:chararray, start:long);
end_sessions = LOAD &apos;hbase://endSession.bea000000.dev.ubithere.com&apos; USING org.apache.pig.backend.hadoop.hbase.HBaseStorage(&apos;meta:timestamp meta:locid&apos;, &apos;-loadKey&apos;) AS (sid:chararray, end:long, locid:chararray);
sessions = JOIN start_sessions BY sid, end_sessions BY sid USING &apos;merge&apos;;
STORE sessions INTO &apos;sessionsTest&apos; USING PigStorage (&apos;*&apos;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;Here is the result of this script :&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2012-01-30 16:12:43,920 [main] INFO  org.apache.pig.Main - Logging error messages to: /root/pig_1327939963919.log
2012-01-30 16:12:44,025 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: hdfs://lxc233:9000
2012-01-30 16:12:44,102 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to map-reduce job tracker at: lxc233:9001
2012-01-30 16:12:44,760 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: MERGE_JION
2012-01-30 16:12:44,923 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false
2012-01-30 16:12:44,982 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 2
2012-01-30 16:12:44,982 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 2
2012-01-30 16:12:45,001 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig script settings are added to the job
2012-01-30 16:12:45,006 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.3.2-1031432, built on 11/05/2010 05:32 GMT
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=lxc233.machine.com
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.6.0_22
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Sun Microsystems Inc.
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-6-sun-1.6.0.22/jre
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/opt/hadoop/conf:/usr/lib/jvm/java-6-sun/jre/lib/tools.jar:/opt/hadoop:/opt/hadoop/hadoop-0.20-append-core.jar:/opt/hadoop/lib/commons-cli-1.2.jar:/opt/hadoop/lib/commons-codec-1.3.jar:/opt/hadoop/lib/commons-el-1.0.jar:/opt/hadoop/lib/commons-httpclient-3.0.1.jar:/opt/hadoop/lib/commons-logging-1.0.4.jar:/opt/hadoop/lib/commons-logging-api-1.0.4.jar:/opt/hadoop/lib/commons-net-1.4.1.jar:/opt/hadoop/lib/core-3.1.1.jar:/opt/hadoop/lib/hadoop-fairscheduler-0.20-append.jar:/opt/hadoop/lib/hadoop-gpl-compression-0.2.0-dev.jar:/opt/hadoop/lib/hadoop-lzo-0.4.14.jar:/opt/hadoop/lib/hsqldb-1.8.0.10.jar:/opt/hadoop/lib/jasper-compiler-5.5.12.jar:/opt/hadoop/lib/jasper-runtime-5.5.12.jar:/opt/hadoop/lib/jets3t-0.6.1.jar:/opt/hadoop/lib/jetty-6.1.14.jar:/opt/hadoop/lib/jetty-util-6.1.14.jar:/opt/hadoop/lib/junit-4.5.jar:/opt/hadoop/lib/kfs-0.2.2.jar:/opt/hadoop/lib/log4j-1.2.15.jar:/opt/hadoop/lib/mockito-all-1.8.2.jar:/opt/hadoop/lib/oro-2.0.8.jar:/opt/hadoop/lib/servlet-api-2.5-6.1.14.jar:/opt/hadoop/lib/slf4j-api-1.4.3.jar:/opt/hadoop/lib/slf4j-log4j12-1.4.3.jar:/opt/hadoop/lib/xmlenc-0.52.jar:/opt/hadoop/lib/jsp-2.1/jsp-2.1.jar:/opt/hadoop/lib/jsp-2.1/jsp-api-2.1.jar:/opt/pig/bin/../conf:/usr/lib/jvm/java-6-sun/jre/lib/tools.jar:/opt/hadoop/lib/commons-codec-1.3.jar:/opt/hbase/lib/guava-r06.jar:/opt/hbase/hbase-0.90.3.jar:/opt/hadoop/lib/log4j-1.2.15.jar:/opt/hadoop/lib/commons-cli-1.2.jar:/opt/hadoop/lib/commons-logging-1.0.4.jar:/opt/pig/pig-withouthadoop.jar:/opt/hadoop/conf_computation:/opt/hbase/conf:/opt/pig/bin/../lib/hadoop-0.20-append-core.jar:/opt/pig/bin/../lib/hadoop-gpl-compression-0.2.0-dev.jar:/opt/pig/bin/../lib/hbase-0.90.3.jar:/opt/pig/bin/../lib/pigudfs.jar:/opt/pig/bin/../lib/zookeeper-3.3.2.jar:/opt/pig/bin/../pig-withouthadoop.jar:
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/opt/hadoop/lib/native/Linux-amd64-64
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=&amp;lt;NA&amp;gt;
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.version=2.6.32-5-amd64
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.name=root
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.home=/root
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/root
2012-01-30 16:12:45,039 [main] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=lxc233.machine.com:2222,lxc231.machine.com:2222,lxc234.machine.com:2222 sessionTimeout=180000 watcher=hconnection
2012-01-30 16:12:45,048 [main-SendThread()] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server lxc231.machine.com/192.168.1.231:2222
2012-01-30 16:12:45,049 [main-SendThread(lxc231.machine.com:2222)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to lxc231.machine.com/192.168.1.231:2222, initiating session
2012-01-30 16:12:45,081 [main-SendThread(lxc231.machine.com:2222)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server lxc231.machine.com/192.168.1.231:2222, sessionid = 0x134c294771a073f, negotiated timeout = 180000
2012-01-30 16:12:46,569 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job
2012-01-30 16:12:46,590 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.
2012-01-30 16:12:46,870 [Thread-13] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=lxc233.machine.com:2222,lxc231.machine.com:2222,lxc234.machine.com:2222 sessionTimeout=180000 watcher=hconnection
2012-01-30 16:12:46,871 [Thread-13-SendThread()] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server lxc233.machine.com/192.168.1.233:2222
2012-01-30 16:12:46,871 [Thread-13-SendThread(lxc233.machine.com:2222)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to lxc233.machine.com/192.168.1.233:2222, initiating session
2012-01-30 16:12:46,872 [Thread-13-SendThread(lxc233.machine.com:2222)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server lxc233.machine.com/192.168.1.233:2222, sessionid = 0x2343822449935e1, negotiated timeout = 180000
2012-01-30 16:12:46,880 [Thread-13] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=lxc233.machine.com:2222,lxc231.machine.com:2222,lxc234.machine.com:2222 sessionTimeout=180000 watcher=hconnection
2012-01-30 16:12:46,880 [Thread-13-SendThread()] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server lxc233.machine.com/192.168.1.233:2222
2012-01-30 16:12:46,880 [Thread-13-SendThread(lxc233.machine.com:2222)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to lxc233.machine.com/192.168.1.233:2222, initiating session
2012-01-30 16:12:46,882 [Thread-13-SendThread(lxc233.machine.com:2222)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server lxc233.machine.com/192.168.1.233:2222, sessionid = 0x2343822449935e2, negotiated timeout = 180000
2012-01-30 16:12:47,091 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete
2012-01-30 16:12:47,703 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_201201201546_0890
2012-01-30 16:12:47,703 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - More information at: http://lxc233:50030/jobdetails.jsp?jobid=job_201201201546_0890
2012-01-30 16:12:55,723 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 25% complete
2012-01-30 16:13:49,312 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 33% complete
2012-01-30 16:13:55,322 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 50% complete
2012-01-30 16:13:57,327 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - job job_201201201546_0890 has failed! Stop running all dependent jobs
2012-01-30 16:13:57,327 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete
2012-01-30 16:13:57,337 [main] ERROR org.apache.pig.tools.pigstats.SimplePigStats - ERROR: Could create instance of class org.apache.pig.backend.hadoop.hbase.HBaseStorage$1, while attempting to de-serialize it. (no default constructor ?)
2012-01-30 16:13:57,337 [main] ERROR org.apache.pig.tools.pigstats.PigStatsUtil - 1 map reduce job(s) failed!
2012-01-30 16:13:57,338 [main] INFO  org.apache.pig.tools.pigstats.SimplePigStats - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
0.20-append	0.9.2-SNAPSHOT	root	2012-01-30 16:12:44	2012-01-30 16:13:57	MERGE_JION

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_201201201546_0890	end_sessions	INDEXER	Message: Job failed!	

Input(s):
Failed to read data from &quot;hbase://endSession.bea000000.dev.ubithere.com&quot;

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_201201201546_0890	-&amp;gt;	null,
null


2012-01-30 16:13:57,338 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Failed!
2012-01-30 16:13:57,339 [main] ERROR org.apache.pig.tools.grunt.GruntParser - ERROR 2997: Encountered IOException. Could create instance of class org.apache.pig.backend.hadoop.hbase.HBaseStorage$1, while attempting to de-serialize it. (no default constructor ?)
Details at logfile: /root/pig_1327939963919.log
2012-01-30 16:13:57,339 [main] ERROR org.apache.pig.tools.grunt.GruntParser - ERROR 2244: Job failed, hadoop does not return any error message
Details at logfile: /root/pig_1327939963919.log
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;And here is the result in the log file :&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Backend error message
---------------------
java.io.IOException: Could create instance of class org.apache.pig.backend.hadoop.hbase.HBaseStorage$1, while attempting to de-serialize it. (no default constructor ?)
	at org.apache.pig.data.BinInterSedes.readWritable(BinInterSedes.java:235)
	at org.apache.pig.data.BinInterSedes.readDatum(BinInterSedes.java:336)
	at org.apache.pig.data.BinInterSedes.readDatum(BinInterSedes.java:251)
	at org.apache.pig.data.BinInterSedes.addColsToTuple(BinInterSedes.java:556)
	at org.apache.pig.data.BinSedesTuple.readFields(BinSedesTuple.java:64)
	at org.apache.pig.impl.io.PigNullableWritable.readFields(PigNullableWritable.java:114)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:67)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:40)
	at org.apache.hadoop.mapreduce.ReduceContext.nextKeyValue(ReduceContext.java:113)
	at org.apache.hadoop.mapreduce.ReduceContext.nextKey(ReduceContext.java:92)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:175)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:566)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:408)
	at org.apache.hadoop.mapred.Child.main(Child.java:170)
Caused by: java.lang.InstantiationException: org.apache.pig.backend.hadoop.hbase.HBaseStorage$1
	at java.lang.Class.newInstance0(Class.java:340)
	at java.lang.Class.newInstance(Class.java:308)
	at org.apache.pig.data.BinInterSedes.readWritable(BinInterSedes.java:231)
	... 13 more

Pig Stack Trace
---------------
ERROR 2997: Encountered IOException. Could create instance of class org.apache.pig.backend.hadoop.hbase.HBaseStorage$1, while attempting to de-serialize it. (no default constructor ?)

java.io.IOException: Could create instance of class org.apache.pig.backend.hadoop.hbase.HBaseStorage$1, while attempting to de-serialize it. (no default constructor ?)
	at org.apache.pig.data.BinInterSedes.readWritable(BinInterSedes.java:235)
	at org.apache.pig.data.BinInterSedes.readDatum(BinInterSedes.java:336)
	at org.apache.pig.data.BinInterSedes.readDatum(BinInterSedes.java:251)
	at org.apache.pig.data.BinInterSedes.addColsToTuple(BinInterSedes.java:556)
	at org.apache.pig.data.BinSedesTuple.readFields(BinSedesTuple.java:64)
	at org.apache.pig.impl.io.PigNullableWritable.readFields(PigNullableWritable.java:114)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:67)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:40)
	at org.apache.hadoop.mapreduce.ReduceContext.nextKeyValue(ReduceContext.java:113)
	at org.apache.hadoop.mapreduce.ReduceContext.nextKey(ReduceContext.java:92)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:175)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:566)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:408)
	at org.apache.hadoop.mapred.Child.main(Child.java:170)
Caused by: java.lang.InstantiationException: org.apache.pig.backend.hadoop.hbase.HBaseStorage$1
	at java.lang.Class.newInstance0(Class.java:340)
	at java.lang.Class.newInstance(Class.java:308)
	at org.apache.pig.data.BinInterSedes.readWritable(BinInterSedes.java:231)
================================================================================
Pig Stack Trace
---------------
ERROR 2244: Job failed, hadoop does not return any error message

org.apache.pig.backend.executionengine.ExecException: ERROR 2244: Job failed, hadoop does not return any error message
	at org.apache.pig.tools.grunt.GruntParser.executeBatch(GruntParser.java:139)
	at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:192)
	at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:164)
	at org.apache.pig.tools.grunt.Grunt.exec(Grunt.java:81)
	at org.apache.pig.Main.run(Main.java:561)
	at org.apache.pig.Main.main(Main.java:111)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:156)
================================================================================
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The same script without using merge works without any problem.&lt;/p&gt;</description>
                <environment>&lt;p&gt;HBase 0.90.3, Hadoop 0.20-append&lt;/p&gt;</environment>
        <key id="12540391">PIG-2495</key>
            <summary>Using merge JOIN from a HBaseStorage produces an error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="bridiver">Brian Johnson</assignee>
                                    <reporter username="kados">Kevin Lion</reporter>
                        <labels>
                    </labels>
                <created>Mon, 30 Jan 2012 16:31:35 +0000</created>
                <updated>Fri, 21 Nov 2014 05:59:13 +0000</updated>
                            <resolved>Thu, 30 Oct 2014 17:12:06 +0000</resolved>
                                    <version>0.9.1</version>
                    <version>0.9.2</version>
                    <version>0.13.1</version>
                                    <fixVersion>0.14.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13223404" author="billgraham" created="Tue, 6 Mar 2012 16:44:57 +0000"  >&lt;p&gt;Thanks for the patch Kevin! A few note about Pig code style:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Indentation should be 4 spaces, you have 2 in some spots.&lt;/li&gt;
	&lt;li&gt;Curly brackets should go at the end of the class name or constructor/method signature, not below it.&lt;/li&gt;
	&lt;li&gt;Please include the standard apache header above the package name for TableSplitComparable&lt;/li&gt;
	&lt;li&gt;I &lt;em&gt;think&lt;/em&gt; we favor brackets in if/else clauses but I&apos;ll let someone else confirm.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;And a few more notes comments:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I would think &lt;tt&gt;TableSplitComparable&lt;/tt&gt; should implement &lt;tt&gt;WritableComparable&amp;lt;TableSplit&amp;gt;&lt;/tt&gt; instead of &lt;tt&gt;WritableComparable&amp;lt;TableSplitComparable&amp;gt;&lt;/tt&gt;, right?&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Your hashcode method seems like it could just be
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;return ((tsplit == null) ? 0 : tsplit.hashCode());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;since it&apos;s just delegating to tsplit. &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Also, the condition in equals could just be:&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;else {
  return tsplit.equals(other.tsplit);
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;ul&gt;
	&lt;li&gt;I don&apos;t think WritableComparable needs to implement Serializable and serialVersionUID.&lt;/li&gt;
	&lt;li&gt;Should the wrapped TableSplit be initialized to an empty split? It seems like it should have to be explicitly set, right?&lt;/li&gt;
	&lt;li&gt;In getSplitComparable you can just return &lt;tt&gt;new TableSplitComparable((TableSplit)split);&lt;/tt&gt; after a ! instanceof check that throws an exception.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13228530" author="kados" created="Tue, 13 Mar 2012 17:30:30 +0000"  >&lt;p&gt;Thanks for those remarks. I&apos;ve modified my patch with all your comments.&lt;br/&gt;
Does it seems okay for you ?&lt;/p&gt;</comment>
                            <comment id="13228967" author="billgraham" created="Wed, 14 Mar 2012 04:53:44 +0000"  >&lt;p&gt;Looks good to me besides one last nit, which is to include &lt;tt&gt;TableSplit&lt;/tt&gt; as the generic type in the &lt;tt&gt;HBaseStorage.getSplitComparable&lt;/tt&gt; signature like so:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;public WritableComparable&amp;lt;TableSplit&amp;gt; getSplitComparable(InputSplit split) throws IOException
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13228968" author="billgraham" created="Wed, 14 Mar 2012 04:53:58 +0000"  >&lt;p&gt;Looks good to me besides one last nit, which is to include &lt;tt&gt;TableSplit&lt;/tt&gt; as the generic type in the &lt;tt&gt;HBaseStorage.getSplitComparable&lt;/tt&gt; signature like so:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;public WritableComparable&amp;lt;TableSplit&amp;gt; getSplitComparable(InputSplit split) throws IOException
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13229108" author="kados" created="Wed, 14 Mar 2012 09:57:15 +0000"  >&lt;p&gt;Okay, it&apos;s done, thanks for your help! What must I do next? &quot;Resolve&quot; the issue?&lt;/p&gt;</comment>
                            <comment id="13229699" author="alangates" created="Wed, 14 Mar 2012 22:23:07 +0000"  >&lt;p&gt;Resolve is when a committer has checked it in.  The next step will be for one of the committers to review it and run tests, and possibly commit it.&lt;/p&gt;</comment>
                            <comment id="13229749" author="dvryaboy" created="Wed, 14 Mar 2012 23:20:03 +0000"  >&lt;p&gt;Assigning to Kevin (you don&apos;t have to do anything, that&apos;s just to give you credit). I&apos;ll review the patch.&lt;/p&gt;</comment>
                            <comment id="13229757" author="dvryaboy" created="Wed, 14 Mar 2012 23:30:12 +0000"  >&lt;p&gt;A few minor comments:&lt;/p&gt;

&lt;p&gt;The @since annotation is wrong &amp;#8211; even if we decide to backport this all the way to 0.9 branch, we have to make it 0.9.3 since 0.9.2 is released. &lt;/p&gt;

&lt;p&gt;toString &amp;#8211; should probably return something more useful than just the class name? Maybe concatenate the actual split&apos;s toString()?&lt;/p&gt;

&lt;p&gt;Overall, I&apos;m not sure what caused the old code to not work and how this is supposed to fix the issue. Just for my edification, can you explain? The difference is only that before, we implemented WritableComparable&amp;lt;InputSplit&amp;gt; and now you implement WritableComparable&amp;lt;TableSplit&amp;gt;?  The test you added fails when I apply it to trunk:&lt;/p&gt;


&lt;p&gt;Testcase: testMergeJoin took 21.401 sec&lt;br/&gt;
        FAILED&lt;br/&gt;
expected:&amp;lt;0&amp;gt; but was:&amp;lt;48&amp;gt;&lt;br/&gt;
junit.framework.AssertionFailedError: expected:&amp;lt;0&amp;gt; but was:&amp;lt;48&amp;gt;&lt;br/&gt;
        at org.apache.pig.test.TestHBaseStorage.testMergeJoin(TestHBaseStorage.java:910)&lt;/p&gt;
</comment>
                            <comment id="13230212" author="kados" created="Thu, 15 Mar 2012 14:47:33 +0000"  >&lt;p&gt;OKay, I&apos;ve modified the @since to 0.9.3. toString() now return the class name and the split&apos;s toString().&lt;/p&gt;

&lt;p&gt;There was an issue because the getSplitComparable must return something Serializable (with a default constructor). The previously anonymous class hadn&apos;t a such thing.&lt;/p&gt;

&lt;p&gt;I&apos;ve also modified the unit test but I can&apos;t test it on my computer because I&apos;ve a timeout when I run it: does someone knows why?&lt;/p&gt;</comment>
                            <comment id="13490431" author="cheolsoo" created="Mon, 5 Nov 2012 03:45:43 +0000"  >&lt;p&gt;Hi Kevin,&lt;/p&gt;

&lt;p&gt;Sorry for the late reply. I was looking into your patch to commit it, but I ran into the same test failure as what Dmitriy mentioned.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I&apos;ve also modified the unit test but I can&apos;t test it on my computer because I&apos;ve a timeout when I run it: does someone knows why?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Does your test log contain anything? Can you please upload your test log to the jira? It can be found at build/test/logs/TEST-org.apache.pig.test.TestHBaseStorage.txt.&lt;/p&gt;

&lt;p&gt;I am canceling patch available for now until the test is fixed.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;</comment>
                            <comment id="13717915" author="pradeepg26" created="Wed, 24 Jul 2013 03:56:51 +0100"  >&lt;p&gt;Hi Kevin,&lt;/p&gt;

&lt;p&gt;I have a very minor request for your patch. When throwing the RuntimeException, could you also include the class information for the given type? This could potentially be useful for debugging purposes.&lt;/p&gt;</comment>
                            <comment id="13959019" author="yzou" created="Thu, 3 Apr 2014 18:38:25 +0100"  >&lt;p&gt;Hi, I wonder if this patch is still being worked on or not? is it still planned to be pulled to the main tip of pig? I am hitting the exactly the same bug doing a merge JOIN on 0.12.0 stable, only that it is actually a self join from the same input hbase table, thought I would not think that matter for the sake of this bug being still there. If you guys need help on getting the patch move forward, I will be glad to help, it&apos;s a good fix in my opinion.&lt;/p&gt;

&lt;p&gt;thanks&lt;/p&gt;</comment>
                            <comment id="14044951" author="bridiver" created="Thu, 26 Jun 2014 19:03:35 +0100"  >&lt;p&gt;I am working on it. I fixed the test, it was a mismatch with binary with string types in hbase. I&apos;m also implementing IndexableLoadFunc and CollectableLoadFunc to give HBaseStorage the full range of optimized joins and groups&lt;/p&gt;</comment>
                            <comment id="14044955" author="bridiver" created="Thu, 26 Jun 2014 19:04:11 +0100"  >&lt;p&gt;There was also an issue with the join key in the test&lt;/p&gt;</comment>
                            <comment id="14047023" author="bridiver" created="Sun, 29 Jun 2014 01:52:47 +0100"  >&lt;p&gt;Here is my patch for 0.12.1 that includes the existing patch, but fixes the test and adds support for IndexableLoadFunc and CollectableLoadFunc&lt;/p&gt;</comment>
                            <comment id="14169801" author="daijy" created="Mon, 13 Oct 2014 20:26:03 +0100"  >&lt;p&gt;I am fine with SplitComparable changes since I see all the review comments from Bill and Dmitriy are addressed and TestHBaseStorage pass for me.&lt;/p&gt;

&lt;p&gt;In seekNear, we&apos;d better to use existing objToBytes method, so that we can deal alternative caster, additional primary key (DateTime, BigInterger), and complex key. I modified the patch with this change and also rebase with trunk.&lt;/p&gt;</comment>
                            <comment id="14169868" author="bridiver" created="Mon, 13 Oct 2014 21:08:16 +0100"  >&lt;p&gt;Although the test passes, there appeared to be some problems when I ran this on a larger data set so I think there might be an issue with the implementation. I&apos;ll try it again with your changes and verify whether or not there was an issue. Perhaps it&apos;s best to split off the changes for IndexableLoadFunc from the CollectableLoadFunc ones?&lt;/p&gt;</comment>
                            <comment id="14170042" author="daijy" created="Mon, 13 Oct 2014 22:39:37 +0100"  >&lt;p&gt;Thanks for verifying. Do you see any exception?&lt;/p&gt;

&lt;p&gt;Also what do you mean &quot;split off the changes for IndexableLoadFunc from the CollectableLoadFunc&quot;?&lt;/p&gt;</comment>
                            <comment id="14170062" author="bridiver" created="Mon, 13 Oct 2014 22:53:06 +0100"  >&lt;p&gt;Two different interfaces were implemented in this patch. IndexableLoadFunc, which possibly still has an issue and CollectableLoadFunc which is a no-op on hbase because keys are unique. I&apos;m suggesting maybe I should make two separate patches because CollectableLoadFunc works great (although there is a related bug in pig &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-4166&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/PIG-4166&lt;/a&gt;), but I&apos;m not 100% sure on IndexableLoadFunc. I didn&apos;t get any exceptions, but the data returned by the script on our actual data didn&apos;t look right. &lt;/p&gt;</comment>
                            <comment id="14170151" author="daijy" created="Mon, 13 Oct 2014 23:48:12 +0100"  >&lt;p&gt;Sounds good. We can get CollectableLoadFunc part in first.&lt;/p&gt;</comment>
                            <comment id="14170180" author="daijy" created="Tue, 14 Oct 2014 00:06:17 +0100"  >&lt;p&gt;Does it work if you put &quot;--caster HBaseBinaryConverter&quot; in HBaseStorage option? By default, HBaseStorage uses Utf8StorageConverter, which is Pig specific.&lt;/p&gt;</comment>
                            <comment id="14189005" author="bridiver" created="Wed, 29 Oct 2014 21:16:00 +0000"  >&lt;p&gt;here is the patch against branch-0.13 for merge join and collected group&lt;/p&gt;</comment>
                            <comment id="14189696" author="daijy" created="Thu, 30 Oct 2014 06:25:09 +0000"  >&lt;p&gt;LGTM, attach a patch resync with trunk.&lt;/p&gt;

&lt;p&gt;How about IndexableLoadFunc? Do you still want to do it?&lt;/p&gt;</comment>
                            <comment id="14190347" author="bridiver" created="Thu, 30 Oct 2014 16:43:54 +0000"  >&lt;p&gt;Yes, but I think there are some problems with the current implementation. Probably best to open another ticket for outer merge join so this one can be closed out with the patch.&lt;/p&gt;</comment>
                            <comment id="14190386" author="bridiver" created="Thu, 30 Oct 2014 17:08:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-4254&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/PIG-4254&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14190393" author="daijy" created="Thu, 30 Oct 2014 17:12:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-2495&quot; title=&quot;Using merge JOIN from a HBaseStorage produces an error&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-2495&quot;&gt;&lt;del&gt;PIG-2495&lt;/del&gt;&lt;/a&gt;-Collectable.patch committed to both trunk and 0.14 branch. Created &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-4255&quot; title=&quot;Implementing IndexableLoadFunc for HBastStorage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-4255&quot;&gt;&lt;del&gt;PIG-4255&lt;/del&gt;&lt;/a&gt; for IndexableLoadFunc change. Thanks Brian!&lt;/p&gt;</comment>
                            <comment id="14190398" author="bridiver" created="Thu, 30 Oct 2014 17:13:37 +0000"  >&lt;p&gt;I think we doubled up on the new ticket. I&apos;ll let you decide which one to keep so we don&apos;t end up deleting both of them.&lt;/p&gt;</comment>
                            <comment id="14190403" author="daijy" created="Thu, 30 Oct 2014 17:15:44 +0000"  >&lt;p&gt;I removed &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-4255&quot; title=&quot;Implementing IndexableLoadFunc for HBastStorage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-4255&quot;&gt;&lt;del&gt;PIG-4255&lt;/del&gt;&lt;/a&gt;. &lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12674569" name="PIG-2495-2.patch" size="26052" author="daijy" created="Mon, 13 Oct 2014 20:26:03 +0100"/>
                            <attachment id="12678129" name="PIG-2495-Collectable.patch" size="8219" author="daijy" created="Thu, 30 Oct 2014 06:25:09 +0000"/>
                            <attachment id="12518467" name="PIG-2495.patch" size="6482" author="kados" created="Thu, 15 Mar 2012 14:36:39 +0000"/>
                            <attachment id="12678000" name="patch" size="12000" author="bridiver" created="Wed, 29 Oct 2014 21:16:00 +0000"/>
                            <attachment id="12653035" name="patch" size="27577" author="bridiver" created="Sun, 29 Jun 2014 01:52:47 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 6 Mar 2012 16:44:57 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>225804</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy8ke7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>83947</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>