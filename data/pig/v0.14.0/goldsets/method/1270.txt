org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler.getJob(MapReduceOper,Configuration,PigContext)
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.createRecordReader(org.apache.hadoop.mapreduce.InputSplit,TaskAttemptContext)
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader.nextKeyValue()
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader.PigRecordReader(InputFormat,PigSplit,LoadFunc,TaskAttemptContext)
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader.PigRecordReader(InputFormat,PigSplit,LoadFunc,TaskAttemptContext,long)
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SampleOptimizer.visitMROp(MapReduceOper)
org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLoad.getLimit()
org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLoad.illustratorMarkup(Object,Object,int)
org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLoad.POLoad(OperatorKey)
org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLoad.setLimit(long)
org.apache.pig.newplan.logical.relational.LogToPhyTranslationVisitor.visit(LOLoad)
org.apache.pig.newplan.logical.relational.LOLoad.getScriptSchema()
org.apache.pig.newplan.logical.rules.LimitOptimizer.OptimizeLimitTransformer.check(OperatorPlan)
org.apache.pig.newplan.logical.rules.LimitOptimizer.OptimizeLimitTransformer.transform(OperatorPlan)
org.apache.pig.test.TestOptimizeLimit.testOPLimit10Optimizer()
org.apache.pig.test.TestOptimizeLimit.testOPLimit2Optimizer()
org.apache.pig.test.TestOptimizeLimit.testOPLimit5Optimizer()
org.apache.pig.test.TestOptimizeLimit.testOPLimit6Optimizer()
