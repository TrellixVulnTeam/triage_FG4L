org.apache.mahout.cf.taste.hadoop.als.DatasetSplitter.WritePrefsMapper.map(Text,Text,Context)
org.apache.mahout.cf.taste.hadoop.als.ParallelALSFactorizationJob.runSolver(Path,Path,Path)
org.apache.mahout.cf.taste.hadoop.pseudo.RecommenderJob.main(String[])
org.apache.mahout.classifier.bayes.WikipediaDatasetCreatorDriver.runJob(String,String,String,boolean,Class<?extendsAnalyzer>,Analyzer)
org.apache.mahout.classifier.df.mapreduce.Classifier.run()
org.apache.mahout.classifier.df.tools.FrequenciesJob.run(Configuration)
org.apache.mahout.classifier.naivebayes.test.TestNaiveBayesDriver.run(String[])
org.apache.mahout.clustering.conversion.InputDriver.runJob(Path,Path,String)
org.apache.mahout.clustering.evaluation.RepresentativePointsDriver.runIterationMR(Configuration,Path,Path,Path,DistanceMeasure)
org.apache.mahout.clustering.spectral.common.AffinityMatrixInputJob.runJob(Path,Path,int,int)
org.apache.mahout.clustering.spectral.common.MatrixDiagonalizeJob.runJob(Path,int)
org.apache.mahout.clustering.spectral.common.UnitVectorizerJob.runJob(Path,Path)
org.apache.mahout.clustering.spectral.common.VectorMatrixMultiplicationJob.runJob(Path,Vector,Path,Path)
org.apache.mahout.clustering.spectral.eigencuts.EigencutsAffinityCutsJob.runjob(Path,Path,Path,Configuration)
org.apache.mahout.clustering.spectral.eigencuts.EigencutsSensitivityJob.runJob(Vector,Vector,Path,double,double,double,double,Path)
org.apache.mahout.fpm.pfpgrowth.dataset.KeyBasedStringTupleGrouper.startJob(Parameters)
org.apache.mahout.fpm.pfpgrowth.PFPGrowth.startAggregating(Parameters,Configuration)
org.apache.mahout.fpm.pfpgrowth.PFPGrowth.startParallelCounting(Parameters,Configuration)
org.apache.mahout.fpm.pfpgrowth.PFPGrowth.startParallelFPGrowth(Parameters,Configuration)
org.apache.mahout.ga.watchmaker.cd.hadoop.CDMahoutEvaluator.evaluate(List<?extendsRule>,Rule,int,Path,Path,Collection<CDFitness>,CDFitness,DatasetSplit)
org.apache.mahout.ga.watchmaker.cd.tool.CDInfosTool.gatherInfos(Descriptors,Path,Path,Collection<String>,String)
org.apache.mahout.ga.watchmaker.MahoutEvaluator.evaluate(FitnessEvaluator<?>,Iterable<?>,Collection<Double>,Double,Path,Path)
org.apache.mahout.graph.linkanalysis.RandomWalk.persistVector(Configuration,Path,Vector)
org.apache.mahout.math.hadoop.stats.BasicStats.computeVarianceTotals(Path,Path,Configuration)
org.apache.mahout.math.stats.entropy.ConditionalEntropy.calculateConditionalEntropy()
org.apache.mahout.math.stats.entropy.ConditionalEntropy.calculateSpecificConditionalEntropy()
org.apache.mahout.math.stats.entropy.ConditionalEntropy.groupAndCountByKeyAndValue()
org.apache.mahout.math.stats.entropy.Entropy.calculateEntropy()
org.apache.mahout.math.stats.entropy.Entropy.groupAndCount()
org.apache.mahout.text.WikipediaToSequenceFile.runJob(String,String,String,boolean,boolean)
org.apache.mahout.utils.SplitInputJob.run(Configuration,Path,Path,int,float)
org.apache.mahout.vectorizer.collocations.llr.CollocDriver.computeNGramsPruneByLLR(Path,Configuration,long,boolean,float,int)
org.apache.mahout.vectorizer.collocations.llr.CollocDriver.generateCollocations(Path,Path,Configuration,boolean,int,int,int)
org.apache.mahout.vectorizer.common.PartialVectorMerger.mergePartialVectors(Iterable<Path>,Path,Path,Configuration,float,boolean,int,boolean,boolean,int)
org.apache.mahout.vectorizer.DictionaryVectorizer.makePartialVectors(Path,Configuration,int,Path,Path,int,boolean,boolean,int)
org.apache.mahout.vectorizer.DictionaryVectorizer.startWordCounting(Path,Path,Configuration,int)
org.apache.mahout.vectorizer.DocumentProcessor.tokenizeDocuments(Path,Class<?extendsAnalyzer>,Analyzer,Path,Configuration)
org.apache.mahout.vectorizer.HighDFWordsPruner.getCommaSeparatedPaths(Iterable<Path>,Path)
org.apache.mahout.vectorizer.HighDFWordsPruner.mergePartialVectors(Iterable<Path>,Path,Path,Configuration,float,boolean,int)
org.apache.mahout.vectorizer.HighDFWordsPruner.pruneVectorsPartial(Path,Path,Path,long,Configuration)
org.apache.mahout.vectorizer.SimpleTextEncodingVectorizer.createVectors(Path,Path,VectorizerConfig)
org.apache.mahout.vectorizer.tfidf.TFIDFConverter.makePartialVectors(Path,Configuration,Long,Long,int,long,Path,Path,boolean,boolean)
org.apache.mahout.vectorizer.tfidf.TFIDFConverter.startDFCounting(Path,Path,Configuration)
