<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:22:14 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-122/MAHOUT-122.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-122] Random Forests Reference Implementation</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-122</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;p&gt;This is the first step of my GSOC project. Implement a simple, easy to understand, reference implementation of Random Forests (Building and Classification). The only requirement here is that &quot;it works&quot;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12426196">MAHOUT-122</key>
            <summary>Random Forests Reference Implementation</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/task.png">Task</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="adeneche">Deneche A. Hakim</assignee>
                                    <reporter username="adeneche">Deneche A. Hakim</reporter>
                        <labels>
                    </labels>
                <created>Sat, 23 May 2009 17:20:45 +0100</created>
                <updated>Wed, 18 Nov 2009 14:05:54 +0000</updated>
                            <resolved>Mon, 28 Sep 2009 06:42:30 +0100</resolved>
                                    <version>0.2</version>
                                    <fixVersion>0.2</fixVersion>
                                    <component>Classification</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12713652" author="adeneche" created="Wed, 27 May 2009 18:32:20 +0100"  >&lt;p&gt;This is a basic reference implementation that builds a forest and estimates the out of bag error along the way. I used Mahout&apos;s Vector to represent the data instances.&lt;br/&gt;
There are no tests at all, I could add them but it will probably take another week, so are they worth it (I mean for a reference imp.) ?&lt;br/&gt;
Here is a short description of the files:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;DataUtils.java and Condition.jva: contains helpers methods that deals with of Vector(s) and arrays of values. I don&apos;t think they&apos;ll play an important role in the distributed version (they need access to all the data at some point)&lt;/li&gt;
	&lt;li&gt;Dataset.java: describes the attributes of the data, how many they are, which one are NUMERICAL and which one are NOMINAL. also sometimes its useful to be able to IGNORE some attributes (for e.g. ID attributes)&lt;/li&gt;
	&lt;li&gt;DataLoader.java: a simple class that converts an array of comma-separated strings (this is the basic format of the UCI datasets) to a Vector List.&lt;br/&gt;
  It is important to note that to be able to store the NOMINAL attributes, which generally are of type String, this method needs to parse all the data to be able to convert those values into Integer.&lt;br/&gt;
  To keep things simple, IGNORED attributes are replaced with Double.NaN, but a more efficient implementation would be to skip them.&lt;br/&gt;
  For now this DataLoader does not know how to deal with missing attributes (&apos;?&apos;), an alternative would be to skip the data lines that contains missing attributes&lt;/li&gt;
	&lt;li&gt;PostOpData.java: contains the data of the Post Operative Dataset from UCI&lt;/li&gt;
	&lt;li&gt;InformationGain.java: entropy and Information Gain calculations. Because those calculations need access to all the data for a given tree node, these methods should probably be rewritten in a map-reduce form&lt;/li&gt;
	&lt;li&gt;DecisionTree.java: contains a simple implementation of the LearnUnprunedTree algorithm described in the Wiki. A special case that was not described in the algorithm is when the data becomes empty (happens from time to time), in this case (and based on the Weka implementation of Random Forests) the method should return a Leaf that predicts -1 (which means it cannot predict the label)&lt;br/&gt;
  For now the output of the classification is the predicted label, or -1 if no label could be predicted. A better solution would be to return the label&apos;s probability distribution&lt;/li&gt;
	&lt;li&gt;Node.java: represents a tree node, two implementations are available for NOMINAL and NUMERICAL attributes&lt;/li&gt;
	&lt;li&gt;ErrorEstimate.java: computes the errors for each distinct label and the global error rate, using the confusion matrix generated by the building algorithm&lt;/li&gt;
	&lt;li&gt;RandomForest.java: uses DecisionTree to build each tree of the forest. Contains a simple example (in the main method), after the execution the program outputs the error rates for each label followed by the total error rate&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I started to think about the distributed implementation, but I could (if necessary) spend some time writing the tests for the reference implementation.&lt;/p&gt;</comment>
                            <comment id="12713856" author="otis" created="Thu, 28 May 2009 05:10:41 +0100"  >&lt;p&gt;I can&apos;t comment on RF impl, but did notice that applying the patch issued warnings about CRs being stripped.  I guess that&apos;s a good thing...&lt;/p&gt;</comment>
                            <comment id="12713896" author="adeneche" created="Thu, 28 May 2009 08:16:40 +0100"  >&lt;blockquote&gt;&lt;p&gt;I can&apos;t comment on RF impl, but did notice that applying the patch issued warnings about CRs being stripped. I guess that&apos;s a good thing... &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s strange, I applied the patch to a fresh checkout of Mahout and launched mvn install, and all went ok!&lt;br/&gt;
Could be because I am using TortoiseSVN to create/apply the patches (although it worked well in the past) ?&lt;/p&gt;</comment>
                            <comment id="12716867" author="adeneche" created="Sat, 6 Jun 2009 12:33:54 +0100"  >&lt;p&gt;&lt;b&gt;second week patch&lt;/b&gt;&lt;br/&gt;
work in progress...&lt;/p&gt;

&lt;p&gt;&lt;b&gt;changes:&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;added many tests, although some are still missing&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;added a new class &quot;Instance&quot; that allows me to add an ID and a separate LABEL to a Vector&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;DataLoader.loadData(String, FileSystem, Path) loads the data from a file, IGNORED attributes are skipped&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Dataset handles only NUMERICAL and CATEGORICAL attributes&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;contains List&amp;lt;String&amp;gt; that represents the labels as found in the data, before being converted to int&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;added a new class &quot;Data&quot; that represents the data being loaded&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;contains methods to create subset from the current Data&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;the only way to get a new Data instance is to load it with DataLoader, or to use methods from an existing Data instance&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;this class could prove useful later to optimize the memory usage of the data&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;ForestBuilder.buildForest uses a PredictionCallback to collect the oob predictions, by changing the callback we can compute different errors rate, for example:&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;Forest out-of-bag error estimation&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;mean tree error rate&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;...&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I added a small running example in ForestBuilder.main(), this example shows a typical use of Random Forests:&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;loads the data from a file, you&apos;ll need to provide a descriptor. For example UciDescriptors.java contains the descriptors for the &quot;glass&quot; and &quot;post-operative&quot; UCI datasets, the datasets are available at the UCI web site)&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;reserves 10% of the data as a test set (not used for now)&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;builds a random forest using the remaining data&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;computes the oob error estimation&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;this procedure is repeated 100 times and the mean oob error estimation is printed&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;if you want to try the example, you&apos;ll need to download the &quot;post-operative&quot; dataset, or the &quot;glass&quot; dataset from UCI, put it somewhere, and change the first line of ForestBuilder.main() to the correct path, and use the corresponding UciDescriptor in the third line.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Note about memory usage:&lt;/b&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;the reference implementation loads the data in-memory, then builds the trees one at a time&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;each tree is built recursively using DecisionTree.learnUnprunedTree(), at each node the data is split and learnUnprunedTree() is called for each subset&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;the current implementation of &quot;Data&quot; is not memory efficient, each subset keeps it own copy of its part of the data, thus, except when there are Leaf nodes, each level of the tree generates one more copy of the data in memory&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;b&gt;Whats next:&lt;/b&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;RandomForest class that will contain the result of the forest building, can be stored/loaded from a file&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;try the implementation on the same UCI datasets as the Breiman&apos;s paper, using the same complete procedure&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;do some memory usage monitoring&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12717024" author="adeneche" created="Sun, 7 Jun 2009 10:23:51 +0100"  >&lt;p&gt;I&apos;ve been reading Breiman&apos;s paper about Random Forests (&lt;a href=&quot;ftp://stat-ftp.berkeley.edu/pub/users/breiman/randomforest2001.pdf&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;available here&lt;/a&gt;), and in page 9 he says:&lt;/p&gt;

&lt;p&gt;&quot;Grow the tree using CART methodology to maximum size and do not prune.&quot;&lt;/p&gt;

&lt;p&gt;So apparently he uses the CART algorithm to grow the trees, and if I&apos;m not wrong, it differs from the algorithm that I described int the wiki &lt;a href=&quot;http://cwiki.apache.org/MAHOUT/random-forests.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://cwiki.apache.org/MAHOUT/random-forests.html&lt;/a&gt;. The most important is the way it splits CATEGORICAL attributes:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;in the algorithm that I&apos;m using a node is built for each value of the attribute&lt;/li&gt;
	&lt;li&gt;in CART a best split value is found (in a similar way to NUMERICAL attributes) and only two nodes are built given that the attribute&apos;s value is equal or not to the split value&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I think that the best thing to do is to create an abstract DecisionTreeBuilder class, this way we can use whatever implementation we want&lt;/p&gt;</comment>
                            <comment id="12718771" author="adeneche" created="Fri, 12 Jun 2009 10:41:09 +0100"  >&lt;p&gt;whats new:&lt;br/&gt;
I added the results for KDD 10% with 10 trees. I tried also to build one single tree with KDD 50% and after more than 12 hours !!! of computing I gave up&lt;/p&gt;

&lt;p&gt;I was wrong about the memory usage of the current implementation, even that each node has its own Data object, all the Data object still share the same Instance objects which all the actual data.&lt;/p&gt;

&lt;p&gt;I did some profiling and I found that &quot;InformationGain.computeSplit()&quot; method takes nearly 98.5% of total time, this is responsible for computing the Information Gain for the current split. So if we want later to optimize this implementation we&apos;ll have to use a better algorithm to compute the Information Gain, the one that I&apos;m aware of and which is available in the Weka source code, computes&lt;br/&gt;
 the sorting indices for the data with each attribute.&lt;/p&gt;

&lt;p&gt;I also did some memory usage profiling using a Runnable that samples every 50ms a rough estimation of memory usage using (Runtime.getTotalMemory() - Runtime.getFreeMemory()). I used the KDD dataset (&amp;gt; 700 Mb of data), I then created different datasets using subsets of different size (1%, 10%, 25%, 50%). Here are the results :&lt;/p&gt;

&lt;p&gt;KDD has 41 attributes (stored as &quot;double&quot;)&lt;br/&gt;
KDD  1% has      49402 instances&lt;br/&gt;
KDD 10% has   494021 instances&lt;br/&gt;
KDD 25% has 1224607 instances&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Dataset &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Nb Trees &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; MUALD&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Max Used Memory &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Nb Nodes &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Max Tree Depth &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD  1% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 35.414.504 b &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 38.069.640 b &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 120 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD  1% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 35.144.096 b &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 45.669.904 b &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 126 (mean) &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 11 (mean) &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD 10% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 201.697.512 b &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 226.653.392 b &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 712 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 22 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD 10% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 201.697.512 b &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 276.780.280 b &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 870 (mean) &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 29 (mean) &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD 25% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 521.515.136 b &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 569.795.152 b &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 930 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 26 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Memory used right after loading the Data&lt;/p&gt;

&lt;p&gt;I should run more tests using KDD 50% and KDD 100%, and also building more trees to see how the memory usage behaves. But because the current implementation is very slow, it may take some time&lt;/p&gt;</comment>
                            <comment id="12718777" author="adeneche" created="Fri, 12 Jun 2009 11:14:38 +0100"  >&lt;p&gt;I did some tests on some of the datasets used in Breiman&apos;s paper to compare the results of the reference implementation.&lt;/p&gt;

&lt;p&gt;The test procedure described in Breiman&apos;s paper is as follows :&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;10% of the dataset is kept apart as a testing set&lt;/li&gt;
	&lt;li&gt;for each dataset we build two forests, one with m=int(log2(M)+1) (called Random-Input) and one with m=1 (called Single-Input)&lt;/li&gt;
	&lt;li&gt;we used the forest that gave the lowest oob error estimation to compute the test set error&lt;/li&gt;
	&lt;li&gt;we compute the test set error using the Single Input Forest, to show that even when m=1 Random Forests give comparable results to greater values of m&lt;/li&gt;
	&lt;li&gt;we compute the mean test set error using every tree of the forest that gave the lowest oob error. This shows how a single Decision Tree performs&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In the following tables:&lt;br/&gt;
*Selection: test set result with the forest that gave the lowest oob error&lt;br/&gt;
*Single Input: test set result with the Single-Input forest&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;One Tree: Mean Tree test set error&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;b&gt;Breiman&apos;s results :&lt;/b&gt;&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Data &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Selection &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Single Input &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; One Tree &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; glass &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20.6 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 21.2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 36.9 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; breast cancer &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.9 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.7 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 6.3 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; diabetes &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 24.2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 24.3 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 33.1 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; sonar &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 15.9 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 18.0 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 31.7 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; ionosphere &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 7.1 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 7.5 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 12.7 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; vehicle &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 25.8 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 26.4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 33.1 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; german &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 24.4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 26.2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 33.3 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;&lt;b&gt;Reference Implementation results :&lt;/b&gt;&lt;br/&gt;
I also included the how much system time (mean) each forest (Random-Input or Single-Input) took to build&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Data &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Selection &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Single Input &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; One Tree &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Mean RI Time &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Mean SI Time &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; glass &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 24.8 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 23.9 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 41.2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 9s  19 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2s 667 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; breast cancer &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.8 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.7 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5.8 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2s 588 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1s  60 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; diabetes &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 24.5 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 24.6 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 32.1 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 34s 875 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10s 284 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; sonar &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 14.6 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 15.3 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 32.3 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10s  89 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2s 227 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; ionosphere &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 7.1 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 7.0 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 15.5 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 33s 190 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 6s  96 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; vehicle &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 	25.3 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 26.4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 33.7 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 42s 194 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10s  21 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; german &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 23.15 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 25.27 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 32.8 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10s 203 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 3s 654 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
</comment>
                            <comment id="12718784" author="adeneche" created="Fri, 12 Jun 2009 11:26:34 +0100"  >&lt;p&gt;&lt;b&gt;3rd Week Patch&lt;/b&gt;&lt;br/&gt;
work in progress...&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Changes&lt;/b&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;ForestBuilder becomes an object that uses a TreeBuilder object&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;RandomForest represents a...guess what ! it has methods to classify single instances or bunch of data. Contains also methods to compute the total and mean&lt;br/&gt;
 number of nodes and mean max depth of the trees&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Added more PredictionCallback implementations!&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;MeanTreeCollector computes the mean classification error among all the trees of the forest&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;MultiCallback allows many callbacks to be passed to the same classification method&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;BreimanExample is a running example similar to the testing procedures used in Breiman&apos;s paper about Random Forests&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;MemoryUsage is a running app used to collect the stats about memory usage&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;DataSplit, a temporary app, allows to split the KDD dataset (1%, 10%, 25%, 50%)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;TreeBuilder is an abstract class that builds a Decision Tree given a Data instance&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;DefaultTreeBuilder implementation of a TreeBuilder based on Andrew W. Moore Decision Trees tutorial&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;b&gt;What&apos;s next&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;some more memory usage tests&lt;/li&gt;
	&lt;li&gt;I think its time to start with the map-reduce implementation, the results of the memory usage tests should help us decide which implementation to pursue&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12720847" author="tdunning" created="Wed, 17 Jun 2009 20:27:40 +0100"  >
&lt;p&gt;Just for grins, I plotted the max memory usage versus number of instances.  The relationship (so far) is very much a straight line.  The fit that R gives me is 450 (se=25) bytes per data instance with a fixed overhead of 23MB (se=14MB).  The fixed overhead can&apos;t necessarily be distinguished from zero, but it looks right.  &lt;/p&gt;

&lt;p&gt;The 450 byte overhead per training instance seems a little bit high, but I don&apos;t know the data well so it might be pretty reasonable.  The original data size was about 100 bytes.&lt;/p&gt;</comment>
                            <comment id="12725125" author="adeneche" created="Mon, 29 Jun 2009 12:16:28 +0100"  >&lt;blockquote&gt;&lt;p&gt;The 450 byte overhead per training instance seems a little bit high, but I don&apos;t know the data well so it might be pretty reasonable. The original data size was about 100 bytes.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I may be able to explain this overhead:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;First of all, the memory estimations that I&apos;ve done didn&apos;t account for the memory not yet garbage collected, so I&apos;ve run the tests again and this time a launched the Garbage Collector just after loading the data;&lt;/li&gt;
	&lt;li&gt;In a separate run, I allocated a double&lt;span class=&quot;error&quot;&gt;&amp;#91;nb instances&amp;#93;&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;nb attributes&amp;#93;&lt;/span&gt; and noted how much memory is used&lt;/li&gt;
&lt;/ul&gt;


&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Dataset &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Data size (nb instances x nb attributes) &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Mem. used by double&lt;span class=&quot;error&quot;&gt;&amp;#91;nb instances&amp;#93;&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;nb attributes&amp;#93;&lt;/span&gt; &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; MUALD &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD   1% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    49.402 x 42 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  19.050.312 B &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.331.360 B &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD  10% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   494.021 x 42 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 178.094.200 B &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 204.659.576 B &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD  25% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1.224.607 x 42 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 438.395.224 B &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 500.341.256 B &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD  50% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.449.215 x 42 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 873.266.456 B &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 998.331.560 B &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;Most of the overhead is caused by how the instances are represented in memory, I&apos;m using a DenseVector so all the attributes are stored in a double[], this means that each attribute uses 8 B of memory. By examining the original data, we can see that most of the attributes contain at most 3 digits and because that are stored as text they take at most 4 B if we count the separator.&lt;/p&gt;

&lt;p&gt;I suppose that the difference between MUALD and the memory used by double[][] is caused by the way the jvm stores the references to the instances&apos; objects.&lt;/p&gt;</comment>
                            <comment id="12727697" author="adeneche" created="Mon, 6 Jul 2009 19:58:58 +0100"  >&lt;p&gt;&lt;b&gt;Optimization patch&lt;/b&gt;&lt;br/&gt;
Just the reference implementation, does not contain the mapred implementation&lt;/p&gt;

&lt;p&gt;&lt;b&gt;changes&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;the class InformationGain responsible for finding the best split using Information Gain has been renamed IgSplit and is now abstract, the class DefaultIgSplit contains the current implementation, and I added an optimized version OptIgSplit&lt;/li&gt;
	&lt;li&gt;examples.CpuTest is a small program (it uses CLI by the way) to test the optimizations. This program works as follows:
	&lt;ul&gt;
		&lt;li&gt;the program loads kdd50%, just to reduce the loading time;&lt;/li&gt;
		&lt;li&gt;using the passed seed, the program creates a random number generator;&lt;/li&gt;
		&lt;li&gt;the program instantiates a TreeBuilder and passes it a DefaultIgSplit or a OptIgSplit depending on the passed parameters&lt;/li&gt;
		&lt;li&gt;the program repeats N times (N is a CommandLine parameter)
		&lt;ul&gt;
			&lt;li&gt;using the passed ratio (a number in the range (0,1]), the program creates a random subset from the data;&lt;/li&gt;
			&lt;li&gt;the program builds a single tree, selecting one random variable at each tree-node&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Here are some results on the KDD dataset, for each ratio we launch the program two times, one time with the DefaultIgSplit and another time with OptIgSplit. Each time we build 50 trees, and the initial seed is always 1L. I mesured the sum of build time for all the trees, it does not include the data loading nor the subset generation&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Ratio &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Default &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Optimized &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.1% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 1s 336 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2s 580 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.5% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 18m 34s 523 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 21s 285 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 36m 37s 953 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 40s 699 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1h 43m 4s 899 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2m 19s 745 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 6h 8m 46s 947 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5m 8s 359 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;Because the KDD dataset does not contain categorical attribute, this results are only for numerical attributes, I shall run another bunch of tests using another dataset. There is still room for improvement, but it requires sorting the whole dataset for each of its numerical attributes. This could be possible by processing the dataset once and storing an optmization-friendly version for latter uses.&lt;/p&gt;

&lt;p&gt;Now that the building algorithm is fast enough, I tried it again with the Breiman&apos;s example and discovered (horrified) that the out-of-bag classification takes a lot of time: using the KDD10%, one tree is build in 5s with the optimized code, and the oob classification takes more than &lt;b&gt;19 minutes&lt;/b&gt; !!! I shall (must) investigate this issue as soon as possible.&lt;/p&gt;</comment>
                            <comment id="12728034" author="adeneche" created="Tue, 7 Jul 2009 12:23:19 +0100"  >&lt;p&gt;I forgot to mention that I used Kdd50% instead of Kdd100% for CpuTest, so a Ratio of 10% in the CpuTest results means 5% of the whole Kdd dataset&lt;/p&gt;</comment>
                            <comment id="12728043" author="adeneche" created="Tue, 7 Jul 2009 12:38:38 +0100"  >&lt;p&gt;I did some tests on the &quot;poker hand&quot; dataset from UCI, it contains 8 categorical attributes and 1.000.000 instances. I got the following results (50 trees) :&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Ratio &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Default &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Optimized &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 11m 31s 253 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 8m 32s 446 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;It seems that the default implementation is fast enough for categorical attributes, and the optimized version is faster.&lt;/p&gt;

&lt;p&gt;I also found the issue with the oob error estimation. The old code was:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Data bag = data.bagging(rng);

Node tree = treeBuilder.build(bag);

&lt;span class=&quot;code-comment&quot;&gt;// predict the label &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the out-of-bag elements
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; index = 0; index &amp;lt; data.size(); index++) {
  Instance v = data.get(index);

  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!bag.contains(v)) {
    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; prediction = tree.classify(v);
    callback.prediction(treeId, v, prediction);
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The problem was with bag.contains(), commenting this test drop the build time from &lt;b&gt;21m 8s 473&lt;/b&gt; to &lt;b&gt;5s 913&lt;/b&gt;. I modified Data.bag() to fill a given boolean array with which instances are sampled in the bag, and used it as follows:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Arrays.fill(sampled, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;);
Data bag = data.bagging(rng, sampled);

Node tree = treeBuilder.build(bag);

&lt;span class=&quot;code-comment&quot;&gt;// predict the label &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the out-of-bag elements
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; index = 0; index &amp;lt; data.size(); index++) {
  Instance v = data.get(index);

  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (sampled[index] == &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) {
    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; prediction = tree.classify(v);
    callback.prediction(treeId, v, prediction);
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The new build time is &lt;b&gt;6s 777&lt;/b&gt;. I think this issue is solved (for now...)&lt;/p&gt;</comment>
                            <comment id="12754666" author="adeneche" created="Sun, 13 Sep 2009 07:25:59 +0100"  >&lt;p&gt;This issue will be committed as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-145&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;MAHOUT-145&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12756029" author="adeneche" created="Wed, 16 Sep 2009 14:38:47 +0100"  >&lt;p&gt;This patch contains the reference implementations and also some code that is common to all implementations.&lt;br/&gt;
If someone could review it before I commit it (my first commit =P )&lt;/p&gt;</comment>
                            <comment id="12759993" author="adeneche" created="Sun, 27 Sep 2009 07:45:27 +0100"  >&lt;ul&gt;
	&lt;li&gt;updated the patch with the latest changes in the trunk (common.* stuff)&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12760172" author="adeneche" created="Mon, 28 Sep 2009 08:37:52 +0100"  >&lt;p&gt;Added a quick start guide in the wiki:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://cwiki.apache.org/confluence/display/MAHOUT/Breiman+Example&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://cwiki.apache.org/confluence/display/MAHOUT/Breiman+Example&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12430164">MAHOUT-145</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12429080">MAHOUT-140</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12410060" name="2w_patch.diff" size="91017" author="adeneche" created="Sat, 6 Jun 2009 12:33:54 +0100"/>
                            <attachment id="12410475" name="3w_patch.diff" size="122735" author="adeneche" created="Fri, 12 Jun 2009 11:26:34 +0100"/>
                            <attachment id="12409191" name="RF reference.patch" size="42106" author="adeneche" created="Wed, 27 May 2009 18:36:06 +0100"/>
                            <attachment id="12412644" name="refimp_Jul6.diff" size="162129" author="adeneche" created="Mon, 6 Jul 2009 19:58:58 +0100"/>
                            <attachment id="12412727" name="refimp_Jul7.diff" size="163898" author="adeneche" created="Tue, 7 Jul 2009 12:38:38 +0100"/>
                            <attachment id="12420649" name="refimp_Sep27.patch" size="177229" author="adeneche" created="Sun, 27 Sep 2009 07:45:27 +0100"/>
                            <attachment id="12419767" name="refimp_Sep_15.patch" size="176998" author="adeneche" created="Wed, 16 Sep 2009 14:38:47 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 28 May 2009 04:10:41 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9943</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hxy72f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23296</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>