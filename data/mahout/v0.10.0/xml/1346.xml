<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:20:11 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-1346/MAHOUT-1346.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-1346] Spark Bindings (DRM)</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-1346</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;p&gt;Spark bindings for Mahout DRM. &lt;br/&gt;
DRM DSL. &lt;/p&gt;

&lt;p&gt;Disclaimer. This will all be experimental at this point.&lt;/p&gt;

&lt;p&gt;The idea is to wrap DRM by Spark RDD with support of some basic functionality, perhaps some humble beginning of Cost-based optimizer &lt;/p&gt;

&lt;p&gt;(0) Spark serialization support for Vector, Matrix &lt;br/&gt;
(1) Bagel transposition &lt;br/&gt;
(2) slim X&apos;X&lt;br/&gt;
(2a) not-so-slim X&apos;X&lt;br/&gt;
(3) blockify() (compose RDD containing vertical blocks of original input)&lt;br/&gt;
(4) read/write Mahout DRM off HDFS&lt;br/&gt;
(5) A&apos;B&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;</description>
                <environment></environment>
        <key id="12672693">MAHOUT-1346</key>
            <summary>Spark Bindings (DRM)</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dlyubimov">Dmitriy Lyubimov</assignee>
                                    <reporter username="dlyubimov">Dmitriy Lyubimov</reporter>
                        <labels>
                    </labels>
                <created>Mon, 7 Oct 2013 21:50:43 +0100</created>
                <updated>Mon, 13 Apr 2015 11:20:44 +0100</updated>
                            <resolved>Tue, 29 Apr 2014 20:56:41 +0100</resolved>
                                    <version>0.9</version>
                                    <fixVersion>0.10.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13788572" author="ssc" created="Mon, 7 Oct 2013 22:07:39 +0100"  >&lt;p&gt;very excited to see this, I think this is a great direction to look into&lt;/p&gt;</comment>
                            <comment id="13788820" author="dlyubimov" created="Tue, 8 Oct 2013 02:57:15 +0100"  >&lt;p&gt;One inconvenience that i seem to be running into quite a bit when i am working on this is that there&apos;s no efficient matrix block implementation that would just take hanging vectors and put them into hashmap while retaining original matrix geometry configuration  (e.g. if I cut out a block (3001:3010,3001:3010), it doesn&apos;t allocate hanging vector tables 1:m to represent this).&lt;/p&gt;

&lt;p&gt;SparseRow/ColumnMatrix does almost what i need; except it needs to have the &quot;Vector[] rows&quot; replaced with some sort of HashMap.. &lt;/p&gt;

&lt;p&gt;maybe i need a new type, something a SparseBlockRowMatrix. that does that. Unfortunately i feel it creates a little overload in the in-core world of types. I would say SparseRow/ColumnMatrix rather should be modified into this. Seems like a simple change, but of course it has implications for use patterns since it would not provide good sequential row-wise iteration speed.&lt;/p&gt;

&lt;p&gt;without this, i am forced manipulating with hash maps of index-&amp;gt; vector things, but that does not make a nice abstraction and disallows in-core DSL.&lt;/p&gt;</comment>
                            <comment id="13820475" author="dlyubimov" created="Tue, 12 Nov 2013 21:18:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://github.com/dlyubimov/mahout-commits/tree/dev-0.9.x-scala&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/dlyubimov/mahout-commits/tree/dev-0.9.x-scala&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;i started moving some things there. In particular, ALS is still not there (still haven&apos;t hashed it out with my boss). but there some inital matrix algorithms to be picked up (even transposition can be blockified and improved). &lt;/p&gt;

&lt;p&gt;Anyone wanting to give me a hand on this?&lt;/p&gt;

&lt;p&gt;Please dont pick weighted ALS-WR so far, i still hope to finish porting it. &lt;/p&gt;

&lt;p&gt;There are more interesting questions there, like parameter validation and fitting. &lt;br/&gt;
Common problem i have is that suppose you have the implicit feedback approach. Then you reformulate it in terms of preference (P) and confidence (C) inputs. The original paper speaks of a specific scheme of forming C that includes one parameter they want to fit. &lt;/p&gt;

&lt;p&gt;More interesting question is, what if we have more than one parameter? I.e. what if we have a bunch of user behavior, suppose, an item search, browse, click, add2card, and finally, aquisition. That&apos;s a whole bunch of parameters to form confidence of user&apos;s preference. I.e. it is reasonable to assume that e.g. since every transaction preceeds by add2card, add2card signifies a positive preference in general (we are just far less confident about that). Then again, abandoned cart may also signify a negative preference, or nothing at all.&lt;/p&gt;

&lt;p&gt;Anyway. suppose we want to perform exploration what&apos;s worth what. Natural way is to do it, again, thru a crossvalidation . Posing such a problem presents a whole new look at &quot;Big Data ML&quot; problems. Now we are using distributed processing not just because the input might be so big, but also because we have a lot of parameter space exploration to do (even if the one iteration problem is not so big). And thus produce more interesting analytical results.&lt;/p&gt;

&lt;p&gt;However, since there are many parameters, the task becomes fairly more interesting. since there is not  so much test data (we still should assume we will have just a handful of crossvalidation runs) various &quot;online&quot; convex searching techniques like SGD or BFGS are not going to be very viable. what i was thinking of, maybe we can start running parallel tries and fit the data into paraboloids (i.e. second degree polynomial regression without interaction terms). That might be a big assumption but that would be enough to get a general sense where global maximum may be even on inputs of a fairly small size. Of course we may discover hyperbolic parabaloid properties along some parameter axes. in which case it would mean we got the preference wrong, so we flip the preference mapping. (i.e. click = (P=1, C=0.5) would flip into click = (P=0, C=0...) and re-validate again.  This is kind of multidimensional variation of one-parameter second degree polynom fitting that Raphael refered to once. &lt;/p&gt;

&lt;p&gt;We are taking on a lot of assumptions here (parameter independence, existence of a good global maximum etc. etc). Perhaps there&apos;s something better to automate that search? &lt;/p&gt;

&lt;p&gt;thanks . &lt;br/&gt;
-Dmitriy&lt;/p&gt;</comment>
                            <comment id="13820483" author="dlyubimov" created="Tue, 12 Nov 2013 21:23:23 +0000"  >&lt;p&gt;P.S. I am kind of dubious step-recorded search would be of sufficient efficiency either. First, we should not assume we are running a good convex landscape. Second, i assume step-recorded search may take fairly long .&lt;/p&gt;</comment>
                            <comment id="13820487" author="dlyubimov" created="Tue, 12 Nov 2013 21:25:47 +0000"  >&lt;p&gt;PPS. the spark module have a specific CDH-2.0 profile to build against CDH 2.0 releases (could be plain hadoop, but that&apos;s what i just happen to be using at the moment). Which is what Spark 0.8 is built against a lot. welcome to add more 2.0 profiles. &lt;/p&gt;</comment>
                            <comment id="13820695" author="ssc" created="Wed, 13 Nov 2013 00:05:22 +0000"  >&lt;p&gt;I can help by looking at the sources from time to time. I&apos;m also working on using mahout vectors in Spark at the moment, yet in a slighty different context.&lt;/p&gt;</comment>
                            <comment id="13820705" author="dlyubimov" created="Wed, 13 Nov 2013 00:11:52 +0000"  >&lt;p&gt;can that context be part of Mahout? Or that would be way off ?&lt;/p&gt;</comment>
                            <comment id="13820717" author="ssc" created="Wed, 13 Nov 2013 00:18:33 +0000"  >&lt;p&gt;Its way off unfortunately, its exploratory research.&lt;/p&gt;</comment>
                            <comment id="13889842" author="dlyubimov" created="Mon, 3 Feb 2014 20:01:01 +0000"  >&lt;p&gt;Aha. Spark 0.9.0 with GraphX is finally released. Time to get hands dirty a bit in this methinks..&lt;/p&gt;</comment>
                            <comment id="13889861" author="ssc" created="Mon, 3 Feb 2014 20:15:03 +0000"  >&lt;p&gt;Big +1 on that.&lt;/p&gt;</comment>
                            <comment id="13906699" author="dlyubimov" created="Thu, 20 Feb 2014 07:21:31 +0000"  >&lt;p&gt;This is now tracked here &lt;a href=&quot;https://github.com/dlyubimov/mahout-commits/tree/dev-1.0-spark&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/dlyubimov/mahout-commits/tree/dev-1.0-spark&lt;/a&gt;&lt;br/&gt;
new module spark. &lt;/p&gt;

&lt;p&gt;I have been rewriting certain things anew. &lt;/p&gt;

&lt;p&gt;Concepts : &lt;br/&gt;
(a) Logical operators (including DRM sources) are expressed as DRMLike trait.&lt;br/&gt;
(b) taking a note from spark book, DRM operators (such as %*% or t) form operator lineage.  Operator lineage does not get optimized into RDD until &quot;action&quot; applied (spark terminology used). &lt;/p&gt;

&lt;p&gt;(c) Unlike in spark, &quot;action&quot; doesn&apos;t really cause any execution but (1) forming optimized RDD sequence (2) producing &quot;checkpointed&quot; DRM. Consequently, &quot;checkpointed&quot; DRM has RDD lineage attached to it, which is also marked for cacheing. Subsequently additional lineages starting out of a checkpointed DRM, will not be able to optimize beyond this checkpoint.&lt;/p&gt;

&lt;p&gt;(d) there&apos;s a &quot;super action&quot; on checkpointed RDD  - such as collection or persitence to HDFS that triggers, if necessary, optimization checkpoint and Spark action. &lt;/p&gt;

&lt;p&gt;E.g. &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val A = drmParallelize(...)

&lt;span class=&quot;code-comment&quot;&gt;// doesn&apos;t &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; anything, give opportunity &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt; lineage to grow further before being optimized
&lt;/span&gt;val squaredA = A.t %*% A

&lt;span class=&quot;code-comment&quot;&gt;// we may trigger optimizer and RDD lineage generation and cacheing explicitly by: 
&lt;/span&gt;squaredA.checkpoint()

&lt;span class=&quot;code-comment&quot;&gt;// Or, we can call &lt;span class=&quot;code-quote&quot;&gt;&quot;superAction&quot;&lt;/span&gt; directly. This will trigger checkpoint() implicitly &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; not yet done
&lt;/span&gt;val inCoreSquaredA = squaredA.collect()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Generally, i support for very few things &amp;#8211; I actually dropped all previously implemented Bagel algorithms. So in fact i have less support now than in 0.9 branch. &lt;/p&gt;

&lt;p&gt;i have kryo support for Mahout vectors and matrix blocks. &lt;br/&gt;
I have hdfs read/write of Mahout&apos;s DRM into DRMLike trait. &lt;/p&gt;

&lt;p&gt;I have some DSL defined such as &lt;br/&gt;
A %*% B &lt;br/&gt;
A %*% inCoreB&lt;br/&gt;
inCoreA %*%: B&lt;/p&gt;

&lt;p&gt;A.t&lt;br/&gt;
inCoreA = A.collect&lt;/p&gt;

&lt;p&gt;A.blockify (coalesces split records into RDD of vertical blocks &amp;#8211; sort of paradigm simiilar to MLI&apos;s MatrixSubmatrix except I implemented it before MLI was announced for the first time &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; so no MLI influence here in fact )&lt;/p&gt;

&lt;p&gt;So now i need to reimplement what Bagel used to be doing, plus optimizer rules for choosing distributed algorithm based on cost rules.&lt;/p&gt;

&lt;p&gt;In fact i came to conclusion there was 0 benefit in using Bagel in the first place, since it just maps all its primitives into shuffle-and-hash group-by RDD operations so there is no any actual operational benefit to using it.&lt;/p&gt;

&lt;p&gt;I probably will reconstitute algorithms at the first iteration using regular spark primitives (groupBy and cartesian for multiplication blocks)&lt;/p&gt;

&lt;p&gt;Once i plug missing pieces (e.g. slim matrix multiplication) I bet i would be able to fit distributed SSVD version in 40 lines just like the in-core one &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Weighted ALS will still be looking less elegant because of some lacking features in linear algebra. For example, it seems like sparse block support (i.e. bunch of sparse row or column vectors hanging off a very small hash map instead of full-size array as in SparseRow(column)Matrix today), but still mostly R-like scripted as far as working with matrix blocks and decompositions.&lt;/p&gt;

&lt;p&gt;So at this point i&apos;d be willing to hear input on these ideas and direction. Perhaps some suggestions. Thanks.&lt;/p&gt;</comment>
                            <comment id="13906710" author="dlyubimov" created="Thu, 20 Feb 2014 07:34:02 +0000"  >&lt;p&gt;a few obvious optimizer rules &lt;/p&gt;

&lt;p&gt;A.t %*% A is obviously detected as a family of unary algorithsm rather than a binary multiplication alborithm&lt;/p&gt;

&lt;p&gt;Geometry and non-zero element estimate plays role in selection of type of algorithm. &lt;/p&gt;

&lt;p&gt;Biggest multiplication via group-by will have to deal, obviously, with cartesian operator and will apply to (A * B&apos;)&lt;/p&gt;

&lt;p&gt;Obvious rewrites: &lt;br/&gt;
A&apos;*B&apos; = (B * A )&apos; (transposition push-up, including elementwise operators too)&lt;br/&gt;
(A&apos;)&apos; = A (transposition merge)&lt;br/&gt;
cost based grouping (A*B)&lt;b&gt;C versus A&lt;/b&gt;(B*C)&lt;br/&gt;
special distributed algorithm versions for in-core operands and diagonal matrices&lt;/p&gt;
</comment>
                            <comment id="13911665" author="dlyubimov" created="Tue, 25 Feb 2014 15:33:42 +0000"  >&lt;p&gt;WIP manual and working notes&lt;/p&gt;</comment>
                            <comment id="13919714" author="dlyubimov" created="Tue, 4 Mar 2014 18:06:19 +0000"  >&lt;p&gt;update&lt;/p&gt;</comment>
                            <comment id="13919887" author="ssc" created="Tue, 4 Mar 2014 20:30:14 +0000"  >&lt;p&gt;Really looking forward to this. Once we have a &quot;pipe&quot; to Spark, I&apos;ll probably donate some network analysis code.&lt;/p&gt;</comment>
                            <comment id="13920291" author="dlyubimov" created="Wed, 5 Mar 2014 00:33:17 +0000"  >&lt;p&gt;@Sebastian (and et al) could you please review if not the code then at least the API pdf (attached)? At this point i have all functional components to do distributed SSVD in dsl so it is really on the verge of commit, but i wouldn&apos;t want do that without no review at all (given how relatively big and conceptual this thing is).&lt;/p&gt;</comment>
                            <comment id="13920319" author="ssc" created="Wed, 5 Mar 2014 01:00:59 +0000"  >&lt;p&gt;Dmitriy, I read through your write-up and I have no words. I really love what you created and I&apos;m looking forward to having this as part of Mahout. Would like to see our algorithms rewritten in your linear algebra dsl and executed (and optimized!) on Spark.&lt;/p&gt;

&lt;p&gt;Btw, be sure to also post your writeup to the spark mailinglist, I&apos;m sure the guys there are also interested!&lt;/p&gt;</comment>
                            <comment id="13923384" author="dlyubimov" created="Fri, 7 Mar 2014 01:34:57 +0000"  >&lt;p&gt;Ok this is finally done. SSVD is working, notes updated. I will commit it later tonight after additional review for misc stuff.&lt;/p&gt;

&lt;p&gt;Please look at the final pdf api ,  and source if needed. &lt;/p&gt;

&lt;p&gt;This will also contain fix for CholeskyDecomosition bug that always reports degenerate matrix.&lt;/p&gt;</comment>
                            <comment id="13923389" author="dlyubimov" created="Fri, 7 Mar 2014 01:38:38 +0000"  >&lt;p&gt;Most of this code is not distributed-tested. Unit tests do due diligence and ensure matrices are produced with more than a trivially single partition, and i also verified some stuff on a live single node spark but i haven&apos;t tried any significant datasets in a reall life cluster. &lt;/p&gt;

&lt;p&gt;Assumption is that we will have to continue working stuff out and gauge bottlenecks of concrete implementations. It is possible additional tuning parameters will be required, esp. for stuff that does blocking etc. &lt;/p&gt;

&lt;p&gt;So it should be marked as &quot;evolving&quot; . &lt;/p&gt;</comment>
                            <comment id="13923585" author="hudson" created="Fri, 7 Mar 2014 05:40:16 +0000"  >&lt;p&gt;SUCCESS: Integrated in Mahout-Quality #2506 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2506/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2506/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1346&quot; title=&quot;Spark Bindings (DRM)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1346&quot;&gt;&lt;del&gt;MAHOUT-1346&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Squashed commit of the following:&lt;/p&gt;

&lt;p&gt;(...too long to list... ) (dlyubimov: rev 1575169)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/bin/mahout&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/pom.xml&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/main/scala/org/apache/mahout/math/scalabindings/MatrixOps.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/main/scala/org/apache/mahout/math/scalabindings/RLikeMatrixOps.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/main/scala/org/apache/mahout/math/scalabindings/SSVD.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/main/scala/org/apache/mahout/math/scalabindings/package.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/test/scala/org/apache/mahout/math/scalabindings/MathSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math/src/main/java/org/apache/mahout/math/CholeskyDecomposition.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/pom.xml&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/pom.xml&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/blas&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/blas/ABt.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/blas/AewB.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/blas/AinCoreB.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/blas/At.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/blas/AtA.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/blas/AtB.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/blas/DrmRddOps.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/blas/Slicing.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/blas/package.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CheckpointedDrm.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CheckpointedDrmBase.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CheckpointedOps.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/DrmLike.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/DrmLikeOps.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/DrmRddInput.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/RLikeDrmOps.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/decompositions&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/decompositions/DQR.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/decompositions/DSSVD.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/package.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/AbstractBinaryOp.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/AbstractUnaryOp.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/CheckpointAction.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAB.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpABAnyKey.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpABt.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAewB.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAewScalar.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAt.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAtA.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAtAnyKey.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAtB.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpMapBlock.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpRowRange.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpTimesLeftMatrix.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpTimesRightMatrix.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/package.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/io&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/io/MahoutKryoRegistrator.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/io/WritableKryoSerializer.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/package.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/blas&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/blas/ABtSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/blas/AewBSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/blas/AtASuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/blas/AtSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/drm&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/drm/DrmLikeOpsSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/drm/DrmLikeSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/drm/RLikeDrmOpsSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/drm/decompositions&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/drm/decompositions/MathSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/test&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/test/LoggerConfiguration.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/test/MahoutLocalContext.scala&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13938408" author="dlyubimov" created="Mon, 17 Mar 2014 21:26:16 +0000"  >&lt;p&gt;updating docs to reflect latest committed state. &lt;br/&gt;
Brought in distributed and in-core stochastic PCA scripts, colmeans, colsums, drm-vector multiplication, more tests etc.etc. see the doc.&lt;/p&gt;</comment>
                            <comment id="13938552" author="hudson" created="Mon, 17 Mar 2014 23:36:03 +0000"  >&lt;p&gt;SUCCESS: Integrated in Mahout-Quality #2526 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2526/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2526/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1346&quot; title=&quot;Spark Bindings (DRM)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1346&quot;&gt;&lt;del&gt;MAHOUT-1346&lt;/del&gt;&lt;/a&gt;: (D)-SPCA and other additions and fixes.&lt;/p&gt;

&lt;p&gt;Squashed commit of the following:&lt;/p&gt;

&lt;p&gt;commit 1ed6267a3cc550d1d648346fca7e152c63909667&lt;br/&gt;
Merge: 95da094 c0260b5&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   Mon Mar 17 11:38:33 2014 -0700&lt;/p&gt;

&lt;p&gt;    Merge branch &apos;trunk&apos; into dev-1.0-spark&lt;/p&gt;

&lt;p&gt;commit 95da094a38d7fbbd654e95bbfb5723c5e1e48c55&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   Mon Mar 17 11:24:28 2014 -0700&lt;/p&gt;

&lt;p&gt;    D-SPCA fixes. test is passing (in-core and out-of-core tests give the same result). However, the test seems to be still rank-deficient (rank=20 instead of desired 100). Not sure why &amp;#8211; the Cholesky seems to be too sensitive.&lt;/p&gt;

&lt;p&gt;commit c907be0f9b35436cf623e1a92941f924382b531d&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   Mon Mar 17 00:10:05 2014 -0700&lt;/p&gt;

&lt;p&gt;    Fixes for D-SPCA: q=0 works, q&amp;gt;0 still doesn&apos;t&lt;/p&gt;

&lt;p&gt;commit 0e24fe88cbbae2db57c06b4d85f5df1b5a2925e5&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   Sun Mar 16 18:16:27 2014 -0700&lt;/p&gt;

&lt;p&gt;    added test for colSums, colMeans&lt;/p&gt;

&lt;p&gt;commit 1012d65ba360cfe944f2f559cf032c7546e19072&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   Sun Mar 16 18:08:25 2014 -0700&lt;/p&gt;

&lt;p&gt;    D-SPCA WIP. Test is not yet working with -q0&lt;/p&gt;

&lt;p&gt;commit 5560f1e928380280b23dbd35efec39b8566eb1a3&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   Sun Mar 9 18:12:03 2014 -0700&lt;/p&gt;

&lt;p&gt;    Fixng random gen in SPCA test codegen&lt;/p&gt;

&lt;p&gt;commit 740cac1eec6a4e1bf256066d86b7b5681f88bd4c&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   Sun Mar 9 18:08:30 2014 -0700&lt;/p&gt;

&lt;p&gt;    removing check for rank deficiency (so pca can complete). User can check the results for that if needed.&lt;br/&gt;
    Adding in-core s-pca test.&lt;/p&gt;

&lt;p&gt;commit f1abfe430987b60a62a0e65cf234ebdc40135275&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   Sun Mar 9 16:19:32 2014 -0700&lt;/p&gt;

&lt;p&gt;    perhaps a better ssvd test assertion&lt;/p&gt;

&lt;p&gt;commit e26596fd6cecb74055c38d838a8b02e9698b17f8&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   Sat Mar 8 22:01:58 2014 -0800&lt;/p&gt;

&lt;p&gt;    first write-up of in-core stochastic PCA&lt;/p&gt;

&lt;p&gt;commit eb3bf98d6abcd8f480e892c74bd7f61b32b33bdf&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   Sat Mar 8 20:35:24 2014 -0800&lt;/p&gt;

&lt;p&gt;    rowsums, colsums, rowmeans, colmeans for in-core + tests (dlyubimov: rev 1578527)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/math-scala/pom.xml&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/main/scala/org/apache/mahout/math/scalabindings/MatrixOps.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/main/scala/org/apache/mahout/math/scalabindings/SSVD.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/main/scala/org/apache/mahout/math/scalabindings/VectorOps.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/main/scala/org/apache/mahout/math/scalabindings/package.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/test/scala/org/apache/mahout/math/scalabindings/MathSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/test/scala/org/apache/mahout/math/scalabindings/MatlabLikeMatrixOpsSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/test/scala/org/apache/mahout/math/scalabindings/MatrixOpsSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/test/scala/org/apache/mahout/math/scalabindings/RLikeMatrixOpsSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/test/scala/org/apache/mahout/math/scalabindings/RLikeVectorOpsSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/test/scala/org/apache/mahout/math/scalabindings/VectorOpsSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/test/scala/org/apache/mahout/test&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/test/scala/org/apache/mahout/test/LoggerConfiguration.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/test/scala/org/apache/mahout/test/MahoutSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/pom.xml&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/blas/AinCoreB.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/blas/AtB.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/blas/Ax.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CheckpointedDrm.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CheckpointedDrmBase.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CheckpointedOps.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/DrmLike.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/RLikeDrmOps.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/decompositions/DQR.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/decompositions/DSPCA.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/decompositions/DSSVD.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/package.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/CheckpointAction.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAewB.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAewScalar.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAt.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAtAnyKey.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAtx.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAx.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpMapBlock.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpRowRange.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/drm/DrmLikeOpsSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/drm/RLikeDrmOpsSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/drm/decompositions/MathSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/test/LoggerConfiguration.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/test/MahoutLocalContext.scala&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13938735" author="hudson" created="Tue, 18 Mar 2014 03:17:51 +0000"  >&lt;p&gt;SUCCESS: Integrated in Mahout-Quality #2527 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2527/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2527/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1346&quot; title=&quot;Spark Bindings (DRM)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1346&quot;&gt;&lt;del&gt;MAHOUT-1346&lt;/del&gt;&lt;/a&gt;: better PCA test &amp;amp; input generator (dlyubimov: rev 1578663)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/test/scala/org/apache/mahout/math/scalabindings/MathSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/drm/decompositions/MathSuite.scala&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13941354" author="dlyubimov" created="Thu, 20 Mar 2014 03:26:37 +0000"  >&lt;p&gt;Actually, non-slim A&apos;A operator is practically A&apos;B without need for a zip... So we are almost done, the biggest work here is the test I suppose.&lt;/p&gt;</comment>
                            <comment id="13945875" author="hudson" created="Mon, 24 Mar 2014 23:41:33 +0000"  >&lt;p&gt;SUCCESS: Integrated in Mahout-Quality #2538 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2538/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2538/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1346&quot; title=&quot;Spark Bindings (DRM)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1346&quot;&gt;&lt;del&gt;MAHOUT-1346&lt;/del&gt;&lt;/a&gt; a bit more syntactically pallatable correction encoding for BB&apos; (dlyubimov: rev 1581012)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/main/scala/org/apache/mahout/math/scalabindings/SSVD.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/decompositions/DSPCA.scala&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13948515" author="hudson" created="Wed, 26 Mar 2014 21:37:33 +0000"  >&lt;p&gt;SUCCESS: Integrated in Mahout-Quality #2539 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2539/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2539/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1346&quot; title=&quot;Spark Bindings (DRM)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1346&quot;&gt;&lt;del&gt;MAHOUT-1346&lt;/del&gt;&lt;/a&gt; style: removing my weird log variable convention, Mahout doesn&apos;t use that (dlyubimov: rev 1582021)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/math-scala/src/main/scala/org/apache/mahout/math/scalabindings/SSVD.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/blas/AtA.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/blas/AtB.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/decompositions/DQR.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/package.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/package.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/drm/RLikeDrmOpsSuite.scala&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1346&quot; title=&quot;Spark Bindings (DRM)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1346&quot;&gt;&lt;del&gt;MAHOUT-1346&lt;/del&gt;&lt;/a&gt;: don&apos;t evaluate debug printout in no-debug mode (dlyubimov: rev 1582020)&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/decompositions/DQR.scala&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13956837" author="dlyubimov" created="Tue, 1 Apr 2014 19:13:10 +0100"  >&lt;p&gt;Added component stack diagram.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12660476">MAHOUT-1297</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12681170">MAHOUT-1365</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12638098" name="BindingsStack.jpg" size="73681" author="dlyubimov" created="Tue, 1 Apr 2014 19:13:10 +0100"/>
                            <attachment id="12635169" name="ScalaSparkBindings.pdf" size="582191" author="dlyubimov" created="Mon, 17 Mar 2014 21:26:16 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 7 Oct 2013 21:07:39 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>352316</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hzil67:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>352604</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>