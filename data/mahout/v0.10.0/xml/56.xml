<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:26:05 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-56/MAHOUT-56.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-56] Watchmaker Integration</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-56</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;p&gt;The goal of this task is to allow watchmaker definded problems be solved in Mahout.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12396296">MAHOUT-56</key>
            <summary>Watchmaker Integration</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/task.png">Task</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gsingers">Grant Ingersoll</assignee>
                                    <reporter username="adeneche">Deneche A. Hakim</reporter>
                        <labels>
                    </labels>
                <created>Mon, 19 May 2008 06:41:40 +0100</created>
                <updated>Sat, 21 May 2011 04:24:03 +0100</updated>
                            <resolved>Tue, 26 Aug 2008 13:57:45 +0100</resolved>
                                                    <fixVersion>0.1</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12597873" author="adeneche" created="Mon, 19 May 2008 06:42:56 +0100"  >&lt;p&gt;I started with the Traveling Salesman Problem (TSP) because the reference implementation already exists within Watchmaker.&lt;/p&gt;

&lt;p&gt;You&apos;ll need to add the following jars to the Mahout/core/lib/ :&lt;/p&gt;

&lt;p&gt;watchmaker-framework-0.4.3.jar&lt;br/&gt;
watchmaker-examples-0.4.3.jar (contains reference implementation of the TSP)&lt;br/&gt;
uncommons-maths-1.0.2.jar&lt;br/&gt;
uncommons-utils.jar&lt;/p&gt;

&lt;p&gt;they are all available with watchmaker0.4.3 &lt;a href=&quot;https://watchmaker.dev.java.net/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://watchmaker.dev.java.net/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I also included some unit tests that should pass without problem.&lt;/p&gt;

&lt;p&gt;The code contains the following 4 classes:&lt;br/&gt;
. RouteEvalMapper : a Hadoop mapper that evaluate the fitness of one candidate solution (GA individual)&lt;br/&gt;
. MahoutRouteEvaluator : takes a GA population in input and launch a Hadoop job to evaluate the fitness of each individual, &lt;br/&gt;
  returns back the results. Takes care of storing the population into an input file, and loading the fitnesses from job outputs&lt;br/&gt;
. MahoutTspEvolutionEngine : Distributed implementation of the evolution engine that uses MahoutRouteEvaluator for the evaluations&lt;br/&gt;
. PopulationUtils : Utility class to store the population into a given FileSystem&lt;/p&gt;

&lt;p&gt;This is the easiest possible implementation, the next steps are :&lt;br/&gt;
. Use serialization to store/load any king of individuals and not only List&amp;lt;String&amp;gt;&lt;br/&gt;
. Use serialization to pass any possible FitnessEvaluator, thus we can use MahoutEvolutionEngine for other problems&lt;br/&gt;
. and as suggested by Ted: use meta-mutation (But I think it will be in a separate Task)&lt;/p&gt;</comment>
                            <comment id="12597998" author="tdunning@veoh.com" created="Mon, 19 May 2008 17:54:04 +0100"  >
&lt;p&gt;What is the license on watchmaker?&lt;/p&gt;

&lt;p&gt;What about the other jars (uncommon-maths and uncommon-utils)?&lt;/p&gt;</comment>
                            <comment id="12598765" author="adeneche" created="Wed, 21 May 2008 20:39:35 +0100"  >&lt;p&gt;&lt;b&gt;Description of the changes&lt;/b&gt;&lt;br/&gt;
I made the code problem independent, and so I changed the class names to remove any reference to TSP.&lt;br/&gt;
The classes are :&lt;br/&gt;
. StringUtils: inspired from the future Stringifier of Hadoop. Translates any given object (even not a Serializable one) &lt;br/&gt;
to a one-line xml representation, and vice versa.&lt;br/&gt;
. MahoutEvolutionEngine: generic distributed Genetic algorithms. Now the constructor takes a FitnessEvaluator&lt;br/&gt;
  that takes care of evaluating every candidate.&lt;br/&gt;
. MahoutEvaluator: evaluate a population of individuals using a given FitnessEvaluator. Uses StringUtils to store &lt;br/&gt;
the population into an input file, and the FitnessEvaluator into the JobConf.&lt;br/&gt;
. EvalMapper: Mapper that evaluate a candidate using the FitnessEvaluator passed into the JobConf.&lt;/p&gt;

&lt;p&gt;Note that we no more need watchmaker-examples to build the code, but we still need it in the tests to &lt;br/&gt;
compare this code with the reference implementation.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Needed libraries&lt;/b&gt;&lt;br/&gt;
you&apos;ll need the xstream library &lt;a href=&quot;http://xstream.codehaus.org/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://xstream.codehaus.org/&lt;/a&gt;, I used the 1.2.1 version. Add the following jars to core/lib&lt;/p&gt;

&lt;p&gt;xpp3_min-*.jar&lt;br/&gt;
xstream-*.jar&lt;/p&gt;

&lt;p&gt;I also included the licenses for all the libraries that I added. And if we plan to use xpp3_min-*.jar we need &lt;br/&gt;
to include the following lines somewhere in the Mahout documentation or in the software:&lt;/p&gt;

&lt;p&gt;  &quot;This product includes software developed by the Indiana University&lt;br/&gt;
  Extreme! Lab (&lt;a href=&quot;http://www.extreme.indiana.edu/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.extreme.indiana.edu/&lt;/a&gt;).&quot;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Next steps&lt;/b&gt;&lt;br/&gt;
There is another example with wathmaker that I want to test with this new code, just to confirm that &lt;br/&gt;
the integration is fine. Then we can talk in the mailing list about the next move, wich could be one of the following :&lt;br/&gt;
. meta-mutations&lt;br/&gt;
. for now Im assuming that each node contains the whole dataset needed to evaluate a candidate. But if the dataset is large enough &lt;br/&gt;
to span on multiple nodes, the user should have the possibility of writing the evaluation funtion in terms of mappers and reducers&lt;br/&gt;
. ...any suggestion ?&lt;/p&gt;</comment>
                            <comment id="12599398" author="gsingers" created="Fri, 23 May 2008 16:16:23 +0100"  >&lt;blockquote&gt;
&lt;p&gt; &quot;This product includes software developed by the Indiana University&lt;br/&gt;
Extreme! Lab (&lt;a href=&quot;http://www.extreme.indiana.edu/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.extreme.indiana.edu/&lt;/a&gt;).&quot;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This typically goes in NOTICE.txt in the root directory.   Feel free to add it, we will clean it up before release.&lt;/p&gt;

&lt;p&gt;I hope to look at the rest of this soon, but others should too.&lt;/p&gt;</comment>
                            <comment id="12599711" author="adeneche" created="Sun, 25 May 2008 20:32:32 +0100"  >&lt;p&gt;I modified the NOTICE.TXT file to conform to xpp3 license.&lt;/p&gt;

&lt;p&gt;also added more tests using another Watchmaker example (Sudoku solver) along with TSP. We don&apos;t probably need them both, but more tests are always welcome.&lt;/p&gt;

&lt;p&gt;I should post soon into the dev-list to talk about the next possible steps...&lt;/p&gt;</comment>
                            <comment id="12606994" author="adeneche" created="Sat, 21 Jun 2008 11:05:47 +0100"  >&lt;p&gt;&lt;b&gt;what&apos;s new&lt;/b&gt;&lt;br/&gt;
. class discovery: based on the following paper &lt;a href=&quot;http://www.cs.bham.ac.uk/~wbl/biblio/gecco1999/GP-417.pdf&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Discovering Comprehensible Classification Rules using Genetic Programming&lt;/a&gt;, a genetic algorithm that searches for the best binary classification rule for a given dataset. The population, which is a list of possible rules, is passed to each mapper that handles a subset of the dataset. All the new stuff is in the package:&lt;/p&gt;

&lt;p&gt;org.apache.mahout.gsoc.watchmaker.classdiscovery&lt;/p&gt;

&lt;p&gt;. I refactored some classes from the previous patch to reuse the existing code. The main change is the class STEvolutionEngine&amp;lt;T&amp;gt; that uses a single thread and the corresponding STFitnessEvaluator&amp;lt;T&amp;gt;. More details will be added to the comments&lt;/p&gt;

&lt;p&gt;. I added easymock library needed to run the tests&lt;/p&gt;

&lt;p&gt;&lt;b&gt;What&apos;s need to be done&lt;/b&gt;&lt;br/&gt;
The following steps need to be done before considering this patch to be complete:&lt;br/&gt;
. classdiscovery.ga.CDGA (the main tool) need to become a full functional command-line tool&lt;br/&gt;
. for now CDGA uses the whole dataset for training, it should split it in a training set and a testing set&lt;br/&gt;
. because classdiscovery is not generic (at least for now), I should move it to the examples along with its corresponding tests&lt;br/&gt;
. arrange the comments&lt;br/&gt;
. there is no need to test the code againt TSP and Soduko, I should remove the Soduko test to make the tests more comprehensible&lt;br/&gt;
. pass the population using the DestributedCache instead of job parameter&lt;/p&gt;</comment>
                            <comment id="12607096" author="adeneche" created="Sun, 22 Jun 2008 15:18:38 +0100"  >&lt;p&gt;classdiscovery.ga.CDGA (the main tool) now accepts command-line parameters&lt;/p&gt;</comment>
                            <comment id="12607832" author="gsingers" created="Wed, 25 Jun 2008 02:28:54 +0100"  >&lt;p&gt;Hi Deneche,&lt;/p&gt;

&lt;p&gt;Seems the latest patch doesn&apos;t apply all that well.  Seems I&apos;m getting double entries of each class in the same file.&lt;/p&gt;

&lt;p&gt;From the top directory, do:&lt;br/&gt;
svn status&lt;br/&gt;
svn diff &amp;gt; watchmaker-tsp.patch&lt;/p&gt;

&lt;p&gt;Also, no need for the &quot;gsoc&quot; package.  This is full-fledged goodness, no need to qualify.  I&apos;d suggest something like org.apache.mahout.genetic.watchmaker or org.apache.mahout.ga.watchmaker would be good.&lt;/p&gt;

&lt;p&gt;Also, if you can zip up the required libraries and attach them, that would save a few trips to track them down.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Grant&lt;/p&gt;</comment>
                            <comment id="12607956" author="adeneche" created="Wed, 25 Jun 2008 11:54:38 +0100"  >&lt;blockquote&gt;&lt;p&gt;Seems the latest patch doesn&apos;t apply all that well. Seems I&apos;m getting double entries of each class in the same file.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah for me too !!! I seems I am using a rather old version of TortoiseSVN, I updated now and should provide a working patch soon&lt;/p&gt;</comment>
                            <comment id="12607977" author="adeneche" created="Wed, 25 Jun 2008 12:14:22 +0100"  >&lt;p&gt;this zip file contains the additional librairies&lt;/p&gt;</comment>
                            <comment id="12608120" author="adeneche" created="Wed, 25 Jun 2008 18:18:57 +0100"  >&lt;p&gt;This patch should work (I tried it)&lt;/p&gt;

&lt;p&gt;Also contains DatasetTextOutputFormat, this is a TextOutputFormat that allows the input to be split into tow disjoint subsets (training and testing)&lt;/p&gt;

&lt;p&gt;the main algo CDGA contains a bug somewhere, cause the results are weird...guess I know what I have to do for the next days (apart from hitting the keyboard with my head)&lt;/p&gt;</comment>
                            <comment id="12609016" author="adeneche" created="Sat, 28 Jun 2008 16:15:30 +0100"  >&lt;p&gt;ouf ! I found the bug, it was hidden in CDFitness, and caused the GA to return weird solutions&lt;/p&gt;</comment>
                            <comment id="12610144" author="adeneche" created="Thu, 3 Jul 2008 07:25:01 +0100"  >&lt;p&gt;I moved the class discovery code (org.apache.mahout.ga.watchmaker.ca) to the examples directory, until I figure out how to make it more generic &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/tongue.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I made some changes to the build.xml :&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;b&gt;ant compile-examples&lt;/b&gt; will now compile all the code int src/main/examples, not that you&apos;ll need the ejb.jar library in order to compile the cf.taste.ejb example&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;ant examples-test&lt;/b&gt; will lunch all the tests in the src/test/examples directory. It will allow us to add unit tests for the examples&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;you can run the CDGA algorithm, after generating the examples-job, by using the following command&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&amp;lt;hadoop-0.17.0_HOME&amp;gt;/bin/hadoop jar &amp;lt;mahout_HOME&amp;gt;/core/build/apache-mahout-0.1-dev-ex.jar org.apache.mahout.ga.watchmaker.cd.CDGA &amp;lt;mahout_HOME&amp;gt;/core/src/main/resources/wdbc/ 0.9 1 0.033 0.1 0 100 10
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I will explain later what all those parameters mean...&lt;/p&gt;</comment>
                            <comment id="12610705" author="adeneche" created="Sat, 5 Jul 2008 17:43:41 +0100"  >&lt;p&gt;Added comments to the new classes. The CDGA comment describes the meaning of the parameters for the program.&lt;/p&gt;</comment>
                            <comment id="12610740" author="adeneche" created="Sun, 6 Jul 2008 12:09:36 +0100"  >&lt;p&gt;&lt;b&gt;changes&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;simplified tests using dummy classes instead of using tsp and soduko&lt;/li&gt;
	&lt;li&gt;added a complete watchmaker example related to TSP, this example comes with watchmaker, I made some modifications to allow the user to choose how the result will be calculated (standalone or distributed)&lt;/li&gt;
	&lt;li&gt;no more need for watchmaker-examples-0.4.3.jar, the examples now need the folliwing library : watchmaker-swing-0.4.3.jar (the new libs.jar contains the required libraries and their licence files)&lt;/li&gt;
	&lt;li&gt;you can run the CDGA algorithm, after generating the examples-job, by using the following command&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; 
&amp;lt;hadoop-0.17.0_HOME&amp;gt;/bin/hadoop jar &amp;lt;mahout_HOME&amp;gt;/core/build/apache-mahout-0.1-dev-ex.jar org.apache.mahout.ga.watchmaker.travellingsalesman.TravellingSalesman
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;make sure to check the &quot;distributed&quot; option to solve the problem using mahout.ga&lt;/p&gt;</comment>
                            <comment id="12610741" author="adeneche" created="Sun, 6 Jul 2008 12:11:07 +0100"  >&lt;p&gt;updated dependencies&lt;/p&gt;</comment>
                            <comment id="12610742" author="adeneche" created="Sun, 6 Jul 2008 12:13:23 +0100"  >&lt;p&gt;updated &quot;zipped&quot; dependencies&lt;/p&gt;</comment>
                            <comment id="12610743" author="adeneche" created="Sun, 6 Jul 2008 12:17:25 +0100"  >&lt;p&gt;TravellingSalesman example GUI&lt;/p&gt;</comment>
                            <comment id="12613040" author="gsingers" created="Sat, 12 Jul 2008 03:55:35 +0100"  >&lt;p&gt;Added ASL where needed.&lt;/p&gt;

&lt;p&gt;Moved StringUtils to utils package.&lt;/p&gt;

&lt;p&gt;Deneche, I think you need to clean up the examples that refer to Daniel Dyer.  I&apos;m assuming this is a watchmaker example that you modified.  I believe the way to handle this is to mark it as ASL and somehow link to where you got the code from.  It is already ASL to begin with, but the copyright is Daniel Dyer.  You probably should also put a reference in NOTICES.txt that some of the code was developed by Daniel.&lt;/p&gt;

&lt;p&gt;Otherwise, looks pretty good.  I&apos;m no GA expert, but I like the TSP GUI!  &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;   Would be interested in seeing some performance numbers as you distribute this out over multiple nodes, but that is not a requirement for committing.&lt;/p&gt;
</comment>
                            <comment id="12613072" author="adeneche" created="Sat, 12 Jul 2008 12:07:44 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Deneche, I think you need to clean up the examples that refer to Daniel Dyer. I&apos;m assuming this is a watchmaker example that you modified. I believe the way to handle this is to mark it as ASL and somehow link to where you got the code from. It is already ASL to begin with, but the copyright is Daniel Dyer. You probably should also put a reference in NOTICES.txt that some of the code was developed by Daniel.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ok, should be evailable in the next patch&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Otherwise, looks pretty good. I&apos;m no GA expert, but I like the TSP GUI! Would be interested in seeing some performance numbers as you distribute this out over multiple nodes, but that is not a requirement for committing.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is a very good idea, but it needs a larger TSP problem (should be able to find one), and a cluster. I&apos;ll definitely try it.&lt;/p&gt;</comment>
                            <comment id="12613907" author="adeneche" created="Wed, 16 Jul 2008 12:09:22 +0100"  >&lt;p&gt;&lt;b&gt;What&apos;s new&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Fixed some bugs that were well hidden in &lt;b&gt;DummyOutputCollector&lt;/b&gt;  and &lt;b&gt;CDMutation&lt;/b&gt;(why the bugs are always hidden !!!), the later unit test has been improved to catch the bug if it manages to come again&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;The ClassDiscovery example should be able to handle Categorical attributes now, but I still need to add a tool that generate Dataset information from any given dataset.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;The &lt;b&gt;Travelling Salesman&lt;/b&gt; comments have been cleared, and a reference to Watchmaker project has been added to the comments inplace of the @author tag. I also added a readme.txt that describes where to look for the changes in the original code.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;b&gt;what&apos;s next&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;A generic map-reduce program to generate dataset informations from the dataset itself.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;multi-class classification&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12613908" author="adeneche" created="Wed, 16 Jul 2008 12:11:16 +0100"  >&lt;p&gt;Updated dependencies.&lt;/p&gt;</comment>
                            <comment id="12616088" author="adeneche" created="Wed, 23 Jul 2008 16:02:23 +0100"  >&lt;p&gt;&lt;b&gt;What&apos;s new&lt;/b&gt;&lt;br/&gt;
CDGA should be able to cope with any given dataset (of course with a certain file format). It uses a special format file that contains enough informations about the dataset. This file (called info file) has the following format:&lt;br/&gt;
for each attribute a corresponding line in the info file describes it, it can be one of the following:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;IGNORED&lt;br/&gt;
  if the attribute is ignored&lt;/li&gt;
	&lt;li&gt;LABEL val1, val2,...&lt;br/&gt;
  if the attribute is the label (class), and its possible values&lt;/li&gt;
	&lt;li&gt;NOMINAL val1, val2,...&lt;br/&gt;
  if the attribute is nominal (categorial), and its possible values&lt;/li&gt;
	&lt;li&gt;NUMERICAL min, max&lt;br/&gt;
  if the attribute is numerical, and its min and max values&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;For now I generated the info file manually for the WDBC dataset. The info file should be in the same parent directory of the input, with the same name as the input directory followed by &quot;.info&quot;. For ex. for a dataset&lt;/p&gt;

&lt;p&gt;build/examples/wdbc/&lt;/p&gt;

&lt;p&gt;the info file should be&lt;/p&gt;

&lt;p&gt;build/examples/wdbc.infos&lt;/p&gt;

&lt;p&gt;&lt;b&gt;What&apos;s next&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Map-Reduce program to automaticly generate the info file from any given dataset.&lt;/li&gt;
	&lt;li&gt;Run CDGA with other datasets&lt;/li&gt;
	&lt;li&gt;Multi-class classification&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12616162" author="apurtell" created="Wed, 23 Jul 2008 18:02:56 +0100"  >&lt;p&gt;Was Weka&apos;s ARFF insufficient? Please see &lt;a href=&quot;http://weka.sourceforge.net/wekadoc/index.php/en:ARFF_(3.5.1&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://weka.sourceforge.net/wekadoc/index.php/en:ARFF_(3.5.1&lt;/a&gt;) . Just a suggestion from a potential Mahout user, but ARFF is a de-facto standard in some ML circles, and being able to move from Weka or Rapidminer to Mahout and back, depending on the scale, would be highly advantageous. &lt;/p&gt;</comment>
                            <comment id="12616213" author="tdunning@veoh.com" created="Wed, 23 Jul 2008 19:36:07 +0100"  >&lt;p&gt;&lt;br/&gt;
R handles arff as well.&lt;/p&gt;</comment>
                            <comment id="12616361" author="adeneche" created="Thu, 24 Jul 2008 08:25:50 +0100"  >&lt;p&gt;In fact the info file is inspired from ARFF. The main differences are :&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;I need to be able to ignore some attributes (for example : ID)&lt;/li&gt;
	&lt;li&gt;I need to store the min and max values for the numerical attributes.&lt;/li&gt;
	&lt;li&gt;If the dataset is not in the ARFF format, I just need to generate its info file, I think its much more efficient than converting it to the ARFF format (I am talking here about very large datasets)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;And you&apos;re right about the Weka and Rapidminer compatibility, so I&apos;ll add to my &lt;b&gt;todo&lt;/b&gt; list : support the ARFF dataset format.&lt;/p&gt;</comment>
                            <comment id="12616508" author="tdunning" created="Thu, 24 Jul 2008 16:53:21 +0100"  >
&lt;p&gt;Actually, I think what we need are three things:&lt;/p&gt;

&lt;p&gt;a) your program that should work from in-memory data sets (probably labeled matrices of some kind).&lt;/p&gt;

&lt;p&gt;b) we need a matrix reader of the kind you propose&lt;/p&gt;

&lt;p&gt;c) we need an arff matrix reader.&lt;/p&gt;

&lt;p&gt;I think that there is a jira around that could cover b &amp;amp; c.&lt;/p&gt;</comment>
                            <comment id="12616527" author="adeneche" created="Thu, 24 Jul 2008 17:41:59 +0100"  >&lt;p&gt;The whole point of the CDGA example is to show how to use Mahout to run a Genetic Algorithm on a very large dataset, cause this is what Map-Reduce is about : large and distributed data.&lt;/p&gt;

&lt;p&gt;Now, it wont harm my program to be able to work with in-memory datasets, and I&apos;ll be more than happy to implement (a) as soon as there is a &quot;stable&quot; solution for (b) and (c).&lt;/p&gt;

&lt;p&gt;I have one question about in-memory datasets : how to pass them to the mappers ? we can&apos;t use the job input if the dataset is in-memory ? so I assume it is passed as a job parameter, is it ?&lt;/p&gt;</comment>
                            <comment id="12616531" author="tdunning" created="Thu, 24 Jul 2008 17:51:59 +0100"  >
&lt;p&gt;I spoke poorly.  &lt;/p&gt;

&lt;p&gt;In-memory is a misnomer.&lt;/p&gt;


&lt;p&gt;It should be possible to have a large arff dataset in HDFS to be used as input as well as a large dataset in your format.&lt;/p&gt;

&lt;p&gt;However you decide to read your data in, it should be usable by others.  Likewise, by symmetrically, with the arff input.  &lt;/p&gt;

&lt;p&gt;How that works should depend a little on your data.  My feeling is that we will need something like a &quot;row-wise splitting matrix input format&quot; that sends groups of rows of a matrix to different mappers.  This input format should accept a configuration argument which is the class to be used to actually decode the format.&lt;/p&gt;

&lt;p&gt;It will probably happen that not all algorithms will be quite so happy with this, especially the groups of rows part.  They may want all mappers to see the entire data set (if the data set is, say, a set of population members rather than real data).  They may want the mappers to have some row-wise map input, but have some side data that is read without using an input format.&lt;/p&gt;

&lt;p&gt;You are really one of the first to define a real user story for this so you should feel free to define what you need in the context of what you think others might be able to use as well. &lt;/p&gt;</comment>
                            <comment id="12616573" author="adeneche" created="Thu, 24 Jul 2008 19:39:34 +0100"  >&lt;p&gt;After meny attemps to load all the informations that you gave me in my brain-processing-cluster-that-doesnt-work-quit-well, let&apos;s see if I understand it correctly:&lt;/p&gt;

&lt;p&gt;The algortihm handles any dataset in a matrix format, where (in my case) the collumns are the attributes (and one of them is the Label) and the rows are the datas.&lt;/p&gt;

&lt;p&gt;Working with Hadoop, we&apos;ll need to pass the dataset in the mapper&apos;s input, so it must be a file (or many files). We&apos;ll then need a custom InputFormat to feed the mappers with the data, and here comes the lovely-named &quot;row-wise splitting matrix input format&quot;.&lt;/p&gt;

&lt;p&gt;Now we want to be able to work with any given dataset file format (including the ARFF and my custom format), and thus the InputFormat needs a decoder that converts the dataset lines into matrix rows.&lt;/p&gt;</comment>
                            <comment id="12616730" author="tdunning@veoh.com" created="Fri, 25 Jul 2008 02:10:37 +0100"  >&lt;p&gt;&lt;br/&gt;
Yes.&lt;/p&gt;</comment>
                            <comment id="12618640" author="gsingers" created="Thu, 31 Jul 2008 11:45:01 +0100"  >&lt;p&gt;Committed revision 681327.&lt;/p&gt;

&lt;p&gt;Let&apos;s open up bugs/issues off of this, or add to this one if needed.  I think the ARFF support should be done separately. Deneche, do you want to add an issue for that?&lt;/p&gt;</comment>
                            <comment id="12618958" author="adeneche" created="Fri, 1 Aug 2008 09:28:05 +0100"  >&lt;blockquote&gt;&lt;p&gt;Committed revision 681327.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Cool, now the patches should be easier to create &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/tongue.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;Let&apos;s open up bugs/issues off of this, or add to this one if needed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It&apos;ll be easier for me if the bug/issues are added here. I should my self add some known open issues soon.&lt;/p&gt;</comment>
                            <comment id="12619471" author="adeneche" created="Mon, 4 Aug 2008 11:43:26 +0100"  >&lt;p&gt;&lt;b&gt;Changes&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;org.apache.mahout.ga.watchmaker.MahoutEvaluator removes any axisting input directory before storing the population&lt;/li&gt;
	&lt;li&gt;org.apache.mahout.ga.watchmaker.cd.FileInfosParser Uses the CATEGORICAL token for symbolic (nominal) attributes. This makes it easy to identify a token using the first character.&lt;/li&gt;
	&lt;li&gt;org.apache.mahout.ga.watchmaker.cd.tool.CDInfosTool is used to generate the .infos file needed by the CDGA for a new dataset.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The new tool works as follow:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;he is invoked using the following command (the dataset path is given as a parameter):&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ ~/hadoop-0.17.0/bin/hadoop jar apache-mahout-0.1-dev-ex.jar org.apache.mahout.ga.watchmaker.cd.tool.CDInfosTool dataset_path
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
	&lt;li&gt;the tool searches for an existing infos file, in the same directory of the dataset with the same name and with the &quot;.infos&quot; extension, that contain the type of the attributes:
	&lt;ul&gt;
		&lt;li&gt;&apos;N&apos; numerical attribute&lt;/li&gt;
		&lt;li&gt;&apos;C&apos; categorical attribute&lt;/li&gt;
		&lt;li&gt;&apos;L&apos; label (this also a categorical attribute)&lt;/li&gt;
		&lt;li&gt;&apos;I&apos; to ignore the attribute&lt;br/&gt;
    each attribute is in a separate line&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;the tool uses a Hadoop job to parse the dataset and collect the informations&lt;/li&gt;
	&lt;li&gt;the results are writen back in the same .info file, in a format compatible with CDGA&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;for example, this is the info file generated for the &lt;a href=&quot;http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;KDDCup (1999)&lt;/a&gt; 10% Training Dataset :&lt;/p&gt;

&lt;div class=&quot;panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;kddcup.data_10_percent.infos&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;panelContent&quot;&gt;
&lt;p&gt;NUMERICAL, 0.0,58329.0&lt;br/&gt;
CATEGORICAL, icmp,udp,tcp&lt;br/&gt;
CATEGORICAL, rje,login,time,systat,ntp_u,mtp,uucp_path,bgp,nntp,efs,Z39_50,csnet_ns,tim_i,X11,telnet,ftp_data,finger,other,exec,uucp,netstat,klogin,ecr_i,remote_job,urh_i,netbios_dgm,pop_2,auth,private,shell,printer,kshell,urp_i,vmnet,pop_3,echo,daytime,iso_tsap,courier,tftp_u,sunrpc,red_i,ctf,supdup,gopher,ssh,sql_net,name,smtp,hostnames,netbios_ssn,ftp,IRC,imap4,netbios_ns,http,ldap,eco_i,link,http_443,domain_u,discard,nnsp,pm_dump,domain,whois&lt;br/&gt;
CATEGORICAL, S2,SF,OTH,S0,S3,RSTR,RSTO,SH,S1,RSTOS0,REJ&lt;br/&gt;
NUMERICAL, 0.0,6.9337562E8&lt;br/&gt;
NUMERICAL, 0.0,5155468.0&lt;br/&gt;
CATEGORICAL, 0,1&lt;br/&gt;
NUMERICAL, 0.0,3.0&lt;br/&gt;
NUMERICAL, 0.0,3.0&lt;br/&gt;
NUMERICAL, 0.0,30.0&lt;br/&gt;
NUMERICAL, 0.0,5.0&lt;br/&gt;
CATEGORICAL, 0,1&lt;br/&gt;
NUMERICAL, 0.0,884.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
NUMERICAL, 0.0,2.0&lt;br/&gt;
NUMERICAL, 0.0,993.0&lt;br/&gt;
NUMERICAL, 0.0,28.0&lt;br/&gt;
NUMERICAL, 0.0,2.0&lt;br/&gt;
NUMERICAL, 0.0,8.0&lt;br/&gt;
NUMERICAL, 0.0,1.4E-45&lt;br/&gt;
CATEGORICAL, 0&lt;br/&gt;
CATEGORICAL, 0,1&lt;br/&gt;
NUMERICAL, 0.0,511.0&lt;br/&gt;
NUMERICAL, 0.0,511.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
NUMERICAL, 0.0,255.0&lt;br/&gt;
NUMERICAL, 0.0,255.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
NUMERICAL, 0.0,1.0&lt;br/&gt;
LABEL, teardrop.,ipsweep.,phf.,nmap.,land.,portsweep.,warezmaster.,smurf.,guess_passwd.,ftp_write.,perl.,loadmodule.,back.,imap.,normal.,pod.,spy.,neptune.,satan.,buffer_overflow.,rootkit.,warezclient.,multihop.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;b&gt;What&apos;s Next&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;I think I found a quick workaround to allow CDGA to handle multi-class classification, I should implement it and try it on the KDD dataset&lt;/li&gt;
	&lt;li&gt;Run the code on a small cluster and hope that it will work &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/tongue.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12621238" author="adeneche" created="Sun, 10 Aug 2008 11:54:09 +0100"  >&lt;p&gt;A made a small (relatively) modification to CDGA that allows him to cope with multi-class classification. You can now give it a target class, and it will (try to) dicover the classification rule for this class. If you have N classes, just run it N times with a different target each time.&lt;/p&gt;

&lt;p&gt;This modification allowed me to run CDGA over the KDD dataset, but it&apos;s veryyyyyyyyyyyyy slow. It takes more than 8 minutes to do one single iteration for one target over the 10% dataset (I didn&apos;t have the courage to run it over the whole dataset). At least now, I have a good dataset to test on a cluster &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;the target class (the index of the value for the LABEL in the info file) is specified just after the dataset name. The following examples run CDGA over the WDBC dataset with target 1:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ ~/hadoop-0.17.0/bin/hadoop jar apache-mahout-0.1-dev-ex.jar org.apache.mahout.ga.watchmaker.cd.CDGA wdbc 1 0.9 1 0.033 0.1 0 100 10
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is the last week of GSoC, so if you have any suggestions about the tests, the comments and the code I think its time for them &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12622197" author="adeneche" created="Wed, 13 Aug 2008 13:38:01 +0100"  >&lt;p&gt;I tested CDGA on a pseudo-distributed (a single PC) manner, and I discovered that I forgot to pass the dataset to the mappers &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/tongue.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Well, it&apos;s done now, and it works on pseudo-distributed.&lt;/p&gt;</comment>
                            <comment id="12622872" author="gsingers" created="Fri, 15 Aug 2008 15:08:35 +0100"  >&lt;p&gt;I&apos;m going to commit and then move the core/test/examples over to examples/...&lt;/p&gt;

&lt;p&gt;Also, I thought we had the wdbc dataset somewhere, but now the example above doesn&apos;t work for me for the class discovery.&lt;/p&gt;</comment>
                            <comment id="12623116" author="adeneche" created="Sat, 16 Aug 2008 12:40:32 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Also, I thought we had the wdbc dataset somewhere, but now the example above doesn&apos;t work for me for the class discovery.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;wdbc was in test/ressources, and now it should be in examples/test/ressources. CDGA dos not work anymore because the code in the repository is weird !&lt;br/&gt;
Some of the code is not the latest one of the patch !!!&lt;/p&gt;

&lt;p&gt;I am verifying all my code and should post soon a correcting patch. In the mean time the following command should run CDGA&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ hadoop-0.17.1/bin/hadoop jar apache-mahout-examples-0.1-dev.job org.apache.mahout.ga.watchmaker.cd.CDGA wdbc 0.9 1 0.033 0.1 0 100 10
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12623139" author="adeneche" created="Sat, 16 Aug 2008 17:31:56 +0100"  >&lt;p&gt;This patch should now work fine. I added the wdbc dataset and modified the tests to look in the correct directory. I also correctected CDGA, it should run now with the following command:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ ~/hadoop-0.17.0/bin/hadoop jar apache-mahout-examples-0.1-dev.job org.apache.mahout.ga.watchmaker.cd.CDGA wdbc 1 0.9 1 0.033 0.1 0 100 10
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12623199" author="adeneche" created="Sun, 17 Aug 2008 16:27:28 +0100"  >&lt;p&gt;A added a small (tiny) tutorial in the wiki. And I don&apos;t remember when, but I think that I accidently removed some lines from the file NOTICE.TXT, &lt;br/&gt;
so if a committer can add them it&apos;ll be great &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;This product includes software developed by the Indiana University
  Extreme! Lab (http://www.extreme.indiana.edu/).

This product includes examples code from the Watchmaker project   
  https://watchmaker.dev.java.net/
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12625712" author="gsingers" created="Tue, 26 Aug 2008 13:57:45 +0100"  >&lt;p&gt;Going to close this one, we can open up new issues as they arise.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12386168" name="libs.zip" size="852737" author="adeneche" created="Wed, 16 Jul 2008 12:11:16 +0100"/>
                            <attachment id="12385344" name="libs.zip" size="510579" author="adeneche" created="Sun, 6 Jul 2008 12:13:20 +0100"/>
                            <attachment id="12384666" name="libs.zip" size="544069" author="adeneche" created="Wed, 25 Jun 2008 12:14:22 +0100"/>
                            <attachment id="12385345" name="tsp-screenshot-1.jpg" size="56486" author="adeneche" created="Sun, 6 Jul 2008 12:17:22 +0100"/>
                            <attachment id="12388365" name="watchmaker-tsp.patch" size="141801" author="adeneche" created="Sat, 16 Aug 2008 17:31:56 +0100"/>
                            <attachment id="12388137" name="watchmaker-tsp.patch" size="68120" author="adeneche" created="Wed, 13 Aug 2008 13:38:01 +0100"/>
                            <attachment id="12387898" name="watchmaker-tsp.patch" size="65046" author="adeneche" created="Sun, 10 Aug 2008 11:54:08 +0100"/>
                            <attachment id="12387463" name="watchmaker-tsp.patch" size="51170" author="adeneche" created="Mon, 4 Aug 2008 11:43:26 +0100"/>
                            <attachment id="12386728" name="watchmaker-tsp.patch" size="345923" author="adeneche" created="Wed, 23 Jul 2008 16:02:23 +0100"/>
                            <attachment id="12386167" name="watchmaker-tsp.patch" size="339740" author="adeneche" created="Wed, 16 Jul 2008 12:09:22 +0100"/>
                            <attachment id="12385916" name="watchmaker-tsp.patch" size="391258" author="gsingers" created="Sat, 12 Jul 2008 03:55:35 +0100"/>
                            <attachment id="12385342" name="watchmaker-tsp.patch" size="312210" author="adeneche" created="Sun, 6 Jul 2008 12:09:34 +0100"/>
                            <attachment id="12385330" name="watchmaker-tsp.patch" size="450304" author="adeneche" created="Sat, 5 Jul 2008 17:43:39 +0100"/>
                            <attachment id="12385173" name="watchmaker-tsp.patch" size="416643" author="adeneche" created="Thu, 3 Jul 2008 07:25:01 +0100"/>
                            <attachment id="12384888" name="watchmaker-tsp.patch" size="414104" author="adeneche" created="Sat, 28 Jun 2008 16:15:30 +0100"/>
                            <attachment id="12384690" name="watchmaker-tsp.patch" size="412119" author="adeneche" created="Wed, 25 Jun 2008 18:18:57 +0100"/>
                            <attachment id="12384451" name="watchmaker-tsp.patch" size="780865" author="adeneche" created="Sun, 22 Jun 2008 15:18:38 +0100"/>
                            <attachment id="12384433" name="watchmaker-tsp.patch" size="534911" author="adeneche" created="Sat, 21 Jun 2008 11:05:47 +0100"/>
                            <attachment id="12382738" name="watchmaker-tsp.patch" size="104435" author="adeneche" created="Sun, 25 May 2008 20:32:32 +0100"/>
                            <attachment id="12382504" name="watchmaker-tsp.patch" size="82351" author="adeneche" created="Wed, 21 May 2008 20:39:35 +0100"/>
                            <attachment id="12382283" name="watchmaker-tsp.patch" size="54386" author="adeneche" created="Mon, 19 May 2008 06:44:22 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>21.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 19 May 2008 16:54:04 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>10010</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hxy7h3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23362</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>