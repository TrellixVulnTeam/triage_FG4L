<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:22:43 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-833/MAHOUT-833.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-833] Make conversion to sequence files map-reduce</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-833</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;p&gt;Given input that is on HDFS, the SequenceFilesFrom****.java classes should be able to do their work in parallel.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12526374">MAHOUT-833</key>
            <summary>Make conversion to sequence files map-reduce</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="smarthi">Suneel Marthi</assignee>
                                    <reporter username="gsingers">Grant Ingersoll</reporter>
                        <labels>
                            <label>MAHOUT_INTRO_CONTRIBUTE</label>
                    </labels>
                <created>Sun, 9 Oct 2011 13:57:38 +0100</created>
                <updated>Mon, 29 Jul 2013 03:09:02 +0100</updated>
                            <resolved>Sun, 23 Jun 2013 19:16:07 +0100</resolved>
                                    <version>0.7</version>
                                    <fixVersion>0.8</fixVersion>
                                    <component>Integration</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13149411" author="jpatterson" created="Mon, 14 Nov 2011 01:32:37 +0000"  >&lt;p&gt;What are the most common expectations around how we expect input files of this type to occur?&lt;/p&gt;

&lt;p&gt;I ask that to better take an angle on how to feed pathnames to map tasks to subdivide the work.&lt;/p&gt;

&lt;p&gt;Depending on factors like:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&quot;lots of directories, few files per directory&quot;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&quot; few directories, lots of files per dir&quot;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Currently the code is built around &quot;tagging along&quot; on the FileSystem.ListStatus( ... ) recursive filter code path, but the MR version will have to be different.&lt;/p&gt;

&lt;p&gt;One approach I&apos;ve kicked around is that you could just walk the directory list and then hash each entry out into a group so regardless of directory each map task gets a (generally) even number of documents to process, but out of the box that doesnt consider trying to keep all of the files in one directory in the same sequence file. Does that matter here? I want to say no, but then again, why not ask.&lt;/p&gt;</comment>
                            <comment id="13149441" author="joekumar" created="Mon, 14 Nov 2011 04:42:35 +0000"  >&lt;p&gt;Josh,&lt;br/&gt;
For the SequenceFilesFromDirectory, the doc comment says &quot;Converts a directory of text documents into SequenceFiles of Specified chunkSize&quot;. so we are anywayz expecting text documents and the output format says  docid =&amp;gt; content. I am thinking that &lt;br/&gt;
1) we should use a custom InputFormat which will parse the data according to specified options. For eg, we can extend the FileInputFormat and specifying isSplitable() to be false. So each file will be consumed by Mapper as 1 whole file. The map function will process the file according to the options and emit key value pairs.&lt;br/&gt;
2) I guess we wont really need a Reducer.&lt;br/&gt;
3) The driver will use setOutputFormatClass(SequenceFileOutputFormat.class) to write the key,values from Mapper as SequenceFile&lt;/p&gt;

&lt;p&gt;The same approach would go for SequenceFilesFromMailArchives where we can have &lt;br/&gt;
1) A separate InputFormat class that will have a RecordReader which will split each mail message as a separate Key, Value pair for consumption by Mapper. Mapper will further parse the message according to the options and emit the proper KV pairs. &lt;br/&gt;
2) I guess we wont really need a Reducer.&lt;br/&gt;
3) The driver will use setOutputFormatClass(SequenceFileOutputFormat.class) to write the key,values from Mapper as SequenceFile&lt;/p&gt;

&lt;p&gt;Team,&lt;br/&gt;
If this approach looks rite, I can submit a patch for this. Please let me know.&lt;/p&gt;

&lt;p&gt;Appreciate any feedbacks,&lt;br/&gt;
Joe.&lt;/p&gt;
</comment>
                            <comment id="13151019" author="jpatterson" created="Wed, 16 Nov 2011 04:45:24 +0000"  >&lt;p&gt;I think for &quot;SequenceFilesFromDirectory&quot; with FileInputFormat you would run into the issue where each file in the directory would generate a map task, and if you had no reducer, each file would be in a separate output sequence file, which would create lots of relatively small files.&lt;/p&gt;

&lt;p&gt;This also has the downside of not leveraging tasks setup/teardown time; Although the reduce side could generate the sequence files, ideally we&apos;d like to see each mapper process more files per task.&lt;/p&gt;

&lt;p&gt;An alternative approach:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;On client side (pre-MR), list files recursively using HDFS api. Output to a file.&lt;/li&gt;
	&lt;li&gt;Use the NLineInputFormat against that file to split among multiple mappers&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;JP&lt;/p&gt;</comment>
                            <comment id="13171916" author="cendrillon" created="Sun, 18 Dec 2011 18:18:00 +0000"  >&lt;p&gt;Is this still open? If so I could take a look.&lt;/p&gt;</comment>
                            <comment id="13171943" author="gsingers" created="Sun, 18 Dec 2011 21:26:43 +0000"  >&lt;p&gt;I think Josh was working on something, but I haven&apos;t seen a patch.  I&apos;d wait for him to chime in.&lt;/p&gt;</comment>
                            <comment id="13171963" author="jpatterson" created="Sun, 18 Dec 2011 23:31:56 +0000"  >&lt;p&gt;if you got a patch, throw it up. I am scheduled to try and get this out the door this week (been on the road a ton lately), I dont want to keep someone else from contributing.&lt;/p&gt;

&lt;p&gt;There are a few more similar to this, if you get a patch up first, I&apos;ll move on to one of those.&lt;/p&gt;</comment>
                            <comment id="13173573" author="joekumar" created="Tue, 20 Dec 2011 22:31:58 +0000"  >&lt;p&gt;Raphael,&lt;/p&gt;

&lt;p&gt;For SequenceFilesFromMailArchives, I started writing a new InputFormat and RecordReader that would parse each of the mail messages and output them into a Sequence File. It is in a very raw state and since I am travelling for work, i wont be able to do much with it for a month. so if you have already started on it, please feel free to upload a patch.. If you are interested in looking at what i&apos;ve written so far, let me know and i&apos;ll cleanup a bit, add some comments and email you or something.&lt;/p&gt;

&lt;p&gt;reg&lt;br/&gt;
Joe.&lt;/p&gt;</comment>
                            <comment id="13177392" author="jpatterson" created="Thu, 29 Dec 2011 21:03:41 +0000"  >&lt;p&gt;Well, it works in MR form, but a quick questions:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;how important is the &quot;chunksize&quot; parameter in the context of mapreduce? do we want to carry this option over, where in a map-only job you&apos;d generally just expect to get a bunch of outputs from each split?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I can add this feature, but it seems like the mechanic works here a bit differently and wanted to make sure it made sense.&lt;/p&gt;

&lt;p&gt;JP&lt;/p&gt;</comment>
                            <comment id="13177902" author="jpatterson" created="Sat, 31 Dec 2011 05:17:36 +0000"  >&lt;p&gt;Ok, I went ahead and added the chunksize param in, it only inflates over the param slightly based on the prefix and adding the paths to each key.&lt;/p&gt;

&lt;p&gt;On another note, what is the best way to kick off this job? &lt;/p&gt;

&lt;p&gt;1. add another command to the mahout bash script prop file?&lt;/p&gt;

&lt;p&gt;2. add a flag to the existing &quot;/bin/mahout seqdirectory&quot; setup that would kickoff the MR job instead of the serial process, something like:&lt;/p&gt;

&lt;p&gt;/bin/mahout seqdirectory -mr [ more options ]&lt;/p&gt;

&lt;p&gt;JP&lt;/p&gt;</comment>
                            <comment id="13179606" author="frankscholten" created="Wed, 4 Jan 2012 16:26:11 +0000"  >&lt;p&gt;Josh: Perhaps you can use a -xm / --method flag to specify MR or sequential execution method. This convention is used by most clustering jobs.&lt;/p&gt;</comment>
                            <comment id="13211631" author="joekumar" created="Mon, 20 Feb 2012 01:55:08 +0000"  >&lt;p&gt;Hey Josh,&lt;br/&gt;
Just wondering if you already have the patch created for SequenceFilesFromDirectory and SequenceFilesFromMailArchives ? If so would you be able to plz upload the same. i am really interested in walking through your approach.&lt;br/&gt;
Joe.&lt;/p&gt;</comment>
                            <comment id="13211670" author="jpatterson" created="Mon, 20 Feb 2012 05:03:11 +0000"  >&lt;p&gt;This patch adds in a codepath for running the SequenceFilesFromDirectory.java sequential process as a MR job. I haven&apos;t had time to do the mail archives one (its slightly different), but I&apos;ll look at that one. Joe asked about my design so I&apos;ll post this now, and in a few days, I&apos;ll post a patch that includes the mail archives one.&lt;/p&gt;</comment>
                            <comment id="13211675" author="jpatterson" created="Mon, 20 Feb 2012 05:26:24 +0000"  >&lt;p&gt;Joe,&lt;br/&gt;
Quick overview of the patch as is:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;only does the SequenceFilesFromDirectory.java codepath, does not address the mail part (yet).&lt;/li&gt;
	&lt;li&gt;old codepath recurses through the dirs wtih fs.listStatus() and writes into a single ChunkedWriter for the sequence file&lt;/li&gt;
	&lt;li&gt;since the dirs can have subdirs, had to include a function that built a recursive list of subdirs based on the input path&lt;/li&gt;
	&lt;li&gt;since we had lots of small file paths, I ended up subclassing CombineFileInputFormat for MultiTextFileInputFormat
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;for a great explanation of how CombineFileInputFormat works and how its used: &lt;a href=&quot;http://lucene.472066.n3.nabble.com/help-on-CombineFileInputFormat-td781357.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.472066.n3.nabble.com/help-on-CombineFileInputFormat-td781357.html&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;basically: each split is a bunch of small file input paths so each mapper gets fed a lot of files (we dont want each mapper looking at a single file like we&apos;d normally see with TextInputFormat)&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;the chunkSize param was a bit of a trick in MR, thought I was going to have to do it by hand in MR, but ended up going with &quot;mapred.max.split.size&quot;&lt;/li&gt;
	&lt;li&gt;tested on the reuters extracted files that are used in some of the demos since it has around 21k smallish text files to work from&lt;/li&gt;
	&lt;li&gt;the JobSplitWriter started complaining about &quot;max block locations exceeded for split&quot;, which caused me to set &quot;mapreduce.job.max.split.locations&quot; to a very large number in the job conf&lt;/li&gt;
	&lt;li&gt;all of the changes are localized in the integration module in o.a.m.text&lt;/li&gt;
	&lt;li&gt;new vs old MR API
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;looking at AbstractJob.prepareJob(), I can see that most of Mahout&apos;s MR Jobs are using the newer MR api. I tried to accommodate that same pattern here.&lt;/li&gt;
		&lt;li&gt;unfortunately, Hadoop 0.20.205 does not currently have a class for CombineFileInputFormat&lt;/li&gt;
		&lt;li&gt;currently the code works with the old API specifically because of this issue, I&apos;m looking at filing a JIRA with Hadoop for this&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13402789" author="jpatterson" created="Thu, 28 Jun 2012 03:33:45 +0100"  >&lt;p&gt;This patch has functionality for the MR versions of both SequenceFilesFromDirectory and SequenceFilesFromMailArchives. &lt;/p&gt;

&lt;p&gt;A few notes:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;I couldnt find a place in the serial version of SequenceFilesFromMailArchives that was actually turning on block compression for the sequence files explicily in code. This could be done by the conf files in hadoop 0.20.205, but it wasnt being done in code afaik&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the serial version of SequenceFilesFromMailArchives seems to not be working correctly in trunk; It does pass tests, but when its run on a .gz file from the ASF mail archives it reports 0 records extracted. The MR version works as intended in this patch, but I did not yet change the serial version.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the structure of SequenceFilesFromMailArchives (MR version) maintains as much of the same functionality / code as I could muster from the serial version. To use the FileLineIterable  in the mbox parsing code, I had to change add a constructor, for instance.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ended up using old MR api because of needing certain functionality that had not yet been ported as of 0.20.205&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13672606" author="robinanil" created="Sun, 2 Jun 2013 18:20:55 +0100"  >&lt;p&gt;Josh, its an old patch so naturally it didn&apos;t apply. Would you be able to update it by next week ? I will leave this on the 0.8 path. Its good to have in the release.&lt;/p&gt;</comment>
                            <comment id="13679169" author="smarthi" created="Sun, 9 Jun 2013 22:25:07 +0100"  >&lt;p&gt;Interim patch, modified to be compatible with present Mahout codebase and upgraded to use new MR API, not done with the unit test changes yet.  Will continue work on this.&lt;/p&gt;</comment>
                            <comment id="13681206" author="gsingers" created="Wed, 12 Jun 2013 14:19:05 +0100"  >&lt;p&gt;The patch seems to be missing the WholeFileRecordReader.&lt;/p&gt;</comment>
                            <comment id="13685039" author="smarthi" created="Mon, 17 Jun 2013 08:15:55 +0100"  >&lt;p&gt;Uploaded patch for review: &lt;a href=&quot;https://reviews.apache.org/r/11774/diff/2/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11774/diff/2/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13691394" author="smarthi" created="Sun, 23 Jun 2013 09:46:56 +0100"  >&lt;p&gt;Final working patch for review: &lt;a href=&quot;https://reviews.apache.org/r/11774/diff/3/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11774/diff/3/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13691563" author="hudson" created="Sun, 23 Jun 2013 20:12:58 +0100"  >&lt;p&gt;Integrated in Mahout-Quality #2100 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2100/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2100/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-833&quot; title=&quot;Make conversion to sequence files map-reduce&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-833&quot;&gt;&lt;del&gt;MAHOUT-833&lt;/del&gt;&lt;/a&gt;: Make conversion to sequence files map-reduce - Checking in, tests pass (Revision 1495863)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
smarthi : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/core/src/main/java/org/apache/mahout/common/AbstractJob.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/core/src/main/java/org/apache/mahout/common/iterator/FileLineIterable.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/core/src/main/java/org/apache/mahout/common/iterator/FileLineIterator.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/MultipleTextFileInputFormat.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromDirectory.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromDirectoryMapper.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromMailArchives.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromMailArchivesMapper.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/WholeFileRecordReader.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/SequenceFilesFromMailArchivesTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/TestSequenceFilesFromDirectory.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13693171" author="hudson" created="Tue, 25 Jun 2013 18:15:04 +0100"  >&lt;p&gt;Integrated in Mahout-Quality #2105 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2105/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2105/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-833&quot; title=&quot;Make conversion to sequence files map-reduce&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-833&quot;&gt;&lt;del&gt;MAHOUT-833&lt;/del&gt;&lt;/a&gt;: Make conversion to sequence files map-reduce (Revision 1496532)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
smarthi : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/CHANGELOG&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13693985" author="hudson" created="Wed, 26 Jun 2013 15:16:43 +0100"  >&lt;p&gt;Integrated in Mahout-Quality #2109 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2109/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2109/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-833&quot; title=&quot;Make conversion to sequence files map-reduce&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-833&quot;&gt;&lt;del&gt;MAHOUT-833&lt;/del&gt;&lt;/a&gt;: Make conversion to sequence files map-reduce (changes based on feedback from code review) (Revision 1496929)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-833&quot; title=&quot;Make conversion to sequence files map-reduce&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-833&quot;&gt;&lt;del&gt;MAHOUT-833&lt;/del&gt;&lt;/a&gt;: Make conversion to sequence files map-reduce - (changes based on feedback from review). (Revision 1496927)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
smarthi : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/core/src/main/java/org/apache/mahout/common/HadoopUtil.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;smarthi : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromDirectory.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromDirectoryMapper.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromMailArchives.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromMailArchivesMapper.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/SequenceFilesFromMailArchivesTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/TestSequenceFilesFromDirectory.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13701396" author="hudson" created="Sat, 6 Jul 2013 20:31:38 +0100"  >&lt;p&gt;Integrated in Mahout-Quality #2131 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2131/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2131/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-833&quot; title=&quot;Make conversion to sequence files map-reduce&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-833&quot;&gt;&lt;del&gt;MAHOUT-833&lt;/del&gt;&lt;/a&gt;: removed code comment. (Revision 1500310)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
smarthi : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/core/src/main/java/org/apache/mahout/common/iterator/FileLineIterable.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12533768" name="MAHOUT-833-final.patch" size="62294" author="jpatterson" created="Thu, 28 Jun 2012 03:33:45 +0100"/>
                            <attachment id="12589623" name="MAHOUT-833.patch" size="34651" author="smarthi" created="Tue, 25 Jun 2013 17:44:59 +0100"/>
                            <attachment id="12515213" name="MAHOUT-833.patch" size="13782" author="jpatterson" created="Mon, 20 Feb 2012 05:03:11 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 14 Nov 2011 01:32:37 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>50941</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hxy2p3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>22588</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>