<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:27:15 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-145/MAHOUT-145.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-145] PartialData mapreduce Random Forests</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-145</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;p&gt;This implementation is based on a suggestion by Ted:&lt;/p&gt;

&lt;p&gt;&quot;modify the original algorithm to build multiple trees for different portions of the data. That loses some of the solidity of the original method, but could actually do better if the splits exposed non-stationary behavior.&quot;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12430164">MAHOUT-145</key>
            <summary>PartialData mapreduce Random Forests</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="adeneche">Deneche A. Hakim</assignee>
                                    <reporter username="adeneche">Deneche A. Hakim</reporter>
                        <labels>
                    </labels>
                <created>Sun, 12 Jul 2009 11:52:57 +0100</created>
                <updated>Thu, 28 Feb 2013 20:38:59 +0000</updated>
                            <resolved>Wed, 30 Sep 2009 06:44:04 +0100</resolved>
                                    <version>0.2</version>
                                    <fixVersion>0.2</fixVersion>
                                    <component>Classification</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12730065" author="adeneche" created="Sun, 12 Jul 2009 12:32:58 +0100"  >&lt;p&gt;A possible implementation is as follows:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Use a custom &lt;b&gt;InputFormat&lt;/b&gt; similar to &lt;b&gt;TextInputFormat&lt;/b&gt; that returns all the lines of a split at ones in a &lt;b&gt;Text&lt;/b&gt; or, better, a custom &lt;b&gt;Writable&lt;/b&gt; that holds a String[].&lt;/li&gt;
	&lt;li&gt;the mapper simply converts the input lines to a &lt;b&gt;Data&lt;/b&gt; instance and uses the reference implementation to build a tree.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The custom &lt;b&gt;InputFormat&lt;/b&gt; can be either a specialized &lt;b&gt;NLineInputFormat&lt;/b&gt; with a custom &lt;b&gt;RecordReader&lt;/b&gt; that returns all the lines of a split at ones; or inherit from &lt;b&gt;FileInputFormat&lt;/b&gt; and uses the same custom &lt;b&gt;RecordReader&lt;/b&gt;.&lt;br/&gt;
The advantage of inheriting from &lt;b&gt;NLineInputFormat&lt;/b&gt; is that it is easy to configure the number of lines (instances) to grow each tree, but reads all the data when generating the splits thus can slow down the implementation because the generation of the splits is done in the client machine.&lt;/p&gt;</comment>
                            <comment id="12730129" author="tdunning" created="Sun, 12 Jul 2009 19:53:04 +0100"  >
&lt;p&gt;What do you think about using a normal mapper structure where the map() method reads one line at a time, stores the record into memory and then does the tree building in the close() method of your mapper?&lt;/p&gt;

&lt;p&gt;This trick is used extensively in streaming.  If you are using 0.18.* then you have to stash the output collector in an instance variable so that you can produce output (or just open a task specific output file).  In 0.20, I think that the Context argument is passed to the close method to avoid that need.  Because production of output in the close() is so important to some applications, you are guaranteed to be able to use the output collector in close().&lt;/p&gt;</comment>
                            <comment id="12730294" author="adeneche" created="Mon, 13 Jul 2009 12:18:41 +0100"  >&lt;blockquote&gt;&lt;p&gt;What do you think about using a normal mapper structure where the map() method reads one line at a time, stores the record into memory and then does the tree building in the close() method of your mapper?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Excellent idea ! and no need to create another custom InputFormat =D&lt;/p&gt;</comment>
                            <comment id="12732990" author="adeneche" created="Sun, 19 Jul 2009 12:09:33 +0100"  >&lt;p&gt;In the partial implementation, the input of the program is the data and T (number of trees). The data is split up between the mappers, but how many trees each mapper should build ?&lt;/p&gt;

&lt;p&gt;I&apos;ve got two ideas:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;easiest&amp;#93;&lt;/span&gt; each mapper builds T trees on its subset of the data, this makes it easy to configure how many trees each mapper builds but its somewhat tricky to estimate the total number of trees because it will depend on FileInputFormat.getsplits() (min split size, block size, data size...)&lt;/li&gt;
	&lt;li&gt;each mapper builds T/M trees where M is the number of mappers available. The user sets the total number of trees, and the number of trees that each mapper builds will depend on the number of splits&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;any suggestion ?&lt;/p&gt;</comment>
                            <comment id="12735703" author="adeneche" created="Mon, 27 Jul 2009 19:41:44 +0100"  >&lt;p&gt;to be able to predict the class of an out-of-bag instance, one must classify it using all the trees of the forest, and because each mapper has access to a subset of the trees, a second job is needed. Unless of course I&apos;m missing something.&lt;/p&gt;

&lt;p&gt;I already implemented the first job, now I should start on the second. &lt;/p&gt;</comment>
                            <comment id="12738112" author="adeneche" created="Sun, 2 Aug 2009 19:40:35 +0100"  >&lt;p&gt;partial-mapred implementation&lt;/p&gt;

&lt;p&gt;&lt;b&gt;changes&lt;/b&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;abstract class org.mahout.rf.mapred.Builder : Base class for Mapred Random Forest builders. Takes care of storing the parameters common to the mapred implementations: tree builder, data path, dataset path and seed. The child classes must implement at least :
	&lt;ul&gt;
		&lt;li&gt;void configureJob(JobConf) : to further configure the job before its launch; and&lt;/li&gt;
		&lt;li&gt;RandomForest parseOutput(JobConf, PredictionCallback) in order to convert the job outputs into a RandomForest and its corresponding oob predictions&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;abstract class org.mahout.rf.mapred.MapredMapper : Base class for Mapred mappers. Loads common parameters from the job&lt;/li&gt;
	&lt;li&gt;org.mahout.rf.mapred.examples.BuildForest : can now build a forest using either the in-mem or partial implementations (mapred or sequential)&lt;br/&gt;
  has also a special mode (-c command-line option) that checks if the results of the mapred vs. sequential implementations are the same, I use it to test the implementations&lt;br/&gt;
  because when using JUnit Hadoop uses a Local runner with just one mapper&lt;/li&gt;
	&lt;li&gt;one important change concerns the Dataset class. This class describes the data attributes. I added a tool (org.apache.mahout.rf.tools.Describe) that takes a data path, and a weird description string then it generates a Dataset and stores it in a file. This file is then passed to the various builders allowing them to convert the data instances in the fly. For example, the KDD description is : &quot;N 3 C 2 N C 4 N C 8 N 2 C 19 N L&quot; (I told you, its weird!!!) that means that :
	&lt;ul&gt;
		&lt;li&gt;the first attribute is Numerical&lt;/li&gt;
		&lt;li&gt;the 3 next attributes are Categorical&lt;/li&gt;
		&lt;li&gt;the 2 next attributes are Numerical&lt;/li&gt;
		&lt;li&gt;...&lt;/li&gt;
		&lt;li&gt;the last attribute is the Label&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;package org.apache.mahout.rf.mapred.partial&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;InterResults : Utility class that stores/loads the intermediate results passed from the 1st to the 2nd step of the partial implementation&lt;/li&gt;
	&lt;li&gt;PartialBuilder : inherits from Builder and builds the forest by splitting the data to the mappers. Runs in two steps:
	&lt;ul&gt;
		&lt;li&gt;in the first step each mapper receives a subset of the data with its input split, builds a given number of trees, returning each tree with the classifications of the instances of the mapper&apos;s split that are oob;&lt;/li&gt;
		&lt;li&gt;in the second step each mapper receives the trees generated by the first step and computes for each tree, that does not belong to the mapper&apos;s partition, the classifications of all the instances of the mapper&apos;s split&lt;br/&gt;
 PartialBuilder goes through the final step results and passes the classifications to a given PredictionCallback, allowing the calling code to compute the oob error estimate.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Step1Mapper : First step mapper. Builds the trees using the data available in the InputSplit. Predict the oob classes for each tree in its growing partition (input split).&lt;/li&gt;
	&lt;li&gt;PartialSequentialBuilder : Simulates the Partial mapreduce implementation in a sequential manner, useful when testing the implementation performances&lt;/li&gt;
	&lt;li&gt;Step2Job : 2nd step of the partial mapreduce builder. Computes the oob predictions using all the trees of the forest&lt;/li&gt;
	&lt;li&gt;Step2Mapper : Second step mapper. Using the trees of the first step, computes the oob predictions for each tree, except those of its own partition, on all instancesof the partition.&lt;/li&gt;
	&lt;li&gt;TreeID: inherits from LongWritable, allows to combine a partition integer and a treeId integer into a single LongWritable. Used by the first and second step to identify uniquely each tree of the forest and to wich partition it belongs.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12739386" author="adeneche" created="Wed, 5 Aug 2009 10:23:32 +0100"  >&lt;p&gt;I&apos;m running some tests to compare between the &lt;b&gt;in-mem&lt;/b&gt; and &lt;b&gt;partial&lt;/b&gt; implementations. Here are the first results from my laptop (hadoop 0.19.1 in pseudo-distributed with 2 cores processor):&lt;/p&gt;

&lt;p&gt;All the tests are using a random seed = 1 and only one random feature is selected at a time.&lt;/p&gt;

&lt;p&gt;KDD 1%&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Map Tasks &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num trees &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; In-Mem build time &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Partial build time &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; In-Mem oob error &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Partial oob error &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  0h 0m 21s 5 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 31s 823 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 8.38E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.43 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 57s 641 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 44s 43 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.45E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.42 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 38s 307 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 4s 523 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.45E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.43 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 3m 5s 883 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 43s 852 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.65E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.42 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 28s 404 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 33s 374 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 8.38E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.32 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 12s 260 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 43s 628 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.65E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.34 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 0s 293 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 47s 994 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.45E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.34 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 3m 28s 69 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 4s 351 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.65E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.34 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 42s 654 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 49s 785 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 7.98E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.23 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 19s 405 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 53s 646 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.45E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.23 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 6s 375 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 56s 89 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.65E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.23 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 3m 33s 253 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 8s 29 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.45E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.23 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 21s 762 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 23s 883 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.04E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.23 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 32s 952 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 22s 12 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.45E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.23 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 4m 4s 487 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 31s 248 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.25E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.23 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 3m 15s 485 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 53s 70 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.25E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.23 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 4m 2s 509 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 51s 733 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.45E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.23 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 5m 27s 252 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 3m 7s 542 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.25E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.23 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
</comment>
                            <comment id="12739584" author="adeneche" created="Wed, 5 Aug 2009 17:10:51 +0100"  >&lt;p&gt;more tests on my laptop:&lt;/p&gt;

&lt;p&gt;KDD 10%&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Map Tasks &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num trees &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; In-Mem build time &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Partial build time &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; In-Mem oob error &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Partial oob error &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 44s 635 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 37s 249 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 3.11E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.63 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 11m 57s 389 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 5m 52s 22 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.63E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.63 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 24m 17s 81 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 10m 46s 735 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.65E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.63 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 47m 24s 519 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 21m 28s 939 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.57E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.63 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 19s 742 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 59s 211 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.92E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.58 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 14m 10s 964 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 32s 969 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.42E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.58 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 27m 12s 29 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 4m 18s 984 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.59E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.58 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 52m 29s 179 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 8m 9s 980 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.42E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.58 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 3m 8s 587 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 12s 826 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5.41E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.50 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 13m 42s 344 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 10s 523 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.63E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.54 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 24m 22s 871 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 3m 0s 816 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.57E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.51 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 49m 39s 381 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 4m 56s 698 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.53E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.51 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 15m 20s 24 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 34s 573 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.42E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.45 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 29m 43s 385 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 3m 7s 545 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.55E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.45 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 50m 43s 957 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 4m 12s 662 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.55E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.45 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 20m 35s 45 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 3m 52s 244 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.46E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.43 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 32m 26s 342 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 4m 24s 853 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.48E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.43 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 55m 28s 281 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 5m 5s 999 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.51E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.43 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
</comment>
                            <comment id="12739775" author="tdunning" created="Wed, 5 Aug 2009 22:49:17 +0100"  >&lt;p&gt;Ouch!&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Map Tasks &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num trees &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; In-Mem build time &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Partial build time &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; In-Mem oob error &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Partial oob error &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; ...&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 57s 641 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 44s 43 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.45E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.42 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; ... &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 3m 33s 253 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 8s 29 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.45E-4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.23 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;This looks like it runs faster (or at least not much slower), but produces astronomically worse results.  &lt;/p&gt;

&lt;p&gt;What really bugs me is that it is worse with few maps.  Am I interpreting this correctly when I say that splitting the data in half and building independent forests increases OOB errors by a factor of 1000?  How could that possibly be?&lt;/p&gt;
</comment>
                            <comment id="12739910" author="adeneche" created="Thu, 6 Aug 2009 07:24:32 +0100"  >&lt;blockquote&gt;&lt;p&gt;What really bugs me is that it is worse with few maps. Am I interpreting this correctly when I say that splitting the data in half and building independent forests increases OOB errors by a factor of 1000? How could that possibly be?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Only one possible explanation: a BUG. I already have an idea where I can find it...&lt;/p&gt;</comment>
                            <comment id="12740872" author="adeneche" created="Sat, 8 Aug 2009 11:38:35 +0100"  >&lt;p&gt;as expected I found a bug and removed it. I then launched another batch of tests on my laptop:&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Map Tasks &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Trees &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Partial oob error &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.043 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.033 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.051 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.051 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.43 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.43 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;as I said in a previous comment, Partial Builder uses two step to complete its job: &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;In The first step each mapper builds a number of trees using the subset of data available in its partition. If there are P partitions, and because of the bagging, each tree is built using about 2/(3 x P) of the data.&lt;/li&gt;
	&lt;li&gt;because all the instances that don&apos;t belong the a tree&apos;s partition can be considered as oob, a second step is used to complete the oob computation. Thus each tree is tested against 1 - 2/(3 x P) of the data&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Using only the first step, I got the following results:&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Map Tasks &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Trees &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Partial oob error &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.85E-4 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.67E-4 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4.88E-4 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2.81E-4 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 7.19E-4 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5.46E-4 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;Although the second step passes the unit tests, there is a possibility of a bug hiding somewhere. I&apos;m going to use the reference implementation and run it on subsets of the data and use the forests to classify the whole data in the same way Partial Builder does, this should confirm if there is a bug or not.&lt;/p&gt;</comment>
                            <comment id="12740876" author="adeneche" created="Sat, 8 Aug 2009 12:27:27 +0100"  >&lt;p&gt;Ok here what I did:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Load KDD 10%&lt;/li&gt;
	&lt;li&gt;partition the data among P partitions&lt;/li&gt;
	&lt;li&gt;for each partition (p) run the ref. implementation builder, we get a forest Fp and a set of predictions Cp&lt;/li&gt;
	&lt;li&gt;for each partition (p)
	&lt;ul&gt;
		&lt;li&gt;for each forest Fk where k &amp;lt;&amp;gt; p, classify the instances of partition p and update Cp&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;compute the oob&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;and launched the test on num trees = 100, and num maps = 2, 10, 50 and got almost exactly the same results as Partial Builder...Conclusion there is no &lt;b&gt;visible&lt;/b&gt; bug in the second step of Partial Builder. &lt;/p&gt;</comment>
                            <comment id="12740914" author="tdunning" created="Sat, 8 Aug 2009 17:47:55 +0100"  >
&lt;p&gt;So at this point, it seems that you &lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;have demonstrated that partitioning works to produce a usable forest because your errors on the partitioned forest seem similar&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;have demonstrated substantial speedup for large numbers of trees&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Is this correct? &lt;/p&gt;</comment>
                            <comment id="12740931" author="adeneche" created="Sat, 8 Aug 2009 19:06:10 +0100"  >&lt;blockquote&gt;&lt;p&gt;have demonstrated that partitioning works to produce a usable forest because your errors on the partitioned forest seem similar&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yep, The last test shows that the results of the partial implementations are correct...or that the reference implementation is wrong, but I&apos;m not considering this possibility (just kidding my first tests on the ref. impl. gave similar results to Breinman&apos;s paper)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;have demonstrated substantial speedup for large numbers of trees&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oh yeah it fast, the partial implementation running on my laptop is two times faster than the in-mem implementation running on a 10 nodes cluster !!!&lt;br/&gt;
but its oob error is not so good. I should use a larger dataset (why not KDD 100%) with more trees and see what happens.&lt;/p&gt;

&lt;p&gt;Actually there is a performance issue that I got using KDD 25% (hum...using bigger datasets seems to bring bigger problems). It should take a day or two to resolve.&lt;/p&gt;</comment>
                            <comment id="12741057" author="adeneche" created="Sun, 9 Aug 2009 10:30:11 +0100"  >&lt;ul&gt;
	&lt;li&gt;resolved a bug in Partial Implementation&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This patch includes &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-140&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;MAHOUT-140 &lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-122&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;MAHOUT-122 &lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="12741460" author="adeneche" created="Mon, 10 Aug 2009 19:16:26 +0100"  >&lt;p&gt;&lt;b&gt;changes&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Partial Implementation has been improved to work better with larger datasets, I&apos;m now able to deal with KDD 50% on EC2.&lt;/p&gt;</comment>
                            <comment id="12741470" author="adeneche" created="Mon, 10 Aug 2009 19:30:45 +0100"  >&lt;p&gt;Here are some results from a 10 nodes cluster (c1.medium):&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Dataset &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Map Tasks &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Trees &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Build Time &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; oob error &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD 10% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 46s 19 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.051 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD 10% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 15s 571 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.090 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD 10% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 46s 19 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.051 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD 25% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 18s 574 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.43 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD 25% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 4m 9s 999 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.019 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD 25% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 42s 293 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.50 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;having some heap size issues, I set  HADOOP_HEAPSIZE=2000 for the next tests:&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Dataset &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Map Tasks &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Trees &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Build Time &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; oob error &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD 50% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 52s 338 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.19 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD 50% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 5m 54s 961 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.18 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; KDD 50% &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 4m 18s 861 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.47 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;For now I&apos;m not able to process KDD 100% because a limitation in my code. The Partial Builder takes 6 minutes to build 100 with 10 maps, but the example program hangs when comparing the forest predictions with the data labels, because the current example code loads the whole dataset in memory before checking the labels =P&lt;/p&gt;</comment>
                            <comment id="12741495" author="tdunning" created="Mon, 10 Aug 2009 20:00:05 +0100"  >
&lt;p&gt;These are confusing numbers.  First, why does the number of trees vary like this?&lt;/p&gt;

&lt;p&gt;Secondly, the oob error jumps around a lot in confusing ways.&lt;/p&gt;

&lt;p&gt;Thirdly, the times don&apos;t seem to match what I would expect.  Moreover, KDD10 at 10 and 50 map tasks take exactly the same amount of time.&lt;/p&gt;

&lt;p&gt;My expectation would have been that running 20 map tasks would do almost twice as well as running 10 because we have 10 machines each of which is dual core.  Running 50 map tasks should be about the same as 20.  We see that pattern on KDD25 except we don&apos;t have a datapoint for 50 maps.&lt;/p&gt;</comment>
                            <comment id="12741759" author="adeneche" created="Tue, 11 Aug 2009 09:39:04 +0100"  >&lt;blockquote&gt;&lt;p&gt;These are confusing numbers. First, why does the number of trees vary like this?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm...well...my primary focus was to check if the implementation was able to handle larger datasets. I shall run another, more coherent, batch of tests soon&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Secondly, the oob error jumps around a lot in confusing ways.&lt;/p&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;&lt;p&gt;Thirdly, the times don&apos;t seem to match what I would expect. Moreover, KDD10 at 10 and 50 map tasks take exactly the same amount of time.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ouch It&apos;s a copy and paste brain-bug !!! Ok, I&apos;ll be more careful with the next test&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;My expectation would have been that running 20 map tasks would do almost twice as well as running 10 because we have 10 machines each of which is dual core. Running 50 map tasks should be about the same as 20. We see that pattern on KDD25 except we don&apos;t have a datapoint for 50 maps.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Re-Ouch, I used the same cofiguration that I used with the In-Mem implementation: &lt;b&gt;mapred.tasktracker.map.tasks.maximum=1&lt;/b&gt; only one mapper at a time on each node&lt;/p&gt;</comment>
                            <comment id="12742000" author="adeneche" created="Tue, 11 Aug 2009 19:16:56 +0100"  >&lt;p&gt;How the Partial Mapred builder works:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;step 0 (centralized): the main program prepares and launches the builder&lt;/li&gt;
	&lt;li&gt;step 1 (mapred job): each mapper builds a set of trees and classifies the oob instances of the partition, return each tree with the classifications of all partition instances (non classified instance get -1)&lt;/li&gt;
	&lt;li&gt;step 1-2 (centralized): the builder processes the outputs of the job two times:
	&lt;ul&gt;
		&lt;li&gt;the first time in order to compute the partitions&apos; sizes and their respective order&lt;/li&gt;
		&lt;li&gt;the second time to extract the trees and pass the oob classifications to a callback&lt;br/&gt;
 this step has been split to avoid loading all the outputs in memory (slows down the program when the data is large)&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;step 2 (mapred job): each mapper uses all the trees of the other partitions to compute the classifications for all the instances of its partition. This completes the oob error computation&lt;/li&gt;
	&lt;li&gt;step 2-2 (centralized): the builder processes the outputs and passes the oob classifications to a callback&lt;/li&gt;
	&lt;li&gt;step 3 (centralized): the main program receives the decision forest, and its callback has received all the oob classifications. In order to compute the oob error it must compare the oob classifications with the real data labels. Actually its done by loading the whole data in memory (ouch!), extracting its labels, then computing the oob error&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;in the test results the build time is the time taken by the steps 1, 1-2, 2 and 2-2. Although the step 3 is not accounted, it slows the tests so much that I was not able to try KDD 100%.&lt;/p&gt;

&lt;p&gt;In the following results, the build time is computed by the program, and I was able to figure out the other times using the log of the program.&lt;/p&gt;

&lt;p&gt;EC2 10 nodes (c1.medium) cluster&lt;br/&gt;
mapred.tasktracker.map.tasks.maximum=2&lt;br/&gt;
mapred.child.java.opts=-Xms500m -Xmx1000m&lt;br/&gt;
export HADOOP_HEAPSIZE=2000&lt;/p&gt;

&lt;p&gt;seed 1, m 1, oob&lt;/p&gt;

&lt;p&gt;KDD 10%&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Map Tasks &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Trees &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Oob Error &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Build Time &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Step 1 &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Step 1-2 &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Step 2 &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Step 2-2 &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Step 3 &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.0515 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 48s 823 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 24s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 15s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 7s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 14s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.0514 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 59s 34 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 27s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 3s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 15s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 14s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 13s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.0513 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 40s 265 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 43s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 7s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 22s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 28s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 13s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.0864 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 37s 366 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 15s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 14s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 7s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 14s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.1024 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 47s 213 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 14s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 17s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 14s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 13s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.0903 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 14s 368 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 18s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 22s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 30s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 13s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.4315 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 37s 657 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 13s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 16s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 8s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 14s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.4316 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 0m 48s 611 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 15s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 16s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 15s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 14s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.4316 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 6s 160 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 14s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 21s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 30s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 12s &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;As soon as I compile the results of KDD50 and KDD100 I&apos;ll post them, then I can start explaining those results (at least I will try)&lt;/p&gt;</comment>
                            <comment id="12742262" author="adeneche" created="Wed, 12 Aug 2009 09:50:22 +0100"  >&lt;p&gt;update: I did a re-run on 50 map tests, the new results are more coherent&lt;/p&gt;

&lt;p&gt;KDD 25%&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Map Tasks &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Trees &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Oob Error &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Build Time &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Step 1 &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Step 1-2 &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Step 2 &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Step 2-2 &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Step 3 &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.0194 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 23s 210 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 39s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 33s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.0203 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 16s 510 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 1s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 9s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 26s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 41s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 33s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.0195 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 4m 10s 9 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 53s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 18s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 39s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 20s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 32s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.3875 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 5s 288 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 18s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 25s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 31s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.3626 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 29s 145 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 23s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 22s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 39s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 33s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.5003 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 30s 789 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 35s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 8s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 28s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 19s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 32s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.5041 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 1s 375 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 19s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 3s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 19s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 21s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 32s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.5041 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 19s 202 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 19s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 22s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 36s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 32s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.5041 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 2s 250 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 18s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 28s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 12s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 33s &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
</comment>
                            <comment id="12742274" author="adeneche" created="Wed, 12 Aug 2009 10:51:39 +0100"  >&lt;p&gt;KDD 50%&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Map Tasks &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Num Trees &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Oob Error &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Build Time &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Step 1 &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Step 1-2 &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Step 2 &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Step 2-2 &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Step 3 &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.1911 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  0h 2m 39s 73 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 23s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 9s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 27s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 40s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 7s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.1902 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 4m 57s 268 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2m 39s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 17s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 40s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 21s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 4s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.1880 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 9m 1s 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4m 37s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 34s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 5s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2m 46s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 6s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.1905 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 44s 853 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 32s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 24s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 44s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 5s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.1853 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 58s 462 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 48s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 9s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 30s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 32s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 3s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.1856 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 5m 20s 231 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 26s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 17s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 47s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2m 50s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 5s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.4738 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 1m 23s 989 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 19s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 24s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 39s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 3s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 200 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.4738 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 2m 10s 921 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 21s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 30s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 16s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 3s &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 50 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 400 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0.4738 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0h 3m 52s 98 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 25s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 7s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 44s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2m 36s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1m 2s &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
</comment>
                            <comment id="12742880" author="adeneche" created="Thu, 13 Aug 2009 17:17:04 +0100"  >&lt;p&gt;&lt;b&gt;Preparing the code for GSoC deadline&lt;/b&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;DONE: move rf.RFUtils.storeWritable() to rf.ref.tools.Describe, becomes private&lt;/li&gt;
	&lt;li&gt;DONE: rename rf.mapred.partial.InterResults.loadForest/storeForest to load/store&lt;/li&gt;
	&lt;li&gt;DONE: delete rf.mapred.partial.Step0Job and the corresponding tests&lt;/li&gt;
	&lt;li&gt;DONE: delete rf.ref.examples.DataSplit&lt;/li&gt;
	&lt;li&gt;DONE: DefaultTreeBuilder uses OptIgSplit by default
	&lt;ul&gt;
		&lt;li&gt;DONE: remove unnecessary calls to DefaultTreeBuilder.setIgSplit()&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12743745" author="adeneche" created="Sat, 15 Aug 2009 19:21:39 +0100"  >&lt;p&gt;&lt;b&gt;Preparing for GSoC deadline&lt;/b&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;DONE: move rf.mapred.xxx.xxxSequentialBuilder to core/tests/
	&lt;ul&gt;
		&lt;li&gt;DONE: move rf.mapred.examples.BuildForest to core/tests/, becomes df.mapred.tools.BuildForest&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;DONE: move a copy of rf.mapred.examples.BuildForest to examples/, no more calls xxxSequentialBuilder&lt;/li&gt;
	&lt;li&gt;DONE: rf.ref.examples.BreinmanExample uses CLI&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12743999" author="adeneche" created="Mon, 17 Aug 2009 09:33:38 +0100"  >&lt;p&gt;&lt;b&gt;GSoC latest patch&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;DONE: move rf.ref.examples.BreimanExample to examples/&lt;/li&gt;
	&lt;li&gt;DONE: move rf.ref.examples.CpuTest to core/tests (tools package)&lt;/li&gt;
	&lt;li&gt;DONE: move rf.ref.examples.MemoryUsage to core/tests (tools package)&lt;/li&gt;
	&lt;li&gt;DONE: move rf.ref.examples.PartialStep2Test to core/tests (tools package), becomes PartialStep2Check&lt;/li&gt;
	&lt;li&gt;DONE: move content of rf.ref.examples.UciDescriptors to ExampleUtils&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;DONE: org.apache.mahout.rf becomes org.apache.mahout.df (Decision Forest)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;DONE: Check that all files contain Apache License&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;DONE: add a link to Andrew&apos;s tutorial in DefaultTreeBuilder&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This should be the last patch concerning GSoC. The next ones will target the 0.2 release&lt;/p&gt;</comment>
                            <comment id="12745144" author="adeneche" created="Wed, 19 Aug 2009 18:36:35 +0100"  >&lt;p&gt;&lt;b&gt;Preparation for mahout 0.2&lt;/b&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;moving to Hadoop 0.20.0 API:
	&lt;ul&gt;
		&lt;li&gt;org.apache.mahout.df.mapred.* contains the code compatible with Hadoop 0.19.1&lt;/li&gt;
		&lt;li&gt;org.apache.mahout.df.mapreduce.* will contain the code that uses Hadoop 0.20.0 API&lt;/li&gt;
		&lt;li&gt;the in-mem implementation has been converted to 0.20.0 and is working&lt;/li&gt;
		&lt;li&gt;the partial implementation still need a looot of work to do, but should be better (or more likely with better bugs)&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12746790" author="adeneche" created="Mon, 24 Aug 2009 10:38:25 +0100"  >&lt;ul&gt;
	&lt;li&gt;DONE: partial implementation that uses Hadoop 0.20.0&lt;/li&gt;
	&lt;li&gt;TODO: convert the partial implementation tests to Hadoop 0.20.0&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12749104" author="adeneche" created="Sat, 29 Aug 2009 10:59:05 +0100"  >&lt;ul&gt;
	&lt;li&gt;DONE: convert the partial implementation tests to Hadoop 0.20.0&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;TODO: test the code on a Hadoop 0.20.0 cluster (EC2)&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12749408" author="adeneche" created="Mon, 31 Aug 2009 08:49:43 +0100"  >&lt;ul&gt;
	&lt;li&gt;Corrected some bugs in the new code when testing in a pseudo-distributed cluster&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12751842" author="adeneche" created="Sun, 6 Sep 2009 09:00:37 +0100"  >&lt;blockquote&gt;&lt;p&gt;*  TODO: test the code on a Hadoop 0.20.0 cluster (EC2)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Looks like I&apos;ll have to wait till Hadoop 0.20.1 to be able to test on EC2...after creating my own AMI (with a lot of pain, being a noob), I stumbled upon the following bug &lt;a href=&quot;http://issues.apache.org/jira/browse/HADOOP-5921&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HADOOP-5921&lt;/a&gt;&lt;/p&gt;
</comment>
                            <comment id="12753572" author="adeneche" created="Thu, 10 Sep 2009 12:20:33 +0100"  >&lt;blockquote&gt;&lt;p&gt;What about using the Yahoo 0.20 distribution?  (&lt;a href=&quot;http://developer.yahoo.com/hadoop/distribution/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://developer.yahoo.com/hadoop/distribution/&lt;/a&gt; )&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yahoo distribution did the job !&lt;/p&gt;

&lt;p&gt;I launched the tests on a 10-nodes cluster with KDD10, and apart from a difference in execution time, the 0.20.0 implementation uses one more step, the results are the same&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;For now I&apos;m not able to process KDD 100% because a limitation in my code. The Partial Builder takes 6 minutes to build 100 with 10 maps, but the example program hangs when comparing the forest predictions with the data labels, because the current example code loads the whole dataset in memory before checking the labels =P&lt;/p&gt;&lt;/blockquote&gt;

&lt;ul&gt;
	&lt;li&gt;TODO: no need to load the whole dataset in memory just to extract the labels, this should help when dealing with large datasets&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12754668" author="adeneche" created="Sun, 13 Sep 2009 07:41:46 +0100"  >&lt;ul&gt;
	&lt;li&gt;Will be committed as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-145&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;MAHOUT-145&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;For now two implementations are available, one that uses Hadoop 0.20.0 API and one that don&apos;t use it. Later only one implementation should remain&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;b&gt;Important&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;one important part  that is still missing is the integration of Decision Forests with Mahout&apos;s Classifiers. It should take some time, so the current code could be committed &lt;b&gt;as it is&lt;/b&gt; (working but not yet integrated) and the integration will probably be available for Mahout 0.3.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12755509" author="adeneche" created="Tue, 15 Sep 2009 15:42:20 +0100"  >&lt;ul&gt;
	&lt;li&gt;DONE: no need to load the whole dataset in memory just to extract the labels, this should help when dealing with large datasets&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12755598" author="adeneche" created="Tue, 15 Sep 2009 18:33:33 +0100"  >&lt;ul&gt;
	&lt;li&gt;This patch also includes &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-140&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;MAHOUT-140&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-122&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;MAHOUT-122&lt;/a&gt;.&lt;/li&gt;
	&lt;li&gt;in-mem and partial implementations are available for Hadoop 0.19.1 (org.apache.mahout.df.mapred.*) and Hadoop 0.20.0 (org.apache.mahout.df.mapreduce)&lt;/li&gt;
	&lt;li&gt;this code is not yet integrated with mahout&apos;s classifiers. I shall start on it, but not in time for mahout 0.2.0&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12760842" author="adeneche" created="Wed, 30 Sep 2009 06:34:01 +0100"  >&lt;p&gt;committed patch&lt;/p&gt;</comment>
                            <comment id="13589902" author="saradelrio" created="Thu, 28 Feb 2013 20:38:59 +0000"  >&lt;p&gt;Hello Deneche A. Hakim:&lt;/p&gt;

&lt;p&gt;I&apos;m testing the Random Forest Partial version in the version of Hadoop: Hadoop 2.0.0-cdh4.1.1&lt;/p&gt;

&lt;p&gt;I&apos;m trying to modify the algorithm, all I do is add more information to the leaves of the tree. Currently containing the label and I want to add another label more:&lt;/p&gt;

&lt;p&gt;@Override&lt;br/&gt;
  public void readFields(DataInput in) throws IOException &lt;/p&gt;
{	
	label = in.readDouble();
	leafWeight = in.readDouble();
  }

&lt;p&gt;  @Override&lt;br/&gt;
  protected void writeNode(DataOutput out) throws IOException &lt;/p&gt;
{
	out.writeDouble(label);
	out.writeDouble(leafWeight);
  }


&lt;p&gt;And I get the following error:&lt;/p&gt;

&lt;p&gt;13/02/27 06:53:27 INFO mapreduce.BuildForest: Partial Mapred implementation&lt;br/&gt;
13/02/27 06:53:27 INFO mapreduce.BuildForest: Building the forest...&lt;br/&gt;
13/02/27 06:53:27 INFO mapreduce.BuildForest: Weights Estimation: IR&lt;br/&gt;
13/02/27 06:53:37 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.&lt;br/&gt;
13/02/27 06:53:39 INFO input.FileInputFormat: Total input paths to process : 1&lt;br/&gt;
13/02/27 06:53:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable&lt;br/&gt;
13/02/27 06:53:39 WARN snappy.LoadSnappy: Snappy native library not loaded&lt;br/&gt;
13/02/27 06:53:39 INFO mapred.JobClient: Running job: job_201302270205_0013&lt;br/&gt;
13/02/27 06:53:40 INFO mapred.JobClient:  map 0% reduce 0%&lt;br/&gt;
13/02/27 06:54:18 INFO mapred.JobClient:  map 20% reduce 0%&lt;br/&gt;
13/02/27 06:54:42 INFO mapred.JobClient:  map 40% reduce 0%&lt;br/&gt;
13/02/27 06:55:03 INFO mapred.JobClient:  map 60% reduce 0%&lt;br/&gt;
13/02/27 06:55:26 INFO mapred.JobClient:  map 70% reduce 0%&lt;br/&gt;
13/02/27 06:55:27 INFO mapred.JobClient:  map 80% reduce 0%&lt;br/&gt;
13/02/27 06:55:49 INFO mapred.JobClient:  map 100% reduce 0%&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient: Job complete: job_201302270205_0013&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient: Counters: 24&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:   File System Counters&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     FILE: Number of bytes read=0&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     FILE: Number of bytes written=1828230&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     FILE: Number of read operations=0&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     FILE: Number of large read operations=0&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     FILE: Number of write operations=0&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     HDFS: Number of bytes read=1381649&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     HDFS: Number of bytes written=1680&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     HDFS: Number of read operations=30&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     HDFS: Number of large read operations=0&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     HDFS: Number of write operations=10&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:   Job Counters &lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     Launched map tasks=10&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     Data-local map tasks=10&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     Total time spent by all maps in occupied slots (ms)=254707&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     Total time spent by all reduces in occupied slots (ms)=0&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:   Map-Reduce Framework&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     Map input records=20&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     Map output records=10&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     Input split bytes=1540&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     Spilled Records=0&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     CPU time spent (ms)=12070&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     Physical memory (bytes) snapshot=949579776&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=8412340224&lt;br/&gt;
13/02/27 06:56:04 INFO mapred.JobClient:     Total committed heap usage (bytes)=478412800&lt;br/&gt;
READ &lt;br/&gt;
nodetype: 0&lt;br/&gt;
Exception in thread &quot;main&quot; java.lang.IllegalStateException: java.io.EOFException&lt;br/&gt;
	at org.apache.mahout.common.iterator.sequencefile.SequenceFileIterator.computeNext(SequenceFileIterator.java:104)&lt;br/&gt;
	at org.apache.mahout.common.iterator.sequencefile.SequenceFileIterator.computeNext(SequenceFileIterator.java:38)&lt;br/&gt;
	at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)&lt;br/&gt;
	at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)&lt;br/&gt;
	at org.apache.mahout.classifier.df.mapreduce.partial.PartialBuilder.processOutput(PartialBuilder.java:129)&lt;br/&gt;
	at org.apache.mahout.classifier.df.mapreduce.partial.PartialBuilder.parseOutput(PartialBuilder.java:96)&lt;br/&gt;
	at org.apache.mahout.classifier.df.mapreduce.Builder.build(Builder.java:312)&lt;br/&gt;
	at org.apache.mahout.classifier.df.mapreduce.BuildForest.buildForest(BuildForest.java:246)&lt;br/&gt;
	at org.apache.mahout.classifier.df.mapreduce.BuildForest.run(BuildForest.java:200)&lt;br/&gt;
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)&lt;br/&gt;
	at org.apache.mahout.classifier.df.mapreduce.BuildForest.main(BuildForest.java:270)&lt;br/&gt;
Caused by: java.io.EOFException&lt;br/&gt;
	at java.io.DataInputStream.readFully(DataInputStream.java:180)&lt;br/&gt;
	at java.io.DataInputStream.readLong(DataInputStream.java:399)&lt;br/&gt;
	at java.io.DataInputStream.readDouble(DataInputStream.java:451)&lt;br/&gt;
	at org.apache.mahout.classifier.df.node.Leaf.readFields(Leaf.java:136)&lt;br/&gt;
	at org.apache.mahout.classifier.df.node.Node.read(Node.java:85)&lt;br/&gt;
	at org.apache.mahout.classifier.df.mapreduce.MapredOutput.readFields(MapredOutput.java:64)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Reader.getCurrentValue(SequenceFile.java:2114)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:2242)&lt;br/&gt;
	at org.apache.mahout.common.iterator.sequencefile.SequenceFileIterator.computeNext(SequenceFileIterator.java:95)&lt;br/&gt;
	... 10 more&lt;/p&gt;

&lt;p&gt;What&apos;s the problem?&lt;br/&gt;
You can try to write something more in the leaves of the tree? Anything.&lt;/p&gt;

&lt;p&gt;Thank you very much.&lt;/p&gt;

&lt;p&gt;Best regards,&lt;/p&gt;

&lt;p&gt;Sara&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12426196">MAHOUT-122</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12416095" name="partial_August_10.patch" size="348925" author="adeneche" created="Mon, 10 Aug 2009 19:16:25 +0100"/>
                            <attachment id="12416457" name="partial_August_13.patch" size="330084" author="adeneche" created="Thu, 13 Aug 2009 17:17:04 +0100"/>
                            <attachment id="12416667" name="partial_August_15.patch" size="332938" author="adeneche" created="Sat, 15 Aug 2009 19:21:39 +0100"/>
                            <attachment id="12416756" name="partial_August_17.patch" size="329794" author="adeneche" created="Mon, 17 Aug 2009 09:33:38 +0100"/>
                            <attachment id="12417040" name="partial_August_19.patch" size="397577" author="adeneche" created="Wed, 19 Aug 2009 18:36:35 +0100"/>
                            <attachment id="12415296" name="partial_August_2.patch" size="332523" author="adeneche" created="Sun, 2 Aug 2009 19:40:35 +0100"/>
                            <attachment id="12417459" name="partial_August_24.patch" size="418079" author="adeneche" created="Mon, 24 Aug 2009 10:38:25 +0100"/>
                            <attachment id="12418056" name="partial_August_27.patch" size="457064" author="adeneche" created="Sat, 29 Aug 2009 10:59:05 +0100"/>
                            <attachment id="12418124" name="partial_August_31.patch" size="458121" author="adeneche" created="Mon, 31 Aug 2009 08:49:42 +0100"/>
                            <attachment id="12415991" name="partial_August_9.patch" size="339940" author="adeneche" created="Sun, 9 Aug 2009 10:30:11 +0100"/>
                            <attachment id="12419638" name="partial_Sep_15.patch" size="458923" author="adeneche" created="Tue, 15 Sep 2009 15:42:20 +0100"/>
                            <attachment id="12420881" name="partial_Sep_30.patch" size="194251" author="adeneche" created="Wed, 30 Sep 2009 06:34:01 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>12.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 12 Jul 2009 18:53:04 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9920</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hxy6xb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23273</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>