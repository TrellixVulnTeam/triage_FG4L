<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:24:40 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-1603/MAHOUT-1603.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-1603] Tweaks for Spark 1.0.x </title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-1603</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;p&gt;Tweaks necessary current codebase on top of spark 1.0.x&lt;/p&gt;</description>
                <environment></environment>
        <key id="12731879">MAHOUT-1603</key>
            <summary>Tweaks for Spark 1.0.x </summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/task.png">Task</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dlyubimov">Dmitriy Lyubimov</assignee>
                                    <reporter username="dlyubimov">Dmitriy Lyubimov</reporter>
                        <labels>
                            <label>DSL</label>
                            <label>scala</label>
                            <label>spark</label>
                    </labels>
                <created>Mon, 4 Aug 2014 23:13:38 +0100</created>
                <updated>Mon, 13 Apr 2015 11:22:04 +0100</updated>
                            <resolved>Fri, 6 Mar 2015 01:32:17 +0000</resolved>
                                    <version>0.9</version>
                                    <fixVersion>0.10.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="14085509" author="githubbot" created="Tue, 5 Aug 2014 00:42:32 +0100"  >&lt;p&gt;GitHub user dlyubimov opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1603&quot; title=&quot;Tweaks for Spark 1.0.x &quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1603&quot;&gt;&lt;del&gt;MAHOUT-1603&lt;/del&gt;&lt;/a&gt;: Tweaks for Spark 1.0.x&lt;/p&gt;

&lt;p&gt;    For folks who (like me) got tired of waiting for Mahout data frames support and would like to run Spark SQL expressions directly in the Mahout Spark shell. &lt;/p&gt;

&lt;p&gt;    (you can thank me later)&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/dlyubimov/mahout&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/dlyubimov/mahout&lt;/a&gt; spark-1.0.x&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #40&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 13e909b58eaa89e212415318655dbe82ef982323&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   2014-08-04T22:00:59Z&lt;/p&gt;

&lt;p&gt;    Initial migration.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="14086975" author="githubbot" created="Wed, 6 Aug 2014 00:33:43 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51274951&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51274951&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    itemsimilarity driver stuff is failing on this. &lt;/p&gt;

&lt;p&gt;    ItemSimilarityDriverSuite:&lt;br/&gt;
    113754 &lt;span class=&quot;error&quot;&gt;&amp;#91;ScalaTest-main-running-ItemSimilarityDriverSuite&amp;#93;&lt;/span&gt; DEBUG org.apache.mahout.sparkbindings.blas.AtA$  - Applying slim A&apos;A.&lt;br/&gt;
    114171 &lt;span class=&quot;error&quot;&gt;&amp;#91;ScalaTest-main-running-ItemSimilarityDriverSuite&amp;#93;&lt;/span&gt; DEBUG org.apache.mahout.sparkbindings.blas.AtB$  - A and B for A&apos;B are not identically partitioned, performing inner join.&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ItemSimilarityDriver, non-full-spec CSV *** FAILED ***&lt;br/&gt;
      Set(iphone    galaxy:1.7260924347106847,iphone:1.7260924347106847,ipad:0.6795961471815897,nexus:0.6795961471815897, surface   surface:4.498681156950466, nexus        iphone:1.7260924347106847,ipad:0.6795961471815897,surface:0.6795961471815897,nexus:0.6795961471815897,galaxy:1.7260924347106847, ipad   galaxy:1.7260924347106847,iphone:1.7260924347106847,ipad:0.6795961471815897,nexus:0.6795961471815897, galaxy    galaxy:1.7260924347106847,iphone:1.7260924347106847,ipad:0.6795961471815897,nexus:0.6795961471815897) did not equal Set(nexus   nexus:0.6795961471815897,iphone:1.7260924347106847,ipad:0.6795961471815897,surface:0.6795961471815897,galaxy:1.7260924347106847, ipad   nexus:0.6795961471815897,iphone:1.7260924347106847,ipad:0.6795961471815897,galaxy:1.7260924347106847, surface   surface:4.498681156950466, iphone       nexus:0.6795961471815897,iphone:1.7260924347106847,ipad:0.6795961471815897,galaxy:1.7260924347106847, galaxy    nexus:0.6795961471815897,iphone:1.7260924347106847,ipad:0.6795961471815897,galaxy:1.7260924347106847) (ItemSimilarityDriverSuite.scala:142)                                     &lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;    the rest seems to pass&lt;/p&gt;</comment>
                            <comment id="14086989" author="githubbot" created="Wed, 6 Aug 2014 00:50:36 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51276205&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51276205&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    also, tests run much slower although cpu remains unsaturated. Something about setting up and tearing down local spark context ???&lt;/p&gt;</comment>
                            <comment id="14088160" author="githubbot" created="Wed, 6 Aug 2014 21:06:57 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51389335&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51389335&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @pferrel perhaps you could look at ItemSimilaritySuite, it doesn&apos;t work on spark 1.0 here? I disabled the tests for now since they are failing.&lt;/p&gt;</comment>
                            <comment id="14088427" author="githubbot" created="Wed, 6 Aug 2014 23:55:52 +0100"  >&lt;p&gt;Github user pferrel commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51408987&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51408987&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Sorry was off the internet during a move (curse you giant nameless cable company!)&lt;/p&gt;

&lt;p&gt;    Anyway these tests are substantially changed in &lt;a href=&quot;https://github.com/apache/mahout/pull/36&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/36&lt;/a&gt; but I haven&apos;t been able to get the new build until now, will check and push 36 first.&lt;/p&gt;

&lt;p&gt;    As to building and tearing down contexts I&apos;m not helping things. For each driver test DistributedSparkSuite in the beforeEach creates a context so I use that to start the test. Then the driver I am using needs to start a context so for every time I call a driver I precede it with the &quot;afterEach&quot; call to shut down the context. Then call the driver, then call &quot;beforeEach&quot; to restore the test context. I also had to tell the driver in a special invisible option not to load Mahout jars with a &quot;--dontAddMahoutJars&quot;. So the context is being built 3 times for every test. but that hasn&apos;t changed, it&apos;s always been that way.&lt;/p&gt;

&lt;p&gt;    We could reuse a single context per test but it would require disabling some stuff in the driver along the lines of what I had to do with &quot;--dontAddMahoutJars&quot;. Since I&apos;ve already had to do this I don&apos;t think it would be a big deal to disable a little more. I&apos;ll look at it once 36 is pushed.&lt;/p&gt;

&lt;p&gt;    Is there any reason to build the context more than once per suite? Seems like if I disable the context things in the driver we could run all tests in a single context, right?&lt;/p&gt;</comment>
                            <comment id="14088433" author="githubbot" created="Thu, 7 Aug 2014 00:01:27 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51409540&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51409540&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    On Wed, Aug 6, 2014 at 3:55 PM, Pat Ferrel &amp;lt;notifications@github.com&amp;gt; wrote:&lt;/p&gt;

&lt;p&gt;    &amp;gt; Sorry was off the internet during a move (curse you giant nameless cable&lt;br/&gt;
    &amp;gt; company!)&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt; Anyway these tests are substantially changed in #36&lt;br/&gt;
    &amp;gt; &amp;lt;&lt;a href=&quot;https://github.com/apache/mahout/pull/36&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/36&lt;/a&gt;&amp;gt; but I haven&apos;t been able to get&lt;br/&gt;
    &amp;gt; the new build until now, will check and push 36 first.&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt; As to building and tearing down contexts I&apos;m not helping things. For each&lt;br/&gt;
    &amp;gt; driver test DistributedSparkSuite in the beforeEach creates a context so I&lt;br/&gt;
    &amp;gt; use that to start the test. Then the driver I am using needs to start a&lt;br/&gt;
    &amp;gt; context so for every time I call a driver I precede it with the &quot;afterEach&quot;&lt;br/&gt;
    &amp;gt; call to shut down the context. Then call the driver, then call &quot;beforeEach&quot;&lt;br/&gt;
    &amp;gt; to restore the test context. I also had to tell the driver in a special&lt;br/&gt;
    &amp;gt; invisible option not to load Mahout jars with a &quot;--dontAddMahoutJars&quot;. So&lt;br/&gt;
    &amp;gt; the context is being built 3 times for every test. but that hasn&apos;t changed,&lt;br/&gt;
    &amp;gt; it&apos;s always been that way.&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt; We could reuse a single context per test but it would require disabling&lt;br/&gt;
    &amp;gt; some stuff in the driver along the lines of what I had to do with&lt;br/&gt;
    &amp;gt; &quot;--dontAddMahoutJars&quot;. Since I&apos;ve already had to do this I don&apos;t think it&lt;br/&gt;
    &amp;gt; would be a big deal to disable a little more. I&apos;ll look at it once 36 is&lt;br/&gt;
    &amp;gt; pushed.&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt; Is there any reason to build the context more than once per suite?&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    Usually, there&apos;s not and that&apos;s exactly what this branch is moving towards&lt;br/&gt;
    (note: this PR is not against master but to  to a side branch called&lt;br/&gt;
    `spark-1.0.x`).&lt;br/&gt;
    Also that&apos;s what they seem to have done in Spark 1.0 as well.&lt;/p&gt;

&lt;p&gt;    There are sometimes (in my other projects) a need to create a custom&lt;br/&gt;
    context but not in Mahout codebase.&lt;/p&gt;


&lt;p&gt;    &amp;gt; Seems like if I disable the context things in the driver we could run all&lt;br/&gt;
    &amp;gt; tests in a single context, right?&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    Right. This branch has already switched to doing that. All algebra tests&lt;br/&gt;
    seem to be fine but these tests are failing now. not sure why. seems&lt;br/&gt;
    functional to me.&lt;/p&gt;

&lt;p&gt;    &amp;gt; &#8212;&lt;br/&gt;
    &amp;gt; Reply to this email directly or view it on GitHub&lt;br/&gt;
    &amp;gt; &amp;lt;&lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51408987&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51408987&lt;/a&gt;&amp;gt;.&lt;br/&gt;
    &amp;gt;&lt;/p&gt;</comment>
                            <comment id="14088443" author="githubbot" created="Thu, 7 Aug 2014 00:11:24 +0100"  >&lt;p&gt;Github user pferrel commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51410370&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51410370&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    OK so DistributedSparkSuite moved the create context into the beforeAll?&lt;/p&gt;</comment>
                            <comment id="14088452" author="githubbot" created="Thu, 7 Aug 2014 00:14:03 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51410605&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51410605&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;gt; OK so DistributedSparkSuite moved the create context into the beforeAll?&lt;/p&gt;

&lt;p&gt;    on this branch, yes.&lt;/p&gt;</comment>
                            <comment id="14088486" author="githubbot" created="Thu, 7 Aug 2014 00:56:30 +0100"  >&lt;p&gt;Github user pferrel commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51413783&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51413783&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Do you want to push this with the &quot;ignore&quot;s and I&apos;ll fix them to use the new DistributedSparkSuite as it gets into the master?&lt;/p&gt;

&lt;p&gt;    BTW any reason we aren&apos;t doing Scala 2.11 since we are upping to Java 7 and Spark 1? &lt;/p&gt;</comment>
                            <comment id="14088506" author="githubbot" created="Thu, 7 Aug 2014 01:19:07 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51415419&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51415419&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    On Wed, Aug 6, 2014 at 4:56 PM, Pat Ferrel &amp;lt;notifications@github.com&amp;gt; wrote:&lt;/p&gt;

&lt;p&gt;    &amp;gt; Do you want to push this with the &quot;ignore&quot;s and I&apos;ll fix them to use the&lt;br/&gt;
    &amp;gt; new DistributedSparkSuite as it gets into the master?&lt;br/&gt;
    &amp;gt;&lt;/p&gt;

&lt;p&gt;    No i probably don&apos;t want ot merge it with non-working tests. As usual, i&lt;br/&gt;
    can add you as collaborator in my account (if i have not yet done so) so&lt;br/&gt;
    you could push directly to my source branch of this (so it reflects in the&lt;br/&gt;
    PR instantaniously) or you can PR against my spark 1.0.x branch, or you can&lt;br/&gt;
    just send me a regular git patch with email, whichever works.&lt;/p&gt;

&lt;p&gt;    &amp;gt; BTW any reason we aren&apos;t doing Scala 2.11 since we are upping to Java 7&lt;br/&gt;
    &amp;gt; and Spark 1?&lt;br/&gt;
    &amp;gt;&lt;/p&gt;

&lt;p&gt;    The reason Scala is fixed where it is fixed is because it is paired to&lt;br/&gt;
    Spark&apos;s version of Scala. Migration between major versions of Scala is a&lt;br/&gt;
    big deal, for Spark and otherwise. Stuff will not work. Minor version of&lt;br/&gt;
    Scala should be generally portable.&lt;/p&gt;



&lt;p&gt;    &amp;gt;  &#8212;&lt;br/&gt;
    &amp;gt; Reply to this email directly or view it on GitHub&lt;br/&gt;
    &amp;gt; &amp;lt;&lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51413783&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51413783&lt;/a&gt;&amp;gt;.&lt;br/&gt;
    &amp;gt;&lt;/p&gt;</comment>
                            <comment id="14088513" author="githubbot" created="Thu, 7 Aug 2014 01:20:06 +0100"  >&lt;p&gt;Github user avati commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51415479&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51415479&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Scala 2.11 port of Spark is in progress &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-1812&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-1812&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14088517" author="githubbot" created="Thu, 7 Aug 2014 01:22:11 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51415624&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51415624&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    sure. there&apos;re tons of stuff in progress but we can only use released&lt;br/&gt;
    artifact as dependencies.&lt;/p&gt;


&lt;p&gt;    On Wed, Aug 6, 2014 at 5:19 PM, Anand Avati &amp;lt;notifications@github.com&amp;gt;&lt;br/&gt;
    wrote:&lt;/p&gt;

&lt;p&gt;    &amp;gt; Scala 2.11 port of Spark is in progress [&lt;br/&gt;
    &amp;gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-1812&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-1812&lt;/a&gt;]&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt; &#8212;&lt;br/&gt;
    &amp;gt; Reply to this email directly or view it on GitHub&lt;br/&gt;
    &amp;gt; &amp;lt;&lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51415479&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51415479&lt;/a&gt;&amp;gt;.&lt;br/&gt;
    &amp;gt;&lt;/p&gt;</comment>
                            <comment id="14088520" author="githubbot" created="Thu, 7 Aug 2014 01:23:05 +0100"  >&lt;p&gt;Github user avati commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51415697&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51415697&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Only meant FYI (in case someone is planning anything). Of course we have to wait for release.&lt;/p&gt;</comment>
                            <comment id="14088526" author="githubbot" created="Thu, 7 Aug 2014 01:27:48 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51416019&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51416019&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    alternatively, you can also just give me a verbal hint what i need to fix,&lt;br/&gt;
    and i can try to patch to the best of my ability.&lt;/p&gt;


&lt;p&gt;    On Wed, Aug 6, 2014 at 5:18 PM, Dmitriy Lyubimov &amp;lt;dlieu.7@gmail.com&amp;gt; wrote:&lt;/p&gt;

&lt;p&gt;    &amp;gt;&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt; On Wed, Aug 6, 2014 at 4:56 PM, Pat Ferrel &amp;lt;notifications@github.com&amp;gt;&lt;br/&gt;
    &amp;gt; wrote:&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt;&amp;gt; Do you want to push this with the &quot;ignore&quot;s and I&apos;ll fix them to use the&lt;br/&gt;
    &amp;gt;&amp;gt; new DistributedSparkSuite as it gets into the master?&lt;br/&gt;
    &amp;gt;&amp;gt;&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt; No i probably don&apos;t want ot merge it with non-working tests. As usual, i&lt;br/&gt;
    &amp;gt; can add you as collaborator in my account (if i have not yet done so) so&lt;br/&gt;
    &amp;gt; you could push directly to my source branch of this (so it reflects in the&lt;br/&gt;
    &amp;gt; PR instantaniously) or you can PR against my spark 1.0.x branch, or you can&lt;br/&gt;
    &amp;gt; just send me a regular git patch with email, whichever works.&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt;&amp;gt; BTW any reason we aren&apos;t doing Scala 2.11 since we are upping to Java 7&lt;br/&gt;
    &amp;gt;&amp;gt; and Spark 1?&lt;br/&gt;
    &amp;gt;&amp;gt;&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt; The reason Scala is fixed where it is fixed is because it is paired to&lt;br/&gt;
    &amp;gt; Spark&apos;s version of Scala. Migration between major versions of Scala is a&lt;br/&gt;
    &amp;gt; big deal, for Spark and otherwise. Stuff will not work. Minor version of&lt;br/&gt;
    &amp;gt; Scala should be generally portable.&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt;&amp;gt;  &#8212;&lt;br/&gt;
    &amp;gt;&amp;gt; Reply to this email directly or view it on GitHub&lt;br/&gt;
    &amp;gt;&amp;gt; &amp;lt;&lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51413783&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51413783&lt;/a&gt;&amp;gt;.&lt;br/&gt;
    &amp;gt;&amp;gt;&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt;&lt;/p&gt;</comment>
                            <comment id="14088538" author="githubbot" created="Thu, 7 Aug 2014 01:44:36 +0100"  >&lt;p&gt;Github user pferrel commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51417124&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51417124&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Ok, I just pushed the new tests, maybe they work. Don&apos;t laugh it could happen.&lt;/p&gt;

&lt;p&gt;    There are likely to be problems with my calling afterEach and beforeEach since their meaning has changed. Fixing this will require mods to the driver too I expect and it&apos;ll probably be easier for me to do it.&lt;/p&gt;

&lt;p&gt;    If you are almost ready with this I&apos;ll upgrade to Spark 1.0.1 and grab your branch.&lt;/p&gt;</comment>
                            <comment id="14089599" author="githubbot" created="Thu, 7 Aug 2014 19:50:33 +0100"  >&lt;p&gt;Github user pferrel commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51514939&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51514939&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    made changes to use the test context in the driver and tests seem to complete correctly up to the point they try to read the output file, which does contain the correct results.&lt;/p&gt;

&lt;p&gt;    ```&lt;br/&gt;
        val indicatorLines = mahoutCtx.textFile(OutPath + &quot;/indicator-matrix/part-00000&quot;)&lt;br/&gt;
    ```&lt;/p&gt;

&lt;p&gt;    The part file is created in the driver using ```rdd.saveAsTextFile(dest)```. It seems like something was getting done before by shutting down the context, maybe I need to close the output file(s) (not sure how to do that since it&apos;s created inside the saveAsTextFile call)?&lt;/p&gt;

&lt;p&gt;    ```&lt;br/&gt;
    java.lang.NullPointerException&lt;br/&gt;
    	at org.apache.spark.SparkContext.defaultParallelism(SparkContext.scala:1215)&lt;br/&gt;
    	at org.apache.spark.SparkContext.defaultMinPartitions(SparkContext.scala:1222)&lt;br/&gt;
    	at org.apache.spark.SparkContext.textFile$default$2(SparkContext.scala:456)&lt;br/&gt;
    	at org.apache.mahout.drivers.ItemSimilarityDriverSuite$$anonfun$4.apply$mcV$sp(ItemSimilarityDriverSuite.scala:303)&lt;br/&gt;
    ```&lt;/p&gt;</comment>
                            <comment id="14089609" author="githubbot" created="Thu, 7 Aug 2014 19:58:46 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51515920&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51515920&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @pferrel where are the changes?&lt;/p&gt;</comment>
                            <comment id="14089638" author="githubbot" created="Thu, 7 Aug 2014 20:14:28 +0100"  >&lt;p&gt;Github user pferrel commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51517989&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51517989&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I can&apos;t push them back to you so they are here&lt;br/&gt;
    &lt;a href=&quot;https://github.com/pferrel/mahout/tree/spark-1.0.x&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/pferrel/mahout/tree/spark-1.0.x&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14089645" author="githubbot" created="Thu, 7 Aug 2014 20:19:33 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51518645&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51518645&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    assuming you are on your local branch named spark-1.0.x with your commit on&lt;br/&gt;
    top of mine current head, please execute&lt;br/&gt;
         push git@github.com:dlyubimov/mahout spark-1.0.x&lt;/p&gt;

&lt;p&gt;    this should go thru&lt;/p&gt;


&lt;p&gt;    On Thu, Aug 7, 2014 at 12:13 PM, Pat Ferrel &amp;lt;notifications@github.com&amp;gt;&lt;br/&gt;
    wrote:&lt;/p&gt;

&lt;p&gt;    &amp;gt; I can&apos;t push them back to you so they are here&lt;br/&gt;
    &amp;gt; &lt;a href=&quot;https://github.com/pferrel/mahout/tree/spark-1.0.x&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/pferrel/mahout/tree/spark-1.0.x&lt;/a&gt;&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt; &#8212;&lt;br/&gt;
    &amp;gt; Reply to this email directly or view it on GitHub&lt;br/&gt;
    &amp;gt; &amp;lt;&lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51517989&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51517989&lt;/a&gt;&amp;gt;.&lt;br/&gt;
    &amp;gt;&lt;/p&gt;</comment>
                            <comment id="14089649" author="githubbot" created="Thu, 7 Aug 2014 20:20:33 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51518705&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51518705&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    oh ok, never mind&lt;/p&gt;
</comment>
                            <comment id="14089713" author="githubbot" created="Thu, 7 Aug 2014 21:00:36 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51523570&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51523570&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    ok i guess like you said tests are still failing&lt;/p&gt;


&lt;p&gt;    On Thu, Aug 7, 2014 at 12:18 PM, Dmitriy Lyubimov &amp;lt;dlieu.7@gmail.com&amp;gt; wrote:&lt;/p&gt;

&lt;p&gt;    &amp;gt; assuming you are on your local branch named spark-1.0.x with your commit&lt;br/&gt;
    &amp;gt; on top of mine current head, please execute&lt;br/&gt;
    &amp;gt;      push git@github.com:dlyubimov/mahout spark-1.0.x&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt; this should go thru&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt; On Thu, Aug 7, 2014 at 12:13 PM, Pat Ferrel &amp;lt;notifications@github.com&amp;gt;&lt;br/&gt;
    &amp;gt; wrote:&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt;&amp;gt; I can&apos;t push them back to you so they are here&lt;br/&gt;
    &amp;gt;&amp;gt; &lt;a href=&quot;https://github.com/pferrel/mahout/tree/spark-1.0.x&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/pferrel/mahout/tree/spark-1.0.x&lt;/a&gt;&lt;br/&gt;
    &amp;gt;&amp;gt;&lt;br/&gt;
    &amp;gt;&amp;gt; &#8212;&lt;br/&gt;
    &amp;gt;&amp;gt; Reply to this email directly or view it on GitHub&lt;br/&gt;
    &amp;gt;&amp;gt; &amp;lt;&lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51517989&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51517989&lt;/a&gt;&amp;gt;.&lt;br/&gt;
    &amp;gt;&amp;gt;&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt;&lt;/p&gt;</comment>
                            <comment id="14089737" author="githubbot" created="Thu, 7 Aug 2014 21:11:23 +0100"  >&lt;p&gt;Github user pferrel commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51524833&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51524833&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Wait, I found the problem. I&apos;m closing the context at the end of the driver. I&apos;ll fix it.&lt;/p&gt;</comment>
                            <comment id="14089741" author="githubbot" created="Thu, 7 Aug 2014 21:13:56 +0100"  >&lt;p&gt;Github user pferrel commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51525161&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51525161&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    ok, past the failure. Now I have to do some test cleanup. &lt;/p&gt;</comment>
                            <comment id="14089745" author="githubbot" created="Thu, 7 Aug 2014 21:15:29 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51525329&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51525329&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @pferrel: So one problem with those tests is that they are creating 2 spark&lt;br/&gt;
    sessions. 1 session is created by tests and another session is created by&lt;br/&gt;
    driver.&lt;/p&gt;

&lt;p&gt;    Spark is very strict with this:&lt;/p&gt;

&lt;p&gt;    (1) Spark is not reentrant w.r.t. session creation are non-reentrant (not&lt;br/&gt;
    just thread-unsafe) &amp;#8211; meaning you can only safely have at most 1 session&lt;br/&gt;
    at a time in a jvm.&lt;br/&gt;
    (2) Spark session itself is reentrant &amp;#8211; meaning multiple threads may&lt;br/&gt;
    invoke asynchronous computational actions on the same session.&lt;/p&gt;

&lt;p&gt;    This may not always manifest, but in the end it always will (ask me how i&lt;br/&gt;
    know &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;    so the problem with those tests is that they probably must not be featuring&lt;br/&gt;
    DistributedSparkSuite but rather just MahoutSuite. Or alternatively you may&lt;br/&gt;
    pass an already existing mahoutContext to the driver code for reuse. But&lt;br/&gt;
    you must ensure the above constraint. The effects will range dramatically&lt;br/&gt;
    if not (from mislabeled rdd partitions in the block manager to   lockups&lt;br/&gt;
    and internal race conditions)&lt;/p&gt;


&lt;p&gt;    On Thu, Aug 7, 2014 at 12:59 PM, Dmitriy Lyubimov &amp;lt;dlieu.7@gmail.com&amp;gt; wrote:&lt;/p&gt;

&lt;p&gt;    &amp;gt; ok i guess like you said tests are still failing&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt; On Thu, Aug 7, 2014 at 12:18 PM, Dmitriy Lyubimov &amp;lt;dlieu.7@gmail.com&amp;gt;&lt;br/&gt;
    &amp;gt; wrote:&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt;&amp;gt; assuming you are on your local branch named spark-1.0.x with your commit&lt;br/&gt;
    &amp;gt;&amp;gt; on top of mine current head, please execute&lt;br/&gt;
    &amp;gt;&amp;gt;      push git@github.com:dlyubimov/mahout spark-1.0.x&lt;br/&gt;
    &amp;gt;&amp;gt;&lt;br/&gt;
    &amp;gt;&amp;gt; this should go thru&lt;br/&gt;
    &amp;gt;&amp;gt;&lt;br/&gt;
    &amp;gt;&amp;gt;&lt;br/&gt;
    &amp;gt;&amp;gt; On Thu, Aug 7, 2014 at 12:13 PM, Pat Ferrel &amp;lt;notifications@github.com&amp;gt;&lt;br/&gt;
    &amp;gt;&amp;gt; wrote:&lt;br/&gt;
    &amp;gt;&amp;gt;&lt;br/&gt;
    &amp;gt;&amp;gt;&amp;gt; I can&apos;t push them back to you so they are here&lt;br/&gt;
    &amp;gt;&amp;gt;&amp;gt; &lt;a href=&quot;https://github.com/pferrel/mahout/tree/spark-1.0.x&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/pferrel/mahout/tree/spark-1.0.x&lt;/a&gt;&lt;br/&gt;
    &amp;gt;&amp;gt;&amp;gt;&lt;br/&gt;
    &amp;gt;&amp;gt;&amp;gt; &#8212;&lt;br/&gt;
    &amp;gt;&amp;gt;&amp;gt; Reply to this email directly or view it on GitHub&lt;br/&gt;
    &amp;gt;&amp;gt;&amp;gt; &amp;lt;&lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51517989&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51517989&lt;/a&gt;&amp;gt;.&lt;br/&gt;
    &amp;gt;&amp;gt;&amp;gt;&lt;br/&gt;
    &amp;gt;&amp;gt;&lt;br/&gt;
    &amp;gt;&amp;gt;&lt;br/&gt;
    &amp;gt;&lt;/p&gt;</comment>
                            <comment id="14089760" author="githubbot" created="Thu, 7 Aug 2014 21:23:21 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51526214&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51526214&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Btw your handling of temporary directory is quite to the point, you may quite possibly make it part of MahoutSuite. Then i have one other place that may use it. Also see similar code in MahoutTest java class for JUnit &amp;#8211; we could just use that i guess.&lt;/p&gt;</comment>
                            <comment id="14089966" author="githubbot" created="Thu, 7 Aug 2014 23:34:11 +0100"  >&lt;p&gt;Github user pferrel commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51541649&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51541649&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    OK, pushed it back to you. The test pass. All drivers and tests share a single context and man are they fast now. Still using DistributedSparkSuite.&lt;/p&gt;

&lt;p&gt;    BTW the tmp dir really needs to be deleted beforeAll and afterEach for convenience not afterAll so I changed that. &lt;/p&gt;</comment>
                            <comment id="14091146" author="githubbot" created="Fri, 8 Aug 2014 19:50:49 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40#issuecomment-51642800&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40#issuecomment-51642800&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    excellent. seems to be working for me. &lt;/p&gt;

&lt;p&gt;    let me squash it and merge to apache/mahout spark_1.0.x. &lt;/p&gt;</comment>
                            <comment id="14091158" author="dlyubimov" created="Fri, 8 Aug 2014 19:59:33 +0100"  >&lt;p&gt;merged to apache/spark-1.0.x branch (here: &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=mahout.git;a=shortlog;h=refs/heads/spark-1.0.x&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=mahout.git;a=shortlog;h=refs/heads/spark-1.0.x&lt;/a&gt;)&lt;/p&gt;</comment>
                            <comment id="14093233" author="githubbot" created="Mon, 11 Aug 2014 21:15:08 +0100"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/40&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/40&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14093397" author="hudson" created="Mon, 11 Aug 2014 23:00:38 +0100"  >&lt;p&gt;FAILURE: Integrated in Mahout-Quality #2739 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2739/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2739/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1603&quot; title=&quot;Tweaks for Spark 1.0.x &quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1603&quot;&gt;&lt;del&gt;MAHOUT-1603&lt;/del&gt;&lt;/a&gt;: Tweaks for Spark 1.0.x (dlyubimov &amp;amp; pferrel) (dlyubimov: rev ee6359f621b508ab7f21df0316941e68c75eb3e5)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/blas/ABtSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/drivers/ItemSimilarityDriver.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/test/DistributedSparkSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/blas/BlasSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/drivers/MahoutOptionParser.scala&lt;/li&gt;
	&lt;li&gt;CHANGELOG&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/drivers/MahoutDriver.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/test/scala/org/apache/mahout/test/LoggerConfiguration.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/blas/AtASuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/blas/AewBSuite.scala&lt;/li&gt;
	&lt;li&gt;pom.xml&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/SparkEngine.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/test/LoggerConfiguration.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/blas/AtSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/drivers/ItemSimilarityDriverSuite.scala&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14349754" author="andrew_palumbo" created="Fri, 6 Mar 2015 01:29:48 +0000"  >&lt;p&gt;this can be closed, right?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 4 Aug 2014 23:42:32 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>409908</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hzsduv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>409902</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>