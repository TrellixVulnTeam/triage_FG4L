<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:26:41 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-1529/MAHOUT-1529.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-1529] Finalize abstraction of distributed logical plans from backend operations</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-1529</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;p&gt;We have a few situations when algorithm-facing API has Spark dependencies creeping in. &lt;/p&gt;

&lt;p&gt;In particular, we know of the following cases:&lt;br/&gt;
&lt;del&gt;(1) checkpoint() accepts Spark constant StorageLevel directly;&lt;/del&gt;&lt;br/&gt;
&lt;del&gt;(2) certain things in CheckpointedDRM;&lt;/del&gt;&lt;br/&gt;
&lt;del&gt;(3) drmParallelize etc. routines in the &quot;drm&quot; and &quot;sparkbindings&quot; package.&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;(5) drmBroadcast returns a Spark-specific Broadcast object&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;(6) Stratosphere/Flink conceptual api changes.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Current tracker:&lt;/b&gt; PR #1 &lt;a href=&quot;https://github.com/apache/mahout/pull/1&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/1&lt;/a&gt; - closed, need new PR for remaining things once ready.&lt;br/&gt;
&lt;b&gt;Pull requests are welcome&lt;/b&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12711103">MAHOUT-1529</key>
            <summary>Finalize abstraction of distributed logical plans from backend operations</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dlyubimov">Dmitriy Lyubimov</assignee>
                                    <reporter username="dlyubimov">Dmitriy Lyubimov</reporter>
                        <labels>
                    </labels>
                <created>Tue, 29 Apr 2014 06:50:25 +0100</created>
                <updated>Mon, 13 Apr 2015 11:21:59 +0100</updated>
                            <resolved>Wed, 28 May 2014 00:40:06 +0100</resolved>
                                                    <fixVersion>0.10.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13984046" author="ssc" created="Tue, 29 Apr 2014 06:54:02 +0100"  >&lt;p&gt;a few more points&lt;/p&gt;

&lt;p&gt;(4) SparkContext must be set as implicit val&lt;br/&gt;
(5) drmBroadcast returns a Spark-specific Broadcast object&lt;/p&gt;</comment>
                            <comment id="13984052" author="dlyubimov" created="Tue, 29 Apr 2014 07:00:10 +0100"  >&lt;p&gt;my thoughts on this: &lt;/p&gt;

&lt;p&gt;(1) factor out DRMLike and logical operators into math-scala module.&lt;br/&gt;
(2) keep spark-specific physical op translations in the spark module.&lt;br/&gt;
(3) create StorageLevel&apos;s verbatim analog in Mahout (this probably needs more careful handling &amp;#8211; needs investigation how it really would map into Stratoshpere, if it all. But assuming for now we want to just walk away from direct Spark dependency in the code, a simple 1:1 translation is probably enough;&lt;br/&gt;
(4) For drmParallelize() etc. set of routines I see really two ways of doing this.&lt;br/&gt;
(4a) wrap engine-specific context into &quot;Either-or&quot; Mahout context. &lt;br/&gt;
(4b) rely on assumption that these routines are not really used in engine-agnostic algorithms, so individual engine will provide semantically identical versions of those by import. At the very least, this will be required for createMahoutContext() call. &lt;br/&gt;
I am really inclined to do (4a) not to lock ourselves into any assuptions except for createMahoutContext() which will have to go into engine-specifc package.&lt;/p&gt;

&lt;p&gt;I will have to think about CheckpointedDRM and CheckpointedDRM$rdd. Maybe the whole CheckpointedDRM also needs to be an engine-specific class. &lt;/p&gt;</comment>
                            <comment id="13984054" author="dlyubimov" created="Tue, 29 Apr 2014 07:02:08 +0100"  >&lt;blockquote&gt;&lt;p&gt;(4) SparkContext must be set as implicit val&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;this was implied in (3)&lt;/p&gt;</comment>
                            <comment id="13986937" author="dlyubimov" created="Thu, 1 May 2014 21:10:40 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ssc&quot; class=&quot;user-hover&quot; rel=&quot;ssc&quot;&gt;Sebastian Schelter&lt;/a&gt; what is the thinking about cache policies? Do we just map it to Spark&apos;s levels? what are considerations w.r.t. Stratoshere here?&lt;/p&gt;</comment>
                            <comment id="13986951" author="ssc" created="Thu, 1 May 2014 21:28:01 +0100"  >&lt;p&gt;I&apos;ll ask the Stratosphere guys to have a look&lt;/p&gt;</comment>
                            <comment id="13986954" author="dlyubimov" created="Thu, 1 May 2014 21:32:57 +0100"  >&lt;p&gt;I guess there&apos;s no concept of intermediate caching at all. Intstead, i guess, there&apos;s a possibility that stuff like writeDRM() is not triggering a computational action which always has to be triggered explicitly. &lt;/p&gt;

&lt;p&gt;Hm. how do we reconcile that.&lt;/p&gt;</comment>
                            <comment id="13986959" author="ssc" created="Thu, 1 May 2014 21:37:52 +0100"  >&lt;p&gt;In Stratosphere the optimizer makes the decision what to put in memory or on disk at what point. So there is no explicit caching, but nevertheless programs could have that and Stratosphere would use it as a hint to the optimizer. I asked on the newly established stratosphere dev list for someone to have a look at this issue.&lt;/p&gt;</comment>
                            <comment id="13986964" author="dlyubimov" created="Thu, 1 May 2014 21:42:21 +0100"  >&lt;p&gt;yes i figured as much. Multiple sinks are defined, and then the optimizer there just goes over what we were trying to do with collapsing common paths or something like that.&lt;/p&gt;

&lt;p&gt;This is actually pretty cool. However, it does pose a conundrum of reconciling with current semantics.&lt;/p&gt;</comment>
                            <comment id="13986981" author="dlyubimov" created="Thu, 1 May 2014 21:53:00 +0100"  >&lt;p&gt;first idea is that we introduce and require an explicit computational action operator, something like drmExecute(implicit ctx) that would force computation in stratosphere, and in case of spark, be ignored. &lt;/p&gt;

&lt;p&gt;Similarly, cache instructions would just be ignored for Stratosphere.&lt;/p&gt;

&lt;p&gt;Generally, coarse-iterative algorithms (&amp;lt;50 iterations &amp;#8211; ALS, ssvd) could just ignore drmExecute() api altogether, leaving it for the caller to execute.&lt;/p&gt;</comment>
                            <comment id="13987426" author="ssc" created="Fri, 2 May 2014 07:26:56 +0100"  >&lt;p&gt;Why would we need that explicit execute operator for Stratosphere? &lt;/p&gt;</comment>
                            <comment id="13987443" author="avati" created="Fri, 2 May 2014 07:48:41 +0100"  >&lt;p&gt;Some thoughts -&lt;/p&gt;

&lt;p&gt;As an algo implementor, does one really care about platform specific details like checkpoint(mem) vs checkpoint(disk) vs cache() etc.? would it not be enough to present one generic call, like .materialize() which would either trigger the computation in the physical layer (or give it a hint)? For persistence, why not just have the explicit .writeDRM() and be done? So as an API consumer there is:&lt;/p&gt;

&lt;p&gt;.materialize() &amp;#8211; (trigger optimizer and computation, thereby avoiding future duplicate evaluations, translates to .checkpoint(MEM) in spark for e.g).&lt;br/&gt;
.writeDRM(filename) &amp;#8211; serialize computed DRM to persistence store (implies materialization if not already)&lt;/p&gt;</comment>
                            <comment id="13987450" author="ssc" created="Fri, 2 May 2014 07:58:49 +0100"  >&lt;p&gt;The problem with having a no-arg materialize operator is that our optimizer would have to make the decision how to materialize the data for spark (in-memory, in-memory in a serialized fashion, on disk). I don&apos;t think that we can/should make that decision ourselves. If people run into OOMs with spark we have to give them something to work around that (e.g. allow them to tell the system to use a different storage level).&lt;/p&gt;

&lt;p&gt;What do you think about keeping those storagelevels, but interpret them as hints to the underlying system, which indicates to the user that the system might make a (hopefully) smarter decision, e.g. something like&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;drm.cache(CacheHint.IN_MEMORY)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="13988088" author="dlyubimov" created="Fri, 2 May 2014 19:51:59 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=avati&quot; class=&quot;user-hover&quot; rel=&quot;avati&quot;&gt;Anand Avati&lt;/a&gt; the use patterns of optimizer checkpoints are discussed at length in my talk. Two basics use cases are explicit management of cache policies and common computational path. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ssc&quot; class=&quot;user-hover&quot; rel=&quot;ssc&quot;&gt;Sebastian Schelter&lt;/a&gt; &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Why would we need that explicit execute operator for Stratosphere?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Correct me if i am reading Stratosphere wrong. (I still haven&apos;t run a single program on it, please forgive me being a bit superficial here). Stratosphere programming api implies that we may define more than 1 sink in the graph (i.e. writeDRM() calls) without triggering computational action.  How would we trigger it if sink definitions such as writeDRM don&apos;t trigger it anymore?&lt;/p&gt;

&lt;p&gt;Also not clear with collect() stuff, i guess it doesn&apos;t have a direct mapping either until Stephan finishes his promised piece on it.&lt;/p&gt;

&lt;p&gt;-d&lt;/p&gt;</comment>
                            <comment id="13988486" author="avati" created="Sat, 3 May 2014 01:33:44 +0100"  >&lt;p&gt;I think we also need&lt;/p&gt;

&lt;p&gt;(6) Rename mahout spark-shell (both command and source dir/files/variables) to &quot;mahout shell&quot; (or mahout console?) which only uses the logical layer and backend layer is selected at runtime/startup.&lt;/p&gt;

&lt;p&gt;Should this be a separate JIRA? It has an overlap with this JIRA I think.&lt;/p&gt;</comment>
                            <comment id="13988493" author="dlyubimov" created="Sat, 3 May 2014 01:43:05 +0100"  >&lt;blockquote&gt;&lt;p&gt;I think we also need&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;(6) Rename mahout spark-shell (both command and source dir/files/variables) to &quot;mahout shell&quot; (or mahout console?) which only uses the logical layer and backend layer is selected at runtime/startup.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No, we don&apos;t . Shell is in essense Spark&apos;s REPL. in that sense it is exactly and literally spark-shell. It includes byte code mechanisms to compile closures on-the-fly and pass them to the backend. &lt;/p&gt;

&lt;p&gt;How other engines would want to do that, i have no clue. Chances for a generic (and cheap) Mahout shell are very slim IMO.&lt;/p&gt;</comment>
                            <comment id="13988495" author="avati" created="Sat, 3 May 2014 01:47:55 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dlyubimov&quot; class=&quot;user-hover&quot; rel=&quot;dlyubimov&quot;&gt;Dmitriy Lyubimov&lt;/a&gt;, are you actively working on this separation? I had started the separation work, and if you are actively working on this I will abandon my effort.&lt;/p&gt;</comment>
                            <comment id="13988497" author="dlyubimov" created="Sat, 3 May 2014 01:51:54 +0100"  >&lt;p&gt;IMO this doesn&apos;t tolerate haste. This is very conceptual. I won&apos;t commit anything until we have finished discussion on the things i outlined for Stratosphere.&lt;/p&gt;

&lt;p&gt;There are little items that i may commit soon (such as wrapping up context and cache manager). &lt;/p&gt;

&lt;p&gt;I think the best mode to work this issue is to create a github side branch and keep squash-committing it little by little while handling little additions via pull request. &lt;/p&gt;

&lt;p&gt;BTW I truly envy the Spark process which is 100% handled by github pull requests. Does anybody knows how they manage to push it back to Apache from there?&lt;/p&gt;</comment>
                            <comment id="13988500" author="dlyubimov" created="Sat, 3 May 2014 01:56:27 +0100"  >&lt;p&gt;tracking here &lt;a href=&quot;https://github.com/dlyubimov/mahout-commits/tree/MAHOUT-1529&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/dlyubimov/mahout-commits/tree/MAHOUT-1529&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13988501" author="avati" created="Sat, 3 May 2014 01:59:01 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dlyubimov&quot; class=&quot;user-hover&quot; rel=&quot;dlyubimov&quot;&gt;Dmitriy Lyubimov&lt;/a&gt;, the purpose of the spark-shell, AFAICT, is to present and interactive interface to work on the DSL. To that end, there is little reason to use the Spark REPL for the purpose.. we could use a vanilla Scala REPL with DSL and operators pre-loaded (imported). And this should work just as fine with Spark, as using the Spark REPL. Doesn&apos;t that feel much cleaner?&lt;/p&gt;</comment>
                            <comment id="13988508" author="dlyubimov" created="Sat, 3 May 2014 02:13:44 +0100"  >&lt;p&gt;yes it&apos;s cleaner but it is not even clear if it is achievable, and if it is, it is expensive. Like i said, you are welcome to try &amp;#8211; if it works with Spark identically to REPL, there will be no arguments not to use it in favor of REPL. &lt;/p&gt;

&lt;p&gt;But my budget on this is very limited, so it is not most pragmatical path for me to get things done.&lt;/p&gt;

&lt;p&gt;Bottom line, for today something that works today beats something hypothetical. &lt;/p&gt;</comment>
                            <comment id="13988511" author="avati" created="Sat, 3 May 2014 02:21:20 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dlyubimov&quot; class=&quot;user-hover&quot; rel=&quot;dlyubimov&quot;&gt;Dmitriy Lyubimov&lt;/a&gt;, by more &quot;expensive&quot;, I assume (and hope) you (only) mean expensive for you in terms of time. Or did you mean expensive in some other way? I am willing to investigate the feasibility - I always intended to mean that. The question really was, do you think it is relevant enough to the same JIRA or worthy of a new one?&lt;/p&gt;</comment>
                            <comment id="13988516" author="dlyubimov" created="Sat, 3 May 2014 02:25:28 +0100"  >&lt;p&gt;it is expensive for anybody&apos;s time (compared to REPL adaptation). I certainly won&apos;t try to do it at this point. If you want to do it, yes, please file a new jira.&lt;/p&gt;

&lt;p&gt;Also, REPL cannot be used with mahout as is. So yes, it is well warranted what we did. &lt;/p&gt;

&lt;p&gt;I am not sure about re-branding, we did too little to warrant that indeed, but REPL can&apos;t work with Mahout, or at the very least it is awkward to do so manually (i.e. tracing all mahout jar dependencies, add them to session and make sure all proper imports are done).&lt;/p&gt;


</comment>
                            <comment id="13988621" author="tdunning" created="Sat, 3 May 2014 09:43:41 +0100"  >&lt;blockquote&gt;
&lt;p&gt;BTW I truly envy the Spark process which is 100% handled by github pull requests. Does anybody knows how they manage to push it back to Apache from there?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It would require that we switch over to git for the main mahout repo.&lt;/p&gt;

&lt;p&gt;If we want to discuss that, we should move to a separate thread.&lt;/p&gt;</comment>
                            <comment id="13988626" author="ssc" created="Sat, 3 May 2014 10:05:15 +0100"  >&lt;p&gt;I just know that it was discussed during their graduation. We could &lt;br/&gt;
simply ask on their mailinglist how they do it.&lt;/p&gt;

&lt;p&gt;--sebastian&lt;/p&gt;

</comment>
                            <comment id="13990002" author="avati" created="Mon, 5 May 2014 22:34:55 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dlyubimov&quot; class=&quot;user-hover&quot; rel=&quot;dlyubimov&quot;&gt;Dmitriy Lyubimov&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ssc&quot; class=&quot;user-hover&quot; rel=&quot;ssc&quot;&gt;Sebastian Schelter&lt;/a&gt;, would appreciate comments/reviews on the shell separation patch at &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1544&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/MAHOUT-1544&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13991495" author="hudson" created="Wed, 7 May 2014 03:50:18 +0100"  >&lt;p&gt;FAILURE: Integrated in Mahout-Quality #2606 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2606/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2606/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt;: completely abstracting away dssvd, dspca and dqr: introducing CacheHint enum&lt;/p&gt;

&lt;p&gt;Squashed commit of the following:&lt;/p&gt;

&lt;p&gt;commit 6c4bf1650f0e87d0d1fc5b9b23c94f6e3553b74d&lt;br/&gt;
Merge: a748e8b 0c5a754&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   Tue May 6 18:20:36 2014 -0700&lt;/p&gt;

&lt;p&gt;    Merge branch &apos;trunk&apos; into &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;commit a748e8b8be2ad7ce44af231147b236726704b561&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   Tue May 6 18:19:35 2014 -0700&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt;: completely abstracting away dssvd, dspca and dqr: introducing CacheHint enum (dlyubimov: rev 1592933)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/decompositions/DSPCA.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/decompositions/DSSVD.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CacheHint.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CheckpointedDrmBase.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/DrmLike.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/package.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/CheckpointAction.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/decompositions/MathSuite.scala&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/spark/src/test/scala/org/apache/mahout/sparkbindings/drm/RLikeDrmOpsSuite.scala&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14000445" author="avati" created="Fri, 16 May 2014 23:55:20 +0100"  >&lt;p&gt;Another thing I notice is that drmBroadcast() returns a raw org.apache.spark.Broadcast variable. I&apos;m thinking a simple wrapper around it to create an abstraction for various backends would be nice. Thoughts?&lt;/p&gt;</comment>
                            <comment id="14000488" author="avati" created="Sat, 17 May 2014 00:21:00 +0100"  >&lt;p&gt;I see drmBroadcast() has already been listed (somehow did not find it last time I saw)&lt;/p&gt;</comment>
                            <comment id="14002651" author="dlyubimov" created="Tue, 20 May 2014 01:48:18 +0100"  >&lt;p&gt;ok i started nudging this a bit forward, did a couple of fairly drastical refactoring, moving api parts to math-scala. math-scala should compile . Decompositions are moved too.&lt;/p&gt;

&lt;p&gt;Things left include moving package-level routines requiring implicit context; fixing spark and spark-shell modules; moving tests where appropriate. &lt;/p&gt;

&lt;p&gt;With tests. a little conundrum is such that we don&apos;t have a &quot;local&quot; engine &amp;#8211; we would use &quot;Spark local&quot; for that, i.e. some concrete engine. So even though decomposition code now completely lives in math-scala with no spark dependencies, it looks like its tests will still have to live in spark module, where unit-testing in local spark mode is defined. It kinda makes sense, since we probably will want to run MathSuite separately for each engine we add; but is a bit weird since it keeps something like ssvd() and its engine-specific tests apart.&lt;/p&gt;</comment>
                            <comment id="14002743" author="avati" created="Tue, 20 May 2014 04:24:58 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dlyubimov&quot; class=&quot;user-hover&quot; rel=&quot;dlyubimov&quot;&gt;Dmitriy Lyubimov&lt;/a&gt;, I had a quick look at the commits, and it looks a lot cleaner separation now. Some comments:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Should DrmLike really be a generic class like DrmLike&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; where T is unbounded? For e.g, it does not make sense to have DrmLike&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;. The only meaningful ones probably are DrmLike&lt;span class=&quot;error&quot;&gt;&amp;#91;Int&amp;#93;&lt;/span&gt; and DrmLike&lt;span class=&quot;error&quot;&gt;&amp;#91;Double&amp;#93;&lt;/span&gt;. Is there someway we can restrict DrmLike to just Int and Double? Or fixate on just Double? While RDD supports arbitrary T, H2O supports only numeric types which is sufficient for Mahout&apos;s needs.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;UPDATE: I see that historically DRM&apos;s row index need not necessarily be numerical. In practice could this be anything other than a number or string?&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;I am toying around with the new separation, to build a pure/from scratch local/in-memory &quot;backend&quot; which communicates through a ByteArrayStream Java serialization. I am hoping this will not only serve as a reference for future backend implementors, but also help to keep test cases of the algorithms inside math-scala. Thoughts?&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&apos;type DrmTuple&lt;span class=&quot;error&quot;&gt;&amp;#91;k&amp;#93;&lt;/span&gt; = (K, Vector)&apos; is probably better placed in spark/../package.scala I think, as it is really an artifact of how the RDD is defined. However, BlockifiedDrmTuple&lt;span class=&quot;error&quot;&gt;&amp;#91;K&amp;#93;&lt;/span&gt; probably still belongs to math-scala.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14003727" author="dlyubimov" created="Tue, 20 May 2014 18:46:12 +0100"  >&lt;p&gt;DRM is legacy Mahout format inherited from all map reduce solvers. &lt;/p&gt;

&lt;p&gt;Perhaps one of the most popular commands, `seq2sparse`, produces string keys (full document path name in the original corpus). A lot of solvers are agnostic propagators of the keys: SSVD -&amp;gt; U, both MR and DSL versions, so is DSPCA, thinQR, and (I think) current and future versions of factorizes such as ALS. For more examples of what key can be, see &quot;Mahout In Action&quot; &amp;#8211; or bug the authors. Going forward, i am very likely internally use a more involved object structures as a key payload.&lt;/p&gt;

&lt;p&gt;I honestly don&apos;t see value in a separate &quot;local&quot; backend as Spark already provides one. It is very unlikely to be used.&lt;/p&gt;

&lt;p&gt;Tuple definitions don&apos;t depend on Spark, at this point i don&apos;t see a reason to make them engine-specific.&lt;/p&gt;



</comment>
                            <comment id="14007580" author="dlyubimov" created="Fri, 23 May 2014 20:35:40 +0100"  >&lt;p&gt;This is now tracked in github pull request #1 . As far as i understand, patches to this issue require issuing PRs to the origin of this PR (branch &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt;-a in github.com:dlyubimov/mahout fork).&lt;/p&gt;</comment>
                            <comment id="14009980" author="dlyubimov" created="Tue, 27 May 2014 18:52:13 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ssc&quot; class=&quot;user-hover&quot; rel=&quot;ssc&quot;&gt;Sebastian Schelter&lt;/a&gt; (or whomever wants to) could you please take a look at PR #1 on github? I need at least one review to continue. I want to commit it in order not to diverge too much, it will be more difficult the longer i wait. &lt;/p&gt;

&lt;p&gt;This does not finalize issue w.r.t Stratosphere model (especially its multi-sink model) but we can tackle that later once they are closer to what they said they&apos;d do. thanks.&lt;/p&gt;</comment>
                            <comment id="14010108" author="githubbot" created="Tue, 27 May 2014 19:49:16 +0100"  >&lt;p&gt;Github user jfarrell commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/1#issuecomment-44318648&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/1#issuecomment-44318648&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt; not linking to jira as discussed in &lt;a href=&quot;https://issues.apache.org/jira/browse/INFRA-7801&quot; title=&quot;Enable Github integration features for Mahout project&quot; class=&quot;issue-link&quot; data-issue-key=&quot;INFRA-7801&quot;&gt;&lt;del&gt;INFRA-7801&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14010124" author="ssc" created="Tue, 27 May 2014 19:57:01 +0100"  >&lt;p&gt;Hi Dmitriy,&lt;/p&gt;

&lt;p&gt;the PR looks good, +1 from me, go ahead!&lt;/p&gt;

&lt;p&gt;Best,&lt;br/&gt;
Sebastian&lt;/p&gt;

</comment>
                            <comment id="14010174" author="githubbot" created="Tue, 27 May 2014 20:33:10 +0100"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/1&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/1&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14010431" author="hudson" created="Tue, 27 May 2014 23:32:10 +0100"  >&lt;p&gt;SUCCESS: Integrated in Mahout-Quality #2620 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2620/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2620/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt; closes PR #1 (dlyubimov: rev 8714a0f722663ea5cb16c14c5b8a01e57574cd93)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAtAnyKey.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/SparkBCast.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/DrmLikeOps.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/drm/DrmLikeSuite.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpAx.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/CacheHint.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAx.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/CheckpointAction.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/blas/AtA.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CheckpointedDrmSpark.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpRowRange.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpABt.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/BCast.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpAtB.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/DrmRddInput.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/blas/MapBlock.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/RLikeDrmOps.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/blas/AewBSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAtA.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/io/MahoutKryoRegistrator.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/blas/AinCoreB.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/RLikeDrmOps.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/DrmLike.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/DistributedContext.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpAtx.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/SparkDistributedContext.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/blas/AtSuite.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/scalabindings/package.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/drm/DrmLikeOpsSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/test/MahoutLocalContext.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpABAnyKey.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/blas/At.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/AbstractBinaryOp.scala&lt;/li&gt;
	&lt;li&gt;math-scala/pom.xml&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/scalabindings/decompositions/SSVD.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/SparkEngine.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CacheHint.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/package.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpAB.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/blas/ABtSuite.scala&lt;/li&gt;
	&lt;li&gt;spark-shell/src/main/scala/org/apache/mahout/sparkbindings/shell/MahoutSparkILoop.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/DrmLike.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAtB.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/AbstractBinaryOp.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/drm/RLikeDrmOpsSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpTimesRightMatrix.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/decompositions/DQR.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAewB.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/CheckpointedOps.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpABAnyKey.scala&lt;/li&gt;
	&lt;li&gt;spark-shell/src/main/scala/org/apache/mahout/sparkbindings/shell/Main.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CheckpointedDrm.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/CheckpointAction.scala&lt;/li&gt;
	&lt;li&gt;spark-shell/src/test/mahout/simple.mscala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpABt.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAewScalar.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpAtAnyKey.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/blas/Slicing.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/decompositions/DSPCA.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/decompositions/MathSuite.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpAt.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CheckpointedDrmSparkOps.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpMapBlock.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAtx.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/decompositions/DSSVD.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/decompositions/DQR.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/blas/package.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpAewScalar.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/blas/AtASuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/blas/DrmRddOps.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/blas/AewB.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAt.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CheckpointedOps.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/AbstractUnaryOp.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/package.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/package.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/blas/ABt.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/scalabindings/SSVD.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpTimesLeftMatrix.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpMapBlock.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/decompositions/DSPCA.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/package.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CheckpointedDrmBase.scala&lt;/li&gt;
	&lt;li&gt;spark/pom.xml&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/decompositions/DSSVD.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpAB.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/OpRowRange.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/DrmLikeOps.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/CheckpointedDrm.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/blas/Ax.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpTimesLeftMatrix.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpAewB.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/DistributedEngine.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/blas/AtB.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/plan/AbstractUnaryOp.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpTimesRightMatrix.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpAtA.scala&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14014985" author="gokhancapan" created="Sun, 1 Jun 2014 14:55:30 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dlyubimov&quot; class=&quot;user-hover&quot; rel=&quot;dlyubimov&quot;&gt;Dmitriy Lyubimov&lt;/a&gt;, I imagine in the near future we will want to add a matrix implementation with fast row and column access for memory-based algorithms such as neighborhood based recommendation. This could be a new persistent storage engineered for locality preservation of kNN, the new Solr backend potentially cast to a Matrix, or something else. &lt;/p&gt;

&lt;p&gt;Anyway, my point is that we could want to add different types of distributed matrices with engine (or data structure) specific strengths in the future. I suggest turning each bahavior (such as Caching) into an additional trait, which the distributed execution engine (or data structure) author can mixin to her concrete implementation (For example Spark&apos;s matrix is one with Caching and Broadcasting). It might even help with easier logical planning (if it supports caching cache it, if partitioned in the same way do this else do this, if one matrix is small broadcast it etc.). &lt;/p&gt;

&lt;p&gt;So I suggest a  a base Matrix trait with nrows and ncols methods (as it currently is), a BatchExecution trait with methods for partitioning and execution in parallel behavior, a Caching trait with methods for caching/uncaching behavior, in the future a RandomAccess trait with methods for accessing rows and columns (and possibly cells) functionality. &lt;/p&gt;

&lt;p&gt;Then a concrete DRM (like) would be a Matrix with BatchExecution and possibly Caching, a concrete RandomAccessMatrix would be a Matrix with RandomAccess, and so on. What do you think and if you and others are positive, how do you think that should be handled?&lt;/p&gt;</comment>
                            <comment id="14016901" author="dlyubimov" created="Tue, 3 Jun 2014 18:31:23 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gokhancapan&quot; class=&quot;user-hover&quot; rel=&quot;gokhancapan&quot;&gt;Gokhan Capan&lt;/a&gt; As i explained before, i don&apos;t favor common hierarchy for matrices with vastly different programming models. I can roll about a dozen of bona-fide arguments as to why, but i am kind of tired speaking on the topic. Main inference of this work is that common algebraic traits are semantically identical but are not always identical in signatures and more over these signature mis-identities do not necessary follow any functional split. This makes common hierarchies inelegant. Second takeaway from this work is that DSL features + IDEA scala plugin are more than a match for OOA approach as far as readability and maintainability is concerned. If we go by Straustrup&apos;s circa 1989 claim that OOA is nothing but code organization for maintainability purposes, then DSL renders strict OOA design moot.&lt;/p&gt;</comment>
                            <comment id="14016998" author="gokhancapan" created="Tue, 3 Jun 2014 19:59:44 +0100"  >&lt;p&gt;Alright, I&apos;m sold.&lt;/p&gt;</comment>
                            <comment id="14017105" author="tdunning" created="Tue, 3 Jun 2014 21:31:16 +0100"  >
&lt;p&gt;I am not sold but I don&apos;t think it is germane to this bug.  I think that the details of whether it is exactly done with common inheritance or standardized traits is an open question, but I think that the overall push that we need some common characteristics that can be communicated easily to the person writing code is very important.&lt;/p&gt;

&lt;p&gt;We also need to support some things that are very inefficient for cases where it just needs to be done.  It is easy to come up with scenarios like diagnostic systems that need to get the value of a single cell and damn the cost.  That doesn&apos;t make element by element access a primary idiom.  It just means that it is possible to do.&lt;/p&gt;

</comment>
                            <comment id="14017119" author="dlyubimov" created="Tue, 3 Jun 2014 21:37:03 +0100"  >&lt;p&gt;There&apos;s a very well established way of communicating DSL to end users by&lt;br/&gt;
now (see, for example, scalatest manual). Literally dozen projects by now.&lt;br/&gt;
None of these projects i know goes by explaining object model exposing DSL&lt;br/&gt;
to the end user.&lt;/p&gt;


</comment>
                            <comment id="14026818" author="githubbot" created="Tue, 10 Jun 2014 19:38:57 +0100"  >&lt;p&gt;Github user avati commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/15#issuecomment-45653931&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/15#issuecomment-45653931&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I assumed this is part of &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt; itself (which renamed @sc to @sdc). Let me resubmit with &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt; in the commit message?&lt;/p&gt;</comment>
                            <comment id="14026831" author="githubbot" created="Tue, 10 Jun 2014 19:45:13 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/15#issuecomment-45654741&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/15#issuecomment-45654741&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    1529 is closed now. besides, it doesn&apos;t have anything to do with shell.&lt;/p&gt;

&lt;p&gt;    it&apos;s fine this is a small change, i&apos;ll merge it without issue&lt;/p&gt;


&lt;p&gt;    On Tue, Jun 10, 2014 at 11:38 AM, Anand Avati &amp;lt;notifications@github.com&amp;gt;&lt;br/&gt;
    wrote:&lt;/p&gt;

&lt;p&gt;    &amp;gt; I assumed this is part of &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt; itself (which renamed @sc&lt;br/&gt;
    &amp;gt; &amp;lt;&lt;a href=&quot;https://github.com/sc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/sc&lt;/a&gt;&amp;gt; to @sdc &amp;lt;&lt;a href=&quot;https://github.com/sdc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/sdc&lt;/a&gt;&amp;gt;). Let me&lt;br/&gt;
    &amp;gt; resubmit with &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt; in the commit message?&lt;br/&gt;
    &amp;gt;&lt;br/&gt;
    &amp;gt; &#8212;&lt;br/&gt;
    &amp;gt; Reply to this email directly or view it on GitHub&lt;br/&gt;
    &amp;gt; &amp;lt;&lt;a href=&quot;https://github.com/apache/mahout/pull/15#issuecomment-45653931&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/15#issuecomment-45653931&lt;/a&gt;&amp;gt;.&lt;br/&gt;
    &amp;gt;&lt;/p&gt;</comment>
                            <comment id="14054211" author="hudson" created="Mon, 7 Jul 2014 23:02:30 +0100"  >&lt;p&gt;SUCCESS: Integrated in Mahout-Quality #2690 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2690/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2690/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt;: third collection of various edits against private branch (dlyubimov: rev e4ba7887fc6dbf17c3d73f8d4aa1045eeb48d53e)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/SparkEngine.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/scalabindings/VectorOps.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/math/decompositions/MathSuite.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/scalabindings/MatrixOps.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/scalabindings/package.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/scalabindings/RLikeOps.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/decompositions/package.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/package.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/blas/package.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/decompositions/ALS.scala&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14061217" author="hudson" created="Mon, 14 Jul 2014 21:51:10 +0100"  >&lt;p&gt;SUCCESS: Integrated in Mahout-Quality #2698 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2698/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2698/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt; (d): moving core engine-independent tests logic to math-scala, spark module running them. (dlyubimov: rev 25a6fc0967357e6ba4aafcaf11bf3f7faec752fd)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/math/decompositions/DistributedDecompositionsSuite.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/test/scala/org/apache/mahout/math/drm/DrmLikeSuiteBase.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/math/decompositions/MathSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/drm/DrmLikeOpsSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/test/DistributedSparkSuite.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/test/scala/org/apache/mahout/math/decompositions/DistributedDecompositionsSuiteBase.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/blas/ABtSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/test/LoggerConfiguration.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/cf/CooccurrenceAnalysisSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/drivers/ItemSimilarityDriverSuite.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/test/scala/org/apache/mahout/math/drm/RLikeDrmOpsSuiteBase.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/blas/AtSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/drm/DrmLikeSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/blas/AtASuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/test/MahoutLocalContext.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/test/scala/org/apache/mahout/test/DistributedMahoutSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/blas/AewBSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/drm/RLikeDrmOpsSuite.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/test/scala/org/apache/mahout/math/drm/DrmLikeOpsSuiteBase.scala&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14061469" author="githubbot" created="Tue, 15 Jul 2014 01:24:06 +0100"  >&lt;p&gt;GitHub user avati opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/29&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/29&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt;: Move dense/sparse matrix test in mapBlock into spark/&lt;/p&gt;

&lt;p&gt;    In h2o engine, the Matrix provided to mapBlock() is an instance of&lt;br/&gt;
    &quot;H2OBlockMatrix extends AbstractMatrix&quot;, and neither a DenseMatrix&lt;br/&gt;
    nor SparseMatrix. H2OBlockMatrix is a 0-copy virtual Matrix exposing&lt;br/&gt;
    just the partition&apos;s data (created at almost no expense), and creates&lt;br/&gt;
    a copy-on-write Matrix only if modified by the blockmapfunction.&lt;/p&gt;

&lt;p&gt;    So these two tests are failing with h2obindings. Hence moving these two&lt;br/&gt;
    tests into spark module.&lt;/p&gt;

&lt;p&gt;    Signed-off-by: Anand Avati &amp;lt;avati@redhat.com&amp;gt;&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/avati/mahout&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/avati/mahout&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt;e&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/29.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/29.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #29&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 1e3cdb68198636c9f38f2d41d782d12edba7a2f7&lt;br/&gt;
Author: Anand Avati &amp;lt;avati@redhat.com&amp;gt;&lt;br/&gt;
Date:   2014-07-15T00:20:09Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt;: Move dense/sparse matrix test in mapBlock into spark/&lt;/p&gt;

&lt;p&gt;    In h2o engine, the Matrix provided to mapBlock() is an instance of&lt;br/&gt;
    &quot;H2OBlockMatrix extends AbstractMatrix&quot;, and neither a DenseMatrix&lt;br/&gt;
    nor SparseMatrix. H2OBlockMatrix is a 0-copy virtual Matrix exposing&lt;br/&gt;
    just the partition&apos;s data (created at almost no expense), and creates&lt;br/&gt;
    a copy-on-write Matrix only if modified by the blockmapfunction.&lt;/p&gt;

&lt;p&gt;    So these two tests are failing with h2obindings. Hence moving these two&lt;br/&gt;
    tests into spark module.&lt;/p&gt;

&lt;p&gt;    Signed-off-by: Anand Avati &amp;lt;avati@redhat.com&amp;gt;&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="14063920" author="githubbot" created="Wed, 16 Jul 2014 19:59:01 +0100"  >&lt;p&gt;Github user avati commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/29#issuecomment-49210898&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/29#issuecomment-49210898&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @dlyubimov - review/merge appreciated&lt;/p&gt;</comment>
                            <comment id="14069357" author="githubbot" created="Mon, 21 Jul 2014 22:47:06 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/29#issuecomment-49670601&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/29#issuecomment-49670601&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    looks fine to me.&lt;/p&gt;</comment>
                            <comment id="14069388" author="githubbot" created="Mon, 21 Jul 2014 23:01:10 +0100"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/29&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/29&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14069455" author="hudson" created="Mon, 21 Jul 2014 23:41:43 +0100"  >&lt;p&gt;SUCCESS: Integrated in Mahout-Quality #2707 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2707/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2707/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1529&quot; title=&quot;Finalize abstraction of distributed logical plans from backend operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1529&quot;&gt;&lt;del&gt;MAHOUT-1529&lt;/del&gt;&lt;/a&gt;(e): Move dense/sparse matrix test in mapBlock into spark (Anand Avati via dlyubimov) (dlyubimov: rev dec441fb895c96d1e756619d15d75bba00b10fa3)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;math-scala/src/test/scala/org/apache/mahout/math/drm/DrmLikeSuiteBase.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/drm/DrmLikeSuite.scala&lt;/li&gt;
	&lt;li&gt;CHANGELOG&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 29 Apr 2014 05:54:02 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>389424</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hzoxlr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>389666</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>