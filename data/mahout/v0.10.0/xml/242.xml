<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:19:47 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-242/MAHOUT-242.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-242] LLR Collocation Identifier</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-242</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;p&gt;Identifies interesting Collocations in text using ngrams scored via the LogLikelihoodRatio calculation. &lt;/p&gt;

&lt;p&gt;As discussed in: &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;http://www.lucidimagination.com/search/document/d051123800ab6ce7/collocations_in_mahout#26634d6364c2c0d2&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.lucidimagination.com/search/document/d051123800ab6ce7/collocations_in_mahout#26634d6364c2c0d2&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;http://www.lucidimagination.com/search/document/b8d5bb0745eef6e8/n_grams_for_terms#f16fa54417697d8e&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.lucidimagination.com/search/document/b8d5bb0745eef6e8/n_grams_for_terms#f16fa54417697d8e&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Current form is a tar of a maven project that depends on mahout. Build as usual with &apos;mvn clean install&apos;, can be executed using:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;mvn -e exec:java  -Dexec.mainClass=&quot;org.apache.mahout.colloc.CollocDriver&quot; -Dexec.args=&quot;--input src/test/resources/article --colloc target/colloc --output target/output -w&quot;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output will be placed in target/output and can be viewed nicely using:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;sort -rn -k1 target/output/part-00000
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Includes rudimentary unit tests. Please review and comment. Needs more work to get this into patch state and integrate with Robin&apos;s document vectorizer work in &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-237&quot; title=&quot;Map/Reduce Implementation of Document Vectorizer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-237&quot;&gt;&lt;del&gt;MAHOUT-237&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Some basic TODO/FIXME&apos;s include:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;use mahout math&apos;s ObjectInt map implementation when available&lt;/li&gt;
	&lt;li&gt;make the analyzer configurable&lt;/li&gt;
	&lt;li&gt;better input validation + negative unit tests.&lt;/li&gt;
	&lt;li&gt;more flexible ways to generate units of analysis (n-1)grams.&lt;/li&gt;
&lt;/ul&gt;


</description>
                <environment></environment>
        <key id="12445157">MAHOUT-242</key>
            <summary>LLR Collocation Identifier</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="drew.farris">Drew Farris</assignee>
                                    <reporter username="drew.farris">Drew Farris</reporter>
                        <labels>
                    </labels>
                <created>Mon, 11 Jan 2010 04:35:58 +0000</created>
                <updated>Thu, 11 Mar 2010 02:14:24 +0000</updated>
                            <resolved>Tue, 9 Feb 2010 17:03:30 +0000</resolved>
                                    <version>0.3</version>
                                    <fixVersion>0.3</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12798575" author="robinanil" created="Mon, 11 Jan 2010 05:03:33 +0000"  >
&lt;ul&gt;
	&lt;li&gt;Try to stick to SequenceFile&amp;lt;Text,Text&amp;gt; docid =&amp;gt; for input  content and leave it to the user to generate this file. There is a SequenceFileFromDirectory class in examples in my patch which does this conversion and writes SequenceFiles  on HDFS directly&lt;/li&gt;
	&lt;li&gt;Also Take a look at the TermCountMapper, where I have parameterized the Lucene Analyzer through the conf&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;If you need to pass a tuple as input or output. Check out the StringTupleWritable class, instead of appending stuff to Text or splitting it.&lt;/li&gt;
&lt;/ul&gt;

</comment>
                            <comment id="12800122" author="drew.farris" created="Thu, 14 Jan 2010 05:54:46 +0000"  >&lt;p&gt;Thanks for taking a look and providing some great feedback Robin.&lt;/p&gt;

&lt;p&gt;Here&apos;s a new version that includes the following changes:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Now runs from a SequenceFile&amp;lt;Text,Text&amp;gt; of ID -&amp;gt; DOC by default. Tested on some medium-sized collections of 10k and 100k files using Robin&apos;s directory to sequence file util.&lt;/li&gt;
	&lt;li&gt;Analyzer is now configurable from the command-line via the --analyzerName option&lt;/li&gt;
	&lt;li&gt;Using a Writable implementation instead of strings to move data around. No more parsing, splitting, concatenating&lt;/li&gt;
	&lt;li&gt;Improved the handling of the output directory, output from passes are written to subdirectories of this directory, so no need to specify multiple output directories any longer.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;After &apos;mvn clean install&apos; a sample can be run like so:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;mvn -e exec:java  -Dexec.mainClass=&quot;org.apache.mahout.colloc.CollocDriver&quot; -Dexec.args=&quot;--input src/test/resources/article --output target/output -w -t&quot;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;d like to get this into patch form as a next step + get all of the license headers on the code here, but I&apos;m not sure where it should live in terms of project/package names, etc. Any thoughts?&lt;/p&gt;

&lt;p&gt;Also, I&apos;m looking for feedback on the algorithm implementation &amp;#8211; this version differs that I presented on the list in that the implementation tracks the part of the orginal n-gram that the sub-part appears in (head, tail). I&apos;m not 100% sure this is necessary or even correct.&lt;/p&gt;

&lt;p&gt;Also, it&apos;s a bummer to have to create an analyzer subclass just to provide an implementation with a no-argument constructor. Has anyone considered making use of a DI framework with mahout? I know Grant has mentioned such options spring or guice with Mahout? Anyone have any strong objections to pull one of those in as a dependency? &lt;/p&gt;</comment>
                            <comment id="12801271" author="drew.farris" created="Sat, 16 Jan 2010 20:50:21 +0000"  >&lt;p&gt;Log-likelihood collocation identifier  in patch form. This puts itself in o.a.m.nlp.collocations.llr&lt;/p&gt;

&lt;p&gt;I think there are some improvements that can be made, but if possible it would be nice to review, commit this version and add on to it later through additional patches More specifically, I&apos;d like to see this:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;include the ability to avoid forming collocations around sentence boundaries and other boundaries per: &lt;a href=&quot;http://www.lucidimagination.com/search/document/d259def498803ffe/collocation_clarification#29fbb050cf5fa64&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.lucidimagination.com/search/document/d259def498803ffe/collocation_clarification#29fbb050cf5fa64&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;work for non-whitespace delimited languages, e.g: anything an analyzer can produce tokens for.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I removed the ability to read in files from a directory, Robin&apos;s document -&amp;gt; sequence file work fits into this well.&lt;/p&gt;</comment>
                            <comment id="12803274" author="isabel" created="Thu, 21 Jan 2010 12:45:19 +0000"  >&lt;p&gt;First of all, thanks for the patch. The code looks good so far, patch applies cleanly and builds w/o problems. Some initial comments and questions I had when reading it: &lt;/p&gt;

&lt;p&gt;CollocMapper, Line 66: If I read your implementation correctly, this means that documents are always read fully into memory, right? So we would assume to only run the ngramCollector over documents that fit into main memory and unable to process larger documents. I am wondering whether this is an issue at all, and if so, whether there is any way around that. &lt;/p&gt;

&lt;p&gt;Gram, Line 192: You can omit the &quot;else&quot; clauses, in case the &quot;if&quot; already returns its result to the caller, however this is a question of style. I was wondering, why in line 177 you did not write &quot;this.position != other.position&quot;? &lt;/p&gt;

&lt;p&gt;NGramCollector, Line 47 (and a few others): Shouldn&apos;t we avoid using deprecated apis instead of suppressing deprecation warnings? &lt;/p&gt;

&lt;p&gt;LLRReducer, Line 143: How about making the method package private if it should be used in unit tests only anyway? &lt;br/&gt;
Line 106: Would be nice to have an additional counter for the skipped grams. &lt;/p&gt;


&lt;p&gt;I agree with you that things like sentence boundary detection and more sophisticated tokenization should be left as work for an additional issue. &lt;/p&gt;

&lt;p&gt;Jake, would be great, if you could have a closer look to verify that this is about the pipeline you had in mind in the referenced e-mail threads and mention anything that might still be missing.&lt;/p&gt;</comment>
                            <comment id="12803302" author="jakemannix" created="Thu, 21 Jan 2010 14:31:05 +0000"  >&lt;p&gt;I can try and take a look at this later today / tonight.&lt;/p&gt;

&lt;p&gt;regarding &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;CollocMapper, Line 66: If I read your implementation correctly, this means that documents are always read fully into memory, right? So we would assume to only run the ngramCollector over documents that fit into main memory and unable to process larger documents. I am wondering whether this is an issue at all, and if so, whether there is any way around that.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Are we really worried about individual documents which are bigger than hundreds of MB?&lt;/p&gt;</comment>
                            <comment id="12803361" author="tdunning" created="Thu, 21 Jan 2010 17:12:06 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Are we really worried about individual documents which are bigger than hundreds of MB?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I am not worried about them at this point.  Even in the most skewed distributions, this would be very, very rare.  How many people on linked in have 100 million friends?&lt;/p&gt;

&lt;p&gt;The quadratic cost of unwindowed collocation detection would make this infeasible first.  For windowed collocation, it isn&apos;t that hard to scan the input, but reading the whole shebang isn&apos;t such a bad thing.&lt;/p&gt;
</comment>
                            <comment id="12803381" author="isabel" created="Thu, 21 Jan 2010 17:34:43 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I am not worried about them at this point.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Also not very worried - probably should have indicated that basically everything I found could be filed as &quot;trivial, minor or style question only&quot;...&lt;/p&gt;</comment>
                            <comment id="12803897" author="drew.farris" created="Fri, 22 Jan 2010 21:58:39 +0000"  >&lt;p&gt;Thanks for the review Isabel, here&apos;s an updated patch.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;CollocMapper, Line 66: If I read your implementation correctly, this means that documents are always read fully into memory, right? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, you are correct. In addition to what Ted and Jake have already said, reading parts documents is a little tricky because there would have to be some overlap to ensure that the collocations around the split were picked up properly. Perhaps there will be an opportunity to do something like this once the collocs are windowed based on sentence boundary? &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Gram, Line 192: You can omit the &quot;else&quot; clauses, in case the &quot;if&quot; already returns its result to the caller, however this is a question of style.&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I prefer the form you describe, easier to read.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I was wondering, why in line 177 you did not write &quot;this.position != other.position&quot;? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m not certain about what you&apos;re referring to here, before edits, line 177 is in the middle of the write() method. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;NGramCollector, Line 47 (and a few others): Shouldn&apos;t we avoid using deprecated apis instead of suppressing deprecation warnings?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ve removed the SuppressWarnings(&quot;deprecated&quot;). The only reason they are there is that I&apos;ve used the hadoop 0.19 api here and I tend to get distracted by the deprecation warnings. &lt;/p&gt;

&lt;p&gt;This brings up a question of policy however. Should I be using the newest hadoop api for new work in Mahout such as this, or should we continue to make efforts to retain backwards compatibility with older hadoop installations? I assumed the policy was the latter, but relish the opportunity to learn the new api &amp;#8211; I just didn&apos;t think Mahout ready to commit to the new api yet.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;LLRReducer, Line 143: How about making the method package private if it should be used in unit tests only anyway? &lt;br/&gt;
Line 106: Would be nice to have an additional counter for the skipped grams. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;done and done, great idea to use the counter to track skipped grams.&lt;/p&gt;</comment>
                            <comment id="12803918" author="zoudini" created="Fri, 22 Jan 2010 22:44:49 +0000"  >&lt;p&gt;Thanks Drew. Some overdue feedback from testing this baby out...&lt;/p&gt;

&lt;p&gt;My use case may differ from what&apos;s more typical, but basically I had 10MM+ semi-processed strings (lowercased, no punctuation, etc.) that I wanted to do my analysis on, not a large document or a series of smaller documents. As a result, I found that using the Lucene Analyzers in the NGramCollector to be horribly ineffecient (the job was taking hours to complete 1% on my modest 7 node cluster). Instead I used some custom logic to generate the n-grams and pass them to the collector. After this modification, the entire set of jobs ran in a little less than an hour even on a larger dataset. &lt;/p&gt;

&lt;p&gt;I know Robin mentioned something about an Ngram generator in the Bayes classifier, I should check it out. &lt;/p&gt;

&lt;p&gt;I guess I would advocate splitting the module as it exists into a couple of different pieces:&lt;/p&gt;

&lt;p&gt;1. A general purpose tool for tokenizing/analyzing a document/documents (or in my case, &apos;documents&apos; consisting of strings). I know there&apos;s some exisitng tools for vectorizing text, and indices, so maybe this is something similar but the basic idea would be to go from document --&amp;gt; analyzed text&lt;/p&gt;

&lt;p&gt;2+3 (These can remain as is in the module or be split). N gram generator and counter and LLR pieces.&lt;/p&gt;

&lt;p&gt;Maybe this is all crazy talk, but it would seem to me refactoring/extracting the pieces out like this would prove useful and allow for code reuse in other modules (other NLP-type modules, elsewhere in the project).&lt;/p&gt;</comment>
                            <comment id="12803944" author="drew.farris" created="Fri, 22 Jan 2010 23:34:58 +0000"  >&lt;p&gt;Decoupling the tokenization logic from the ngrammer is a great idea. I think Ted sort of alluded to this in a recent post on another subject as well. Here, the input would really be a stream of tokens. It makes a great deal of sense to do the analysis offline. &lt;/p&gt;

&lt;p&gt;I&apos;ll take a shot a providing a SequenceFile&amp;lt;Doc ID, Document&amp;gt; -&amp;gt; SequenceFile&amp;lt;DocId, TokenStream&amp;gt; utility and update this code to take input from there. I suspect it would also be handy to be able to easily string a bunch of these processing steps (Document files &amp;gt; Sequence file&amp;lt;Doc Id, Doc&amp;gt; -&amp;gt; Sequence File&amp;lt;DocId, TokenStream together into a chain, but that&apos;s a larger issue. What does anyone else think?&lt;/p&gt;

&lt;p&gt;Also, I wanted to ask: does it make more sense to emit a sequence file &amp;lt;longwritable, text&amp;gt; (or gram) instead of a text file? There had been some recent traffic on this list about this wrt line endings and I suspect it may be more reasonable to provide the former as output (or both!?)&lt;/p&gt;
</comment>
                            <comment id="12803979" author="tdunning" created="Sat, 23 Jan 2010 01:06:14 +0000"  >
&lt;p&gt;Drew, &lt;/p&gt;

&lt;p&gt;I think that what we really need is a serialized form for something a lot like a Lucene document, i.e. SequenceFile&amp;lt;key=docId, value=map&amp;lt;fieldname, list&amp;lt;token&amp;gt;&amp;gt;&amp;gt;  where token is either a string or a string and a token number or a string and a token number and an offset (i.e. record(string, position, offset) with nullable fields).  One really clever integration point would be to build an implementation of a Lucene IndexWriter that would emit these serialized documents.&lt;/p&gt;

&lt;p&gt;My guess is that Avro would be a useful tool in implementing this.  It should be quite easy to emit simpler forms of this from any of our current code.&lt;/p&gt;</comment>
                            <comment id="12804158" author="drew.farris" created="Sat, 23 Jan 2010 22:10:28 +0000"  >&lt;p&gt;Ted, &lt;/p&gt;

&lt;p&gt;Thanks for the advice, I&apos;ll take a look at doing something in line with the structure you describe. It may be useful to re-used the classes introduced with Lucene&apos;s new &lt;a href=&quot;http://lucene.apache.org/java/2_9_1/api/core/org/apache/lucene/analysis/TokenStream.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;TokenStream API&lt;/a&gt;, where essentially each Token is really a collection of different types of &lt;a href=&quot;http://lucene.apache.org/java/2_9_1/api/core/org/apache/lucene/util/Attribute.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;attributes&lt;/a&gt;. Each of the existing attributes are serializable which suggests that there might be a short path to Writable for these, I&apos;ll see if Avro offers any shortcuts here. A subclass of IndexWriter may indeed be a very quick route to this.&lt;/p&gt;

&lt;p&gt;I also wonder if flipping this around and implementing a LuceneIndexInputFormat may be another option. &lt;/p&gt;


</comment>
                            <comment id="12804191" author="tdunning" created="Sun, 24 Jan 2010 03:24:05 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Each of the existing attributes are serializable which suggests that there might be a short path to Writable for these, I&apos;ll see if Avro offers any shortcuts here. A subclass of IndexWriter may indeed be a very quick route to this.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Perhaps.  But the fact that Avro data is self describing and highly portable is probably as important as most other considerations.   There are also lots of concessions to Java that are in the Lucene document that are very different from the concessions to good serialization that we need.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I also wonder if flipping this around and implementing a LuceneIndexInputFormat may be another option.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes.  Or at least a conversion system for spilling an index into SequenceFiles.&lt;/p&gt;</comment>
                            <comment id="12805834" author="jake.mannix" created="Thu, 28 Jan 2010 08:25:28 +0000"  >&lt;p&gt;Hey Drew, I&apos;m not much of a maven guy - what&apos;s the maven-foo you use to get this running?&lt;/p&gt;

&lt;p&gt;mvn clean install&lt;/p&gt;

&lt;p&gt;followed by &lt;/p&gt;

&lt;p&gt;mvn &lt;del&gt;e exec:java  -Dexec.mainClass=&quot;org.apache.mahout.colloc.CollocDriver&quot; -Dexec.args=&quot;&lt;/del&gt;-input src/test/resources/article --colloc target/colloc --output target/output -w&quot;&lt;/p&gt;

&lt;p&gt;?  Returns with some classpath sadness for me, probably because I haven&apos;t set it up correctly...&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Caused by: java.lang.ClassNotFoundException: org.apache.mahout.colloc.CollocDriver&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12806357" author="drew.farris" created="Fri, 29 Jan 2010 14:49:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;Hey Drew, I&apos;m not much of a maven guy - what&apos;s the maven-foo you use to get this running?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Jake, my mistake, I should have included updated docs when I updated the patch. &lt;/p&gt;

&lt;p&gt;I eliminated the code to read plain text files from a directory, so you would need to begin by producing a SequenceFile&amp;lt;Text,Text&amp;gt; (document id, document) as input. Robin&apos;s utility in mahout-examples, o.a.m.text.SequenceFilesFromDirectory can do this. Run the following from the &apos;examples&apos; directory;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
mvn -e exec:java -Dexec.mainClass=&lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.mahout.text.SequenceFilesFromDirectory&quot;&lt;/span&gt; -Dexec.args=&lt;span class=&quot;code-quote&quot;&gt;&quot;--parent (...input directory..) --outputDir (..output directory..) --charset UTF-8&quot;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once you have the sequence file to use as input, run the following from the &apos;examples&apos; directory as well.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
mvn -e exec:java  -Dexec.mainClass=&lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.mahout.nlp.collocations.llr.CollocDriver&quot;&lt;/span&gt; -Dexec.args=&lt;span class=&quot;code-quote&quot;&gt;&quot;--input (..path-to-input..) --output (..path-to-output..) -w&quot;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once the driver class is run, the collocations will be in (output-directory)/colloc/part-00000 as plaintext. They can be sorted by LLR score using the same sort command I included in the previous comment above (I have a question about this below).&lt;/p&gt;

&lt;p&gt;FWIW, I need to re-submit the patch to clean up some of the pom changes to &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-215&quot; title=&quot;Provide jars with mahout release.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-215&quot;&gt;&lt;del&gt;MAHOUT-215&lt;/del&gt;&lt;/a&gt; were applied.&lt;/p&gt;

&lt;p&gt;A couple follow up questions while you&apos;re looking at this:&lt;/p&gt;

&lt;p&gt;Currently I just dump the results of the second pass to a file, not sorted by LLR score. I could sort by LLR by sending it through another pass with an identity mapper and a reducer but I suspect that&apos;s probably pretty inefficient. Is there a better way to sort the output of the second pass by LLR?&lt;/p&gt;

&lt;p&gt;If I only wanted to emit the top 1-10% of the collocs (user configurable), how would I tell the reducer to stop emitting results at a certain point (or is yet another pass needed to achieve something like this?)&lt;/p&gt;

&lt;p&gt;Would it be better to emit a sequencefile&amp;lt;LongWritable,Text&amp;gt; instead of a text file as the output from the final pass?&lt;/p&gt;
</comment>
                            <comment id="12828924" author="drew.farris" created="Wed, 3 Feb 2010 03:11:51 +0000"  >&lt;p&gt;Updated patch, removed pom modifications checked in as a part of &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-215&quot; title=&quot;Provide jars with mahout release.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-215&quot;&gt;&lt;del&gt;MAHOUT-215&lt;/del&gt;&lt;/a&gt;. Applies and builds cleanly against r905872.&lt;/p&gt;</comment>
                            <comment id="12830966" author="drew.farris" created="Mon, 8 Feb 2010 15:11:58 +0000"  >&lt;p&gt;Updated patch now includes a combiner for pass1&lt;/p&gt;</comment>
                            <comment id="12830968" author="robinanil" created="Mon, 8 Feb 2010 15:19:30 +0000"  >&lt;p&gt;Mind If I move this to util along with rest of the text stuff&lt;/p&gt;</comment>
                            <comment id="12830971" author="drew.farris" created="Mon, 8 Feb 2010 15:23:42 +0000"  >&lt;p&gt;No problem moving this to util, I wasn&apos;t sure where stuff like this is supposed to live.&lt;/p&gt;</comment>
                            <comment id="12830975" author="robinanil" created="Mon, 8 Feb 2010 15:28:47 +0000"  >&lt;p&gt;I will just run this and start thinking on integrating this with DictionaryVectorizer. Move it to util and upload the new patch. I will commit first and then start refactoring. &lt;/p&gt;</comment>
                            <comment id="12830983" author="robinanil" created="Mon, 8 Feb 2010 15:39:19 +0000"  >&lt;ul&gt;
	&lt;li&gt;In the map/reduce job try adding increasing a counter when you encounter a gram and another counter when you encounter an error, instead of throwing errors&lt;/li&gt;
	&lt;li&gt;Make the output a sequencefile instead of TextOutput format ?&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12831026" author="jake.mannix" created="Mon, 8 Feb 2010 18:09:46 +0000"  >&lt;p&gt;util?  I don&apos;t think this belongs in util.  I kind like making an nlp package in core, and eventually we can split it out to its own maven submodule.&lt;/p&gt;
</comment>
                            <comment id="12831289" author="drew.farris" created="Tue, 9 Feb 2010 04:25:30 +0000"  >&lt;p&gt;Moved to utils based on discussion on the dev list. This can be committed as-is, or I can take a closer look at Robin&apos;s suggested refactoring (counters, sequence file output) and submit a revised patch later&lt;/p&gt;</comment>
                            <comment id="12831540" author="robinanil" created="Tue, 9 Feb 2010 17:03:30 +0000"  >&lt;p&gt;Committed and resolved. &lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12435247" name="MAHOUT-242.patch" size="53568" author="drew.farris" created="Tue, 9 Feb 2010 04:25:30 +0000"/>
                            <attachment id="12435171" name="MAHOUT-242.patch" size="53024" author="drew.farris" created="Mon, 8 Feb 2010 15:11:58 +0000"/>
                            <attachment id="12434631" name="MAHOUT-242.patch" size="49867" author="drew.farris" created="Wed, 3 Feb 2010 03:11:51 +0000"/>
                            <attachment id="12431152" name="MAHOUT-242.patch" size="52866" author="drew.farris" created="Fri, 22 Jan 2010 21:58:39 +0000"/>
                            <attachment id="12430520" name="MAHOUT-242.patch" size="52648" author="drew.farris" created="Sat, 16 Jan 2010 20:50:21 +0000"/>
                            <attachment id="12430232" name="mahout-colloc.tar.gz" size="14659" author="drew.farris" created="Thu, 14 Jan 2010 05:54:46 +0000"/>
                            <attachment id="12429869" name="mahout-colloc.tar.gz" size="12173" author="drew.farris" created="Mon, 11 Jan 2010 04:36:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 11 Jan 2010 05:03:33 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9823</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hxy6br:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23176</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>