<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:17:34 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-237/MAHOUT-237.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-237] Map/Reduce Implementation of Document Vectorizer</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-237</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;p&gt;Current Vectorizer uses Lucene Index to convert documents into SparseVectors&lt;br/&gt;
Ted is working on a Hash based Vectorizer which can map features into Vectors of fixed size and sum it up to get the document Vector&lt;br/&gt;
This is a pure bag-of-words based Vectorizer written in Map/Reduce. &lt;/p&gt;

&lt;p&gt;The input document is in SequenceFile&amp;lt;Text,Text&amp;gt; . with key = docid, value = content&lt;br/&gt;
First Map/Reduce over the document collection and generate the feature counts.&lt;br/&gt;
Second Sequential pass reads the output of the map/reduce and converts them to SequenceFile&amp;lt;Text, LongWritable&amp;gt; where key=feature, value = unique id &lt;br/&gt;
    Second stage should create shards of features of a given split size&lt;br/&gt;
Third Map/Reduce over the document collection, using each shard and create Partial(containing the features of the given shard) SparseVectors &lt;br/&gt;
Fourth Map/Reduce over partial shard, group by docid, create full document Vector&lt;/p&gt;</description>
                <environment></environment>
        <key id="12444653">MAHOUT-237</key>
            <summary>Map/Reduce Implementation of Document Vectorizer</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="robinanil">Robin Anil</assignee>
                                    <reporter username="robinanil">Robin Anil</reporter>
                        <labels>
                    </labels>
                <created>Tue, 5 Jan 2010 02:45:43 +0000</created>
                <updated>Sat, 21 May 2011 04:23:58 +0100</updated>
                            <resolved>Fri, 5 Feb 2010 09:31:43 +0000</resolved>
                                    <version>0.3</version>
                                    <fixVersion>0.3</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12796502" author="robinanil" created="Tue, 5 Jan 2010 02:47:52 +0000"  >&lt;p&gt;single shard based document vectorizer. Needs some tidying up. (Work in progress)&lt;/p&gt;

&lt;p&gt;TODO: Split the output of first Map/Reduce into shards of given chunk size&lt;br/&gt;
TODO: Map/Reduce job for the merge phase &lt;/p&gt;</comment>
                            <comment id="12798448" author="robinanil" created="Sun, 10 Jan 2010 07:20:50 +0000"  >&lt;p&gt;Example code which converts an input directory to sequence files recursively  and assigns docid as the relative path from the parent directory along with with a prefix &lt;br/&gt;
The code also chunks the sequence files as specified by the chunksize&lt;/p&gt;

&lt;p&gt;Dictionary vectorizer also chunks the dictionary file and runs multiple map/reduces over them to create partial vectors which then get summed to create the final document vector&lt;/p&gt;</comment>
                            <comment id="12798475" author="robinanil" created="Sun, 10 Jan 2010 12:09:25 +0000"  >&lt;p&gt;Some tidying up. Still the large output bug remains&lt;/p&gt;</comment>
                            <comment id="12798713" author="robinanil" created="Mon, 11 Jan 2010 16:37:47 +0000"  >&lt;p&gt;Working patch. 20newsgroups take about a minute to convert to vectors on single mapper/reducer. Will test with larger collections and see&lt;/p&gt;</comment>
                            <comment id="12799365" author="robinanil" created="Tue, 12 Jan 2010 20:15:06 +0000"  >&lt;p&gt;Uses String Reader. Removes unused imports and added License headers and unused variables.&lt;br/&gt;
Still bzip decompressing wikipedia dump. Wish there was a mapreduce for that&lt;/p&gt;</comment>
                            <comment id="12799508" author="srowen" created="Wed, 13 Jan 2010 01:10:57 +0000"  >&lt;p&gt;I&apos;ll commit &amp;#8211; still seeing some code inspection warnings but we can look at it later.&lt;/p&gt;</comment>
                            <comment id="12799557" author="jake.mannix" created="Wed, 13 Jan 2010 03:42:04 +0000"  >&lt;p&gt;Given the following code in PartialVectorGenerator:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;	      
&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Entry&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;,MutableInt&amp;gt; pair : termFrequency.entrySet()) {
  &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; tk = pair.getKey();
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (dictionary.containsKey(tk) == &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt;;
  vector.setQuick(dictionary.get(tk).intValue(), pair.getValue().doubleValue());
}	      
&lt;span class=&quot;code-keyword&quot;&gt;assert&lt;/span&gt; (vector.getNumNondefaultElements() == termFrequency.size());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Why is this assert expected to pass?  If there are dictionary.containsKey(tk) ever returns true, this will fail...&lt;/p&gt;</comment>
                            <comment id="12799560" author="jake.mannix" created="Wed, 13 Jan 2010 03:49:18 +0000"  >&lt;p&gt;It appears that there is just a missing line above when the termFrequency map is created:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(dictionary.containsKey(tk) == &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;needs to be inserted to get the map and the vector to have the same sizes. &lt;/p&gt;</comment>
                            <comment id="12799587" author="robinanil" created="Wed, 13 Jan 2010 05:38:50 +0000"  >&lt;p&gt;reopening this to let in further review&lt;/p&gt;</comment>
                            <comment id="12799625" author="jake.mannix" created="Wed, 13 Jan 2010 06:53:02 +0000"  >&lt;p&gt;Looking at this a little: &lt;/p&gt;

&lt;p&gt;is there a reason why the termFrequency map needs to exist?  &lt;/p&gt;

&lt;p&gt;if instead of:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

      SparseVector vector;
      Map&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;,MutableInt&amp;gt; termFrequency = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HashMap&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;,MutableInt&amp;gt;();

      token = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Token();
      ts.reset();
      &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; ((token = ts.next(token)) != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
        &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; tk = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;(token.termBuffer(), 0, token.termLength());
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(dictionary.containsKey(tk) == &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt;;
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (termFrequency.containsKey(tk) == &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) {
          count += tk.length() + 1;
          termFrequency.put(tk, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; MutableInt(0));
        }
        termFrequency.get(tk).increment();
      }

      vector =
          &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SparseVector(key.toString(), &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.MAX_VALUE, termFrequency.size());

      &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Map.Entry&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;,MutableInt&amp;gt; pair : termFrequency.entrySet()) {
        &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; tk = pair.getKey();
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (dictionary.containsKey(tk) == &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt;;
        vector.setQuick(dictionary.get(tk).intValue(), pair.getValue()
            .doubleValue());
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;we instead just built it up on the vector itself:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; valueStr = value.toString();
      vector =
          &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SparseVector(key.toString(), &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.MAX_VALUE, valueString.length / 5); &lt;span class=&quot;code-comment&quot;&gt;// guess at initial size
&lt;/span&gt;
      token = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Token();
      ts.reset();
      &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; ((token = ts.next(token)) != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
        &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; tk = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;(token.termBuffer(), 0, token.termLength());
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(dictionary.containsKey(tk) == &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt;;
        &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; tokenKey = dictionary.get(tk);
        vector.setQuick(tokenKey, vector.getQuick(tokenKey) + 1);
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;At least when I micro-benchmark this, it&apos;s about 10% faster this way.  Not much, but it&apos;s also simpler code.&lt;/p&gt;</comment>
                            <comment id="12799631" author="robinanil" created="Wed, 13 Jan 2010 07:18:05 +0000"  >&lt;p&gt;Ok. Done&lt;/p&gt;</comment>
                            <comment id="12803275" author="isabel" created="Thu, 21 Jan 2010 12:48:22 +0000"  >&lt;p&gt;Hmm, Robin your last comment is &quot;ok. done&quot; however the issue is still open?&lt;/p&gt;</comment>
                            <comment id="12828761" author="robinanil" created="Tue, 2 Feb 2010 21:03:33 +0000"  >&lt;p&gt;Added IDF job which takes a sequence file of doc-id=&amp;gt;Vector. Calculates Tf-Idf using TFIDF class(internally uses Lucene DefaultSimilarity class, not yet modifiable)&lt;/p&gt;

&lt;p&gt;has similar options to lucene driver (minDf, maxDfPercent). &lt;/p&gt;

&lt;p&gt;Purely Map/reduce solution. Chunks the Document Frequency Sequence File. and does multiple map/reduces over the input vectors as specified by the chunk size.&lt;/p&gt;


&lt;p&gt;Seems like the Text field Vector Class Name (i.e RandomAccessSparseVector etc) is taking most of the space in the sequencefile. Cant we compact it(with an integer id and a factory)?&lt;/p&gt;
</comment>
                            <comment id="12828763" author="tdunning" created="Tue, 2 Feb 2010 21:10:15 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Seems like the Text field Vector Class Name (i.e RandomAccessSparseVector etc) is taking most of the space in the sequencefile. Cant we compact it(with an integer id and a factory)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What about switching to Avro to avoid this?&lt;/p&gt;</comment>
                            <comment id="12830018" author="robinanil" created="Fri, 5 Feb 2010 09:04:25 +0000"  >&lt;p&gt;4 Main Entry points&lt;br/&gt;
DocumentProcessor - does SequenceFile =&amp;gt; StringTuple(later replaced by StructuredDocumentWritable backed by AvroWritable)&lt;br/&gt;
DictionaryVectorizer - StringTuple of documents =&amp;gt; Tf Vector&lt;br/&gt;
PartialVectorMerger - merges partial vectors based on their doc id. Does optional normalizing(used by both DictionaryVectorizer(no normalizing) and TFIDFConverter (optional normalizing0&lt;br/&gt;
TfidfConverter - Converts tf vector to tfidf vector with optional normalizing&lt;/p&gt;

&lt;p&gt;An example which uses all of them&lt;br/&gt;
hadoop jar examples/target/mahout-examples-0.3-SNAPSHOT.job org.apache.mahout.text.SparseVectorsFromSequenceFiles -i reuters-seqfiles -o reuters-vectors -w (tfidf|tf) --norm 2(works only when tfidf enabled not with tf)&lt;/p&gt;</comment>
                            <comment id="12830025" author="robinanil" created="Fri, 5 Feb 2010 09:30:48 +0000"  >&lt;p&gt;Working Implementation DictionaryVectorizer using with tf, tfidf weighting and normalization. &lt;/p&gt;</comment>
                            <comment id="12831396" author="jake.mannix" created="Tue, 9 Feb 2010 10:25:40 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    RandomAccessSparseVector vector =
        &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; RandomAccessSparseVector(key.toString(), &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.MAX_VALUE,
            valueString.length() / 5); &lt;span class=&quot;code-comment&quot;&gt;// guess at initial size&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This whole Integer.MAX_VALUE thing is killing me whenever I try to move back and forth between sparse and dense vectors (which is necessary for performance in the DistributedLanczos I&apos;m working on).  Ugh.  &lt;/p&gt;

&lt;p&gt;We really need to have a vector flag which says &quot;I&apos;m infinite dimensional, I just return 0 whenever you ask me about dimensions I don&apos;t know about&quot;, so we don&apos;t have to have this hack of Integer.MAX_VALUE as the dimension.  I&apos;ve suggested it to people myself, but it&apos;s such a baaaaad hack.&lt;/p&gt;</comment>
                            <comment id="12831410" author="srowen" created="Tue, 9 Feb 2010 10:56:06 +0000"  >&lt;p&gt;I dunno, I think of it as exactly that flag, doesn&apos;t seem bad to me. How about defining a constant &quot;INFINITE_DIMENSION&quot; that has this value?&lt;/p&gt;</comment>
                            <comment id="12831413" author="jake.mannix" created="Tue, 9 Feb 2010 11:09:21 +0000"  >&lt;p&gt;I think of it as that flag as well, but when doing decompositions of matrices, you will have a matrix with a bunch (N = numRows == 10^&lt;/p&gt;
{8+}
&lt;p&gt;) of sparse vectors, each of which has some dimension (M = numCols).  Your goal is to find a matrix which has some (k = desiredRank = 100&apos;s) &lt;b&gt;dense&lt;/b&gt; vectors which each has cardinality M.  If M is Integer.MAX_VALUE, you need a couple TB of RAM to even construct this final product.  You most certainly do not want to have eigenvectors which are represented as sparse vectors, because this is a) horribly inefficient storage for them (they&apos;re dense) and b) horribly inefficient CPU-wise (ditto).&lt;/p&gt;

&lt;p&gt;We could certainly &lt;b&gt;use&lt;/b&gt; Vector.size() == Integer.MAX_VALUE as an effective &quot;flag&quot; that it&apos;s unbounded, but the important thing is what we do with that information: when you create a DenseVector of this size, the key would be to &lt;b&gt;not&lt;/b&gt; initialize the array this large, but instead initialize it to some small value, but set an internal flag saying that whenever some does a get/getQuick outside of range, return 0, and if someone does a set/setQuick outside of range, the vector automagically resizes internally to that size, and then sets.  So it becomes a &quot;grow as needed&quot; dense vector of infinite dimension.&lt;/p&gt;</comment>
                            <comment id="12831420" author="jake.mannix" created="Tue, 9 Feb 2010 11:33:45 +0000"  >&lt;p&gt;I do notice that recently added to this set of classes is the TFIDFConverter, which does keep track of featureCount, which actually solves most of my issue in this particular case, I think.  Looking into it further.&lt;/p&gt;</comment>
                            <comment id="12831428" author="robinanil" created="Tue, 9 Feb 2010 11:57:50 +0000"  >&lt;p&gt;You just needed the count? You could always map/reduce it and store it. TFIDF methods is very sneaky(keeping the count as a static key) is not very extensible&lt;/p&gt;</comment>
                            <comment id="12831432" author="jake.mannix" created="Tue, 9 Feb 2010 12:08:30 +0000"  >&lt;p&gt;Yeah, well, I need the count, and I also am modifying the vectorizer and tfidf version to a) create vectors of the proper dimension (after doing createDictionaryChunks(), we know what the dimension of the output vectors is bound to be), and b) take a &quot;--sequentialAccessOutput&quot; cmdline flag to allow for the possibility of (in the final reducer) converting the vectors from their mutation-friendly form of RandomAccessSparseVector, and sealing them up in the not-very-mutation-friendly, but zippily faster for some tasks, SequentialAccessSparseVector form.&lt;/p&gt;

&lt;p&gt;I&apos;ll put up a patch with all my DistributedLanczosSolver stuff, because that&apos;s where this is needed (plus anyone who wants finite dimensional vectors, sometimes of SequentialAccess optimized form &lt;span class=&quot;error&quot;&gt;&amp;#91;like the clusterers&amp;#93;&lt;/span&gt;)&lt;/p&gt;</comment>
                            <comment id="12831457" author="srowen" created="Tue, 9 Feb 2010 13:56:48 +0000"  >&lt;p&gt;Sounds like what you really need (and what I could use) is something like getHighestNonZeroIndex() ?&lt;/p&gt;</comment>
                            <comment id="12831680" author="srowen" created="Tue, 9 Feb 2010 21:36:23 +0000"  >&lt;p&gt;PS I think ted&apos;s suggestion that we need &apos;stretchable&apos; and non-stretchable versions of implementations, perhaps some boolean flag that causes it to expand versus error. A &apos;stretchable&apos; vector is exactly what I need actually.&lt;/p&gt;</comment>
                            <comment id="12831681" author="jake.mannix" created="Tue, 9 Feb 2010 21:39:15 +0000"  >&lt;p&gt;Yes, this is actually what I was suggesting as well.  &lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12430039" name="DictionaryVectorizer.patch" size="65250" author="robinanil" created="Tue, 12 Jan 2010 20:15:06 +0000"/>
                            <attachment id="12429906" name="DictionaryVectorizer.patch" size="50811" author="robinanil" created="Mon, 11 Jan 2010 16:37:47 +0000"/>
                            <attachment id="12429849" name="DictionaryVectorizer.patch" size="50434" author="robinanil" created="Sun, 10 Jan 2010 12:09:25 +0000"/>
                            <attachment id="12429846" name="DictionaryVectorizer.patch" size="49822" author="robinanil" created="Sun, 10 Jan 2010 07:20:50 +0000"/>
                            <attachment id="12429412" name="DictionaryVectorizer.patch" size="24874" author="robinanil" created="Tue, 5 Jan 2010 02:47:52 +0000"/>
                            <attachment id="12434944" name="MAHOUT-237-tfidf.patch" size="97394" author="robinanil" created="Fri, 5 Feb 2010 09:04:25 +0000"/>
                            <attachment id="12434588" name="MAHOUT-237-tfidf.patch" size="36634" author="robinanil" created="Tue, 2 Feb 2010 21:03:33 +0000"/>
                            <attachment id="12429907" name="SparseVector-VIntWritable.patch" size="2041" author="robinanil" created="Mon, 11 Jan 2010 16:37:47 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 13 Jan 2010 01:10:57 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9828</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hxy6cv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23181</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>