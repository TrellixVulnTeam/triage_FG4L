<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:27:30 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-1597/MAHOUT-1597.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-1597] A + 1.0 (element-wise scala operation) gives wrong result if rdd is missing rows, Spark side</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-1597</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-comment&quot;&gt;// Concoct an rdd with missing rows
&lt;/span&gt;    val aRdd: DrmRdd[Int] = sc.parallelize(
      0 -&amp;gt; dvec(1, 2, 3) ::
          3 -&amp;gt; dvec(3, 4, 5) :: Nil
    ).map { &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; (key, vec) =&amp;gt; key -&amp;gt; (vec: Vector)}

    val drmA = drmWrap(rdd = aRdd)

    val controlB = inCoreA + 1.0

    val drmB = drmA + 1.0

    (drmB -: controlB).norm should be &amp;lt; 1e-10

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;should not fail.&lt;/p&gt;

&lt;p&gt;it was failing due to elementwise scalar operator only evaluates rows actually present in dataset. &lt;/p&gt;

&lt;p&gt;In case of Int-keyed row matrices, there are implied rows that yet may not be present in RDD. &lt;/p&gt;

&lt;p&gt;Our goal is to detect the condition and evaluate missing rows prior to physical operators that don&apos;t work with missing implied rows.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12728969">MAHOUT-1597</key>
            <summary>A + 1.0 (element-wise scala operation) gives wrong result if rdd is missing rows, Spark side</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dlyubimov">Dmitriy Lyubimov</assignee>
                                    <reporter username="dlyubimov">Dmitriy Lyubimov</reporter>
                        <labels>
                    </labels>
                <created>Tue, 22 Jul 2014 22:03:01 +0100</created>
                <updated>Mon, 13 Apr 2015 11:21:17 +0100</updated>
                            <resolved>Mon, 28 Jul 2014 18:35:30 +0100</resolved>
                                    <version>0.9</version>
                                    <fixVersion>0.10.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="14070893" author="githubbot" created="Tue, 22 Jul 2014 22:06:02 +0100"  >&lt;p&gt;GitHub user dlyubimov opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/33&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/33&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1597&quot; title=&quot;A + 1.0 (element-wise scala operation) gives wrong result if rdd is missing rows, Spark side&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1597&quot;&gt;&lt;del&gt;MAHOUT-1597&lt;/del&gt;&lt;/a&gt;: A + 1.0 (element-wise scala operation) gives wrong result if rdd is missing rows, Spark side&lt;/p&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/dlyubimov/mahout&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/dlyubimov/mahout&lt;/a&gt; intfixing&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/33.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/33.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #33&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 45642b65f3f1620a4e2187af4b2b54e26ce1c42e&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   2014-07-22T01:19:37Z&lt;/p&gt;

&lt;p&gt;    WIP&lt;/p&gt;

&lt;p&gt;commit 746b3ddc6c0e7e8bb89ce591c32ba1b70ec688e6&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   2014-07-22T18:25:57Z&lt;/p&gt;

&lt;p&gt;    WIP&lt;/p&gt;

&lt;p&gt;commit 1ff376b2ddd1bcbe61f896d14e27d7a413e7313c&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   2014-07-22T20:23:14Z&lt;/p&gt;

&lt;p&gt;    Code up for lazy int-keyed missing rows fix&lt;/p&gt;

&lt;p&gt;commit c9ac3be81ed464ccc4d440b8187e15efa9a21193&lt;br/&gt;
Author: Dmitriy Lyubimov &amp;lt;dlyubimov@apache.org&amp;gt;&lt;br/&gt;
Date:   2014-07-22T21:03:25Z&lt;/p&gt;

&lt;p&gt;    Tests, passing .&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="14070909" author="githubbot" created="Tue, 22 Jul 2014 22:15:42 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/33#issuecomment-49802148&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/33#issuecomment-49802148&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Lazy evaluation.&lt;br/&gt;
    i.e. if element-wise scalar execution is not put into physical plan, then fix will never be evaluated.&lt;br/&gt;
    Similarly probably could be fixed in other conditions.&lt;br/&gt;
    Also should survive &quot;masking&quot; stuff (such as mapBlock() or other unary operators in between source rdd and elementwise scalar).&lt;/p&gt;</comment>
                            <comment id="14070999" author="githubbot" created="Tue, 22 Jul 2014 23:00:06 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/33#issuecomment-49807387&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/33#issuecomment-49807387&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Also fixes `A + B` with missing rows. &lt;/p&gt;

&lt;p&gt;    What else there was?&lt;/p&gt;</comment>
                            <comment id="14071001" author="githubbot" created="Tue, 22 Jul 2014 23:00:32 +0100"  >&lt;p&gt;Github user avati commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/33#issuecomment-49807438&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/33#issuecomment-49807438&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    The missing rows seems to be a spark specific characteristic (For e.g all matrices in h2o are fundamentally sparse (they are just called dense if they happen to have all rows))&lt;/p&gt;

&lt;p&gt;    I think (not completely sure yet), that the canHaveMissingRows could be moved into DrmRddInput instead of DrmLike and have it propagate recursively through the plan DAG as it is evaluated in tr2phys().&lt;/p&gt;

&lt;p&gt;    Each operator, like At.scala, can inspect srcA.canHaveMissingRows instead of op.canHaveMissingRows. This way DrmLike would not be polluted.&lt;/p&gt;</comment>
                            <comment id="14071004" author="githubbot" created="Tue, 22 Jul 2014 23:01:07 +0100"  >&lt;p&gt;Github user avati commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/33#issuecomment-49807502&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/33#issuecomment-49807502&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    CbindAB had similar problems like A + B&lt;/p&gt;</comment>
                            <comment id="14071011" author="githubbot" created="Tue, 22 Jul 2014 23:07:10 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/33#issuecomment-49808110&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/33#issuecomment-49808110&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @avati no i don&apos;t think so. This is similar to quick summaries of nrow, ncol and these needs to be known before RDD chain is constructed. &lt;/p&gt;

&lt;p&gt;    It may be viewed as an architectural problem as we don&apos;t very explicitly define separation between physical operators and logical (or, rather, every logical operator is also physical, although inverse is false). So DAG plans should have private&lt;span class=&quot;error&quot;&gt;&amp;#91;mahout&amp;#93;&lt;/span&gt; collection of properties that help logical rewrites. &lt;/p&gt;

&lt;p&gt;    Missing rows should be pertinent to other engines as well as we ask them to support DRM over HDFS ( drmLoadFromHDFS method), and in persistent form DRM may have missing implied rows regardless of the engine. The engine, subsequently, may choose to fix it eagerly or lazily &amp;#8211; but it doesn&apos;t change the fact that DRMs in Mahout historically may have missing implied rows, as coming out from vectorizers, there&apos;s no agreement to the contrary AFAICT.&lt;/p&gt;</comment>
                            <comment id="14071016" author="githubbot" created="Tue, 22 Jul 2014 23:13:32 +0100"  >&lt;p&gt;Github user avati commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/33#issuecomment-49808739&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/33#issuecomment-49808739&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Hmm, I think moving canHaveMissingRows to DrmRddInput should work. Unlike nrow and ncol which can signal an error, havemissingrows silently fixes it (i.e &quot;take extra step&quot; instead of &quot;assert consistency&quot;). So I don&apos;t think it has to be known upfront. fixIntConsistency() is anyways called within a physical operator - so we just need to guarantee that the physical operator can see a reliable canHaveMissingRows value.&lt;/p&gt;

&lt;p&gt;    Since the plan is always evaluated bottom up at the physical layer, even if intermediate operators are optimized out by the logical optimizer, the flag still propagates DrmRddInput to DrmRddInput as long as the physical operators propagate it. So AewScalar would be seeing a trustable srcA.canHaveMissingRows.&lt;/p&gt;</comment>
                            <comment id="14071023" author="githubbot" created="Tue, 22 Jul 2014 23:18:45 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/33#issuecomment-49809300&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/33#issuecomment-49809300&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    the point is there has to be diagnostics propagating thru DAG to help rewrites based on initial quick summaries of the checkpoints. &lt;/p&gt;

&lt;p&gt;    E.g. in initial version there was also a non-zero element estimate that (I hoped) would help optimizer to take certain rewrite decisions. I removed it as it was too much for the first step. But if cost optimizations ever become a larger part of this, operators need to be able to carry optimizer specific information . &lt;/p&gt;

&lt;p&gt;    RDDInput stuff on the other hand is merely an &quot;either/or&quot; rdd (either blockifed or row-wise). As such it is the sole final product of the optimizer. Result can&apos;t carry helper information pertinent to building result tree, I feel that would be a bad optimizer architecture.&lt;/p&gt;</comment>
                            <comment id="14071027" author="githubbot" created="Tue, 22 Jul 2014 23:22:56 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/33#issuecomment-49809684&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/33#issuecomment-49809684&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Like i said, abstraction for optimizer-related information might be better (and perhaps the one that can carry engine-specific parts), but these attribute bags must be on the dag itself.&lt;/p&gt;

&lt;p&gt;    I also see that there&apos;s a big chance this will be a factor for Flink integration as well.&lt;/p&gt;</comment>
                            <comment id="14071043" author="githubbot" created="Tue, 22 Jul 2014 23:32:14 +0100"  >&lt;p&gt;Github user avati commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/33#issuecomment-49810561&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/33#issuecomment-49810561&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    OK. If we were looking at just ensuring correctness in the spark engine&lt;br/&gt;
    then it could have been restricted to just physical operators and&lt;br/&gt;
    DrmRddInput to propagate up the missingness-flag in the RDD it represents.&lt;br/&gt;
    However, If we are looking at doing cost estimation in the optimizer in the&lt;br/&gt;
    future with this info, then you may want to put it into DrmLike.&lt;/p&gt;

&lt;p&gt;    +1&lt;/p&gt;</comment>
                            <comment id="14071049" author="githubbot" created="Tue, 22 Jul 2014 23:35:01 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/33#issuecomment-49810810&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/33#issuecomment-49810810&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Hm. CBind test over implied rows works for me. Can&apos;t seem to reproduce.&lt;/p&gt;</comment>
                            <comment id="14071092" author="githubbot" created="Wed, 23 Jul 2014 00:08:00 +0100"  >&lt;p&gt;Github user dlyubimov commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/33#issuecomment-49813626&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/33#issuecomment-49813626&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    yeah these codes (a we b fix and CBind post-cogrouping) are doing identical thing although just slightly differently. Not sure which one would be more efficient at this point. Probably neither. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14076552" author="hudson" created="Mon, 28 Jul 2014 19:31:43 +0100"  >&lt;p&gt;SUCCESS: Integrated in Mahout-Quality #2716 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2716/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2716/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1597&quot; title=&quot;A + 1.0 (element-wise scala operation) gives wrong result if rdd is missing rows, Spark side&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1597&quot;&gt;&lt;del&gt;MAHOUT-1597&lt;/del&gt;&lt;/a&gt;: A + 1.0 (element-wise scala operation) gives wrong result if rdd is missing rows, Spark side (dlyubimov) (dlyubimov: rev 377dcace16fe4fd77baaab91ad575e9da5c49ac0)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpAt.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/AbstractUnaryOp.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/package.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/blas/package.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CheckpointedDrmSpark.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/blas/AewB.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/drm/DrmLikeSuite.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/DrmLike.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/test/scala/org/apache/mahout/math/drm/RLikeDrmOpsSuiteBase.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/AbstractBinaryOp.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpAewScalar.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/SparkEngine.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/CheckpointedDrm.scala&lt;/li&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/drm/RLikeDrmOpsSuite.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpAtA.scala&lt;/li&gt;
	&lt;li&gt;CHANGELOG&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14077782" author="githubbot" created="Tue, 29 Jul 2014 15:54:50 +0100"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/mahout/pull/33&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/mahout/pull/33&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14088369" author="hudson" created="Wed, 6 Aug 2014 23:18:43 +0100"  >&lt;p&gt;SUCCESS: Integrated in Mahout-Quality #2732 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2732/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2732/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1597&quot; title=&quot;A + 1.0 (element-wise scala operation) gives wrong result if rdd is missing rows, Spark side&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1597&quot;&gt;&lt;del&gt;MAHOUT-1597&lt;/del&gt;&lt;/a&gt;: A + 1.0 (fixes) (dlyubimov: rev 7a50a291b4598e9809f9acf609b92175ce7f953b)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;spark/src/test/scala/org/apache/mahout/sparkbindings/drm/DrmLikeSuite.scala&lt;/li&gt;
	&lt;li&gt;spark/src/main/scala/org/apache/mahout/sparkbindings/drm/CheckpointedDrmSpark.scala&lt;/li&gt;
	&lt;li&gt;math-scala/src/main/scala/org/apache/mahout/math/drm/logical/OpAewScalar.scala&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 22 Jul 2014 21:06:02 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>407043</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hzrwh3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>407061</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>