<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:19:13 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-396/MAHOUT-396.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-396] Proposal for Implementing Hidden Markov Model</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-396</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;h4&gt;&lt;a name=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h4&gt;
&lt;p&gt;This is a project proposal for a summer-term university project to write a (sequential) HMM implementation for Mahout. Five students will work on this project as part of a course mentored by Isabel Drost.&lt;/p&gt;

&lt;h4&gt;&lt;a name=&quot;Abstract%3A&quot;&gt;&lt;/a&gt;Abstract:&lt;/h4&gt;
&lt;p&gt;Hidden Markov Models are used in multiple areas of Machine Learning, such as speech recognition, handwritten letter recognition or natural language processing. A Hidden Markov Model (HMM) is a statistical model of a process consisting of two (in our case discrete) random variables O and Y, which change their state sequentially. The variable Y with states &lt;/p&gt;
{y_1, ... , y_n}
&lt;p&gt; is called the &quot;hidden variable&quot;, since its state is not directly observable. The state of Y changes sequentially with a so called - in our case first-order - Markov Property. This means, that the state change probability of Y only depends on its current state and does not change in time. Formally we write: P(Y(t+1)=y_i|Y(0)...Y(t)) = P(Y(t+1)=y_i|Y(t)) = P(Y(2)=y_i|Y(1)). The variable O with states &lt;/p&gt;
{o_1, ... , o_m}
&lt;p&gt; is called the &quot;observable variable&quot;, since its state can be directly observed. O does not have a Markov Property, but its state propability depends statically on the current state of Y. &lt;/p&gt;

&lt;p&gt;Formally, an HMM is defined as a tuple M=(n,m,P,A,B), where n is the number of hidden states, m is the number of observable states, P is an n-dimensional vector containing initial hidden state probabilities, A is the nxn-dimensional &quot;transition matrix&quot; containing the transition probabilities such that A&lt;span class=&quot;error&quot;&gt;&amp;#91;i,j&amp;#93;&lt;/span&gt;=P(Y(t)=y_i|Y(t-1)=y_j) and B is the mxn-dimensional &quot;observation matrix&quot; containing the observation probabilties such that B&lt;span class=&quot;error&quot;&gt;&amp;#91;i,j&amp;#93;&lt;/span&gt;= P(O=o_i|Y=y_j).&lt;/p&gt;

&lt;p&gt;Rabiner [&lt;a href=&quot;#reference1&quot;&gt;1&lt;/a&gt;] defined three main problems for HMM models:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Evaluation: Given a sequence O of observations and a model M, what is the probability P(O|M)  that sequence O was generated by model M. The Evaluation problem can be efficiently solved using the Forward algorithm&lt;/li&gt;
	&lt;li&gt;Decoding: Given a sequence O of observations and a model M, what is the most likely sequence Y*=argmax(Y) P(O|M,Y) of hidden variables to generate this sequence. The Decoding problem can be efficiently sovled using the Viterbi algorithm.&lt;/li&gt;
	&lt;li&gt;Learning: Given a sequence O of observations, what is the most likely model M*=argmax(M)P(O|M) to generate this sequence.  The Learning problem can be efficiently solved using the Baum-Welch algorithm.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;The target of each milestone is defined as the implementation for the given goals, the respective documentation and unit tests for the implementation.&lt;/p&gt;

&lt;h4&gt;&lt;a name=&quot;Timeline&quot;&gt;&lt;/a&gt;Timeline&lt;/h4&gt;
&lt;p&gt;Mid of May 2010 - Mid of July 2010&lt;/p&gt;

&lt;h4&gt;&lt;a name=&quot;Milestones&quot;&gt;&lt;/a&gt;Milestones&lt;/h4&gt;
&lt;p&gt;I) Define an HMM class based on Apache Mahout Math package offering interfaces to set model parameters, perform consistency checks, perform output prediction.&lt;br/&gt;
1 week from May 18th till May 25th.&lt;/p&gt;

&lt;p&gt;II) Write sequential implementations of forward (cf. problem 1 [&lt;a href=&quot;#reference1&quot;&gt;1&lt;/a&gt;]) and backward algorithm.&lt;br/&gt;
2 weeks from May 25th till June 8th.&lt;/p&gt;

&lt;p&gt;III) Write a sequential implementation of Viterbi algorithm (cf. problem 2 [&lt;a href=&quot;#reference1&quot;&gt;1&lt;/a&gt;]), based on existing forward algorithm implementation.&lt;br/&gt;
2 weeks from June 8th till June 22nd&lt;/p&gt;

&lt;p&gt;IV) Have a running sequential implementation of Baum-Welch algorithm for model parameter learning (application II &lt;span class=&quot;error&quot;&gt;&amp;#91;ref&amp;#93;&lt;/span&gt;), based on existing forward/backward algorithm implementation.&lt;br/&gt;
2 weeks from June 8th till June 22nd&lt;/p&gt;

&lt;p&gt;V) Provide a usage example of HMM implementation, demonstrating all three problems.&lt;br/&gt;
2 weeks from June 22nd till July 6th&lt;/p&gt;

&lt;p&gt;VI) Finalize documentation and implemenation, clean up open ends.&lt;br/&gt;
1 week from July 6th till July 13th&lt;/p&gt;

&lt;h4&gt;&lt;a name=&quot;References%3A&quot;&gt;&lt;/a&gt;References:&lt;/h4&gt;
&lt;p&gt;&lt;a name=&quot;reference1&quot;&gt;&lt;/a&gt;[&lt;a href=&quot;http://www.cs.ubc.ca/~murphyk/Bayes/rabiner.pdf&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;1&lt;/a&gt;]    Lawrence R. Rabiner (February 1989). &quot;A tutorial on Hidden Markov Models and selected applications in speech recognition&quot;. Proceedings of the IEEE 77 (2): 257-286. doi:10.1109/5.18626.&lt;/p&gt;

&lt;p&gt;Potential test data sets:&lt;br/&gt;
&lt;a href=&quot;http://www.cnts.ua.ac.be/conll2000/chunking/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.cnts.ua.ac.be/conll2000/chunking/&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Character+Trajectories&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://archive.ics.uci.edu/ml/datasets/Character+Trajectories&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12464627">MAHOUT-396</key>
            <summary>Proposal for Implementing Hidden Markov Model</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mheimel">Max Heimel</assignee>
                                    <reporter username="mheimel">Max Heimel</reporter>
                        <labels>
                    </labels>
                <created>Sun, 16 May 2010 20:31:12 +0100</created>
                <updated>Sun, 31 Oct 2010 15:49:30 +0000</updated>
                            <resolved>Fri, 24 Sep 2010 12:17:33 +0100</resolved>
                                    <version>0.4</version>
                                    <fixVersion>0.4</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12868035" author="tdunning" created="Sun, 16 May 2010 21:16:18 +0100"  >
&lt;p&gt;Great stuff.&lt;/p&gt;

&lt;p&gt;Hopefully it will be possible to adapt this to a parallel implementation.  Since the Baum-Welch algorithm is an instance of an EM algorithm map-reduce implementation should be simple, much as it is with k-means.  Moreover, much of the code in a map-reduce implementation would be shared with a sequential version.&lt;/p&gt;</comment>
                            <comment id="12871617" author="mheimel" created="Wed, 26 May 2010 11:45:05 +0100"  >&lt;p&gt;This patch adds the base HMM model class and a prediction mechanism to predict a sequence of output states from A model. Additionally, the stubs  for further implementation are added. We still have to add unit tests for the HMM base class, which will be done with the next update (adding forward/backward algorithm and further helper methods).&lt;/p&gt;</comment>
                            <comment id="12871636" author="mheimel" created="Wed, 26 May 2010 12:52:49 +0100"  >&lt;p&gt;renamed patch file to stick with naming conventions &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12871780" author="robinanil" created="Wed, 26 May 2010 16:50:24 +0100"  >&lt;p&gt;Few comments on the code tyle. See Mahout  core classes to see the code and naming conventions&lt;/p&gt;

&lt;p&gt;1. package org.apache.mahout.sequenceLearning.hmm;&lt;br/&gt;
remove capitalization  and change to package org.apache.mahout.classifier.sequencelearning.hmm;&lt;/p&gt;

&lt;p&gt;2. Use the eclipse code style sheet. &lt;/p&gt;

&lt;p&gt;3. 	java.util.Vector&amp;lt;Integer&amp;gt; outputSequence &lt;br/&gt;
dont use Java.vector, kinda confuses with the Mahout vector. For integer arrays use the super-fast       o.a.m.math.list.IntArrayList&lt;/p&gt;

&lt;p&gt;4. Before you put the final patch, put the Apache License too. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;
</comment>
                            <comment id="12871782" author="bmargulies" created="Wed, 26 May 2010 16:57:59 +0100"  >&lt;p&gt;Why inside &apos;classifier&apos;? Are you defining all sequence problems as classification?&lt;/p&gt;</comment>
                            <comment id="12871881" author="gsingers" created="Wed, 26 May 2010 19:43:47 +0100"  >&lt;p&gt;Would be great if you could fill in the HMM section under &lt;a href=&quot;https://cwiki.apache.org/MAHOUT/algorithms.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/MAHOUT/algorithms.html&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12872748" author="mheimel" created="Fri, 28 May 2010 01:39:23 +0100"  >&lt;p&gt;Worked in the suggestions made by Robin Anil (move to classifier/sequencelearning/hmm, use eclipe code style sheet, add apache licese, use IntArrayList instead of java.util.vector&amp;lt;Integer&amp;gt;).&lt;/p&gt;</comment>
                            <comment id="12875910" author="mheimel" created="Sat, 5 Jun 2010 15:58:05 +0100"  >&lt;p&gt;With this patch, the HMM implementation contains the forward and backward algorithm plus unit tests. There might however still be interface changes at how the HMMAlgorithms Object is handled...&lt;/p&gt;</comment>
                            <comment id="12878278" author="mheimel" created="Sat, 12 Jun 2010 17:00:52 +0100"  >&lt;p&gt;Patch now contains implementation &amp;amp; unit tests of Viterbi algorithm for HMM decoding.&lt;/p&gt;</comment>
                            <comment id="12878280" author="mheimel" created="Sat, 12 Jun 2010 17:07:45 +0100"  >&lt;p&gt;I just submitted the latest HMM patch, which contains implementations for the forward/backward and Viterbi algorithm. This allows solving the problems of decoding and evaluatiing a Hidden Markov model. The next step on the HMM Agenda will be the Baum-Welch algorithm to tackle the learning problem. &lt;/p&gt;

&lt;p&gt;The open to-dos are:&lt;br/&gt;
1) Implement the Baum-Welch algorithm and write unit tests for the implementation. (I hope to finish this task by next week... )&lt;br/&gt;
2) Find real-world examples that make use of the HMM implementation to demonstrate both usage and usefullness (where to find good data sets?)&lt;br/&gt;
3) Implement methods for serializing/deserializing an HMMModel (to file? to string? both?)&lt;br/&gt;
4) Write logarithmically scaled versions of the Hmm related algorithms to better handle numeric issues with very low probabiliites.&lt;br/&gt;
5) Think about adding interfaces to the HmmEvaluator methods, that accept state names instead of state numbers to provide more user convenience in using the HMM implementation.&lt;/p&gt;

&lt;p&gt;Do you have any further remarks, comments, suggestions?&lt;/p&gt;</comment>
                            <comment id="12878319" author="qiuyan" created="Sat, 12 Jun 2010 23:12:41 +0100"  >&lt;p&gt;Marc and I will do the 2. task:&lt;br/&gt;
Find real-world examples that make use of the HMM implementation to demonstrate both usage and usefullness&lt;/p&gt;</comment>
                            <comment id="12880146" author="isabel" created="Fri, 18 Jun 2010 10:56:41 +0100"  >&lt;p&gt;Assigning to Max Heimel who is doing most of the implementation and integration work so far.&lt;/p&gt;</comment>
                            <comment id="12891402" author="mheimel" created="Fri, 23 Jul 2010 00:49:50 +0100"  >&lt;p&gt;Patch containing the full HMM implementation. This includes implementations of forward, backward, Viterbi algorithm and three learning algorithms (supervised, Viterbi, Baum-Welch). All algorithms are available in a normal and log-scaled variant. The HMM model can now be exported to JSON.  &lt;br/&gt;
This patch also contains a small demo application that implements a POS tagger using the HMM implementation. Using the test/training data sets from &lt;a href=&quot;http://flexcrfs.sourceforge.net/#Case_Study&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://flexcrfs.sourceforge.net/#Case_Study&lt;/a&gt; this demo-application achieves a tagging accuracy of 94% by applying supervised learning. The learning and tagging process takes less than a second on a 2,6Ghz AMD dual core processor with 5Gb of RAM running Ubuntu 10.04.&lt;/p&gt;</comment>
                            <comment id="12891403" author="mheimel" created="Fri, 23 Jul 2010 00:51:16 +0100"  >&lt;p&gt;Patch containing the full HMM implementation. This includes implementations of forward, backward, Viterbi algorithm and three learning algorithms (supervised, Viterbi, Baum-Welch). All algorithms are available in a normal and log-scaled variant. The HMM model can now be exported to JSON.&lt;br/&gt;
This patch also contains a small demo application that implements a POS tagger using the HMM implementation. Using the test/training data sets from &lt;a href=&quot;http://flexcrfs.sourceforge.net/#Case_Study&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://flexcrfs.sourceforge.net/#Case_Study&lt;/a&gt; this demo-application achieves a tagging accuracy of 94% by applying supervised learning. The learning and tagging process takes less than a second on a 2,6Ghz AMD dual core processor with 5Gb of RAM running Ubuntu 10.04.&lt;/p&gt;</comment>
                            <comment id="12891416" author="mheimel" created="Fri, 23 Jul 2010 01:14:25 +0100"  >&lt;p&gt;The latest patch contains the finished implementation and test suite of  sequential Hidden Markov Models for Apache Mahout and should be ready for review. &lt;/p&gt;

&lt;p&gt;The implementation now offers all the required functionality (initialization, evaluation, training, loading/storing) and should work fairly efficient. All algorithms are implemented to optionally use log-likelihoods to trade off computation time for increased numerical stability in case of long output sequences. Models can be serialized and deserialized from Json. There are three training algorithms tackling different usage scenarios (supervised, Viterbi, Baum-Welch) available.&lt;/p&gt;

&lt;p&gt;I included a small demo-program (org.apache.mahout.classifier.sequencelearning.hmm.example.PosTagger.java) that demonstrates usage of the model class by implementing a simple PartOfSpeech-tagger using the training/test data sets from &lt;a href=&quot;http://flexcrfs.sourceforge.net/#Case_Study&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://flexcrfs.sourceforge.net/#Case_Study&lt;/a&gt;. Using simple supervised learning on the training data set &amp;amp; assuming unknown words to be of type PNP (proper noun present), the tagger reaches a test accuracy of 94%.  The program output with timings on my Athlon 2.6Ghz dual core with 4GB of RAM running Ubuntu 10.04 is:&lt;br/&gt;
&quot;Using URL: &lt;a href=&quot;http://www.jaist.ac.jp/~hieuxuan/flexcrfs/CoNLL2000-NP/train.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.jaist.ac.jp/~hieuxuan/flexcrfs/CoNLL2000-NP/train.txt&lt;/a&gt;&lt;br/&gt;
Reading and parsing training data file ... done in 22.479 seconds!&lt;br/&gt;
	Read 211727 lines containing 8936 sentences with a total of 19122 distinct words and 43 distinct POS tags.&lt;br/&gt;
Training HMM model ... done in 0.719 seconds!&lt;br/&gt;
Reading and parsing test data file ... done in 3.189 seconds!&lt;br/&gt;
	Read 47377 lines containing 2012 sentences.&lt;br/&gt;
POS tagging test data file ... done in 0.475 seconds!&lt;br/&gt;
Tagged the test file with an error rate of: 0.060176879076345065&quot;&lt;/p&gt;

&lt;p&gt;There are still some open ends that need to be looked into. The major points are:&lt;br/&gt;
1) Redesigning HmmAlgorithms to handle SparseMatrix/SparseVector more efficiently (via nonZeroIterator)&lt;/p&gt;

&lt;p&gt;2) Serializing and Deserializing of a model is currently possible using JSON. However, for large models this becomes highly inefficient. E.g. serializing the model created in the PosTagging example results in an 18MB JSO file that takes much&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/warning.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; longer to deserialze than a reconstruction from the training data takes. It would thus probably be a good idea to look into binary serialization/deserialization.&lt;/p&gt;

&lt;p&gt;3) Convergence check for Viterbi/Baum-Welch: currently the convergenc check uses an &quot;ad-hoc&quot; matrix difference. Since BW is an EM algorithm, it would probably be mathematically more sound to switch to using the model likelihood for the convergence check.&lt;/p&gt;

&lt;p&gt;4) Parallelization: The traditional algorithms (forward,backward,viterbi,baum-welch) are probably hard to parallelize using M/R - there is some prior work regarding parallelization, but I haven&apos;t quite looked into this yet. A more suitable approach to HMM parallelization would be to train in parallel on multiple sequences (e.g. one per mapper) and then merge the resulting HMMs in the reducer step. &lt;/p&gt;</comment>
                            <comment id="12893143" author="qiuyan" created="Wed, 28 Jul 2010 12:46:30 +0100"  >&lt;p&gt;We&apos;ve made another test over the same training data and test data with a statistic approach. For each word which also exists in the training data, we assign it with the corresponding Pos tag, that appeared most frequently. For all unknown words, we assign it with the type NNP. The precision turned out to be 91.7%.&lt;/p&gt;</comment>
                            <comment id="12898284" author="isabel" created="Fri, 13 Aug 2010 16:44:59 +0100"  >&lt;p&gt;Patch applies cleanly with &quot;-p1&quot; (was generated from a git clone of Mahout), builds, all tests green after applying it.&lt;/p&gt;

&lt;p&gt;Some comments after taking an initial look at the code:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Please don&apos;t use &quot;System.out.println&quot; anywhere in the code - use Loggers instead.&lt;/li&gt;
	&lt;li&gt;I still see quite a few int Arrays in the example code. Could you please provide some explanation of why you did not use the o.a.m.math.list.IntArrayList as proposed by Robin?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Rest of the code looks to me otherwise - though I am to be considered highly subjective in that matter. Would be glad if a second Mahout developer had time to have a look.&lt;/p&gt;

&lt;p&gt;Just for the record: The current implementation is sequential-only. During the past few weeks I have come accross a few publications that might be interesting for follow-up work: &quot;Scaling the iHMM: Parallelization versus Hadoop&quot;. In addition there seem the have been works in the direction of spectral learning algorithms for HMMs that might be interesting: &quot;Hilbert Space Embeddings of Hidden Markov Models (L. Song, B. Boots, S. Saddiqi, G. Gordon, A. Smola)&quot; and  &quot;A spectral algorithm for learning hidden Markov models (D. Hsu, S. Kakade, T. Zhang)&quot;&lt;/p&gt;</comment>
                            <comment id="12898285" author="isabel" created="Fri, 13 Aug 2010 16:46:25 +0100"  >&lt;p&gt;Hmpf - please add a &quot;good&quot; between: &quot;Rest of the code looks&quot; and &quot;to me otherwise&quot;.&lt;/p&gt;</comment>
                            <comment id="12909745" author="mheimel" created="Wed, 15 Sep 2010 15:23:09 +0100"  >&lt;p&gt;Sorry for the long delay, I have some exams coming up, so I had to focus on learning &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Here are my comments reagarding your review (I will comment on the paralleization papers, once I read through them &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;I have fixed the issue with using System.out by replacing it by calls to LOG.info( .. ) in the PosTagger example.&lt;/li&gt;
	&lt;li&gt;I have fixed some build errors within the unit tests that must have come up since you reviewed the code.&lt;/li&gt;
	&lt;li&gt;I moved the PosTagger example to mahout-examples subproject&lt;/li&gt;
	&lt;li&gt;Regarding the IntArrayList: There actually was a problem I encountered which made me switch to int[]  - however I cannot recall it. Shame on me &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  However, since int[] only gets used in places where the array size is guaranteed not to change, and since you can easily get an int[] from an IntArray, I actually don&apos;t see an advantage of using IntArray over int[]. If I am assessing this wrong, please let me know and I will look into replacing the int[] with IntArray objects.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I have attached the latest patch.&lt;/p&gt;</comment>
                            <comment id="12909747" author="mheimel" created="Wed, 15 Sep 2010 15:24:09 +0100"  >&lt;p&gt;Latest patch, containing fixes for the comments raised by Isabel during code review.&lt;/p&gt;</comment>
                            <comment id="12910616" author="isabel" created="Fri, 17 Sep 2010 16:09:53 +0100"  >&lt;p&gt;Patch should be applied with -p1 set.&lt;/p&gt;

&lt;p&gt;One more sweep over the patch to remove style issues: Fixed indent, a few variable names, some typos in the documentation, added some documentation where missing, removed unused imports/variables.&lt;/p&gt;

&lt;p&gt;Max, please be so kind to double-check that in the course of code cleanup nothing broke and especially that documentation is still correct. I marked one particular method with a TODO that had an unclear comment.&lt;/p&gt;

&lt;p&gt;Sean, as you have done so much work in recent weeks to get our code base clean - it would be really great, if you could double-check that I neither missed a problem nor introduced new ones - tried to stick with our checkstyle coding conventions, findbugs configuration and the additional checks that intellij has built-in.&lt;/p&gt;</comment>
                            <comment id="12913129" author="tdunning" created="Tue, 21 Sep 2010 19:01:12 +0100"  >&lt;p&gt;Isabel,&lt;/p&gt;

&lt;p&gt;Is this ready to check in?&lt;/p&gt;</comment>
                            <comment id="12914414" author="isabel" created="Fri, 24 Sep 2010 12:17:33 +0100"  >&lt;p&gt;Changes committed.&lt;/p&gt;</comment>
                            <comment id="12914417" author="isabel" created="Fri, 24 Sep 2010 12:19:59 +0100"  >&lt;p&gt;Thanks to Max Heimel, Marc Hofer, Qiuyan Xu and Van Long Nguyen for contributing the patch.&lt;/p&gt;</comment>
                            <comment id="12914456" author="hudson" created="Fri, 24 Sep 2010 13:56:53 +0100"  >&lt;p&gt;Integrated in Mahout-Quality #319 (See &lt;a href=&quot;https://hudson.apache.org/hudson/job/Mahout-Quality/319/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://hudson.apache.org/hudson/job/Mahout-Quality/319/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-396&quot; title=&quot;Proposal for Implementing Hidden Markov Model&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-396&quot;&gt;&lt;del&gt;MAHOUT-396&lt;/del&gt;&lt;/a&gt; - add HMM support for sequence classification. Thanks to Max&lt;br/&gt;
Heimel, Marc Hofer, Qiuyan Xu and Van Long Nguyen for contributing the&lt;br/&gt;
patch.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12454860" name="MAHOUT-396.diff" size="114963" author="isabel" created="Fri, 17 Sep 2010 16:09:53 +0100"/>
                            <attachment id="12450241" name="MAHOUT-396.diff" size="108366" author="mheimel" created="Fri, 23 Jul 2010 00:51:16 +0100"/>
                            <attachment id="12446955" name="MAHOUT-396.diff" size="46620" author="mheimel" created="Sat, 12 Jun 2010 17:00:52 +0100"/>
                            <attachment id="12446410" name="MAHOUT-396.diff" size="44513" author="mheimel" created="Sat, 5 Jun 2010 15:58:05 +0100"/>
                            <attachment id="12445730" name="MAHOUT-396.diff" size="28177" author="mheimel" created="Fri, 28 May 2010 01:39:22 +0100"/>
                            <attachment id="12445543" name="MAHOUT-396.diff" size="22784" author="mheimel" created="Wed, 26 May 2010 12:52:49 +0100"/>
                            <attachment id="12454657" name="MAHOUT-396.patch" size="110740" author="mheimel" created="Wed, 15 Sep 2010 15:24:08 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 16 May 2010 20:16:18 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9668</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hxy5dj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23022</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>