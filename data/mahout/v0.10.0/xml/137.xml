<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:22:29 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-137/MAHOUT-137.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-137] Convert Clustering Algs to use Vector Writable</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-137</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;p&gt;All M/R jobs should use Vector writable instead of encoding and decoding strings.  We can have a separate utility that converts serialized GSON, Strings, whatever into the appropriate vectors.  See &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-136&quot; title=&quot;Change Canopy MR Implementation to use Vector Writable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-136&quot;&gt;&lt;del&gt;MAHOUT-136&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;http://www.lucidimagination.com/search/document/6a55f260826fd77f/jira_commented_mahout_136_change_canopy_mr_implementation_to_use_vector_writable&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.lucidimagination.com/search/document/6a55f260826fd77f/jira_commented_mahout_136_change_canopy_mr_implementation_to_use_vector_writable&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12428472">MAHOUT-137</key>
            <summary>Convert Clustering Algs to use Vector Writable</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gsingers">Grant Ingersoll</assignee>
                                    <reporter username="gsingers">Grant Ingersoll</reporter>
                        <labels>
                    </labels>
                <created>Sat, 20 Jun 2009 14:26:51 +0100</created>
                <updated>Wed, 18 Nov 2009 14:05:55 +0000</updated>
                            <resolved>Mon, 29 Jun 2009 18:03:28 +0100</resolved>
                                                    <fixVersion>0.2</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12722246" author="jeastman" created="Sat, 20 Jun 2009 20:21:21 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-136&quot; title=&quot;Change Canopy MR Implementation to use Vector Writable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-136&quot;&gt;&lt;del&gt;MAHOUT-136&lt;/del&gt;&lt;/a&gt; changed Canopy to use Writable between map and reduce steps, but input and output formats are still Text. In the interests of consistency and efficiency, it makes sense to convert all of the clustering jobs to use Writables for I/O too. We can have a separate utility job to convert from Writable form to Json or other textual representations if that is needed. Since most clustering jobs will have an input step to prepare the points for clustering anyway, having this output Writables vs Text would be a small change.&lt;/p&gt;</comment>
                            <comment id="12722272" author="gsingers" created="Sat, 20 Jun 2009 23:58:19 +0100"  >&lt;p&gt;Yes, this is the plan.  The problem I&apos;m having right now is between the CanopyDriver and the ClusterDriver for Canopy.  I&apos;ve made Canopy Writable (similar to the formatString approach where it just stores the centroid and the canopy id) but this isn&apos;t fully working yet.&lt;/p&gt;</comment>
                            <comment id="12722294" author="gsingers" created="Sun, 21 Jun 2009 03:44:08 +0100"  >&lt;p&gt;Here&apos;s a start, but not all the tests don&apos;t pass yet.&lt;/p&gt;</comment>
                            <comment id="12722295" author="gsingers" created="Sun, 21 Jun 2009 03:55:27 +0100"  >&lt;p&gt;I should mention, it is only for Canopy and only two tests in TestCanopyCreation fail.  All the pieces pass except for the main one that tests the full M/R job.&lt;/p&gt;</comment>
                            <comment id="12722360" author="jeastman" created="Sun, 21 Jun 2009 15:54:52 +0100"  >&lt;p&gt;You got bit by the fact that the reader is not creating a distinct instance and is reusing Canopy value. This makes all of the canopies identical and messes up the test. Here I&apos;m making a copy of the canopy before adding it to the canopies list. The unit test now passes. Before committing these changes, you really ought to fix the code in examples too.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;      try {
        Text key = new Text();
        Canopy value = new Canopy();
        while (reader.next(key, value)) {
          canopies.add(new Canopy(value.getCenter(),value.getCanopyId()));
        }
      } finally {
        reader.close();
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12722361" author="gsingers" created="Sun, 21 Jun 2009 16:01:27 +0100"  >&lt;p&gt;Ah, cool.  Thanks!  I&apos;ve got a ways to go on this one, but will start with small steps.&lt;/p&gt;</comment>
                            <comment id="12722367" author="jeastman" created="Sun, 21 Jun 2009 16:11:16 +0100"  >&lt;p&gt;I find it a bit troubling that SparseVector.class must be specified explicit as the map and job output types instead of just Vector.class&lt;/p&gt;</comment>
                            <comment id="12722372" author="jeastman" created="Sun, 21 Jun 2009 16:31:39 +0100"  >&lt;p&gt;How about we add a job argument to set whether to use DenseVector or SparseVector?&lt;/p&gt;

&lt;p&gt;Looks like we will need an OutputDriver step in Synthetic Control now to convert back to human-readable form. I have a patch for the rest of it if you want it, let me know.&lt;/p&gt;

&lt;p&gt;I&apos;m going to work on Mean Shift and Dirichlet later today while you finish Canopy and do Kmeans?&lt;/p&gt;</comment>
                            <comment id="12722373" author="gsingers" created="Sun, 21 Jun 2009 16:40:45 +0100"  >&lt;blockquote&gt;&lt;p&gt;I find it a bit troubling that SparseVector.class must be specified explicit as the map and job output types instead of just Vector.class&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agreed, but I was following your lead.&lt;/p&gt;

&lt;p&gt;Sounds good on MS and Dirichlet&lt;/p&gt;</comment>
                            <comment id="12722382" author="jeastman" created="Sun, 21 Jun 2009 17:55:34 +0100"  >&lt;p&gt;Evidently, Hadoop needs to know the concrete class so it does not have to marshall the class name with every instance. It makes sense and is more efficient but it will require us to be more clever about using DenseVectors. A job argument would do the trick, and we might want to add another to specify the Binary/Json output encoding so we don&apos;t always have to always do an output driver step to get something human-readable. &lt;/p&gt;</comment>
                            <comment id="12722383" author="jeastman" created="Sun, 21 Jun 2009 17:58:55 +0100"  >&lt;p&gt;This is a bit more efficient patch for the ClusterMapper:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;        Canopy value = new Canopy();
        while (reader.next(key, value)) {
          canopies.add(value);
          value = new Canopy();
        }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12722585" author="gsingers" created="Mon, 22 Jun 2009 14:04:38 +0100"  >&lt;p&gt;Canopy tests pass.  Ran the Synthetic control in local mode and it works, but haven&apos;t validated the output, as we need to write up the OutputDriver that takes in a sequence file and outputs GSON.&lt;/p&gt;

&lt;p&gt;Added the need to pass in the concrete Vector implementation.  Also changed computeCentroid to return Vector (the actual implementation is still Sparse, but we should reserve the flexibility)&lt;/p&gt;</comment>
                            <comment id="12722608" author="gsingers" created="Mon, 22 Jun 2009 15:02:30 +0100"  >&lt;p&gt;Updates LuceneIterable to have options for output VectorIterable.  Also makes it easy for others to plug in their output mechanism.&lt;/p&gt;

&lt;p&gt;I&apos;d like to commit this as an interim today so that Jeff can sync up and work on his side.&lt;/p&gt;</comment>
                            <comment id="12722609" author="gsingers" created="Mon, 22 Jun 2009 15:04:04 +0100"  >&lt;p&gt;The right patch.&lt;/p&gt;</comment>
                            <comment id="12722663" author="jeastman" created="Mon, 22 Jun 2009 17:22:35 +0100"  >&lt;p&gt;Here&apos;s some code (which depends upon the AbstractVector methods becoming public) which encodes the class name in addition to the elements and is vector-type agnostic.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  public void readFields(DataInput in) throws IOException {
    this.canopyId = in.readInt();
    this.center = AbstractVector.readVector(in);
  }

  @Override
  public void write(DataOutput out) throws IOException {
    out.writeInt(canopyId);
    AbstractVector.writeVector(out, computeCentroid());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12722666" author="gsingers" created="Mon, 22 Jun 2009 17:33:43 +0100"  >&lt;p&gt;The only thing I worry about w/ this approach is that forName() call is pretty time consuming.&lt;/p&gt;</comment>
                            <comment id="12722688" author="gsingers" created="Mon, 22 Jun 2009 18:21:36 +0100"  >&lt;p&gt;BTW, this seems like a good ? for core-user@hadoop.a.o. &lt;/p&gt;
</comment>
                            <comment id="12722690" author="gsingers" created="Mon, 22 Jun 2009 18:24:18 +0100"  >&lt;p&gt;Also, did you look at what I did in the patch I posted to handle it?  Basically, push the question off to the user.  &lt;/p&gt;

&lt;p&gt;Of course, that is slightly less than ideal.  It seems like people shouldn&apos;t have to care about the underlying implementation.  Furthermore, I don&apos;t know the likelihood that one would need to mix dense w/ sparse.  Intuition suggests to me that if one vector needs to be dense, then most vectors are likely to be dense and likewise, that if one vector is going to be sparse, the nature of the problem is such that all vectors are sparse (thinking of text), but this isn&apos;t based on any personal experience, it&apos;s just a guess.&lt;/p&gt;</comment>
                            <comment id="12722708" author="jeastman" created="Mon, 22 Jun 2009 18:46:09 +0100"  >&lt;p&gt;Yes, I saw that and that was my original approach too. I do like the ability to have the clustering jobs be vector-type agnostic and pushing it into an argument does work. On output, we still need it as a job argument since we need to know the type at config-time. This also allows us to use the same internal form between mapper and reducer steps in a clustering. I agree users would not like to have to worry about specifying it if we could avoid it, maybe that&apos;s the real question for core-user. &lt;/p&gt;

&lt;p&gt;I also think it is unlikely that a given application of clustering would mix sparse and dense vectors though it would allow us to make the particular encoding be automatic on a per-instance basis. Using the optimized AbstractVector methods on input would add a little storage overhead to the input data but would allow this flexibility. &lt;/p&gt;
</comment>
                            <comment id="12722754" author="gsingers" created="Mon, 22 Jun 2009 19:41:13 +0100"  >&lt;p&gt;I asked the question on &lt;a href=&quot;http://hadoop.markmail.org/message/jr4cbem46erlhgzu&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hadoop.markmail.org/message/jr4cbem46erlhgzu&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12722863" author="gsingers" created="Mon, 22 Jun 2009 23:15:26 +0100"  >&lt;p&gt;Draft of KMeans conversion.  Most tests pass except testKMeansReducer and testKMeansMRJob.  &lt;/p&gt;

&lt;p&gt;In reading the testKMeansMRJob() it is not clear to me what that last part of the test is doing (after the BufferedReader)&lt;/p&gt;

&lt;p&gt;As for the Reducer test, I&apos;m not sure why the Centers aren&apos;t matching up.&lt;/p&gt;

&lt;p&gt;Some extra eyes would be appreciated.&lt;/p&gt;</comment>
                            <comment id="12722930" author="gsingers" created="Tue, 23 Jun 2009 03:00:51 +0100"  >&lt;p&gt;Fuzzy kMeans conversion, but tests fail.  Some doubt in my mind about the validity of some of the tests, but still working through those.  Could use some extra eyes from the authors of these pieces.&lt;/p&gt;</comment>
                            <comment id="12723067" author="gsingers" created="Tue, 23 Jun 2009 14:02:17 +0100"  >&lt;p&gt;I see the problem now with KMeans (and likely Fuzzy KMeans, and it is a source of confusion.  Namely, it&apos;s the whole relationship between Cluster.center and Cluster.centroid.  It seems as the Cluster goes from formatCluster through decodeCluster the centroid (computed in formatCluster) then becomes the center for the next time around.   In the testKMeansReducer, this never happens since we aren&apos;t serializing through the string layer. &lt;/p&gt;

&lt;p&gt;Obviously, I can correct this in the test, but it seems a bit strange.  AIUI, the center holds the current iteration center and it seems like the centroid is the result of where the center is being moved to, right?  This does indeed happen in my implementation of Writable, but since that isn&apos;t being called in the test, it doesn&apos;t occur.&lt;/p&gt;</comment>
                            <comment id="12723102" author="gsingers" created="Tue, 23 Jun 2009 16:05:00 +0100"  >&lt;p&gt;OK, I&apos;ve got KMeans passing.  Was a transposition error in the test on my part.  Now trying to get Fuzzy working&lt;/p&gt;</comment>
                            <comment id="12723170" author="gsingers" created="Tue, 23 Jun 2009 17:33:08 +0100"  >&lt;p&gt;Found the issues with *KMeans.  Tests pass.   Need to update the examples, then I will commit.&lt;/p&gt;</comment>
                            <comment id="12723187" author="gsingers" created="Tue, 23 Jun 2009 18:03:26 +0100"  >&lt;p&gt;The KMeans examples seem a bit trickier, b/c they seem to be abusing the fact that the output of Canopy looks very much like a Cluster as well when viewed as Text.  Unfortunately, the KMeansMapper is looking for a Cluster object, but is getting a Canopy.&lt;/p&gt;

&lt;p&gt;Any thoughts on how to remedy?&lt;/p&gt;</comment>
                            <comment id="12723193" author="jeastman" created="Tue, 23 Jun 2009 18:21:38 +0100"  >&lt;p&gt;Short term: have the examples job just convert them before running Hadoop&lt;/p&gt;

&lt;p&gt;Long term: factor the canopy- and kmeans-specific stuff out of Canopy and Cluster. Replace Canopy with simplified Cluster&lt;/p&gt;</comment>
                            <comment id="12723221" author="gsingers" created="Tue, 23 Jun 2009 18:58:33 +0100"  >&lt;p&gt;I think I found a better way: SequenceFile.Reader.getValueClass() returns the type.  I should be able to detect whether it is Canopy or Cluster and deal appropriately.  I&apos;ll post a patch if it works.&lt;/p&gt;</comment>
                            <comment id="12723233" author="gsingers" created="Tue, 23 Jun 2009 19:21:45 +0100"  >&lt;p&gt;Tests pass, fixed the issue w/ Canopy -&amp;gt; Cluster mapping.  Will commit shortly.&lt;/p&gt;

&lt;p&gt;Jeff, can you hook in your AbstractVector stuff in replacing my string workaround (for serialization of Canopy/Cluster)&lt;/p&gt;
</comment>
                            <comment id="12723235" author="gsingers" created="Tue, 23 Jun 2009 19:24:22 +0100"  >&lt;p&gt;Committed revision 787776.  This contains the patch I just submitted.&lt;/p&gt;</comment>
                            <comment id="12723678" author="jeastman" created="Wed, 24 Jun 2009 19:45:50 +0100"  >&lt;p&gt;revision 788071 and 788116 implement Writable changes to MeanShift and Dirichlet clustering. MeanShift no longer has the bogus combiner but still holds all clustered points so it really wont scale well. Dirichlet needs some more fixing but that is another issue.&lt;/p&gt;

&lt;p&gt;Some cleanup of directory structures to improve uniformity of naming is needed. Will do that under this issue since it is minor.&lt;/p&gt;</comment>
                            <comment id="12723688" author="gsingers" created="Wed, 24 Jun 2009 20:14:44 +0100"  >&lt;p&gt;FYI, I&apos;ve refactored Canopy/Cluster slightly to have a base class in common.  I also have been putting together some output tools that live in the utils module (similar to the LuceneIterable, etc.)&lt;/p&gt;</comment>
                            <comment id="12725249" author="gsingers" created="Mon, 29 Jun 2009 18:03:28 +0100"  >&lt;p&gt;I believe they are all converted.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12428422">MAHOUT-136</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12430881">MAHOUT-148</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12411561" name="MAHOUT-137.patch" size="167650" author="gsingers" created="Tue, 23 Jun 2009 19:21:45 +0100"/>
                            <attachment id="12411549" name="MAHOUT-137.patch" size="164246" author="gsingers" created="Tue, 23 Jun 2009 17:33:08 +0100"/>
                            <attachment id="12411481" name="MAHOUT-137.patch" size="162551" author="gsingers" created="Tue, 23 Jun 2009 03:00:51 +0100"/>
                            <attachment id="12411465" name="MAHOUT-137.patch" size="121534" author="gsingers" created="Mon, 22 Jun 2009 23:15:26 +0100"/>
                            <attachment id="12411410" name="MAHOUT-137.patch" size="84710" author="gsingers" created="Mon, 22 Jun 2009 15:04:04 +0100"/>
                            <attachment id="12411409" name="MAHOUT-137.patch" size="84710" author="gsingers" created="Mon, 22 Jun 2009 15:02:30 +0100"/>
                            <attachment id="12411400" name="MAHOUT-137.patch" size="69810" author="gsingers" created="Mon, 22 Jun 2009 14:04:38 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 20 Jun 2009 19:21:21 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9928</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hxy6z3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23281</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>