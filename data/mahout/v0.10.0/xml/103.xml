<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:20:50 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-103/MAHOUT-103.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-103] Co-occurence based nearest neighbourhood</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-103</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;p&gt;Nearest neighborhood type queries for users/items can be answered efficiently and effectively by analyzing the co-occurrence model of a user/item w.r.t another. This patch aims at providing an implementation for answering such queries based upon simple co-occurrence counts.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12412892">MAHOUT-103</key>
            <summary>Co-occurence based nearest neighbourhood</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ankur">Ankur</assignee>
                                    <reporter username="ankur">Ankur</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 Jan 2009 07:53:23 +0000</created>
                <updated>Sat, 21 May 2011 04:24:18 +0100</updated>
                            <resolved>Wed, 23 Dec 2009 19:51:07 +0000</resolved>
                                                    <fixVersion>0.3</fixVersion>
                                    <component>Collaborative Filtering</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="12668473" author="ankur" created="Thu, 29 Jan 2009 14:01:36 +0000"  >&lt;p&gt;Ok here is a quick patch with just enough documentation and no unit tests or dummy data. The code works but following things can be improved...&lt;/p&gt;

&lt;p&gt;1. The code can be better structured and integrated.&lt;br/&gt;
2. Logging needs to be added.&lt;br/&gt;
3.  Documentation can be more informative. &lt;br/&gt;
4. Dummy data and unit tests need to be added. &lt;/p&gt;</comment>
                            <comment id="12668475" author="ankur" created="Thu, 29 Jan 2009 14:02:26 +0000"  >&lt;p&gt;I hoping to make the above improvements after I get some review comments.&lt;/p&gt;</comment>
                            <comment id="12682674" author="srowen" created="Tue, 17 Mar 2009 13:41:28 +0000"  >&lt;p&gt;Oh my just saw this. My thoughts after looking at the patch:&lt;/p&gt;

&lt;p&gt;Overall this feels like its doing the same thing as a combination of TanimotoCoefficientSimilarity and BooleanPreferenceUser &amp;#8211; defining user/item similarity in terms of simple co-occurrence of items in users. &lt;/p&gt;

&lt;p&gt;In particular FitnessEvaluator looks like the same thing as ItemSimilarity. Click feels like a domain-specific class &amp;#8211; to represent an Item in the framework that doesn&apos;t have an associated pref value, use BooleanUserPreference with GenericUser.&lt;/p&gt;

&lt;p&gt;The Hadoop job likewise seems domain-specific.&lt;/p&gt;</comment>
                            <comment id="12682915" author="ankur" created="Wed, 18 Mar 2009 05:06:42 +0000"  >&lt;p&gt;Hey Sean, Thanks for review comments. Some specific questions&lt;/p&gt;

&lt;p&gt;1. This indeed is doing approximately the same thing as TanimotoCoefficientSimilarity and BooleanPreferenceUser. The difference being that similarity computations is parallelized in map-reduce.&lt;/p&gt;

&lt;p&gt;2. The idea of introducing a FitnessEvaluator was to allow people to apply domain specific things when comparing a preference. Are you suggesting the replacement of FitnessEvaluator with ItemSimilarity ?&lt;/p&gt;

&lt;p&gt;3. The Hadoop job was written to run this thing stand-alone. What modifications do you feel would be appropriate for integration into the framework?&lt;/p&gt;</comment>
                            <comment id="12683170" author="srowen" created="Wed, 18 Mar 2009 21:04:52 +0000"  >&lt;p&gt;1. How do you feel about, therefore, changing to use more abstract objects rather than, say, &quot;Click&quot;? These objects could be the existing ones, or modified or new ones. I think as you say the existing objects are about what is needed. That way the solution is that much more reusable. Same with the job &amp;#8211; the more it uses abstract/standard classes, the more reusable I think it looks.&lt;/p&gt;

&lt;p&gt;2. Yeah the two interfaces are nearly identical: provide a method that takes two &quot;items&quot; as input and a numerical &quot;score&quot; as output. I suppose it just makes sense to use the existing ItemSimilarity interface in this section of the code.&lt;/p&gt;

&lt;p&gt;3. Good question, here is my brief digression:&lt;/p&gt;

&lt;p&gt;The code was originally written with an &quot;on-line&quot; model in mind &amp;#8211; recommendations happen in real-time. Over time that has proved inefficient or impractical for large data sets, though it remains quite nice for small- to medium-size data sets. Hence i have attempted to preserve the real-time model at the core, and build a batch-oriented extension around it using Hadoop.&lt;/p&gt;

&lt;p&gt;The two are a bit separate, and that is fine. So in this section of the code, I don&apos;t mind attaching Hadoop-related jobs that are not intimately connected to the core code. I am trying to keep them as consistent as possible so that the original on-line and newer off-line models don&apos;t evolve into two separate worlds within this part of the code.&lt;/p&gt;

&lt;p&gt;To be specific... well I don&apos;t know, I don&apos;t have a problem with adding this job actually. Ideally we build a bit more around it: takes as input the standard preference-file format as used by FileDataModel, and outputs a file format that can be ready by a new ItemSimillarity implementation that would read and cache all these results. That would be a nice step towards integrating with the core code.&lt;/p&gt;

&lt;p&gt;This is something I have been remiss in - I wrote a job to do the pre-computation of item-item diffs for slope one but never wrote an implementation of DiffStorage that would read this output and operate based on those results. This would close the loop. &lt;/p&gt;

&lt;p&gt;How about we make #3 my part of this issue, to complete the connection between this job and the core code a bit more?&lt;/p&gt;</comment>
                            <comment id="12683232" author="tdunning" created="Wed, 18 Mar 2009 23:22:08 +0000"  >&lt;p&gt; &amp;gt; 1. How do you feel about, therefore, changing to use more abstract objects rather than, say, &quot;Click&quot;? &lt;/p&gt;

&lt;p&gt;How is click more or less abstract than the term &quot;user&quot;?&lt;/p&gt;
</comment>
                            <comment id="12683238" author="srowen" created="Wed, 18 Mar 2009 23:45:35 +0000"  >&lt;p&gt;The comparison would be to Item. You could say that&apos;s as domain-specific as Click; I&apos;d suggest that User/Item are the &apos;abstract&apos; concepts in this context since collaborative filtering is invariably explained in terms of users and items, though of course your user or item can be whatever you like.&lt;/p&gt;

&lt;p&gt;At least, there is no need to have both &quot;Click&quot; and &quot;Item&quot; &amp;#8211; unless this particular context requires one to store more information about a click as an item, in which case it should at least implement Item. But I don&apos;t think that&apos;s the case.&lt;/p&gt;

&lt;p&gt;The good news is that this work doesn&apos;t seem to only apply to processing click logs, so, I&apos;m suggesting it might be even more useful to express it in terms of the &apos;abstract&apos; concepts in this context.&lt;/p&gt;</comment>
                            <comment id="12683251" author="srowen" created="Thu, 19 Mar 2009 00:10:35 +0000"  >&lt;p&gt;The comparison would be to Item. You could say that&apos;s as domain-specific as Click; I&apos;d suggest that User/Item are the &apos;abstract&apos; concepts in this context since collaborative filtering is invariably explained in terms of users and items, though of course your user or item can be whatever you like.&lt;/p&gt;

&lt;p&gt;At least, there is no need to have both &quot;Click&quot; and &quot;Item&quot; &amp;#8211; unless this particular context requires one to store more information about a click as an item, in which case it should at least implement Item. But I don&apos;t think that&apos;s the case.&lt;/p&gt;

&lt;p&gt;The good news is that this work doesn&apos;t seem to only apply to processing click logs, so, I&apos;m suggesting it might be even more useful to express it in terms of the &apos;abstract&apos; concepts in this context.&lt;/p&gt;</comment>
                            <comment id="12683320" author="ankur" created="Thu, 19 Mar 2009 04:44:37 +0000"  >&lt;p&gt;Alright! then I&apos;ll incorporate 1 and 2 as suggested by Sean and also add some documentation. To digress a little bit, I would also like to suggest a map-red implementation of the log-likelihood ratio test as described in Ted&apos;s paper. As in my own experience simple co-occurence counts don&apos;t take into account the popularity bias that gets introduced because of items that have unusually high number of occurrences.&lt;/p&gt;</comment>
                            <comment id="12683516" author="tdunning" created="Thu, 19 Mar 2009 16:55:25 +0000"  >
&lt;p&gt;Hmmm.... I actually think of a click as the relation that connects a user to an item.  As such, it is distinct from either.&lt;/p&gt;

&lt;p&gt;And I routinely do recommendation like computations that involve users, network entities, query terms, documents, and other things that you would call users as they relate (by abstract clicks) to users, query terms, videos, music, web pages, network entities, words, query terms and other things that you would call items.&lt;/p&gt;

&lt;p&gt;There is a horrible tension here between naming things by their most common usage and expecting programmers to realize that they really are abstract entities or naming things in a total abstract way and risking that no programmers ever catch on.  An example of an abstract naming that derives from linguistic terminology might be Agent (instead of User), Relation (instead of Click) and Target (instead of Item).  This makes the general interaction be Relation \subsetof Agent x Target.  I wouldn&apos;t recommend this, however, because (as you say) people generally describe social algorithms in excessively concrete ways.   &lt;/p&gt;</comment>
                            <comment id="12683536" author="srowen" created="Thu, 19 Mar 2009 17:36:36 +0000"  >&lt;p&gt;In the context it is used here, a click is an &quot;Item&quot;. It is the thing whose co-occurrence determines relationships between users, not between users and items.&lt;/p&gt;

&lt;p&gt;I don&apos;t know of a CF algorithm that uses a &apos;click&apos; &amp;#8211; certainly you could use this to infer preferences, but that is a separate question.&lt;/p&gt;

&lt;p&gt;Like I said, we have to pick some terminology, and while I take your points, I think it is obvious that User and Item strike the right balance between abstract-ness and legibility.&lt;/p&gt;

&lt;p&gt;The only point I ask anyone to concede is that Item and Click are redundant in this context. You can dislike the term Item, but I feel certain it should not be changed.&lt;/p&gt;</comment>
                            <comment id="12776919" author="ankur" created="Thu, 12 Nov 2009 09:13:23 +0000"  >&lt;p&gt;Hello Folks, I know its been a while since I looked at this patch and a lot has changed in Mahout since. I would really like this to be incorporated into to MAHOUT core as I know for sure that the algo works very well on large-datasets of user-click histories that are inherently sparse. and strongly feel that MAHOUT community can benefit from it.&lt;/p&gt;

&lt;p&gt;Here are the code changes that I have in mind from Sean&apos;s  (ages old &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;) comment.&lt;/p&gt;

&lt;p&gt;1. Replace Click with Item.&lt;br/&gt;
2. Replace FitnessEvaluator with ItemSimilarity interface.&lt;br/&gt;
3. Add some test case on real dataset.&lt;/p&gt;

&lt;p&gt;For 3,  I need a publicly available dataset of the form user-&amp;gt;item (No ratings here). One option is to take the netflix prize dataset and binarize the user ratings (&amp;lt;2.5 = 0, &amp;gt;2.5=1). Can someone suggest a different dataset ? &lt;/p&gt;</comment>
                            <comment id="12776921" author="srowen" created="Thu, 12 Nov 2009 09:17:40 +0000"  >&lt;p&gt;Re-post an updated patch and happy to give my comments on it. The more the merrier. If it&apos;s basically sound I&apos;d like to mention it in the forthcoming book which I&apos;m writing now.&lt;/p&gt;

&lt;p&gt;I use the GroupLens, Jester, Netflix data sets regularly. Indeed, just drop the rating. The framework can do this automatically too if you like in the DataModel.&lt;/p&gt;</comment>
                            <comment id="12776939" author="ankur" created="Thu, 12 Nov 2009 10:15:36 +0000"  >&lt;p&gt;&amp;gt;Re-post an updated patch ....&lt;/p&gt;

&lt;p&gt;Sure I&apos;ll have the updated code coming by early next week.&lt;/p&gt;

&lt;p&gt;&amp;gt;If it&apos;s basically sound I&apos;d like to mention it ....&lt;/p&gt;

&lt;p&gt;+10, The more people know about it the better chances it has of being used &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  &lt;/p&gt;

&lt;p&gt;&amp;gt;I use the GroupLens, Jester, Netflix data sets regularly. Indeed, just drop the rating ...&lt;/p&gt;

&lt;p&gt;Simply dropping the rating might introduce too much noise. I was thinking of keeoing only those that have ratings &amp;gt; 2.5 (or 2 to be more liberal). &lt;/p&gt;</comment>
                            <comment id="12776951" author="srowen" created="Thu, 12 Nov 2009 11:15:23 +0000"  >&lt;p&gt;That last point is interesting. Another school of thought is that rating something, even negatively, suggests you have a closer association to that thing than to the millions of other things you&apos;ve never heard of.&lt;/p&gt;

&lt;p&gt;Let&apos;s say you rate Bach a 5 and Brahms a 4 and Mendelssohn a 1.5. Would you rather recommend a Mendelssohn recording to this person, or death metal?&lt;/p&gt;

&lt;p&gt;This is my understanding of the intuition I&apos;ve gotten from Ted, and seems to bear out somewhat in practice, that ratings have a lot less info than one would think.&lt;/p&gt;

&lt;p&gt;Well it&apos;s obviously something one can evaluate within the framework with the evaluator code to decide for sure.&lt;/p&gt;</comment>
                            <comment id="12776966" author="ankur" created="Thu, 12 Nov 2009 12:23:11 +0000"  >&lt;p&gt;In that case dropping ratings might not be such a good idea and may lead to bad results. Consider the following movies that a user might have seen with the scores&lt;/p&gt;

&lt;p&gt;Matrix - 4.5&lt;br/&gt;
Matrix Reloaded - 2.5&lt;br/&gt;
Matrix Revolutions - 2&lt;/p&gt;

&lt;p&gt;Assuming that a lot of people have watched these movies and didn&apos;t like the subsequent two versions, they still will get high similarity scores w.r.t &quot;Matrix&quot; going purely by co-occurrence. IMHO, that leaves us with the following 2 alternatives :-&lt;/p&gt;

&lt;p&gt;1. Add the ratings when counting co-occurrence and hope that better ones will stand out even if they co-occur less.&lt;br/&gt;
2. Apply a &quot;Re-scorer&quot; that re-ranks the the similar items for a given item based on their average scores.&lt;/p&gt;

&lt;p&gt;Point 1 is something I am thinking of trying out.   &lt;/p&gt;
</comment>
                            <comment id="12776986" author="srowen" created="Thu, 12 Nov 2009 13:13:27 +0000"  >&lt;p&gt;What&apos;s the problem in this example? Two people that have both seen all three Matrix films are probably similar. All the more so if they&apos;ve rated the first one highly and the other two poorly. You&apos;d correctly identify them as similar with or without ratings here.&lt;/p&gt;

&lt;p&gt;The issue, I suppose, comes up when you encounter someone who didn&apos;t like the first one and liked the other two (strange, I know). Without pref values, we&apos;d draw the same conclusion &amp;#8211; they have some similarity. With pref values, most metrics would say they are very dissimilar.&lt;/p&gt;

&lt;p&gt;I actually think that&apos;s the wrong conclusion! The fact that two people bothered to watch all three says much more about their similarities than the variance in ratings says about their differences. I&apos;d still guess they&apos;re sorta-similar, and metrics without pref values would tend to draw the more correct conclusion.&lt;/p&gt;


&lt;p&gt;Of course there&apos;s no one right answer, and we can easily construct situations where throwing out pref values indeed hurts the result. I&apos;m only asserting that it&apos;s entirely possible, in real data sets, for ratings to &lt;b&gt;hurt&lt;/b&gt; on the whole. &lt;/p&gt;


&lt;p&gt;Let&apos;s start by adding the basic approach and then keep going to look at variations. I at least have some global knowledge of how the framework is set up and could help design in these variations in a way that&apos;s consistent with the framework.&lt;/p&gt;
</comment>
                            <comment id="12778827" author="ankur" created="Tue, 17 Nov 2009 11:42:39 +0000"  >&lt;p&gt;Ok,  so here&apos;s the revised version of the algorithm that this jira proposes to implement.  I have tried to make the code as clean and readable as possible. Next I plan to write some test code for preparing and running on Netflix prize dataset. As a part of data preparation the &apos;dates&apos; and &apos;ratings&apos; will be dropped and algo will run on (user-id, item-id) pairs. &lt;/p&gt;

&lt;p&gt;Not sure how we can include age related decay/boost when counting co-occurrence. May be others can pitch in once we have the basic stuff working fine.&lt;/p&gt;</comment>
                            <comment id="12778838" author="srowen" created="Tue, 17 Nov 2009 12:18:51 +0000"  >&lt;p&gt;It looks fine to me, with one request &amp;#8211; put it in a subpackage of the .hadoop package? I&apos;m going to rearrange the bits already in there into subpackages as they no longer share one related purpose.&lt;/p&gt;

&lt;p&gt;From there if I have any other comments we can look at those after it&apos;s committed. I&apos;m certain it&apos;s good enough to get into the repo now, if you believe it&apos;s ready.&lt;/p&gt;

&lt;p&gt;In about 2 weeks I am beginning writing the recommenders-in-Hadoop chapter, so this is very timely. I&apos;ve been worried since my Hadoop-related code has been stymied by a Hadoop bug that&apos;s still not fixed. I am hoping your approach has a way around it.&lt;/p&gt;

&lt;p&gt;I&apos;d like to synthesize one approach to using Hadoop 0.20+ based on our implementations and then look to making the whole project consistent in this regard.&lt;/p&gt;</comment>
                            <comment id="12778911" author="ankur" created="Tue, 17 Nov 2009 14:50:13 +0000"  >&lt;p&gt;Thanks for the quick lookup, appreciate that &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;/p&gt;

&lt;p&gt;Putting in a subpackage, sure, for now I&apos;ll just leave all the main code under one subpackage (how about &apos;bigram&apos;) until u have it sorted out. &lt;/p&gt;

&lt;p&gt;As for the code, once I have the test code ready for netflix dataset and at least one unit test, it will be good to go. One question, How do we apply precision-recall or RMSE or any other evaluation technique to the results since all we are doing is counting co-occurrence ?&lt;/p&gt;

&lt;p&gt;Do u have the JIRA for this hadoop related bug? &lt;/p&gt;</comment>
                            <comment id="12778950" author="srowen" created="Tue, 17 Nov 2009 15:52:08 +0000"  >&lt;p&gt;I don&apos;t have a JIRA, just some threads on the mailing list. I&apos;m going to dig back in to this next week and if I still see the problem formally report the bug. I hope it&apos;s cleared up in the latest code.&lt;/p&gt;

&lt;p&gt;Yeah this code just implements counting co-occurrence, which isn&apos;t a complete recommender. Ideally each of these subpackages is a Hadoop-based recommender system that outputs recommendations.&lt;/p&gt;

&lt;p&gt;When the input has rating values, you will output estimated rating values too, I&apos;d imagine. That&apos;s good, but not quite what&apos;s needed to conduct an RMSE evaluation of the estimates. For that we&apos;d want to hold back, say, 5% of the data and see how well it estimated the ratings of that 5%. But the output is recommendations, which don&apos;t necessarily include that 5% of test data.&lt;/p&gt;

&lt;p&gt;(You could write a separate job that does it, sure.)&lt;/p&gt;

&lt;p&gt;But seems relatively easier to conduct a precision-recall test. Identify for each user some &quot;good&quot; recommendations, perhaps their favorite items. Remove those from the input. See how much of it gets recommended back in the output. From that you can compute precision and recall figures on the recommendations.&lt;/p&gt;

&lt;p&gt;It&apos;s all a nice-to-have &amp;#8211; to start I&apos;d like to have a couple end-to-end, consistent recommenders based on Hadoop. I can see three right now:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Your co-occurrence-based system&lt;/li&gt;
	&lt;li&gt;The, er, dot-product-based item-based recommender Ted sketched, which I&apos;ll write. Not sure what to call it.&lt;/li&gt;
	&lt;li&gt;The pseudo-distributed system already in there&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12781838" author="ankur" created="Tue, 24 Nov 2009 09:40:52 +0000"  >&lt;p&gt;For this co-occurrence based recommender I am planning to write a set of map-reduce jobs that compute recommendations for users as folllowing:-&lt;/p&gt;

&lt;p&gt;1. Take user&apos;s item history&lt;br/&gt;
2. for each item in his history fetch the top-N similar items. (Similarity based on co-occurrence)&lt;br/&gt;
3. Add the co-occurrence scores if an item appears more than once (NOT weighted avg). Consider an e.g. user-history &lt;/p&gt;
{ M1, M2, M3 }
&lt;p&gt; and top - 3 similar movies for each of these along with co-occurrence scores &lt;/p&gt;

&lt;p&gt;M1 -&amp;gt; (A, 5), (B, 4), (C, 2)&lt;br/&gt;
M2 -&amp;gt; (D, 6), (E, 3), (F, 2)&lt;br/&gt;
M3 -&amp;gt; (G, 8), (C, 5), (B, 2)  &lt;/p&gt;

&lt;p&gt;So the final scores in decreasing order will look like&lt;br/&gt;
(G, 8)&lt;br/&gt;
(C, 7)&lt;br/&gt;
(B, 6)&lt;br/&gt;
(D, 6)&lt;br/&gt;
(A, 5)&lt;br/&gt;
(E, 3)&lt;br/&gt;
(F, 2)&lt;/p&gt;

&lt;p&gt;The idea I want to capture is that a candidate item gets higher score if its similar to more items in user&apos;s click history.&lt;/p&gt;

&lt;p&gt;Do you see any issue with this approach ? Any other better approach that you can think of ?&lt;/p&gt;

&lt;p&gt;As for the precision-recall test, I am still trying to see how to divide the data in &apos;train&apos; and &apos;test&apos; for a fair evaluation. How do we do it in the existing code ?&lt;/p&gt;</comment>
                            <comment id="12781858" author="srowen" created="Tue, 24 Nov 2009 10:34:38 +0000"  >&lt;p&gt;Yes, this is basically item-based recommendation. With some superficial changes, it would exactly fit that model. Co-occurrence here is like a similarity metric, which is ultimately used as a weighting. Canonically this value would be in &lt;span class=&quot;error&quot;&gt;&amp;#91;-1,1&amp;#93;&lt;/span&gt;, and you can easily map [1,...) into that range of course.&lt;/p&gt;

&lt;p&gt;Next you&apos;re sort of estimating preferences when you add up co-occurrence values. Canonically, you&apos;d be doing a weighted average over M1 - M3. This is the same thing &amp;#8211; you&apos;re just not dividing by 3.&lt;/p&gt;

&lt;p&gt;The result is conceptually the same, though different approaches would yield slightly different results. I&apos;m not necessarily suggesting you change the algorithm. At the same time I am also about to implement this very same thing &amp;#8211; the more &apos;canoncial&apos; form, to go hand-in-hand with the existing GenericItemBasedRecommender. I&apos;d rather avoid duplication, and would like to make the Hadoop-based implementation as analogous to the existing code as possible. All I&apos;d say is, go ahead, and maybe we look at generalizing it or shifting these concepts towards the canonical setup later.&lt;/p&gt;

&lt;p&gt;Look at GenericIRStatsEvaluator and subclass for precision-recall approaches.&lt;/p&gt;</comment>
                            <comment id="12791971" author="ankur" created="Thu, 17 Dec 2009 15:24:03 +0000"  >&lt;p&gt;Ok, so here is the next version which I again re-wrote completely &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; for performance reasons. The version now computes item similarity and uses that to generate recommendations in truely hadoop fashion. In a nutshell the recommendations are generated in 2 steps:-&lt;/p&gt;

&lt;p&gt;1. Join item-similarity data (generated via analyzing co-occurence) with user-click data&lt;br/&gt;
2. Group output of step 1. on user key so that we recieve all potential candidates for a user in a reducer and also all items already clicked/seen by him so that they can be excluded from final recommendations set.&lt;/p&gt;

&lt;p&gt;Also attached &lt;br/&gt;
1. Perl script to convert the netflix data into required format (userId \t movieId) &lt;br/&gt;
2. Bash script used to run in on 50 node hadoop cluster. The recommendations are generated for all the users in less than 45 min.&lt;/p&gt;</comment>
                            <comment id="12791975" author="ankur" created="Thu, 17 Dec 2009 15:29:32 +0000"  >&lt;p&gt;@Reviewers&lt;br/&gt;
Please excuse the non existence of code comments, unit test and Precision-Recall test classes. They will be added in subsequent versions.&lt;/p&gt;</comment>
                            <comment id="12793617" author="srowen" created="Tue, 22 Dec 2009 13:48:16 +0000"  >&lt;p&gt;My only significant concern is that this overlaps a lot with what I&apos;ve already committed under .item. However I&apos;m not against committing this as this part of the code is still in an experimental phase where we should have room to play and see what &apos;sticks&apos;.&lt;/p&gt;

&lt;p&gt;There is I think a lot of small changes that need to be made here to fit code style, etc. I&apos;m willing to commit after those sorts of things are addressed, and also volunteer to do them.&lt;/p&gt;

&lt;p&gt;If you&apos;re reasonably willing to evolve and integrate this code along with the surrounding code, it&apos;s fine by me to get this in and continue working that way.&lt;/p&gt;</comment>
                            <comment id="12793628" author="ankur" created="Tue, 22 Dec 2009 14:40:29 +0000"  >&lt;p&gt;Evolving the code to integrate better with the existing stuff is fine with me. I  am in  general ok with throwing away code if it can be replaced by existing stuff that is better. &lt;/p&gt;

&lt;p&gt;However, I don&apos;t think its a good idea to try to come up with a unified approach of generating hadoop based recommendations. I am afraid we&apos;ll create more problems than we&apos;d solve.&lt;/p&gt;

&lt;p&gt;I see recommendations in hadoop world as the following linear chain of M/R jobs&lt;/p&gt;

&lt;p&gt;Data-Formatting -&lt;del&gt;&amp;gt; Data Filter --&amp;gt; Core Recommender&lt;/del&gt;-&amp;gt; Post Processor&lt;/p&gt;

&lt;p&gt;The last 2 jobs can themselves be comprised of 1 or more M/R jobs.&lt;/p&gt;

&lt;p&gt;&amp;gt; There is I think .....&lt;/p&gt;

&lt;p&gt;Let me come up with the unit-tests and code documentation. After that you can start doing the changes. Thanks a lot for help. Appreciate that &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;BTW did u have a chance to actually run it on netflix-data ?&lt;/p&gt;</comment>
                            <comment id="12793631" author="srowen" created="Tue, 22 Dec 2009 14:54:42 +0000"  >&lt;p&gt;Yep, fine by me.&lt;/p&gt;

&lt;p&gt;I think it would be far easier to unit test / document the &apos;final&apos; version rather than something that will change notably? really I&apos;m talking about formatting, style, use of libraries, etc. How about I post my version of the patch now?&lt;/p&gt;

&lt;p&gt;I have not run it. I trust you&apos;re on top of that.&lt;/p&gt;</comment>
                            <comment id="12793676" author="jake.mannix" created="Tue, 22 Dec 2009 17:10:35 +0000"  >&lt;p&gt;I&apos;ve actually got a bunch of variations of this in the .item package as well, but I haven&apos;t got them all fully working yet.  I&apos;m hoping they&apos;re a bit faster than what&apos;s in there now.&lt;/p&gt;</comment>
                            <comment id="12793717" author="srowen" created="Tue, 22 Dec 2009 18:31:00 +0000"  >&lt;p&gt;Happy for you to commit a work-in-progress there so we can collaborate, if you feel it would be useful.&lt;/p&gt;</comment>
                            <comment id="12794036" author="ankur" created="Wed, 23 Dec 2009 12:37:18 +0000"  >&lt;p&gt;I skimmed through your version and what&apos;s present in .item package. Few immediate things that come to mind are&lt;br/&gt;
1. Moving to AbstractJob&lt;br/&gt;
2.  Re-factoring to separate map,reduce and job classes. Personally I hate that coz  the code base just bloats when number of M/R jobs increase.&lt;/p&gt;

&lt;p&gt;I have been trying to setup my idea using IntelliJ.codestyle.xml provided by mahout cwiki. I placed the file under idea_home/config/codeStyles and restarted idea but it still does not an import option  in File-&amp;gt;Settings-&amp;gt;Code Style.  Idea shows following messages in the back ground&lt;br/&gt;
Field not copied JAVA_INDENT_OPTIONS&lt;br/&gt;
Field not copied JSP_INDENT_OPTIONS&lt;br/&gt;
Field not copied XML_INDENT_OPTIONS&lt;br/&gt;
Field not copied OTHER_INDENT_OPTIONS&lt;br/&gt;
Field not copied FIELD_TYPE_TO_NAME&lt;br/&gt;
Field not copied STATIC_FIELD_TYPE_TO_NAME&lt;br/&gt;
Field not copied PARAMETER_TYPE_TO_NAME&lt;br/&gt;
Field not copied LOCAL_VARIABLE_TYPE_TO_NAME&lt;br/&gt;
Field not copied PACKAGES_TO_USE_IMPORT_ON_DEMAND&lt;br/&gt;
Field not copied IMPORT_LAYOUT_TABLE&lt;/p&gt;

&lt;p&gt;I am using v 8.1.4&lt;/p&gt;

&lt;p&gt;Once i set this up, I am gonna look at your version and what&apos;s there in .item package&lt;/p&gt;</comment>
                            <comment id="12794064" author="srowen" created="Wed, 23 Dec 2009 14:57:49 +0000"  >&lt;p&gt;I&apos;m not worried about integrating with AbstractJob just this second but at some point all our MR jobs ought to have some consistent approach. I also don&apos;t feel too strongly about Mapper/Reducers as inner classes. It&apos;s the same amount of code either way, so I don&apos;t think that&apos;s the difference, and I prefer the clarify of top-level classes in general unless a class is truly intricately associated to another class. But don&apos;t change that now.&lt;/p&gt;

&lt;p&gt;Am I understanding you&apos;re roughly OK with this form of the patch, and I should submit, or..?&lt;/p&gt;

&lt;p&gt;Looking at .item can come later too. I&apos;m mostly thinking of small/local changes at the moment.&lt;/p&gt;</comment>
                            <comment id="12794133" author="ankur" created="Wed, 23 Dec 2009 18:18:46 +0000"  >&lt;p&gt;Your changes don&apos;t look too mutating and yes roughly speaking I am ok. Since we are talking about committing  this I would like to say that I tested this for correctness on very small hand-coded data-set and then ran it on netflix-data. However I couldn&apos;t verify its correctness over netflix data though I am pretty confident it works correctly. That is why I was hoping to have a couple of unit test:-&lt;/p&gt;

&lt;p&gt;1.   To verify that similar items are identified correctly.&lt;br/&gt;
2.   None of the seen items are recommended for a user. &lt;/p&gt;

&lt;p&gt;But since this is not the final version, can you suggest any other approach to be 100% sure of correctness? I don&apos;t want something to be committed only to discover a silly issue later just because we didn&apos;t take extra care.&lt;/p&gt;</comment>
                            <comment id="12794173" author="srowen" created="Wed, 23 Dec 2009 19:23:21 +0000"  >&lt;p&gt;I think it&apos;s OK to put it in, in this form. It will facilitate further collaboration on the code. It&apos;s understood, I think, that it is experimental and not guaranteed bug-free.&lt;/p&gt;

&lt;p&gt;I think perhaps the easiest way to test these things is to create a small test case, manually verify the output is correct, and then save it as &quot;golden&quot; output. Then the test just verifies the output is always exactly the same. This may cause spurious failures &amp;#8211; maybe the recommendations get better after a change! but best to fail when it shouldn&apos;t than the other way around.&lt;/p&gt;

&lt;p&gt;OK will commit what I have now to get this in place, since I think it&apos;s good enough to go in SVN at this point.&lt;/p&gt;</comment>
                            <comment id="12794192" author="srowen" created="Wed, 23 Dec 2009 19:51:07 +0000"  >&lt;p&gt;Resolved, as initial version is committed&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12428732" name="MAHOUT-103.patch" size="42399" author="srowen" created="Tue, 22 Dec 2009 14:57:05 +0000"/>
                            <attachment id="12425212" name="mahout-103.patch.v1" size="19365" author="ankur" created="Tue, 17 Nov 2009 11:42:39 +0000"/>
                            <attachment id="12428300" name="mahout-103.patch.v2" size="40790" author="ankur" created="Thu, 17 Dec 2009 15:26:51 +0000"/>
                            <attachment id="12428301" name="prepare.pl" size="2021" author="ankur" created="Thu, 17 Dec 2009 15:26:51 +0000"/>
                            <attachment id="12428302" name="run.sh" size="2015" author="ankur" created="Thu, 17 Dec 2009 15:26:51 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 17 Mar 2009 13:41:28 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9963</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hxy76n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23315</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>