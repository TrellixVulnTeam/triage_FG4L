<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:28:02 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-602/MAHOUT-602.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-602] &quot;Partial Implementation&quot; throws exceptions</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-602</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;p&gt;The &quot;Partial Implementation&quot; described on the wiki page &lt;a href=&quot;https://cwiki.apache.org/confluence/display/MAHOUT/Partial+Implementation&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Partial Implementation&lt;/a&gt; fails with the given dataset and operations.&lt;/p&gt;


</description>
                <environment>&lt;p&gt;Macos X&lt;br/&gt;
java version &quot;1.6.0_22&quot;&lt;br/&gt;
Java(TM) SE Runtime Environment (build 1.6.0_22-b04-307-10M3261)&lt;br/&gt;
Java HotSpot(TM) 64-Bit Server VM (build 17.1-b03-307, mixed mode)&lt;/p&gt;</environment>
        <key id="12497175">MAHOUT-602</key>
            <summary>&quot;Partial Implementation&quot; throws exceptions</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="adeneche">Deneche A. Hakim</assignee>
                                    <reporter username="lancenorskog">Lance Norskog</reporter>
                        <labels>
                    </labels>
                <created>Mon, 31 Jan 2011 07:09:27 +0000</created>
                <updated>Sat, 21 May 2011 04:18:51 +0100</updated>
                            <resolved>Fri, 4 Feb 2011 23:13:28 +0000</resolved>
                                    <version>0.4</version>
                                    <fixVersion>0.5</fixVersion>
                                    <component>Classification</component>
                        <due>Fri, 11 Feb 2011 00:00:00 +0000</due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12988673" author="lancenorskog" created="Mon, 31 Jan 2011 07:20:21 +0000"  >&lt;p&gt;Scenario:&lt;/p&gt;

&lt;p&gt;I attempted to follow the tutorial on the wiki. The wiki page apparently predates the &apos;bin/mahout&apos; shell script. I used that instead of the given bin/hadoop commands.&lt;/p&gt;

&lt;p&gt;The command given to create a &quot;file descriptor&quot; did not work. It includes a string of letters which define a CSV file. The string is wrong.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bin/mahout org.apache.mahout.df.tools.Describe -p testdata/KDDTrain+.arff 
-f testdata/KDDTrain+.info -d N 3 C 2 N C 4 N C 8 N 2 C 19 N L
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This throws an exception. I added a &apos;1&apos; (one) to the beginning and that made it run. This seems to be the correct fix.&lt;/p&gt;

&lt;p&gt;After this ran, I tried the next command:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bin/mahout org.apache.mahout.df.mapreduce.BuildForest 
-Dmapred.max.split.size=1874231 -oob -d testdata/KDDTrain+_20Percent.arff 
-ds testdata/KDDTrain+_20Percent.info -sl 5 -p -t 100 -o nsl-forest
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This throws an ArrayIndexOutOfBounds exception. The full logfile is attached.&lt;/p&gt;

&lt;p&gt;I tried this same job with different sizes of mapred.split.size, and got the same exception and index of &apos;100&apos;.&lt;/p&gt;

&lt;p&gt;The logfile is attached as partialImp_fullKDD_errors.log.&lt;/p&gt;</comment>
                            <comment id="12988861" author="adeneche" created="Mon, 31 Jan 2011 19:43:14 +0000"  >&lt;p&gt;What version of Mahout are you using ? I remember trying this example just before the release of Mahout-0.4 and it was Ok. And I just tried it using the latest checkout from svn and it worked perfectly, although I didn&apos;t use the mahout script but called hadoop direclty as shown in the wiki.&lt;/p&gt;

&lt;p&gt;did you change the data as described in the wiki ?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Open the train and test files and remove all the lines that begin with &apos;@&apos;. All those lines are at the top of the files. Actually you can keep those lines somewhere, because they&apos;ll help us describe the dataset to Mahout&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="12989968" author="lancenorskog" created="Thu, 3 Feb 2011 05:40:49 +0000"  >&lt;p&gt;There is an off-by-one error somewhere. The code generates two files with &apos;number of trees requested&apos; instead of one. &lt;/p&gt;

&lt;p&gt;To make things easier I created 10 trees instead of 100. Two files of trees are created instead of just one. The patch prints the hashCode() for each tree.toString. You can see that the two files have different trees. I have included the value for each tree in the attached log 10_hashCode.log. (10_toString.log shows the actual string dump for each tree.) &lt;/p&gt;

&lt;p&gt;Apply the patch attached as PartialImplementationBug1.patch, if you want to recreate the experiment. Try different numbers of trees and it will always make two files of N trees instead of just 1.&lt;/p&gt;

&lt;p&gt;This was the command line, as per the wiki:&lt;br/&gt;
$HADOOP_HOME/bin/hadoop jar /Users/lancenorskog/Documents/open/mahout/examples/target/mahout-examples-0.5-SNAPSHOT-job.jar org.apache.mahout.df.mapreduce.BuildForest -Dmapred.max.split.size=1874231 -oob -d ../../datasets/KDDTrain/KDDTrain+_20Percent.arff -ds ../../datasets/KDDTrain/KDDTrain+_20Percent.info  -sl 5 -p -t 10 -o nsl-forest&lt;/p&gt;</comment>
                            <comment id="12989969" author="lancenorskog" created="Thu, 3 Feb 2011 05:42:02 +0000"  >&lt;p&gt;Patch the reading code to show the counting error.&lt;/p&gt;</comment>
                            <comment id="12989970" author="lancenorskog" created="Thu, 3 Feb 2011 05:42:53 +0000"  >&lt;p&gt;Error log for &quot;-t 10&quot; meaning &quot;generate 10 trees&quot;. Includes prints of the hashCode() for each tree. All are different.&lt;/p&gt;

&lt;p&gt;Since the hashCode() output is different, that means each tree is unique. &lt;/p&gt;
</comment>
                            <comment id="12989971" author="lancenorskog" created="Thu, 3 Feb 2011 05:43:38 +0000"  >&lt;p&gt;Error log for 10 trees. Prints actual tree strings; rather less readable than the hashCode() output.&lt;/p&gt;</comment>
                            <comment id="12989974" author="lancenorskog" created="Thu, 3 Feb 2011 05:45:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;did you change the data as described in the wiki ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes. If you leave them in the program does not run at all.&lt;/p&gt;</comment>
                            <comment id="12990024" author="srowen" created="Thu, 3 Feb 2011 09:25:42 +0000"  >&lt;p&gt;You aren&apos;t just referring to the fact that you&apos;ll get part-r-00000, part-r-00001, etc. ? that&apos;s normal.&lt;/p&gt;</comment>
                            <comment id="12990223" author="adeneche" created="Thu, 3 Feb 2011 18:35:26 +0000"  >&lt;p&gt;Ok I was finaly able to reproduce the bug, it happens only when Hadoop is running in &apos;local&apos; (not even pseudo-distributed). I will try to post a patch as soon as possible.&lt;/p&gt;

&lt;p&gt;But still I wasn&apos;t able to reproduce the first error (with Describe) even in &apos;local&apos; mode.&lt;/p&gt;</comment>
                            <comment id="12990295" author="lancenorskog" created="Thu, 3 Feb 2011 20:42:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;You aren&apos;t just referring to the fact that you&apos;ll get part-r-00000, part-r-00001, etc. ? that&apos;s normal.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ask for 10 trees. You get part-r-00000 with 10 trees, and part-r-00001 with 10 trees.&lt;/p&gt;</comment>
                            <comment id="12990296" author="lancenorskog" created="Thu, 3 Feb 2011 20:44:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;Ok I was finaly able to reproduce the bug, it happens only when Hadoop is running in &apos;local&apos; (not even pseudo-distributed). I will try to post a patch as soon as possible.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thank you. I only use local mode so it didn&apos;t occur to try it in the distributed modes. Is it possible to abstract out all such problems so that the Hadoop mode does not affect Mahout code?&lt;/p&gt;</comment>
                            <comment id="12990374" author="tdunning" created="Thu, 3 Feb 2011 23:31:36 +0000"  >&lt;blockquote&gt;
&lt;p&gt; Is it possible to abstract out all such problems so that the Hadoop mode does not affect Mahout code?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It is sort-of possible.&lt;/p&gt;

&lt;p&gt;The big problem is that in local mode, everything runs in the same JVM.  That has lots of implications about the accidental use of shared memory.  Many a Hadoop beginner has been very confused when their program fails dramatically when first run on a truly distributed model.&lt;/p&gt;</comment>
                            <comment id="12990396" author="srowen" created="Fri, 4 Feb 2011 00:10:55 +0000"  >&lt;p&gt;Well, it definitely is possible to write things correctly in that classes and Mappers and Reducers don&apos;t depend on being in the same JVM or on the same machine. If some code isn&apos;t doing that it&apos;s just a bug. I don&apos;t know if abstraction somehow solves the problem &amp;#8211; just proper encapsulation and such.&lt;/p&gt;

&lt;p&gt;Usually it&apos;s the other way around in this kind of bug: works when stuff is in the same JVM, then breaks later. I wonder what the interaction is here that&apos;s causing the reverse?&lt;/p&gt;

&lt;p&gt;I&apos;d point a finger at any static members as first suspects.&lt;/p&gt;</comment>
                            <comment id="12990465" author="adeneche" created="Fri, 4 Feb 2011 06:29:27 +0000"  >&lt;p&gt;When I first wrote this code (two years ago) I found that when running in &apos;local&apos; mode Hadoop doesn&apos;t launch more than one mapper even if the partition size should create many. And because it&apos;s important for the code to know how many mappers did run in the first step, I made the code check if it&apos;s in &apos;local&apos; mode and assume that only 1 single mapper did run in that case. But it looks like that now, even in &apos;local&apos; mode, many mappers are actually launched.&lt;/p&gt;</comment>
                            <comment id="12990498" author="hudson" created="Fri, 4 Feb 2011 09:59:02 +0000"  >&lt;p&gt;Integrated in Mahout-Quality #609 (See &lt;a href=&quot;https://hudson.apache.org/hudson/job/Mahout-Quality/609/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://hudson.apache.org/hudson/job/Mahout-Quality/609/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-602&quot; title=&quot;&amp;quot;Partial Implementation&amp;quot; throws exceptions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-602&quot;&gt;&lt;del&gt;MAHOUT-602&lt;/del&gt;&lt;/a&gt; Removed unnecessary code and comment&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-602&quot; title=&quot;&amp;quot;Partial Implementation&amp;quot; throws exceptions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-602&quot;&gt;&lt;del&gt;MAHOUT-602&lt;/del&gt;&lt;/a&gt; Removed the check for Hadoop local mode&lt;/p&gt;</comment>
                            <comment id="12990650" author="srowen" created="Fri, 4 Feb 2011 17:53:04 +0000"  >&lt;p&gt;Lance, does the latest commit fix the issue?&lt;/p&gt;</comment>
                            <comment id="12990780" author="lancenorskog" created="Fri, 4 Feb 2011 22:17:04 +0000"  >&lt;p&gt;Yes, that fixed it. Thanks!&lt;br/&gt;
Also, the &apos;data description language&apos; string from the wiki page works now. I probably misinterpreted exceptions before.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12470104" name="10_hashCode.log" size="6355" author="lancenorskog" created="Thu, 3 Feb 2011 05:42:53 +0000"/>
                            <attachment id="12470105" name="10_toString.log" size="35312" author="lancenorskog" created="Thu, 3 Feb 2011 05:43:38 +0000"/>
                            <attachment id="12470103" name="PartialImplementationBug1.patch" size="1702" author="lancenorskog" created="Thu, 3 Feb 2011 05:42:02 +0000"/>
                            <attachment id="12469799" name="partialImp_fullKDD_errors.log" size="8784" author="lancenorskog" created="Mon, 31 Jan 2011 07:21:15 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 31 Jan 2011 19:43:14 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9459</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hxy43r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>22816</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>