<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:28:01 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-157/MAHOUT-157.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-157] Frequent Pattern Mining using Parallel FP-Growth</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-157</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;p&gt;Implement: &lt;a href=&quot;http://infolab.stanford.edu/~echang/recsys08-69.pdf&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://infolab.stanford.edu/~echang/recsys08-69.pdf&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12431988">MAHOUT-157</key>
            <summary>Frequent Pattern Mining using Parallel FP-Growth</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="robinanil">Robin Anil</assignee>
                                    <reporter username="robinanil">Robin Anil</reporter>
                        <labels>
                    </labels>
                <created>Sun, 2 Aug 2009 11:14:56 +0100</created>
                <updated>Tue, 31 Mar 2015 23:49:10 +0100</updated>
                            <resolved>Sun, 18 Oct 2009 23:22:34 +0100</resolved>
                                    <version>0.2</version>
                                    <fixVersion>0.2</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12739179" author="robinanil" created="Tue, 4 Aug 2009 22:26:47 +0100"  >&lt;p&gt;Added class FPGrowth&amp;lt;T&amp;gt; where T could be any Datatype which denotes a feature&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;FPGrowth&amp;lt;String&amp;gt; fp = new FPGrowth&amp;lt;String&amp;gt;();
Collection&amp;lt;List&amp;lt;String&amp;gt;&amp;gt; transactions = new ArrayList&amp;lt;List&amp;lt;String&amp;gt;&amp;gt;();

    transactions.add(Arrays.asList(&quot;E&quot;, &quot;A&quot;, &quot;D&quot;, &quot;B&quot;));
    transactions.add(Arrays.asList(&quot;D&quot;, &quot;A&quot;, &quot;C&quot;, &quot;E&quot;, &quot;B&quot;));
    transactions.add(Arrays.asList(&quot;C&quot;, &quot;A&quot;, &quot;B&quot;, &quot;E&quot;));
    transactions.add(Arrays.asList(&quot;B&quot;, &quot;A&quot;, &quot;D&quot;));
    transactions.add(Arrays.asList(&quot;D&quot;));
    transactions.add(Arrays.asList(&quot;D&quot;, &quot;B&quot;));
    transactions.add(Arrays.asList(&quot;A&quot;, &quot;D&quot;, &quot;E&quot;));
    transactions.add(Arrays.asList(&quot;B&quot;, &quot;C&quot;));
 Map&amp;lt;List&amp;lt;Attribute&amp;lt;String&amp;gt;&amp;gt;, Integer&amp;gt; frequentPatterns = fp.generateFrequentPatterns(transactions);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;Implemented 3 stages in PFPGrowth Algorithm.&lt;/p&gt;

&lt;p&gt;FIXME: if transaction lengths are long, i.e there are many features, then Conditional FP subtree will have a single path with many nodes. This can cause combinatorial explosion while going through all possible combinations. Currently limited to 6 grams(a frequent pattern of length 6). So generates at max nC1+nC2+nC3+nC4+nC5+nC6 patterns instead of Sigma &lt;span class=&quot;error&quot;&gt;&amp;#91;k=1 to n&amp;#93;&lt;/span&gt; (nCk) patterns.&lt;/p&gt;
</comment>
                            <comment id="12739181" author="robinanil" created="Tue, 4 Aug 2009 22:29:25 +0100"  >&lt;p&gt;Uses this patch for generating Combinations nCk. Its in BSD license. Code attached without any change from here &lt;a href=&quot;http://www.koders.com/java/fidAD43F65D67DC8A5E4086DB82B622EE88B4DC2D0C.aspx&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.koders.com/java/fidAD43F65D67DC8A5E4086DB82B622EE88B4DC2D0C.aspx&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12739750" author="robinanil" created="Wed, 5 Aug 2009 22:09:10 +0100"  >&lt;ul&gt;
	&lt;li&gt;Fixed svn diff.&lt;/li&gt;
	&lt;li&gt;Implemented Parallel FPGrowth.&lt;/li&gt;
	&lt;li&gt;Tests on vanilla FPGrowth returns correct solution for an example in literature.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12742033" author="isabel" created="Tue, 11 Aug 2009 20:49:18 +0100"  >&lt;p&gt;Patch applies to trunk but I run into problems when trying to get it to compile. I needed to apply &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-124&quot; title=&quot;Online Classification using HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-124&quot;&gt;&lt;del&gt;MAHOUT-124&lt;/del&gt;&lt;/a&gt; first. Then I got an error that indicated that you are using the Combinations class not only in the tests (where it is put by the diff) but also in the regular source code. After copying the class to src/main/java, I get the following error: &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-157&quot; title=&quot;Frequent Pattern Mining using Parallel FP-Growth&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-157&quot;&gt;&lt;del&gt;MAHOUT-157&lt;/del&gt;&lt;/a&gt;/core/src/main/java/org/apache/mahout/fpm/pfpgrowth/ParallelFPGrowthReducer.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;92,41&amp;#93;&lt;/span&gt; get(java.lang.String) in org.apache.mahout.common.Parameters cannot be applied to (java.lang.String,java.lang.String)&lt;/p&gt;

&lt;p&gt;I guess I have done something wrong when applying the patches one after another?&lt;/p&gt;


&lt;p&gt;Other than that I only have some general comments before going into more detail for the review: I am missing some documentation, both JavaDoc and package.html, at least a link to the original paper would be nice to have.&lt;/p&gt;

&lt;p&gt;PFPGrowth - seems like you do quite a lot of work in your constructor. I think it is no good idea to start map reduce jobs from within a constructor. Maybe I am reading something wrong here?&lt;/p&gt;

&lt;p&gt;Is it possible to break up the test into unit tests? I think that would make changing the code and tracking where the change actually broke the code by far easier.&lt;/p&gt;

&lt;p&gt;AggregatorReducer, line 88: Please avoid calls to &amp;lt;Exception&amp;gt;.printStackTrace() - usually those messages get lost when the system is in production. Better log the message with Logger.&amp;lt;fatal|error|warn&amp;gt;(&quot;your message&quot;, &amp;lt;Exception&amp;gt;) - maybe rethrow the exception if you cannot handle it properly.&lt;/p&gt;

&lt;p&gt;TreeNode - the class seems to contain public attributes only but no methods. Please at least explain which type of tree these nodes are supposed to be a part of. From the code alone I am not able to understand the its usage... &lt;/p&gt;</comment>
                            <comment id="12742207" author="robinanil" created="Wed, 12 Aug 2009 05:12:23 +0100"  >&lt;p&gt;Respose  one by one. &lt;/p&gt;

&lt;p&gt;1) Didnt realise it was kept in test.  I will move it shortly.&lt;/p&gt;

&lt;p&gt;2) I made a couple of changes in the class Parameters which I frequently use to serialize and deserialize data in and out of map/reduce jobs both in Bayes and FPgrowth. Since the incremental change applies only to PFPG, it would be great if &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-124&quot; title=&quot;Online Classification using HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-124&quot;&gt;&lt;del&gt;MAHOUT-124&lt;/del&gt;&lt;/a&gt; gets committed soon after I fix the changes suggested there.&lt;/p&gt;

&lt;p&gt;3) Tests and Docs (I am already on it)&lt;/p&gt;

&lt;p&gt;4) i dont need to keep any particular state in PFPgrowth. I can change the construct to PFPGrowth.executeJob(params).&lt;/p&gt;

&lt;p&gt;5) Re: &quot;Is it possible to break test&quot; Currently this patch has only FPGrowth(sequential) test. PFPGrowth tests will be put up soon&lt;/p&gt;

&lt;p&gt;6) Fixed&lt;/p&gt;

&lt;p&gt;7) TreeNode is tha basic unit of the FP-Tree and Conditional FPTree. it doesn&apos;t need any method. I didnt use getNext(),  getParent() etc to get members to speed up things i.e to remove the overhead of a very frequent function call&lt;/p&gt;



</comment>
                            <comment id="12744161" author="robinanil" created="Mon, 17 Aug 2009 19:41:19 +0100"  >&lt;p&gt;Added javadocs. &lt;/p&gt;

&lt;p&gt;PFPgrowth returns correct solution for every data i have put through it. I still feel the Vanilla FPGrowth and Top K FPGrowth implementation is slow for very small minSupport values. &lt;/p&gt;

&lt;p&gt;Also it occurred to me FPGrowth could be replaced easily by any frequent itemset Mining Algorithm like Apriori and the rest of the code(Partitioning and Aggregating) could remain exactly the same. So I propose to go the Algorithm Interface way like I did in Bayes/CBayes. I am also waiting for &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-108&quot; title=&quot;Implementation of Assoication Rules learning by Apriori algorithm&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-108&quot;&gt;&lt;del&gt;MAHOUT-108&lt;/del&gt;&lt;/a&gt; to see if its doing something drastically different from data partitioning employed here.&lt;/p&gt;







</comment>
                            <comment id="12749511" author="robinanil" created="Mon, 31 Aug 2009 15:22:34 +0100"  >&lt;p&gt;Performance Improvements in sequential version&lt;/p&gt;</comment>
                            <comment id="12751770" author="robinanil" created="Sat, 5 Sep 2009 17:48:31 +0100"  >&lt;p&gt;Improvements in Code structure.&lt;br/&gt;
Massive performance improvement 10x improvement in speed. Takes half the memory.&lt;br/&gt;
50K transactions with a minSupport 10K takes 15 second instead of 2:20 min in the earlier patch.(thanks to YourKit profiling and multiple iterations of 80/20 rule).  &lt;/p&gt;

&lt;p&gt;Current bottle necks(could lead to at max 30% reduction in runtime)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Need for a faster HashMap. (there are a lot of put/get) Could use some primitive representation there.&lt;/li&gt;
	&lt;li&gt;Need a faster implementation of a bounded SortedSet. Currently use an encapsulated TreeSet where least value is removed after every insert call  if the max capacity is found to be exceeded. Another frequent operation is: merge two bounded SortedSets&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Updated Tests&lt;/p&gt;</comment>
                            <comment id="12751788" author="tdunning" created="Sat, 5 Sep 2009 21:18:27 +0100"  >
&lt;p&gt;.bq Need a faster implementation of a bounded SortedSet. Currently use an encapsulated TreeSet where least value is removed after every insert call  if the max capacity is found to be exceeded. Another frequent operation is: merge two bounded SortedSets&lt;/p&gt;

&lt;p&gt;This sounds more like a priority queue and a sorted set.  Since the priority queue doesn&apos;t need keep all elments in sorted order, it may be cheaper than a SortedSet.&lt;/p&gt;

&lt;p&gt;On a separate note, it is common that the most impressive optimization for keeping top-n elements is to simply avoid inserting into the priority queue if you know that it will just get kicked out.  This can be done by looking at the score on the current lowest element.  The next step is to cache that lowest score.  This can often decrease the number of heap insertions by several orders of magnitude.&lt;/p&gt;</comment>
                            <comment id="12751822" author="robinanil" created="Sun, 6 Sep 2009 05:34:26 +0100"  >&lt;p&gt;More than insertion the major operation cost is in merge. Currently merge is insert one by one.  Had it been 2 sorted arrays merge would have been done at in O&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; time.  If its either TreeSet or PriorityQueue(heap) is used the merge operation would take O(nLogn).  One thing to note is that the size of the heap is very small (max 1000)&lt;/p&gt;</comment>
                            <comment id="12751923" author="tdunning" created="Sun, 6 Sep 2009 16:46:04 +0100"  >
&lt;p&gt;Hmm...&lt;/p&gt;

&lt;p&gt;You can get a significant improvement on the merge time because you may be able to insert in a different order which allows you to guess pretty accurates which half of the two queues you will not want to insert.  That is only  a (small) constant improvement, however.&lt;/p&gt;

&lt;p&gt;I am still curious to know if you can even get a priority queue that has linear expected behavior.&lt;/p&gt;

&lt;p&gt;What is the structure of the score?  Is it possible to store it as a fixed point number?  If so, then you can use radix sort to advantage.  Even without the integer nature, you should be able to break the score range into roughly equal sized chunks which are kept in unordered lists.  After some number of insertions, it will become clear that an entire chunk should be lost.  After a large number, you will lose enough chunks that you need to rechunk the score domain.  My guess is that the asymptotic behavior will not be much better unless you can be very clever about partial rechunking.&lt;/p&gt;

&lt;p&gt;A final question is whether a dedicated priority queue that keeps the score as a primitive will help.  The benefits could be similar to those gained by primitive hashMaps.&lt;/p&gt;

</comment>
                            <comment id="12751990" author="robinanil" created="Mon, 7 Sep 2009 02:02:19 +0100"  >&lt;p&gt;What I am merging are not integers its a pair of a list of integers(the pattern found) and an integer(the support of the pattern).  My Comparison operator is first based on support(higher to lower), then sizes of the pattern(longer to shorter), then the lexicographic ordering if the patterns are of same size and support. &lt;/p&gt;

&lt;p&gt;I have been reading up a couple of optmisations to fpgrowth&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Compressing the FPTree data structure representation for faster growth recursion (&lt;a href=&quot;http://ftp1.de.freebsd.org/Publications/CEUR-WS/Vol-90/liu.pdf&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ftp1.de.freebsd.org/Publications/CEUR-WS/Vol-90/liu.pdf&lt;/a&gt;&lt;br/&gt;
                                                                                                                             &lt;a href=&quot;http://www.computing.edu.au/~sucahyoy/article/hpdm04.pdf&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.computing.edu.au/~sucahyoy/article/hpdm04.pdf&lt;/a&gt; )&lt;/li&gt;
	&lt;li&gt;Detecting Frequent Closed item-sets.(if a pattern (a1 a2 .... an) is there with some support. Instead of outputting 2^n sets in the power-set of that set, output just the pattern provided the item-set is closed(definition here &lt;a href=&quot;http://ftp1.de.freebsd.org/Publications/CEUR-WS/Vol-90/liu.pdf&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ftp1.de.freebsd.org/Publications/CEUR-WS/Vol-90/liu.pdf&lt;/a&gt; )&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12752249" author="isabel" created="Mon, 7 Sep 2009 20:44:06 +0100"  >&lt;p&gt;The formatting still looks a bit weird (spaces, line length etc.)&lt;/p&gt;

&lt;p&gt;PFPGrowth, line 101, 183, 214 - please at least add a warning log message prior to deleting pre-existing output path and document somewhere on the usage page that default behaviour is deleting the output path, if exists. (I think that differs from the implementation in lda - we need to agree on consistant behaviour across mahout in such cases).&lt;/p&gt;

&lt;p&gt;line 174 - the combiner is commented out?&lt;/p&gt;

&lt;p&gt;ParallelCountingMapper - shouldn&apos;t you report status through the reporter during mapping?&lt;/p&gt;

&lt;p&gt;ParallelFPGrowthMapper - line 87 - please do not use e.printStackTrace() but generate a regular log message and log the exception stack trace through the logger.&lt;/p&gt;

&lt;p&gt;I would love to see some more comments: the expected format of key and value, the expected content of glist and flist.&lt;/p&gt;

&lt;p&gt;ParallelFPGrowthReducer line 111 - don&apos;t use e.printStackTrace.&lt;/p&gt;

&lt;p&gt;AggregatorReducer - line 91 same&lt;/p&gt;

&lt;p&gt;Attribute/TreeNode - The code is pretty clear, still I would love to see some more documentation on the overall data structure.&lt;/p&gt;

&lt;p&gt;FrequentPatternMaxHeap - line 74 - Huh? Judging from the return value, you can omit the comparison against null here. (line 81 same.&lt;/p&gt;

&lt;p&gt;FPGrowth - line 42 - the method name should not start with a capital letter.&lt;/p&gt;

&lt;p&gt;517 lines for implementing the whole algorithm in one class - looks a bit large for me. Is it possible to split it up?&lt;/p&gt;

&lt;p&gt;line 165 - converting from Integer to int and back again usually costs quite a bit of performance. Is there a way to rely on primitives only, or implement your own incrementable integer type? Btw., Integer.valueOf(1) should be replaced by Integer.ONE - that should be quicker and prevent in-accuracies.&lt;/p&gt;

&lt;p&gt;Type T - I think it would make the code better readable if T were given a clearer name, something like TransactionType? Otherwise you need to document what exactly T represents.&lt;/p&gt;

&lt;p&gt;line 229: Would reformulating the while conditions as &quot;while(!tempNode.childNodes.isEmpty()) &lt;/p&gt;
{ ... }
&lt;p&gt; make the code clearer here?&lt;/p&gt;

&lt;p&gt;line 239: Where does the magic number 6 come from here? Define as a constant with a speaking name?&lt;/p&gt;

&lt;p&gt;the two generatedSinglePathPatterns methods look rather similar - is it possible to not copy the code but extract it into its own method or reuse one in the other?&lt;/p&gt;

&lt;p&gt;line 293 (and earlier): Where does the magic number 4 come from? Define constant with speaking name?&lt;/p&gt;

&lt;p&gt;line 506: Looks like a strange log message?&lt;/p&gt;

&lt;p&gt;Concerning your idea of going the algorithm interface way for fpGrowth: If you can already make out what the interface should look like, I think that would be a good way to make it easier for future implementors of other frequent itemset algorithms.&lt;/p&gt;</comment>
                            <comment id="12757101" author="robinanil" created="Fri, 18 Sep 2009 11:58:28 +0100"  >&lt;p&gt;This is the story of optimization of FPGrowth implementation,  step by step and how linear speedup was achieved. &lt;/p&gt;

&lt;p&gt;a 300K transaction with 100 features takes just 5 secs to mine top 1000 patterns(ignoring the time taken to read the data).&lt;/p&gt;

&lt;p&gt;Background&lt;br/&gt;
      FPGrowth algorithm takes a list of itemsets(an itemset has multiple items) and a support value(that is min count a pattern mined should satify so as to be considered as a frequent pattern).&lt;br/&gt;
      Our aim here was to implement Top K frequent patterns.&lt;/p&gt;

&lt;p&gt;Algorithm Description&lt;br/&gt;
      FPTree is a compact tree representation of all itemsets where each branch denotes one itemset, duplicate itemset are represented in a single branch with counts increased. Each itemset is sorted according the the counts of each item in the whole database, The frequent items come at the begining of the tree and branches out based on if the next highest item is different.&lt;br/&gt;
at every recursive stage, a unique item is taken from the tree and a conditional tree is generated and mined for rest of the patterns. &lt;br/&gt;
What ever patterns return from the recursion, the current pattern is added to each of the pattern&lt;/p&gt;

&lt;p&gt;Implementation&lt;br/&gt;
    I started like every other java programmer, had node class representing the tree with parent, next(at the same level) and list of children. I was never able to go past 50K transactions with a minSupport of 10K  which is quite large.&lt;/p&gt;

&lt;p&gt;Dilligently, i started replacing replacing HashMaps to ArrayLists, Queue to ArrayDeque, PriorityQueue to TreeMap and with Yourkit i found bottlenecks and brought down the whole thing to 15 seconds for 50K with minSupport 10K down from some 1:40 secs&lt;/p&gt;

&lt;p&gt;You can find that patch as September-10.patch&lt;/p&gt;

&lt;p&gt;Memory used was too huge near about 1Gb for the 50K dataset. Time to find top 1000 patterns for 200K was 50 mins with a heap size of 1.6GB(half the time i felt the program was swapping in and out)&lt;/p&gt;

&lt;p&gt;After reading up the ibm presentation, I went on a crusade to use primitives as much as possible,&lt;/p&gt;

&lt;p&gt;First problem was, TreeNode is still a class and one of the major bottlenecks&lt;br/&gt;
1. Converted Tree into an multiple int [] arrays where i keep fixed properties. Like parent&lt;span class=&quot;error&quot;&gt;&amp;#91;node&amp;#93;&lt;/span&gt; next&lt;span class=&quot;error&quot;&gt;&amp;#91;node&amp;#93;&lt;/span&gt; value&lt;span class=&quot;error&quot;&gt;&amp;#91;node&amp;#93;&lt;/span&gt; childCount&lt;span class=&quot;error&quot;&gt;&amp;#91;node&amp;#93;&lt;/span&gt;&lt;br/&gt;
2. Converted Children into a int[][]  where i resize the child array and copy dynamically when number of children exceeds the allocated limit&lt;br/&gt;
3. Converted Pattern from List&amp;lt;Integer&amp;gt; to a resizable int[] with automatic resizing&lt;br/&gt;
GROWTH_FACTOR was set as 1.5&lt;br/&gt;
instantly the memory for 50K dataset came down to 400MB. and time came down to 8 seconds&lt;/p&gt;

&lt;p&gt;Secondly I noticed that at every recursive step a new conditional tree has to be generation, and Java was reallocating space again for an FPTree. &lt;br/&gt;
I  implemented a FPTree.clear which just sets the node count as zero and where ever array allocation was done, i did a check for if already allocated.&lt;/p&gt;

&lt;p&gt;Then I kept K trees, where K is the recursion depth which is the largest size of a transaction.  I reused the K Trees where space is already allocated by passing the List&amp;lt;FPTree&amp;gt; to each recursive step. &lt;/p&gt;

&lt;p&gt;Space of 50K transaction came down to 180MB and runtime to 5 seconds.&lt;/p&gt;

&lt;p&gt;I tried to do the same for the merge two TopK patterns and get TopK function, but that didnt give much saving, so i went back into using a TreeMap.&lt;/p&gt;

&lt;p&gt;Earlier, Ted had suggested me to check the least element before inserting into the heap do optimise the merge. &lt;br/&gt;
Yesterday it hit me that, If the heap is already full, I not only dont need to add pattern less than the least, but i also dont need to generate such patterns.&lt;/p&gt;

&lt;p&gt;So with a MutableInt, At every recursive step, if the heap is already full, the minimumSupport was raised. and subsequent recursions prunes away that portion of the tree.&lt;/p&gt;

&lt;p&gt;And to make all these aggressive, instead of the standard bottom up manner of FPGrowth(where long patterns need to be generated first). I started in the top down manner(where high support items get generated first). so the minSupport get raised quickly and we wont ever consider low support patterns. &lt;/p&gt;

&lt;p&gt;Runtimes I am seeing is amazing, &lt;/p&gt;

&lt;p&gt;for 50K even if i set the minSupport as 1000, it gets raised quickly to 24K and it takes a second to completely mine top 1000 patterns with no change in the output.&lt;br/&gt;
for 100K support gets raised to 61K time taken around 2 secods.&lt;br/&gt;
for 200K support gets raised to 93K time taken is around 3-4 seconds.&lt;br/&gt;
for 300K the time taken is around 5 seconds.&lt;br/&gt;
(database reading time not included)&lt;/p&gt;

&lt;p&gt;memory utilisation also decreased, we use the space for the entire FPtree, and very low space for each conditional tree.&lt;br/&gt;
All these could be found in September-18.patch&lt;/p&gt;


&lt;p&gt;I was thinking if we can figure out a way to converge upon the minSupport in the very begining, then tree could be pruned away and we would be having a very fast FPGrowth implementation&lt;/p&gt;

&lt;p&gt;More next week.&lt;br/&gt;
PS: Please dont review these patches(it may or may not have documentation, sometimes no license, tons of commented code)&lt;/p&gt;
</comment>
                            <comment id="12757324" author="tdunning" created="Fri, 18 Sep 2009 19:35:09 +0100"  >
&lt;p&gt;Nice work Robin (even with the code in preliminary form).&lt;/p&gt;

&lt;p&gt;Are these times on a single machine?  Or on a cluster?&lt;/p&gt;

&lt;p&gt;What happens with much larger data sets (10M items, say)?&lt;/p&gt;

&lt;p&gt;How long &lt;b&gt;is&lt;/b&gt; the database reading time that you are ignoring?&lt;/p&gt;
</comment>
                            <comment id="12761144" author="robinanil" created="Thu, 1 Oct 2009 10:17:12 +0100"  >&lt;p&gt;Finished Sequential version of FPGrowth. May need some more documentation and cleanup&lt;/p&gt;

&lt;p&gt;run ParallelFPGrowth in examples&lt;br/&gt;
with following settings&lt;/p&gt;

&lt;p&gt;s = min support&lt;br/&gt;
h = max size of heap&lt;br/&gt;
g = number of groups (works for parallel version)&lt;/p&gt;

&lt;p&gt;-i /home/robina/Desktop/accidents.dat -o output -s 3 -h 100 -g 1000 -method sequential&lt;/p&gt;

&lt;p&gt;accidents file is a transaction list with each line as a traction with features delimited by comma or tab&lt;br/&gt;
You can download a dataset from here &lt;a href=&quot;http://fimi.cs.helsinki.fi/data/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://fimi.cs.helsinki.fi/data/&lt;/a&gt;&lt;br/&gt;
the dataset needs to be converted into comma separated or tab separated. (Ensure there are trailing commas at the end of the line)&lt;/p&gt;

&lt;p&gt;the output file will have the top h patterns for each frequent feature&lt;/p&gt;</comment>
                            <comment id="12762137" author="robinanil" created="Mon, 5 Oct 2009 11:15:50 +0100"  >&lt;p&gt;Reply to Ted&apos;s Queries&lt;/p&gt;

&lt;p&gt;1. The timings are run on a Machine(Single Threaded on a Core2Duo 3.0Ghz)  &lt;br/&gt;
     It takes approximately 3 mins to mine top 50 patterns for each 320 features in a 340K transaction list&lt;br/&gt;
2. Database Reading Time is approximately 5 seconds for 340K transactions.&lt;br/&gt;
3. Initial FPTree building time is approximately 4 seconds for 340K transactions&lt;br/&gt;
4. FPGrowth is run 320 times and total time is 3 mins. So average time to fetch top 50 pattern containing a given feature is approximately 0.5 sec&lt;/p&gt;

&lt;p&gt;Parallel FPGrowth will split the database transactions such that only transactions containing a few features will be treated on one node, reducing fp-tree building time and also parallely executing the fpgrowth step.&lt;/p&gt;
</comment>
                            <comment id="12763281" author="robinanil" created="Wed, 7 Oct 2009 22:42:10 +0100"  >&lt;p&gt;Implementation of Top K Parallel FPGrowth using the optimised algorithm detailed above. &lt;br/&gt;
This implementation uses Custom Writable Classes instead of Text. &lt;/p&gt;


&lt;p&gt;Need to do testing and verification of results.  But code wise the implementation is done&lt;/p&gt;</comment>
                            <comment id="12763506" author="robinanil" created="Thu, 8 Oct 2009 15:43:53 +0100"  >&lt;p&gt;Tested the Map/Reduce Pipeline. The result shows that PFPGrowth is working. The results need to be checked if the answer is correct or not.&lt;/p&gt;

&lt;p&gt;To run the test you need to put comma separated transactions into (a) transaction file(s) and place them in &lt;span class=&quot;error&quot;&gt;&amp;#91;MAHOUT_HOME&amp;#93;&lt;/span&gt;/testdata/transactions&lt;/p&gt;</comment>
                            <comment id="12763929" author="isabel" created="Fri, 9 Oct 2009 10:21:42 +0100"  >&lt;p&gt;Great work Robin. I just had a look at the code and only found some minor things: &lt;/p&gt;

&lt;p&gt;ParallelFPGrowth &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;it might be a good idea to reuse the DefaultOptionCreator to generate common options like input and output.&lt;/li&gt;
	&lt;li&gt;I would love to see a help option as well.&lt;/li&gt;
	&lt;li&gt;What happens, if the users gives the wrong parameters? As a user, I would rather not get confronted with a stack trace, even though it is an example.&lt;/li&gt;
	&lt;li&gt;did you provide details on how to run the algorithm, the assumptions it makes, file format, behaviour if the output file exists already on the wiki?&lt;/li&gt;
	&lt;li&gt;the class is named ParallelFPGrowth, but if I read it correctly, it looks like the entry point for both, the parallel and sequential version. Maybe rename to FPGrowthJob?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;FPGrowth &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;line 98 is this really a recoverable error that does not cause inconsistancies later on? Log message says &quot;this should not happen&quot; - what if against all odds, it does happen? Why not throw a non-Checked Exception?&lt;/li&gt;
	&lt;li&gt;line 177 we should not have source code that is commented out in newly added code.&lt;/li&gt;
	&lt;li&gt;The class seems to implement both - top k and vanilla fp growth - would it make sense to split that up into different classes?&lt;/li&gt;
	&lt;li&gt;generateFrequentPatterns - maybe it is just me, but I am always happy to find tiny little comments in methods that long that very shortly explain what the following code block is doing.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;FPTreeDepthCache &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;maybe mention in the docs that the implementation is not threadsafe?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;FPTree, Pattern &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;missing a class comment.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Pattern &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;line 173 - please remove code that is commented out&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;AggregatorMapper &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the reporter is left unused.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Nice-To-Have: It would be nice to have package level comments in JavaDoc as well.&lt;/p&gt;</comment>
                            <comment id="12763983" author="robinanil" created="Fri, 9 Oct 2009 12:57:31 +0100"  >&lt;p&gt;FPGrowthReducer now reads DB Shards in a streaming fashion&lt;/p&gt;</comment>
                            <comment id="12764381" author="robinanil" created="Sat, 10 Oct 2009 23:21:21 +0100"  >&lt;p&gt;Completed streaming fpgrowth where transactions are read in a stream using an Iterator. &lt;/p&gt;

&lt;p&gt;The patch looks good (except for the comments above which has to be integrated)&lt;/p&gt;

&lt;p&gt;Units Tests average 90% coverage&lt;/p&gt;</comment>
                            <comment id="12764689" author="robinanil" created="Mon, 12 Oct 2009 15:08:14 +0100"  >&lt;p&gt;Improved FPGrowth mining speed 1.5-2x by caching recently generated conditional FPTrees (the parameter can now be configured on large mem systems)&lt;br/&gt;
Added comments. Package summary&lt;br/&gt;
Tests Coverage &amp;gt; 98%&lt;br/&gt;
custom regex splitter pattern can be provided via a parameter to split the input line into itemsets(words or group of words etc). This will prove helpful for parsing various formats of texts.&lt;/p&gt;

&lt;p&gt;Included Isabels Comments. &lt;/p&gt;

&lt;p&gt;e.g. Current usage for String Objects&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;
FPGrowth fp = new FPGrowth();
Set features = new HashSet();
SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, path,Text.class, TopKStringPatterns.class);
fp.generateTopKStringFrequentPatterns(
 		new StringRecordIterator(new FileLineIterable(new File(input), encoding, false), pattern), 
        fp.generateFList(
        	new StringRecordIterator(new FileLineIterable(new File(input), encoding, false), pattern), minSupport),
       	minSupport,
        maxHeapSize, 
        features,
        new StringOutputConvertor(new SequenceFileOutputCollector(writer))
  );
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
	&lt;li&gt;The first argument is the iterator of transaction in this case its Iterator&amp;lt;List&amp;lt;String&amp;gt;&amp;gt;&lt;/li&gt;
	&lt;li&gt;The second argument is the output of generateFList function, which returns the frequent items and their frequencies from the given database transaction iterator&lt;/li&gt;
	&lt;li&gt;The third argument is the minimum Support of the pattern to be generated&lt;/li&gt;
	&lt;li&gt;The fourth argument is the maximum number of patterns to be mined for each feature&lt;/li&gt;
	&lt;li&gt;The fifth argument is the set of features for which the frequent patterns has to be mined&lt;/li&gt;
	&lt;li&gt;The last argument is an output collector which takes &lt;span class=&quot;error&quot;&gt;&amp;#91;key, value&amp;#93;&lt;/span&gt; of Feature and TopK Patterns of the format &lt;span class=&quot;error&quot;&gt;&amp;#91;String, List&amp;lt;Pair&amp;lt;List&amp;lt;String&amp;gt;, Long&amp;gt;&amp;gt;&amp;#93;&lt;/span&gt; and writes them to the appropriate writer class which takes care of storing the object, in this case in a Sequence File Output format&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The numGroups parameter in FPGrowthJob specifies the number of groups into which transactions have to be decomposed. &lt;br/&gt;
The numTreeCacheEntries parameter specifies the number of generated conditional FP-Trees to be kept in memory so as not to regenerate them. Increasing this number increases the memory consumption but might improve speed until a certain point. This depends entirely on the dataset in question. A value of 5-10 is recommended for mining upto top 100 patterns for each feature&lt;/p&gt;</comment>
                            <comment id="12764811" author="robinanil" created="Mon, 12 Oct 2009 21:13:44 +0100"  >&lt;p&gt;some general cleanup, formatting, javadocs. made using latest trunk.&lt;/p&gt;

&lt;p&gt;The patch is ready for another round of review. &lt;/p&gt;</comment>
                            <comment id="12764814" author="robinanil" created="Mon, 12 Oct 2009 21:19:31 +0100"  >&lt;p&gt;Also, All the Jobs are now in the new mapreduce.* api (&amp;gt;0.20.0).  Cleaned all unused imports. Except for OutputCollector Interface, there is no pre 0.20.0 hadoop classes used.&lt;/p&gt;

&lt;p&gt;I kept only one final TopK implementation, removed Vanilla FPGrowth implementation(its still there in one of the patches)&lt;/p&gt;

&lt;p&gt;all reporters are being used. &lt;/p&gt;
</comment>
                            <comment id="12765205" author="robinanil" created="Tue, 13 Oct 2009 20:53:09 +0100"  >&lt;p&gt;Tried running 1.6GB dense transaction dataset(webdocs) on a single node cluster. Mapper seem to be creating huge groups of transactions. So converted all the transactions to integers at the mapper stage.&lt;/p&gt;

&lt;p&gt;The size of mapper output is too large for one node to handle. Seems it would need atleast a  5-10Node cluster to test the above dataset&lt;/p&gt;</comment>
                            <comment id="12766030" author="isabel" created="Thu, 15 Oct 2009 12:40:53 +0100"  >&lt;p&gt;The patch looks good to me. Good work Robin.&lt;/p&gt;</comment>
                            <comment id="12767147" author="robinanil" created="Sun, 18 Oct 2009 23:22:34 +0100"  >&lt;p&gt;Committed&lt;/p&gt;</comment>
                            <comment id="13979725" author="qubit93" created="Thu, 24 Apr 2014 14:35:35 +0100"  >&lt;p&gt;Hey Robin, Regarding your comment dated 07/Sep/09 06:32 &lt;br/&gt;
I know its been a long time since the post, but i actually wanted to use pfpgrowth on mahout without closing of the itemsets.&lt;br/&gt;
For it, I downloaded your source and tried to interpret it and initially i thought that the issue was in FPGrowth.generateSinglePathPatterns() as you are adding the entire conditional FP Tree in the frequentPatterns. &lt;br/&gt;
For eg: if the conditional fp tree had &lt;span class=&quot;error&quot;&gt;&amp;#91;f:3 c:3 a:3 m:3&amp;#93;&lt;/span&gt;, then this method makes the pattern &lt;span class=&quot;error&quot;&gt;&amp;#91;f,c,a,m | 3&amp;#93;&lt;/span&gt; and inserts it into the FrequentPatternMaxHeap. I thought the problem was not generating all the combinations here but it seems that i couldn&apos;t able to understand the code correctly.&lt;br/&gt;
Could you please just lead me to the point(s) or code snippet(s) where the closure is being performed so that i could test on how to remove this closure.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Aman&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12416785" name="MAHOUT-157-August-17.patch" size="70525" author="robinanil" created="Mon, 17 Aug 2009 18:41:23 +0100"/>
                            <attachment id="12417436" name="MAHOUT-157-August-24.patch" size="77415" author="robinanil" created="Mon, 24 Aug 2009 03:52:38 +0100"/>
                            <attachment id="12418148" name="MAHOUT-157-August-31.patch" size="79557" author="robinanil" created="Mon, 31 Aug 2009 15:22:34 +0100"/>
                            <attachment id="12415666" name="MAHOUT-157-August-6.patch" size="55799" author="robinanil" created="Wed, 5 Aug 2009 22:11:56 +0100"/>
                            <attachment id="12415664" name="MAHOUT-157-Combinations-BSD-License.patch" size="7894" author="robinanil" created="Wed, 5 Aug 2009 22:09:10 +0100"/>
                            <attachment id="12415523" name="MAHOUT-157-Combinations-BSD-License.patch" size="7765" author="robinanil" created="Tue, 4 Aug 2009 22:29:25 +0100"/>
                            <attachment id="12422013" name="MAHOUT-157-CompactTransactionMapperFormat.patch" size="140764" author="robinanil" created="Tue, 13 Oct 2009 20:53:09 +0100"/>
                            <attachment id="12420994" name="MAHOUT-157-Oct-1.patch" size="88609" author="robinanil" created="Thu, 1 Oct 2009 10:17:12 +0100"/>
                            <attachment id="12421808" name="MAHOUT-157-Oct-10.pfpgrowth.patch" size="112431" author="robinanil" created="Sat, 10 Oct 2009 23:21:20 +0100"/>
                            <attachment id="12421628" name="MAHOUT-157-Oct-8.TestedMapReducePipeline.patch" size="94352" author="robinanil" created="Thu, 8 Oct 2009 15:43:53 +0100"/>
                            <attachment id="12421585" name="MAHOUT-157-Oct-8.pfpgrowth.patch" size="88376" author="robinanil" created="Wed, 7 Oct 2009 22:42:10 +0100"/>
                            <attachment id="12421730" name="MAHOUT-157-Oct-9.StreamingDBRead-Inprogress.patch" size="107055" author="robinanil" created="Fri, 9 Oct 2009 12:57:31 +0100"/>
                            <attachment id="12420012" name="MAHOUT-157-September-10.patch" size="88657" author="robinanil" created="Fri, 18 Sep 2009 11:58:28 +0100"/>
                            <attachment id="12420013" name="MAHOUT-157-September-18.patch" size="94335" author="robinanil" created="Fri, 18 Sep 2009 11:58:28 +0100"/>
                            <attachment id="12418719" name="MAHOUT-157-September-5.patch" size="81805" author="robinanil" created="Sat, 5 Sep 2009 17:48:31 +0100"/>
                            <attachment id="12421900" name="MAHOUT-157-codecleanup-javadocs.patch" size="130750" author="robinanil" created="Mon, 12 Oct 2009 21:13:44 +0100"/>
                            <attachment id="12421871" name="MAHOUT-157-final.patch" size="128024" author="robinanil" created="Mon, 12 Oct 2009 15:08:14 +0100"/>
                            <attachment id="12415520" name="MAHOUT-157-inProgress-August-5.patch" size="31657" author="robinanil" created="Tue, 4 Aug 2009 22:26:47 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>18.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 11 Aug 2009 19:49:18 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9908</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hxy6un:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23261</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>