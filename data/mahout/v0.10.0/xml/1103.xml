<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:25:08 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-1103/MAHOUT-1103.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-1103] clusterpp is not writing directories for all clusters</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-1103</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;p&gt;After running kmeans clustering on a set of ~3M points, clusterpp fails to populate directories for some clusters, no matter what k is.&lt;/p&gt;

&lt;p&gt;I&apos;ve tested this on my data with k = 300, 250, 150, 100, 50, 25, 10, 5, 2&lt;/p&gt;

&lt;p&gt;Even with k=2 only one cluster directory was created. For each reducer that fails to produce directories there is an empty part-r-* file in the output directory.&lt;/p&gt;

&lt;p&gt;Here is my command sequence for the k=2 run:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;bin/mahout kmeans -i ssvd2/USigma -c 2clusters/init-clusters -o 2clusters/pca-clusters -dm org.apache.mahout.common.distance.TanimotoDistanceMeasure -cd 0.05 -k 2 -x 15 -cl

bin/mahout clusterdump -i 2clusters/pca-clusters/clusters-*-final -o 2clusters.txt

bin/mahout clusterpp -i 2clusters/pca-clusters -o 2clusters/bottom&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;The output of clusterdump shows two clusters: VL-3742464 and VL-3742466 containing 2585843 and 1156624 points respectively.&lt;/p&gt;

&lt;p&gt;Discussion on the user mailing list suggested that this might be caused by the default hadoop hash partitioner. The hashes of these two clusters aren&apos;t identical, but they are close. Putting both cluster names into a Text and caling hashCode() gives:&lt;br/&gt;
VL-3742464 -&amp;gt; -685560454&lt;br/&gt;
VL-3742466 -&amp;gt; -685560452&lt;/p&gt;

&lt;p&gt;Finally, when running with &quot;-xm sequential&quot;, everything performs as expected.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12612976">MAHOUT-1103</key>
            <summary>clusterpp is not writing directories for all clusters</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gsingers">Grant Ingersoll</assignee>
                                    <reporter username="mmolek">Matt Molek</reporter>
                        <labels>
                            <label>clusterpp</label>
                    </labels>
                <created>Mon, 22 Oct 2012 15:16:45 +0100</created>
                <updated>Mon, 3 Feb 2014 08:06:13 +0000</updated>
                            <resolved>Sun, 9 Jun 2013 13:41:36 +0100</resolved>
                                    <version>0.8</version>
                                    <fixVersion>0.8</fixVersion>
                                    <component>Clustering</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13481408" author="paritoshranjan" created="Mon, 22 Oct 2012 15:56:47 +0100"  >&lt;p&gt;&quot;I&apos;ve tested this on my data with k = 300, 250, 150, 100, 50, 25, 10, 5, 2&quot;&lt;/p&gt;

&lt;p&gt;Since its not working for even two clusters, I don&apos;t see any problem due to the Partitioner. The input here looks like the output of SSVD. There has been problems reported earlier also, where SSVD output was creating problems in clustering.&lt;/p&gt;

&lt;p&gt;Can your try kmeans + clusterpp without performing SSVD on the vectors? I suspect this to be the problem for now, but we will have to test it. &lt;/p&gt;

&lt;p&gt;The sequential and mapreduce versions are completely differernt implementations, so, its normal to have a bug in one version which is not present in the second version.&lt;/p&gt;

&lt;p&gt;Please update once you test it.&lt;/p&gt;</comment>
                            <comment id="13481433" author="mmolek" created="Mon, 22 Oct 2012 16:20:55 +0100"  >&lt;p&gt;Yes, I am clustering on ssvd output. I will try again with the vectors directly from seq2sparse and update once I&apos;m done.&lt;/p&gt;

&lt;p&gt;I was just reading up on the way the HashPartitioner works though, and I do think it is part of the issue. HashPartitioner uses the following logic to determine what partition a key belongs to: int partition = (key.hashCode() &amp;amp; Integer.MAX_VALUE) % numReduceTasks;&lt;/p&gt;

&lt;p&gt;That yields a partition of 0 for both VL-3742464 and VL-3742466. If however, they were named VL-0 and VL-1, they would be properly split up by the HashPartitioner. I think if clusters were always named VL-i where 0&amp;lt;=i&amp;lt;k, then there would not be an issue. Dealing with this weird naming scheme (which I don&apos;t know the origin of since I&apos;m not familiar with the inner workings of kmeans) seems to be the issue.&lt;/p&gt;</comment>
                            <comment id="13481544" author="paritoshranjan" created="Mon, 22 Oct 2012 18:46:04 +0100"  >&lt;p&gt;Instead of changing the nomenclature of clusters, we should create a partitioner which solves the problem ( if the problem is in partitioner ). &lt;/p&gt;

&lt;p&gt;By changing the nomenclature of the clusters, we will be fixing the bug just for this particular case. In case, someone creates as many as 3742464 clusters ( assume ), or more, then again the same problem will rise. So, we should fix it at a generic level.&lt;/p&gt;

&lt;p&gt;Looking forward for your tests without SVD. As I said earlier, also try to use a better Partitioner. The partitioner can be changed in postProcessMR method of ClusterOutputPostProcessorDriver class. &lt;/p&gt;

&lt;p&gt;You can read this page &lt;a href=&quot;https://cwiki.apache.org/MAHOUT/how-to-contribute.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/MAHOUT/how-to-contribute.html&lt;/a&gt; to see how to get code and generate patches.&lt;/p&gt;</comment>
                            <comment id="13481546" author="dlyubimov" created="Mon, 22 Oct 2012 18:50:17 +0100"  >&lt;blockquote&gt;&lt;p&gt;Since its not working for even two clusters, I don&apos;t see any problem due to the Partitioner. The input here looks like the output of SSVD. There has been problems reported earlier also, where SSVD output was creating problems in clustering.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;What issues? Can you be more specific? &lt;/p&gt;

&lt;p&gt;The only discussion i am aware of was with Pat and he was having problem using embedded style and with the fact that there were no --USigma output available at that time. &lt;/p&gt;

&lt;p&gt;I am not aware of any issues in the HEAD. he should be able to use --pca true option and if it retains enough variance (i.e. fairly rapid spectrum decay in the first 100-ish values) he should be fine at least with euclidean coordinates clustering. &lt;/p&gt;

&lt;p&gt;if he looks at cosine similarities for topical clustering (aka LSA) he doesn&apos;t need --pca option.&lt;/p&gt;

&lt;p&gt;Either way it is not a problem of SSVD but a problem of the approach.&lt;/p&gt;</comment>
                            <comment id="13481550" author="mmolek" created="Mon, 22 Oct 2012 18:55:43 +0100"  >&lt;blockquote&gt;&lt;p&gt;he should be able to use --pca true option and if it retains enough variance (i.e. fairly rapid spectrum decay in the first 100-ish values) he should be fine at least with euclidean coordinates clustering.&lt;/p&gt;

&lt;p&gt;if he looks at cosine similarities for topical clustering (aka LSA) he doesn&apos;t need --pca option.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hi Dmitriy, sorry for going a little off topic here, but could you elaborate on this? I&apos;ve been experimenting with using either cosine or tanimoto distance on the USigma output of ssvd with -pca true. Are those not appropriate distance measures for the -pca output?&lt;/p&gt;</comment>
                            <comment id="13481552" author="dlyubimov" created="Mon, 22 Oct 2012 18:57:01 +0100"  >&lt;p&gt;btw Tanimoto distance suggests he actually wants LSA topics, not pure PCA (euclidean). Further on, usually output U is taken for this purpose. &lt;/p&gt;

&lt;p&gt;I would suggest the author to prototype with R on a document subset first to make sure his pipeline yields result he expects. Unfortunately we don&apos;t have an easy way to convert DRM to R data sets (yet), hopefully some work will be done at some point to bridge that gap.&lt;/p&gt;</comment>
                            <comment id="13481557" author="dlyubimov" created="Mon, 22 Oct 2012 18:59:16 +0100"  >&lt;blockquote&gt;&lt;p&gt;Hi Dmitriy, sorry for going a little off topic here, but could you elaborate on this? I&apos;ve been experimenting with using either cosine or tanimoto distance on the USigma output of ssvd with -pca true. Are those not appropriate distance measures for the -pca output?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ll reply on user list, that way somebody will surely try to correct me since i have been doing straightforward LSA only.&lt;/p&gt;</comment>
                            <comment id="13481626" author="mmolek" created="Mon, 22 Oct 2012 19:54:13 +0100"  >&lt;p&gt;I&apos;ve finished a test with k=25 on input directly from seq2sparse, and the problem has persisted. I&apos;m pretty sure it&apos;s because of the way the HashPartitioner is splitting up the &quot;VL-*&quot; Text keys, and doesn&apos;t have anything to do with the input vectors (whether they came from seq2sparse or ssvd).&lt;/p&gt;

&lt;p&gt;I can&apos;t start working on a patch right now, but I will check back when I have some free time and see what I can do if there hasn&apos;t been any progress.&lt;/p&gt;</comment>
                            <comment id="13481680" author="paritoshranjan" created="Mon, 22 Oct 2012 20:19:40 +0100"  >&lt;p&gt;Dmitriy, I was talking about the issue where VectorIds were being lost. That was not a ssvd problem, but the way ssvd + kmeans was used. I faintly remember that, so I just wanted to make sure that the same problem is not there.&lt;/p&gt;</comment>
                            <comment id="13481702" author="dlyubimov" created="Mon, 22 Oct 2012 20:32:12 +0100"  >&lt;p&gt;You mean, propagation of names in NamedVector to products of U? yes this has been addressed at the same time as --USigma, current trunk should be good.&lt;/p&gt;</comment>
                            <comment id="13483390" author="paritoshranjan" created="Wed, 24 Oct 2012 17:54:56 +0100"  >&lt;p&gt;Dmitriy - yes, I think it was the same error. &lt;/p&gt;

&lt;p&gt;Matt - I have created a partitioner and applied it at ClusterOutputPostProcessorDriver assuming the valid cluster Ids are the latest and sequential i.e. ids will be VL-8543 to VL 8563 if 20 unique clusters are there. The attached test case demonstrates that it will work for this scenario.&lt;/p&gt;

&lt;p&gt;If you want, you can try this patch on trunk, and check whether it works or not. I am not sure about it, as I still need to figure out the nomenclature of relevant cluster Ids.  &lt;/p&gt;</comment>
                            <comment id="13489762" author="paritoshranjan" created="Fri, 2 Nov 2012 21:23:34 +0000"  >&lt;p&gt;I tried to test cluster post processing with Junit but the problem is while running through Junits ( standalone mode ), the numpartitions is always 1. So, the partitioner does not behave in the way it should. &lt;/p&gt;

&lt;p&gt;I will try running it on a cluster to test the results. &lt;/p&gt;

&lt;p&gt;I think the current approach to post process is highly dependent on cluster ids + partitioner which is somehow not correct. Any change in clustering approach will have an impact on cluster post processing. I will also think of another ways to solve it.&lt;/p&gt;</comment>
                            <comment id="13598990" author="mmolek" created="Mon, 11 Mar 2013 17:02:12 +0000"  >&lt;p&gt;I&apos;ve implemented an idea for this that works regardless of what the cluster ids are. It&apos;s in a separate class right now, but if you like the idea, I can refactor it as a patch to the current clusterpp code.&lt;/p&gt;

&lt;p&gt;I made a class similar to o.a.m.clustering.topdown.postprocessor.ClusterCountReader, called ClusterIDReader. Given a clustering output directory, it reads all the cluster ids and returns a list containing the cluster ids.&lt;/p&gt;

&lt;p&gt;To actually process the data, I run a MapReduce job over the clusterdPoints ouput directory. In the mapper&apos;s setup function, the list of clusters is obtained from ClusterIDReader, and a HashMap is constructed. The HashMap maps each cluster id to an int from 0 to k-1. The mapper emits each clustered vector with its new key 0 to k-1.&lt;/p&gt;

&lt;p&gt;There are k reducers, one for each cluster, and each reducer uses ClusterIDReader to reverse the clusterID mapping that was created by the mappers. This allows the original cluster ids to be preserved at the end of the job. Once the job is done, the movePartFilesToRespectiveDirectories method works as before to move the part files to correctly named directories. &lt;/p&gt;

&lt;p&gt;Because the intermediate keys are guaranteed to be an unbroken sequence of ints from 0 to k-1, I think the hash partitioner will always send the vectors from each cluster to exactly one reducer (assuming there are k reducers).&lt;/p&gt;

&lt;p&gt;Would you like a version of this as a patch?&lt;/p&gt;

</comment>
                            <comment id="13672209" author="gsingers" created="Sat, 1 Jun 2013 20:30:24 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dlyubimov&quot; class=&quot;user-hover&quot; rel=&quot;dlyubimov&quot;&gt;Dmitriy Lyubimov&lt;/a&gt; or &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mmolek&quot; class=&quot;user-hover&quot; rel=&quot;mmolek&quot;&gt;Matt Molek&lt;/a&gt; any updates on this?&lt;/p&gt;</comment>
                            <comment id="13672657" author="gsingers" created="Sun, 2 Jun 2013 20:49:39 +0100"  >&lt;p&gt;I can reproduce this.&lt;/p&gt;</comment>
                            <comment id="13672658" author="gsingers" created="Sun, 2 Jun 2013 21:02:36 +0100"  >&lt;p&gt;This seems like a flat out bug in the ClusterPP, since it says it is supposed to write separate directories, so it doesn&apos;t seem to me like we need to add new classes here, but instead should fix the bug.  Still looking.&lt;/p&gt;</comment>
                            <comment id="13672669" author="gsingers" created="Sun, 2 Jun 2013 21:25:11 +0100"  >&lt;p&gt;Hmm, so this works in Sequential mode, but not in MapReduce mode&lt;/p&gt;</comment>
                            <comment id="13672718" author="gsingers" created="Mon, 3 Jun 2013 00:32:33 +0100"  >&lt;p&gt;It has an assumption in the code that each cluster id ends up in a different part file by the fact the number of reducers is set to the number of clusters which is supposed to mean that there should be one output part file per reducer (i.e. per cluster id), but that isn&apos;t happening, at least in the simple testing I&apos;m doing using pseudo M/R mode using data generated from.  Can someone test this on a real Hadoop cluster, as I don&apos;t have access to one right at the moment?  At least in the non-cluster env, the work around is to run in sequential mode.&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;bin/mahout org.apache.mahout.clustering.syntheticcontrol.meanshift.Job -x 25 -cd 5 -t1 50 -t2 10 -dm org.apache.mahout.common.distance.EuclideanDistanceMeasure -i /path/content/synthetic_control.data  -ow -o output -cl&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;... org.apache.mahout.clustering.topdown.postprocessor.ClusterOutputPostProcessorDriver -i output -o output/postMR&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="13672760" author="mmolek" created="Mon, 3 Jun 2013 03:28:12 +0100"  >&lt;blockquote&gt;
&lt;p&gt;This seems like a flat out bug in the ClusterPP, since it says it is supposed to write separate directories, so it doesn&apos;t seem to me like we need to add new classes here, but instead should fix the bug.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well yes, it is a bug. I&apos;ve reproduced it on a real cluster (that&apos;s what lead me to origianlly post this jira). The problem is that the distributed clusterpp job assumes that the hash partitioner will correctly distribute the cluster ids, one to each reducer. That would only happen in the situation where the clusters are numbered 1 to k or some other convenient numbering. That is rarely, if ever, the case.&lt;/p&gt;

&lt;p&gt;The only way I could think to get this working is to temporarily remap the cluster ids to a more convenient numbering that would play well with the hash partitioner. See my earlier comment for the exact way I went about that. I don&apos;t think any small tweaks will fix the current distributed code. As far as I can tell, you either need to temporarily change the cluster numbering, or write some new partitioner (and I can&apos;t think of a way to do it with a paritioner). Maybe there&apos;s some third option, but I can&apos;t think of one.&lt;/p&gt;

&lt;p&gt;I&apos;m happy to try coming up with a patch for the way I&apos;ve solved it, if you want to go about it that way.&lt;/p&gt;</comment>
                            <comment id="13672836" author="gsingers" created="Mon, 3 Jun 2013 06:42:17 +0100"  >&lt;blockquote&gt;&lt;p&gt;Well yes, it is a bug. I&apos;ve reproduced it on a real cluster (that&apos;s what lead me to origianlly post this jira)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Yeah, just confirming it.  We get a lot of non-bugs reported.  I wonder if we used to just sequentially dole out cluster ids and that changed w/ the clustering refactoring.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;That would only happen in the situation where the clusters are numbered 1 to k or some other convenient numbering. That is rarely, if ever, the case.&lt;br/&gt;
The only way I could think to get this working is to temporarily remap the cluster ids to a more convenient numbering that would play well with the hash partitioner&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t know a lot about partitioners just yet and that makes me think they might be heavy handed here, but it occurs to me that we can take advantage of that the number of clusters is small and during setup simply load up the cluster id map and create the &quot;convenient numbering&quot; for writing during the reduce phase to 0 - n-1 (where n is the number of clusters).&lt;/p&gt;

&lt;p&gt;Then, in the &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;movePartFilesToRespectiveDirectories&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; we should get renamed appropriately.&lt;/p&gt;

&lt;p&gt;Would that work?&lt;/p&gt;</comment>
                            <comment id="13672981" author="gsingers" created="Mon, 3 Jun 2013 11:35:03 +0100"  >&lt;p&gt;OK, I read up on partitioners and I&apos;d agree, Matt, this is effectively hadoop&apos;s way of doing what I proposed and doesn&apos;t pollute the M/R code, so I&apos;m going to go forward w/ your patch.&lt;/p&gt;</comment>
                            <comment id="13673071" author="gsingers" created="Mon, 3 Jun 2013 13:36:46 +0100"  >&lt;p&gt;Matt, out of curiosity, what&apos;s your use case for the clusterpp?  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=robinanil&quot; class=&quot;user-hover&quot; rel=&quot;robinanil&quot;&gt;Robin Anil&lt;/a&gt; and I are both looking at this code and wondering why it is useful to separate out the clusters into their own directory.  &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-843&quot; title=&quot;Top Down Clustering&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-843&quot;&gt;&lt;del&gt;MAHOUT-843&lt;/del&gt;&lt;/a&gt; doesn&apos;t shed any light on it for us either.&lt;/p&gt;

&lt;p&gt;Also, I don&apos;t think the current patch partitions correctly.  For instance, try a numPartitions of 2 and cluster ids of 153 and 53.  Then, 10^1 means you get 153 % 10 and 53 % 10 both = 3 and you have a collision.  So, I think I&apos;m back to my original thought, which is in the mappers and reducers, we need to load up the cluster ids and just map it there.&lt;/p&gt;</comment>
                            <comment id="13673119" author="mmolek" created="Mon, 3 Jun 2013 14:58:40 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Yeah, just confirming it. We get a lot of non-bugs reported. I wonder if we used to just sequentially dole out cluster ids and that changed w/ the clustering refactoring.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry, no problem. I just wanted to make sure nothing was getting overlooked since this thread is getting rather long.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;which is in the mappers and reducers, we need to load up the cluster ids and just map it there.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s exactly what I&apos;ve gotten working on my own project. It&apos;s not submitted here yet as a patch because the first version of it that I made was just to see if it would work, and isn&apos;t in mahout&apos;s code style. I think there was a different earlier patch from Paritosh which is the patch currently attached. My code is pretty simple. I can submit a patch in the next couple of days once I find a little free time.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Matt, out of curiosity, what&apos;s your use case for the clusterpp? Robin Anil and I are both looking at this code and wondering why it is useful to separate out the clusters into their own directory.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;For me, the value in separating the clusters out into their own directories is that it makes it very easy to lauch further mahout jobs against the contents of an individual cluster. I cluster, separate the results, and then launch new jobs against each clusterpp output directory. I find it pretty useful.&lt;/p&gt;
</comment>
                            <comment id="13673143" author="gsingers" created="Mon, 3 Jun 2013 15:10:33 +0100"  >&lt;blockquote&gt;&lt;p&gt;I can submit a patch in the next couple of days once I find a little free time&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Awesome.  Please do.  I&apos;ve got momentum on this issue and towards 0.8, so if you can soon, that would be great.  Don&apos;t worry about codestyle, I can take care of that and any other pieces. If you have the gist of it working, then you&apos;ll save me a bit of time.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;different earlier patch&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ah, my confusion...  Sorry about that.&lt;/p&gt;</comment>
                            <comment id="13677163" author="gsingers" created="Thu, 6 Jun 2013 16:54:01 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mmolek&quot; class=&quot;user-hover&quot; rel=&quot;mmolek&quot;&gt;Matt Molek&lt;/a&gt; Any luck on the patch?  I&apos;d like to close this out before 0.8 if possible.&lt;/p&gt;</comment>
                            <comment id="13677261" author="mmolek" created="Thu, 6 Jun 2013 18:24:37 +0100"  >&lt;p&gt;I&apos;ve been held up with some local problems with running tests. When building mahout with testing enabled, I&apos;m getting lots of out of memory errors that I haven&apos;t figured out yet. This is happening to me on a clean checkout of the trunk, so it&apos;s nothing I&apos;ve modified. It must just be something weird with my local environment.&lt;/p&gt;

&lt;p&gt;So, apologies for not being able to fully test this. It does build with -DskipTests=true though, and it worked fine when testing it on some real data just now.&lt;/p&gt;

&lt;p&gt;As I was typing this up I just remembered that I changed the keys from Texts to IntWritables, since int is the only type of ID a ClusterWritable can have. That probably makes the map/reduce implementation inconsistent with the way the sequential method does it though. To get identical output to the sequential method, the reducer just needs to output a Text with the cluster id, instead of an IntWritable with the cluster id like is does in my patch.&lt;/p&gt;</comment>
                            <comment id="13677269" author="srowen" created="Thu, 6 Jun 2013 18:29:17 +0100"  >&lt;p&gt;A-ha, I bet that&apos;s related to my last change to reduce the memory allowed during tests, in order to avoid a different kind of out-of-memory problem. It succeeds for me locally on Java 7. Try upping &quot;-Xmx512m&quot; in pom.xml to &quot;-Xmx768M&quot;. What version of Java? if it&apos;s 6, maybe try &quot;-XX:+UseCompressedOops&quot; instead / as well? Hopefully there is a middle ground that works here.&lt;/p&gt;</comment>
                            <comment id="13677328" author="mmolek" created="Thu, 6 Jun 2013 19:13:04 +0100"  >&lt;p&gt;Fount it, I think. Increasing the -Xmx option wasn&apos;t the solution, but the problem was related to the the parallel testing configuration. I have 6 cores, and the forkCount in pom.xml is set to 1.5C. 9 parallel tests was more than could fit into available memory on my computer. It would&apos;ve taken me a while to figure out that I should look there, so thanks for the suggestion.&lt;/p&gt;</comment>
                            <comment id="13677335" author="srowen" created="Thu, 6 Jun 2013 19:19:17 +0100"  >&lt;p&gt;Hmm, but would that cause an OutOfMemoryError? that implies that there was not enough heap in each JVM. The problem you describe is what I saw too; too much heap from too many JVMs causing a load of swapping. The JVMs themselves were fine; they had plenty of heap. It&apos;s just that the whole machine was slowing to a crawl due to swapping. Reducing forkCount would still leave each JVM with the same heap, and if it&apos;s not sufficient, it would still fail.&lt;/p&gt;

&lt;p&gt;I can however imagine that the current setting is a little tight, and when the machine slows due to swapping, it makes the GC give up due to excessive time in collection, earlier. Then the swapping could induce `OutOfMemoryError`, maybe.&lt;/p&gt;

&lt;p&gt;But if you just mean you saw too much swapping... how much RAM do you have? I would think 8GB would kind of work.&lt;/p&gt;</comment>
                            <comment id="13677346" author="mmolek" created="Thu, 6 Jun 2013 19:28:50 +0100"  >&lt;p&gt;Sorry, I was too general with my terminology. It wasn&apos;t actually an OutOfMemoryError. The actual error message was one I hadn&apos;t come across before:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There is insufficient memory for the Java Runtime Environment to continue.&lt;br/&gt;
Native memory allocation (malloc) failed to allocate 857408 bytes for Chunk::new&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I have 8GB of ram, so I was surprised that I didn&apos;t have room for 9 512MB VM&apos;s to run, but lowering the forkCount did fix the problem for me.&lt;/p&gt;</comment>
                            <comment id="13677389" author="srowen" created="Thu, 6 Jun 2013 20:07:42 +0100"  >&lt;p&gt;512MB of heap can mean quite a bit more than that used by the JVM. Thread stacks, native code memory allocations, buffers, and other stuff adds up to maybe 25% more in overhead. Do you have swap off? then all your other OS stuff is resident in RAM too and that could take a lot.&lt;/p&gt;

&lt;p&gt;There&apos;s some argument to turn down fork to one per core, although that probably leaves cores underutilized as many JVMs will be waiting on I/O at any given time. With 1C, core tests take 10.5 minutes for me (2 cores, 4 virtual cores). It&apos;s 9.3 minutes with 1.5C.&lt;/p&gt;

&lt;p&gt;Hmm, is it better to turn this down to make sure the tests run out of the box for more people, and leave it to those with big machines to manually tune this upwards? Or vice versa. The speed difference is about 15%. The number of people for whom it would fail now is... I don&apos;t know. It failed for 3 of us before my change, now down to 1. Might be reasonable to think 5-10% of users won&apos;t be able to run the tests as is?&lt;/p&gt;</comment>
                            <comment id="13677665" author="mmolek" created="Fri, 7 Jun 2013 00:38:20 +0100"  >&lt;p&gt;I have 8GB of swap, so I&apos;m confused by the memory error. When nothing else is running, I&apos;m only using 1.1GB of memory and 0% swap, so I should&apos;ve been ok with 9 concurrent tests. &lt;/p&gt;</comment>
                            <comment id="13678727" author="gsingers" created="Sat, 8 Jun 2013 12:13:56 +0100"  >&lt;p&gt;Matt, can you check this iteration on your patch?  That being said, it doesn&apos;t work for me running the MR job locally when testing on a small data set.  Would be nice to get this self contained somehow in a small unit test.&lt;/p&gt;</comment>
                            <comment id="13678753" author="gsingers" created="Sat, 8 Jun 2013 16:57:15 +0100"  >&lt;p&gt;The MapReduce portion of this will never function correctly in Hadoop LocalMode.  I&apos;ve added a printout to the Driver to note this in my next patch.&lt;/p&gt;</comment>
                            <comment id="13679049" author="hudson" created="Sun, 9 Jun 2013 14:15:30 +0100"  >&lt;p&gt;Integrated in Mahout-Quality #2063 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2063/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2063/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1103&quot; title=&quot;clusterpp is not writing directories for all clusters&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1103&quot;&gt;&lt;del&gt;MAHOUT-1103&lt;/del&gt;&lt;/a&gt;: properly partition the data for MapReduce (Revision 1491191)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
gsingers : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/topdown/postprocessor/ClusterCountReader.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/topdown/postprocessor/ClusterOutputPostProcessor.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/topdown/postprocessor/ClusterOutputPostProcessorDriver.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/topdown/postprocessor/ClusterOutputPostProcessorMapper.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/topdown/postprocessor/ClusterOutputPostProcessorReducer.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/core/src/main/java/org/apache/mahout/vectorizer/DictionaryVectorizer.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/core/src/main/java/org/apache/mahout/vectorizer/SparseVectorsFromSequenceFiles.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/core/src/main/java/org/apache/mahout/vectorizer/term/TFPartialVectorReducer.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/core/src/main/java/org/apache/mahout/vectorizer/tfidf/TFIDFPartialVectorReducer.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/examples/bin/cluster-reuters.sh&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13679274" author="hudson" created="Mon, 10 Jun 2013 04:13:11 +0100"  >&lt;p&gt;Integrated in Mahout-Quality #2071 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2071/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2071/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-1103&quot; title=&quot;clusterpp is not writing directories for all clusters&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-1103&quot;&gt;&lt;del&gt;MAHOUT-1103&lt;/del&gt;&lt;/a&gt;: properly partition the data for MapReduce - code cleanup based on review, instantiate Maps with Maps.newHashMap() (Revision 1491329)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
smarthi : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/topdown/postprocessor/ClusterOutputPostProcessor.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12586863" name="MAHOUT-1103.patch" size="25925" author="gsingers" created="Sat, 8 Jun 2013 12:13:56 +0100"/>
                            <attachment id="12586536" name="MAHOUT-1103.patch" size="10345" author="mmolek" created="Thu, 6 Jun 2013 18:24:37 +0100"/>
                            <attachment id="12550649" name="MAHOUT-1103.patch" size="5080" author="paritoshranjan" created="Wed, 24 Oct 2012 17:54:56 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 22 Oct 2012 14:56:47 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>250327</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy4ron:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>61641</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>