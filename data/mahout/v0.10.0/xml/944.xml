<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 04:18:07 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/MAHOUT-944/MAHOUT-944.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[MAHOUT-944] LuceneIndexToSequenceFiles (lucene2seq) utility</title>
                <link>https://issues.apache.org/jira/browse/MAHOUT-944</link>
                <project id="12310751" key="MAHOUT">Mahout</project>
                    <description>&lt;p&gt;Here is a lucene2seq tool I used in a project. It creates sequence files based on the stored fields of a lucene index.&lt;/p&gt;

&lt;p&gt;The output from this tool can be then fed into seq2sparse and from there you can do text clustering.&lt;/p&gt;

&lt;p&gt;Comes with Java bean configuration.&lt;/p&gt;

&lt;p&gt;Let me know what you think. Some CLI code can be added later on. I used this for a small-scale project +- 100.000 docs. Is a MR version useful or is that overkill?&lt;/p&gt;

&lt;p&gt;See &lt;a href=&quot;https://github.com/frankscholten/mahout/tree/lucene2seq&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/frankscholten/mahout/tree/lucene2seq&lt;/a&gt; for commits and review comments from Simon Willnauer (Thanks Simon!)&lt;/p&gt;

&lt;p&gt;or the attached patch.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12538032">MAHOUT-944</key>
            <summary>LuceneIndexToSequenceFiles (lucene2seq) utility</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gsingers">Grant Ingersoll</assignee>
                                    <reporter username="frankscholten">Frank Scholten</reporter>
                        <labels>
                    </labels>
                <created>Wed, 11 Jan 2012 09:33:52 +0000</created>
                <updated>Mon, 3 Feb 2014 08:06:01 +0000</updated>
                            <resolved>Thu, 6 Jun 2013 16:51:37 +0100</resolved>
                                    <version>0.5</version>
                                    <fixVersion>0.8</fixVersion>
                                    <component>Integration</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13201395" author="frankscholten" created="Mon, 6 Feb 2012 16:58:53 +0000"  >&lt;p&gt;Started working on CLI code. Still have to support lucene queries as a parameter. I think it would be cool to add field separators in between the contents of the field and the extra fields. That way this tool also be used as an entry point into seq2encoded.&lt;/p&gt;

&lt;p&gt;See &lt;a href=&quot;https://github.com/frankscholten/mahout/commit/25584aac9dc0727ebc86ae245768f592161d4813&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/frankscholten/mahout/commit/25584aac9dc0727ebc86ae245768f592161d4813&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13204382" author="frankscholten" created="Thu, 9 Feb 2012 09:16:47 +0000"  >&lt;p&gt;Ah, seq2encoded currently supports text only. I was under the impression that seq2encoded could be configured to encode several data types simultaneously, such as body and lines from the 20 News example. No need for field separators then for lucene2seq&lt;/p&gt;</comment>
                            <comment id="13205562" author="frankscholten" created="Fri, 10 Feb 2012 17:28:21 +0000"  >&lt;p&gt;CLI now supports all options.&lt;/p&gt;</comment>
                            <comment id="13205568" author="frankscholten" created="Fri, 10 Feb 2012 17:33:50 +0000"  >&lt;p&gt;Added git patch. Previous patch created by IntelliJ contained headers and weird formatting.&lt;/p&gt;</comment>
                            <comment id="13206079" author="frankscholten" created="Sat, 11 Feb 2012 11:41:23 +0000"  >&lt;p&gt;New patch. This time generated with &apos;git diff --no-prefix&apos;&lt;/p&gt;

&lt;p&gt;Run &apos;git config --global diff.noprefix true&apos;&lt;br/&gt;
to have git always use the --no-prefix option.&lt;/p&gt;</comment>
                            <comment id="13206348" author="lancenorskog" created="Sun, 12 Feb 2012 04:36:05 +0000"  >&lt;p&gt;A map-reduce version:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Lets you handle much bigger indexes. There are a lot of huge ones. I can see clustering Wikipedia articles with this.&lt;/li&gt;
	&lt;li&gt;It is possible to sort by score. This makes it easy to grab a thousand interesting documents and ignore the rest. Our doc-prep facilities could make good use of this.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13206385" author="frankscholten" created="Sun, 12 Feb 2012 09:50:20 +0000"  >&lt;p&gt;1. Ok. This involves using the FileSystemDirectory from Hadoop contrib, writing a custom InputFormat and RecordReader which splits the document result across the mappers. Correct?&lt;/p&gt;

&lt;p&gt;2. I guess the sort by score would mostly be useful for the sequential version?&lt;/p&gt;</comment>
                            <comment id="13206670" author="lancenorskog" created="Mon, 13 Feb 2012 04:29:33 +0000"  >&lt;p&gt;This is a Lucene query. It&apos;s already sorted! So, the sequential algorithm should already do this. It would be helpful if the sequential version could split the output across multiple files. This allows the subsequent m/r jobs to run more efficiently.&lt;/p&gt;

&lt;p&gt;Text search applications (Solr, Elasticsearch, Indextank, Katta) support splitting large indexes into &quot;shards&quot; across multiple computers. If this is a map/reduce job, it can handle index shards from multiple computers, and set target disk file sizes. &lt;/p&gt;

&lt;p&gt;I guess those are the classes you need.&lt;/p&gt;

</comment>
                            <comment id="13206983" author="frankscholten" created="Mon, 13 Feb 2012 17:04:11 +0000"  >&lt;p&gt;Added initial MR version which works on my local machine based on a logical split of the document result set. Each Mapper fetches its own documents from the index. Will test tomorrow on a cluster.&lt;/p&gt;

&lt;p&gt;See &lt;a href=&quot;https://github.com/frankscholten/mahout/commit/e26a8c6c0869b451a80f9aced30895a64981d80c&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/frankscholten/mahout/commit/e26a8c6c0869b451a80f9aced30895a64981d80c&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If I understand correctly I can improve data locality by making it so each Mapper is assigned his own shard, a physical split. For this I have to create an InputSplit and RecordReader implementation that knows about the different shards.&lt;/p&gt;

</comment>
                            <comment id="13208376" author="gsingers" created="Wed, 15 Feb 2012 11:18:33 +0000"  >&lt;p&gt;Looks reasonable at first blush, with a few comments:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Why the need to get the scorer, etc.?  I wonder if it would be more efficient to just have a simple Collector that did the work and we skipped scoring, etc.&lt;/li&gt;
	&lt;li&gt;What&apos;s the benefit of the Field/Extra Fields thing?  Would it make sense to just have List&amp;lt;String&amp;gt; fields?  If there is more than one, let&apos;s concat, otherwise...&lt;/li&gt;
	&lt;li&gt;LuceneIndexToSequenceFilesConfiguration -&amp;gt; LISFConfig?  Let&apos;s shorten that sucker up as the verbosity doesn&apos;t really get us anything&lt;/li&gt;
	&lt;li&gt;In the Driver, please switch the input args processing to the AbstractJob model.  See KMeansDriver as an example&lt;/li&gt;
	&lt;li&gt;Even if we don&apos;t have a M/R job, it would be nice if we could take in, via the driver, multiple indexes.  You could imagine piling all of your shards together and then converting them all.&lt;/li&gt;
	&lt;li&gt;Have you tested this with numeric (trie) fields?&lt;/li&gt;
	&lt;li&gt;The integration pom.xml inherits from the parent, which has Lucene defined in it, so no need to mod the integration one, I think.  We should upgrade the parent one to 3.5.0.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;A better name for all of this is probably LuceneStorageTo... as it implies that the fields must have storage.  I could see us having another implementation that works on the posting list itself&lt;/p&gt;</comment>
                            <comment id="13208380" author="gsingers" created="Wed, 15 Feb 2012 11:25:41 +0000"  >&lt;p&gt;I&apos;ll take care of the pom -&amp;gt; 3.5 issue.&lt;/p&gt;</comment>
                            <comment id="13209102" author="lancenorskog" created="Thu, 16 Feb 2012 03:40:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;Why the need to get the scorer, etc.? I wonder if it would be more efficient to just have a simple Collector that did the work and we skipped scoring, etc.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This allows subsampling by the document relevance. Mahout is woefully deficient in sampling tools. This mode should be an option. &lt;/p&gt;</comment>
                            <comment id="13209184" author="jake.mannix" created="Thu, 16 Feb 2012 07:20:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;A better name for all of this is probably LuceneStorageTo... as it implies that the fields must have storage. I could see us having another implementation that works on the posting list itself&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Let&apos;s keep the name the same, and at some point I&apos;ll get around to scratching that particular itch - I&apos;ve long wanted a nice map-reduce job which &quot;uninverted&quot; the index into bag-of-words vectors.  Everyone writes &quot;let&apos;s build an inverted index with map-reduce&quot;.  Nobody writes the uninversion step!&lt;/p&gt;</comment>
                            <comment id="13209337" author="gsingers" created="Thu, 16 Feb 2012 13:13:42 +0000"  >&lt;p&gt;I&apos;ve got that need soon, too, Jake.  So, it will likely hit at some point.&lt;/p&gt;</comment>
                            <comment id="13210384" author="frankscholten" created="Fri, 17 Feb 2012 17:07:49 +0000"  >&lt;p&gt;Good feedback guys.&lt;/p&gt;

&lt;p&gt;My current priority is an MapReduce implementation that works on a single FileSystemDirectory (from Hadoop contrib/index).&lt;/p&gt;

&lt;p&gt;Just added new code for this: &lt;a href=&quot;https://github.com/frankscholten/mahout/commit/595484c0661ad7e373bbf24519f8061b9051d58b&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/frankscholten/mahout/commit/595484c0661ad7e373bbf24519f8061b9051d58b&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My previous commit had a bug, all Mappers worked on the entire input cause I still used an IndexReader instead of SegmentReader. Added unit tests for this and this works. However once I made the fix I had trouble starting a Hadoop / Mahout cluster with Whirr so didn&apos;t run it on an actual cluster. Will try again soon and report back.&lt;/p&gt;

&lt;p&gt;When this all works I will fix the field / extraFields things, changing the options parsing other things you mentioned.&lt;/p&gt;

&lt;p&gt;Then I can look at multiple indexes or shards.&lt;/p&gt;</comment>
                            <comment id="13211744" author="frankscholten" created="Mon, 20 Feb 2012 09:50:25 +0000"  >&lt;p&gt;Whirr Hadoop cluster works again, see &lt;a href=&quot;https://issues.apache.org/jira/browse/WHIRR-518&quot; title=&quot;Change to OpenJDK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;WHIRR-518&quot;&gt;&lt;del&gt;WHIRR-518&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Now the index is split at the segment level. Each mapper processes one segment. The downside is that input splits have different sizes and the number of map tasks&lt;br/&gt;
equals the number of segments.&lt;/p&gt;

&lt;p&gt;I think is a problem but maybe not in a situation with many shards? If it is a problem do you have any suggestions? Perhaps a split should be part of a segment. How should I implement this, by combining this with my earlier implementation?&lt;/p&gt;</comment>
                            <comment id="13211843" author="frankscholten" created="Mon, 20 Feb 2012 13:50:53 +0000"  >&lt;p&gt;Made some more changes: &lt;a href=&quot;https://github.com/frankscholten/mahout/commit/855bc3d47a938bfe3c4cd0ca573b8f50189314fd&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/frankscholten/mahout/commit/855bc3d47a938bfe3c4cd0ca573b8f50189314fd&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Why the need to get the scorer, etc.? I wonder if it would be more efficient to just have a simple Collector that did the work and we skipped scoring, etc.&lt;/li&gt;
	&lt;li&gt;&lt;del&gt;What&apos;s the benefit of the Field/Extra Fields thing? Would it make sense to just have List&amp;lt;String&amp;gt; fields? If there is more than one, let&apos;s concat, otherwise...&lt;/del&gt;&lt;/li&gt;
	&lt;li&gt;LuceneIndexToSequenceFilesConfiguration -&amp;gt; LISFConfig? Let&apos;s shorten that sucker up as the verbosity doesn&apos;t really get us anything&lt;/li&gt;
	&lt;li&gt;&lt;del&gt;In the Driver, please switch the input args processing to the AbstractJob model. See KMeansDriver as an example&lt;/del&gt;&lt;/li&gt;
	&lt;li&gt;Even if we don&apos;t have a M/R job, it would be nice if we could take in, via the driver, multiple indexes. You could imagine piling all of your shards together and then converting them all.&lt;/li&gt;
	&lt;li&gt;Have you tested this with numeric (trie) fields?&lt;/li&gt;
	&lt;li&gt;&lt;del&gt;The integration pom.xml inherits from the parent, which has Lucene defined in it, so no need to mod the integration one, I think. We should upgrade the parent one to 3.5.0.&lt;/del&gt;&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13212660" author="frankscholten" created="Tue, 21 Feb 2012 15:30:20 +0000"  >&lt;p&gt;Added test for numeric fields and multiple indices &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/frankscholten/mahout/commit/f0eb3a08ab763131c55bbfa8faf73e772bfac4bd&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/frankscholten/mahout/commit/f0eb3a08ab763131c55bbfa8faf73e772bfac4bd&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://github.com/frankscholten/mahout/commit/6825c57e1b000b74da69f4e345ef8f2bcdcb5918&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/frankscholten/mahout/commit/6825c57e1b000b74da69f4e345ef8f2bcdcb5918&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Should I refactor the configuration bean to LuceneStorageConfiguration?&lt;/p&gt;</comment>
                            <comment id="13212988" author="lancenorskog" created="Tue, 21 Feb 2012 21:42:20 +0000"  >&lt;p&gt;Can the configuration object also store information about saving to Lucene indexes? It would be nice to have that info in one place. &lt;/p&gt;</comment>
                            <comment id="13213483" author="frankscholten" created="Wed, 22 Feb 2012 09:28:11 +0000"  >&lt;p&gt;Saving to Lucene indexes is a different use case. I suggest to make a separate ticket for that when this one is done. Later on we can probably refactor the configuration so it can be used both ways.&lt;/p&gt;</comment>
                            <comment id="13215734" author="frankscholten" created="Fri, 24 Feb 2012 16:55:09 +0000"  >&lt;p&gt;Renamed config to LuceneStorageConfig and simplified serialization. Added AbstractLuceneStorageTest with helper methods for indexing documents.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/frankscholten/mahout/commit/41ee459d075c3aa2e10eab4eb5580cbf505fcbf6&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/frankscholten/mahout/commit/41ee459d075c3aa2e10eab4eb5580cbf505fcbf6&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Does anyone know of a large index I can use for testing? Wikipedia is not that big, the sequential lucene2seq version takes only 3,5 minutes on my machine to convert it into a sequence file.&lt;/p&gt;</comment>
                            <comment id="13217150" author="gsingers" created="Mon, 27 Feb 2012 11:21:39 +0000"  >&lt;p&gt;Frank, can you put up a patch, please?  That way we know it&apos;s donated, etc.&lt;/p&gt;</comment>
                            <comment id="13218025" author="frankscholten" created="Tue, 28 Feb 2012 09:38:47 +0000"  >&lt;p&gt;Added latest patch in sync with trunk&lt;/p&gt;</comment>
                            <comment id="13220070" author="frankscholten" created="Thu, 1 Mar 2012 14:44:52 +0000"  >&lt;p&gt;Added bugfix for when using a full directory name as index path. &lt;/p&gt;</comment>
                            <comment id="13220077" author="frankscholten" created="Thu, 1 Mar 2012 14:57:59 +0000"  >&lt;p&gt;Added version to lucene-queries dependency.&lt;/p&gt;</comment>
                            <comment id="13221492" author="lancenorskog" created="Sat, 3 Mar 2012 03:25:58 +0000"  >&lt;p&gt;Would the bugfix also apply over HDFS or S3?&lt;/p&gt;</comment>
                            <comment id="13222231" author="frankscholten" created="Mon, 5 Mar 2012 09:03:51 +0000"  >&lt;p&gt;This bugfix is for the sequential version.&lt;/p&gt;</comment>
                            <comment id="13222234" author="frankscholten" created="Mon, 5 Mar 2012 09:12:39 +0000"  >&lt;p&gt;Patch including recent bugfixes&lt;/p&gt;</comment>
                            <comment id="13231038" author="frankscholten" created="Fri, 16 Mar 2012 10:36:49 +0000"  >&lt;p&gt;Grant: do you some have time to review this patch?&lt;/p&gt;</comment>
                            <comment id="13270367" author="gsingers" created="Tue, 8 May 2012 12:19:58 +0100"  >&lt;p&gt;I&apos;ll try to get to this patch this week.&lt;/p&gt;</comment>
                            <comment id="13672480" author="gsingers" created="Sun, 2 Jun 2013 13:10:36 +0100"  >&lt;p&gt;Frank, any reason this patch touches files like MeanShiftCanopy, etc.?&lt;/p&gt;</comment>
                            <comment id="13672483" author="gsingers" created="Sun, 2 Jun 2013 13:16:24 +0100"  >&lt;p&gt;Looks like they are all formatting issues.  Fixing.&lt;/p&gt;</comment>
                            <comment id="13672485" author="gsingers" created="Sun, 2 Jun 2013 13:25:22 +0100"  >&lt;p&gt;Removes all the re-formatting issues.  More coming shortly&lt;/p&gt;</comment>
                            <comment id="13672486" author="gsingers" created="Sun, 2 Jun 2013 13:33:48 +0100"  >&lt;p&gt;This needs to be brought up to Lucene 4.  (We should also update to Lucene 4.3)&lt;/p&gt;</comment>
                            <comment id="13672526" author="gsingers" created="Sun, 2 Jun 2013 15:13:17 +0100"  >&lt;p&gt;Progress on bringing up to Lucene 4.3.  Still needs work since dealing with Segments has changed.&lt;/p&gt;</comment>
                            <comment id="13672561" author="gsingers" created="Sun, 2 Jun 2013 16:09:36 +0100"  >&lt;p&gt;Almost compiles the main code, waiting for an answer on &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-4055&quot; title=&quot;Refactor SegmentInfo / FieldInfo to make them extensible&quot; class=&quot;issue-link&quot; data-issue-key=&quot;LUCENE-4055&quot;&gt;&lt;del&gt;LUCENE-4055&lt;/del&gt;&lt;/a&gt; about how to handle the name filtering stuff.&lt;/p&gt;

&lt;p&gt;Haven&apos;t looked at tests yet.&lt;/p&gt;

&lt;p&gt;Also, haven&apos;t looked at whether this is the right thing to do semantically in the M/R code just yet.  Segment per mapper is interesting, but wondering about the implications of that.&lt;/p&gt;</comment>
                            <comment id="13672567" author="gsingers" created="Sun, 2 Jun 2013 16:16:26 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mikemccand&quot; class=&quot;user-hover&quot; rel=&quot;mikemccand&quot;&gt;Michael McCandless&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rcmuir&quot; class=&quot;user-hover&quot; rel=&quot;rcmuir&quot;&gt;Robert Muir&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thetaphi&quot; class=&quot;user-hover&quot; rel=&quot;thetaphi&quot;&gt;Uwe Schindler&lt;/a&gt; &amp;#8211; Would love it if one of you core Lucene guys could give this a review as I&apos;m upgrading Frank&apos;s 3.x Lucene code to 4.x and am unsure on whether this is the best approach for dealing w/ a Lucene index as an input to Hadoop for then converting to Mahout vectors.  The current approach uses a Segment per mapper.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mumrah&quot; class=&quot;user-hover&quot; rel=&quot;mumrah&quot;&gt;David Arthur&lt;/a&gt; You should also take a look at this based on creating an index directly from the term dictionary, etc.&lt;/p&gt;</comment>
                            <comment id="13672574" author="gsingers" created="Sun, 2 Jun 2013 16:22:10 +0100"  >&lt;p&gt;fixed a few more compile issues&lt;/p&gt;</comment>
                            <comment id="13676406" author="gsingers" created="Wed, 5 Jun 2013 22:58:23 +0100"  >&lt;p&gt;Reworked some of the collector stuff for the sequential case.  Tests pass, but haven&apos;t reviewed the thoroughness of the tests yet.  Still needs another run through and review of the M/R code, as I haven&apos;t looked at that in depth yet.&lt;/p&gt;

&lt;p&gt;All that being said, this is getting really close.&lt;/p&gt;</comment>
                            <comment id="13677057" author="gsingers" created="Thu, 6 Jun 2013 15:23:05 +0100"  >&lt;p&gt;I think this is ready to go.  Some other eyeballs would be appreciated.&lt;/p&gt;

&lt;p&gt;Changes from last patch:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;changelog addition&lt;/li&gt;
	&lt;li&gt;Cleaned up and standardized a lot of the tests&lt;/li&gt;
	&lt;li&gt;Added tests for multiple commit points and multiple directories&lt;/li&gt;
	&lt;li&gt;Cleaned up and simplified a number of areas&lt;/li&gt;
	&lt;li&gt;Added license headers where missing&lt;/li&gt;
	&lt;li&gt;The sequential and M/R version are now consistent in their handling of empty id fields and values&lt;/li&gt;
	&lt;li&gt;Added some counters to the M/R job&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13677159" author="gsingers" created="Thu, 6 Jun 2013 16:51:37 +0100"  >&lt;p&gt;Went ahead and committed, as I believe it is functional.  Extra eyeballs to review would be good.&lt;/p&gt;</comment>
                            <comment id="13677203" author="hudson" created="Thu, 6 Jun 2013 17:29:38 +0100"  >&lt;p&gt;Integrated in Mahout-Quality #2043 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2043/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2043/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-944&quot; title=&quot;LuceneIndexToSequenceFiles (lucene2seq) utility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-944&quot;&gt;&lt;del&gt;MAHOUT-944&lt;/del&gt;&lt;/a&gt;: progress up to main compiling except for the file name filter.  haven&apos;t run tests (Revision 1490329)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
gsingers : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/integration/pom.xml&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/LuceneIndexFileNameFilter.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/LuceneSegmentInputFormat.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/LuceneSegmentInputSplit.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/LuceneSegmentRecordReader.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/LuceneStorageConfiguration.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/ReadOnlyFileSystemDirectory.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromLuceneStorage.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromLuceneStorageDriver.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromLuceneStorageMRJob.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromLuceneStorageMapper.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/AbstractLuceneStorageTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/LuceneSegmentInputFormatTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/LuceneSegmentInputSplitTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/LuceneSegmentRecordReaderTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/LuceneStorageConfigurationTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/SequenceFilesFromLuceneStorageDriverTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/SequenceFilesFromLuceneStorageMRJobTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/SequenceFilesFromLuceneStorageTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/pom.xml&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/src/conf/driver.classes.default.props&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13677208" author="smarthi" created="Thu, 6 Jun 2013 17:32:27 +0100"  >&lt;p&gt;Grant, the code that&apos;s been committed has references to Lucene_35 version. Please change to Lucene_42, the trunk&apos;s presently at Lucene 4.2.1.&lt;/p&gt;

&lt;p&gt;Skimming through the files that have been checked in for this JIRA:&lt;/p&gt;

&lt;p&gt;a) Use of old Lucene 3.x APIs that have are no more supoorted in Lucene 4.x.&lt;br/&gt;
b) Unused imports&lt;br/&gt;
c) missing License headers - LuceneSegmentRecordReaderTest.java, SequenceFilesFromLuceneStorageMapper.java&lt;br/&gt;
d) also seeing import* in LuceneSegmentRecordReaderTest.java&lt;/p&gt;</comment>
                            <comment id="13677223" author="gsingers" created="Thu, 6 Jun 2013 17:53:50 +0100"  >&lt;p&gt;uh oh.  Should have been 4.3.  Must have messed up Git.  WTF.  The whole thing is messed up.&lt;/p&gt;</comment>
                            <comment id="13677226" author="smarthi" created="Thu, 6 Jun 2013 17:58:18 +0100"  >&lt;p&gt;You did update pom.xml to Lucene 4.3, but there are references to Version.LUCENE_42 in other files, all of which now show up as deprecated. &lt;/p&gt;

&lt;p&gt;Future enhancement would be to make the Lucene version configurable and avoid this frequenct Version updates in code.&lt;/p&gt;</comment>
                            <comment id="13677237" author="gsingers" created="Thu, 6 Jun 2013 18:01:54 +0100"  >&lt;p&gt;Hmm, I wonder if I should have squashed my local commits:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Committed r1490329&lt;br/&gt;
W: 0a28b0f322ffe888553b9e2adf0b6f098b679f16 and refs/remotes/origin/trunk differ, using rebase:&lt;br/&gt;
:040000 040000 779e2a48da78d2f59f994c83eb1cb91a42b04d41 6e8221954eecd7ee27788976dc7b2665985cd7e6 M	integration&lt;br/&gt;
:100644 100644 492aa3aacbee4e33fb70a2e361d772a9d881ae04 09c5ae712a035af3eef2c3c56db708b8fa75e1b3 M	pom.xml&lt;br/&gt;
:040000 040000 39350289431946a74a7bd15fbf72947261055536 c7274b40f5de032b1668ed9d6f2d1fa24ff0a124 M	src&lt;br/&gt;
Current branch &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-944&quot; title=&quot;LuceneIndexToSequenceFiles (lucene2seq) utility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-944&quot;&gt;&lt;del&gt;MAHOUT-944&lt;/del&gt;&lt;/a&gt; is up to date.&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;of revisions changed&lt;br/&gt;
before:&lt;br/&gt;
 d668ddf606dbb0d046f0fe8e3eb97e06fcd4c406&lt;br/&gt;
9eafd07120a1810d778dfeb4502ba36b5b3eacfe&lt;br/&gt;
253a58c30d0a22150234975f782720248b51a8cb &lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;after:&lt;br/&gt;
 0a28b0f322ffe888553b9e2adf0b6f098b679f16&lt;br/&gt;
d668ddf606dbb0d046f0fe8e3eb97e06fcd4c406&lt;br/&gt;
9eafd07120a1810d778dfeb4502ba36b5b3eacfe&lt;br/&gt;
253a58c30d0a22150234975f782720248b51a8cb &lt;br/&gt;
 If you are attempting to commit  merges, try running:&lt;br/&gt;
	 git rebase --interactive --preserve-merges  refs/remotes/origin/trunk &lt;br/&gt;
Before dcommitting&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="13677240" author="gsingers" created="Thu, 6 Jun 2013 18:04:38 +0100"  >&lt;p&gt;Here&apos;s the diff to trunk at the moment compared with what I have committed on my local branch.  Either dcommit hasn&apos;t finished applying all the commits or it broke.&lt;/p&gt;</comment>
                            <comment id="13677242" author="gsingers" created="Thu, 6 Jun 2013 18:05:29 +0100"  >&lt;p&gt;That patch should apply from trunk, but I&apos;m curious now to know what happened, so I want to give it a bit.&lt;/p&gt;</comment>
                            <comment id="13677630" author="smarthi" created="Thu, 6 Jun 2013 23:55:54 +0100"  >&lt;p&gt;Grant, the latest commit to trunk is much better, but we are still missing LuceneSeqFileHelper.java&lt;/p&gt;

&lt;p&gt;Also, now that we have upgraded to Lucene 4.3 there are bunch of places still referring to Version.LUCENE_42 that now show up as deprecated, those would need to be modified too. I can open a separate JIRA for that and commit a fix after we get past the issue this one.&lt;/p&gt;</comment>
                            <comment id="13677707" author="hudson" created="Fri, 7 Jun 2013 01:47:36 +0100"  >&lt;p&gt;Integrated in Mahout-Quality #2044 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2044/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2044/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-944&quot; title=&quot;LuceneIndexToSequenceFiles (lucene2seq) utility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-944&quot;&gt;&lt;del&gt;MAHOUT-944&lt;/del&gt;&lt;/a&gt;: fix the things that should have been committed the first time (Revision 1490457)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-944&quot; title=&quot;LuceneIndexToSequenceFiles (lucene2seq) utility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-944&quot;&gt;&lt;del&gt;MAHOUT-944&lt;/del&gt;&lt;/a&gt;: progress up to main compiling except for the file name filter.  haven&apos;t run tests - removed duplicate Lucene 4.3 detection, wondering if its even required here given that trunk/pom.xml already has it. (Revision 1490453)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
gsingers : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/CHANGELOG&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/LuceneIndexFileNameFilter.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/LuceneSegmentInputFormat.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/LuceneSegmentRecordReader.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/LuceneStorageConfiguration.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/ReadOnlyFileSystemDirectory.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromLuceneStorage.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromLuceneStorageDriver.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromLuceneStorageMRJob.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/SequenceFilesFromLuceneStorageMapper.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/AbstractLuceneStorageTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/LuceneSegmentInputFormatTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/LuceneSegmentInputSplitTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/LuceneSegmentRecordReaderTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/SequenceFilesFromLuceneStorageDriverTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/SequenceFilesFromLuceneStorageMRJobTest.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/SequenceFilesFromLuceneStorageTest.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;smarthi : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/integration/pom.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13677788" author="gsingers" created="Fri, 7 Jun 2013 04:43:45 +0100"  >&lt;p&gt;Added LuceneSeqFileHelper.  Need to switch back to a pure SVN workflow, I guess, as I seem to be getting the git one wrong.&lt;/p&gt;

&lt;p&gt;As for the Version thing, I will try to get to it today.&lt;/p&gt;</comment>
                            <comment id="13677794" author="smarthi" created="Fri, 7 Jun 2013 04:59:02 +0100"  >&lt;p&gt;I&apos;ll take care of the Version thing, have a JIRA M-1244 open for that.&lt;/p&gt;</comment>
                            <comment id="13678246" author="smarthi" created="Fri, 7 Jun 2013 19:15:38 +0100"  >&lt;p&gt;Grant, we seem to be missing a LuceneIndexToSequenceFilesDriver.java&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

./bin/mahout lucene2seq

WARNING: Unable to add class: org.apache.mahout.text.LuceneIndexToSequenceFilesDriver
java.lang.ClassNotFoundException: org.apache.mahout.text.LuceneIndexToSequenceFilesDriver
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:423)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:356)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName0(Native Method)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.java:188)
	at org.apache.mahout.driver.MahoutDriver.addClass(MahoutDriver.java:237)
	at org.apache.mahout.driver.MahoutDriver.main(MahoutDriver.java:119)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;or should this actually be a call to org.apache.mahout.text.SequenceFilesFromLuceneStorageDriver&lt;/p&gt;</comment>
                            <comment id="13678293" author="gsingers" created="Fri, 7 Jun 2013 19:42:38 +0100"  >&lt;p&gt;Saw that.  Fixing.  Not a show stopper, but needs to be fixed.&lt;/p&gt;</comment>
                            <comment id="13678379" author="hudson" created="Fri, 7 Jun 2013 21:10:39 +0100"  >&lt;p&gt;Integrated in Mahout-Quality #2054 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2054/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2054/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-944&quot; title=&quot;LuceneIndexToSequenceFiles (lucene2seq) utility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-944&quot;&gt;&lt;del&gt;MAHOUT-944&lt;/del&gt;&lt;/a&gt;: fix test (Revision 1490794)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-958&quot; title=&quot;NullPointerException in RepresentativePointsMapper when running cluster-reuters.sh example with kmeans&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-958&quot;&gt;&lt;del&gt;MAHOUT-958&lt;/del&gt;&lt;/a&gt;: fix use with globs, &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-944&quot; title=&quot;LuceneIndexToSequenceFiles (lucene2seq) utility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-944&quot;&gt;&lt;del&gt;MAHOUT-944&lt;/del&gt;&lt;/a&gt;: minor tweak to driver.classes (Revision 1490793)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
gsingers : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/text/LuceneSegmentRecordReader.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/SequenceFilesFromLuceneStorageDriverTest.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;gsingers : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/CHANGELOG&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/integration/src/main/java/org/apache/mahout/clustering/evaluation/RepresentativePointsDriver.java&lt;/li&gt;
	&lt;li&gt;/mahout/trunk/src/conf/driver.classes.default.props&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13681694" author="smarthi" created="Wed, 12 Jun 2013 23:17:14 +0100"  >&lt;p&gt;See this error when running SequenceFilesFromLuceneStorageMRJobTest (from Mahout-Quality build-2076):&lt;/p&gt;

&lt;p&gt;see &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2076&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2076&lt;/a&gt; &lt;/p&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

java.lang.ClassCastException: org.apache.mahout.text.LuceneSegmentInputSplit cannot be &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt; to org.apache.hadoop.mapred.InputSplit
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:412)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:214)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Seems like the issue is that the old MR InputSplit is being referenced somewhere in the code, have not looked deeply into it yet.&lt;/p&gt;</comment>
                            <comment id="13681725" author="hudson" created="Wed, 12 Jun 2013 23:58:57 +0100"  >&lt;p&gt;Integrated in Mahout-Quality #2077 (See &lt;a href=&quot;https://builds.apache.org/job/Mahout-Quality/2077/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Mahout-Quality/2077/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/MAHOUT-944&quot; title=&quot;LuceneIndexToSequenceFiles (lucene2seq) utility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAHOUT-944&quot;&gt;&lt;del&gt;MAHOUT-944&lt;/del&gt;&lt;/a&gt;: lucene2seq - code cleanup (Revision 1492450)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
smarthi : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/mahout/trunk/integration/src/test/java/org/apache/mahout/text/SequenceFilesFromLuceneStorageMRJobTest.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13681744" author="gsingers" created="Thu, 13 Jun 2013 00:22:37 +0100"  >&lt;p&gt;Suneel, weird.  I didn&apos;t see that before.  We are using the new APIs, AFAICT, so not sure what is going on.  So tired of the stupidity of the dual Map/Reduce APIs in Hadoop.&lt;/p&gt;</comment>
                            <comment id="13682325" author="gsingers" created="Thu, 13 Jun 2013 16:11:16 +0100"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=smarthi&quot; class=&quot;user-hover&quot; rel=&quot;smarthi&quot;&gt;Suneel Marthi&lt;/a&gt;, the error only seems to happen when running all the tests and it seems to be intermittent.  It almost looks like some type of classpath issue.&lt;/p&gt;</comment>
                            <comment id="13682327" author="smarthi" created="Thu, 13 Jun 2013 16:13:53 +0100"  >&lt;p&gt;Yes it is very intermittent, the very next build was successful. Still wondering as to how the type cast to old M/R API could happen?&lt;/p&gt;</comment>
                            <comment id="13691667" author="smarthi" created="Mon, 24 Jun 2013 03:15:39 +0100"  >&lt;p&gt;This error was seen consistently today in successive Jenkins builds.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
INFO:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@dac21
Jun 23, 2013 11:10:04 PM org.apache.hadoop.mapred.LocalJobRunner$Job run
WARNING: job_local_0001
java.lang.ClassCastException: org.apache.mahout.text.LuceneSegmentInputSplit cannot be &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt; to org.apache.hadoop.mapred.InputSplit
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:412)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:214)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Not sure as to where this is coming from, the code is all new M/R APIs AFAIK. How/Who invokes OldMapper in a MapReduce job? &lt;/p&gt;</comment>
                            <comment id="13802980" author="n0rritt" created="Wed, 23 Oct 2013 17:03:07 +0100"  >&lt;p&gt;Is it intended that wildcard queries are not supported?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
13/10/23 15:05:46 INFO mapred.JobClient: Task Id : attempt_201310210841_18260_m_000004_2, Status : FAILED
java.lang.UnsupportedOperationException: Query lang:de* does not implement createWeight
	at org.apache.lucene.search.Query.createWeight(Query.java:80)
	at org.apache.mahout.text.LuceneSegmentRecordReader.initialize(LuceneSegmentRecordReader.java:60)
	at org.apache.mahout.text.LuceneSegmentInputFormat.createRecordReader(LuceneSegmentInputFormat.java:76)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:644)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:268)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408)
	at org.apache.hadoop.mapred.Child.main(Child.java:262)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12586531" name="MAHOUT-944-minor.patch" size="70982" author="gsingers" created="Thu, 6 Jun 2013 18:04:38 +0100"/>
                            <attachment id="12586507" name="MAHOUT-944.patch" size="93332" author="gsingers" created="Thu, 6 Jun 2013 15:23:05 +0100"/>
                            <attachment id="12586401" name="MAHOUT-944.patch" size="87649" author="gsingers" created="Wed, 5 Jun 2013 22:58:23 +0100"/>
                            <attachment id="12585764" name="MAHOUT-944.patch" size="82828" author="gsingers" created="Sun, 2 Jun 2013 16:22:10 +0100"/>
                            <attachment id="12585762" name="MAHOUT-944.patch" size="82764" author="gsingers" created="Sun, 2 Jun 2013 16:09:36 +0100"/>
                            <attachment id="12585760" name="MAHOUT-944.patch" size="83659" author="gsingers" created="Sun, 2 Jun 2013 15:13:17 +0100"/>
                            <attachment id="12585756" name="MAHOUT-944.patch" size="86983" author="gsingers" created="Sun, 2 Jun 2013 13:25:22 +0100"/>
                            <attachment id="12517056" name="MAHOUT-944.patch" size="385656" author="frankscholten" created="Mon, 5 Mar 2012 09:12:39 +0000"/>
                            <attachment id="12516299" name="MAHOUT-944.patch" size="88130" author="frankscholten" created="Tue, 28 Feb 2012 09:38:47 +0000"/>
                            <attachment id="12514209" name="MAHOUT-944.patch" size="39887" author="frankscholten" created="Sat, 11 Feb 2012 11:41:23 +0000"/>
                            <attachment id="12514124" name="MAHOUT-944.patch" size="39933" author="frankscholten" created="Fri, 10 Feb 2012 17:33:50 +0000"/>
                            <attachment id="12514122" name="MAHOUT-944.patch" size="53844" author="frankscholten" created="Fri, 10 Feb 2012 17:28:21 +0000"/>
                            <attachment id="12510170" name="MAHOUT-944.patch" size="20845" author="frankscholten" created="Wed, 11 Jan 2012 09:35:03 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>13.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 12 Feb 2012 04:36:05 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>223538</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hxy20f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>22477</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>