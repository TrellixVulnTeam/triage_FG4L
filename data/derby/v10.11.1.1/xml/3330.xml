<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:18:09 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-3330/DERBY-3330.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-3330] provide support for unique constraint over keys that include one or more nullable columns.</title>
                <link>https://issues.apache.org/jira/browse/DERBY-3330</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;Allow unique constraint over keys which include one or more nullable fields.  Prior to this change Derby only supported unique constraints on keys that included no nullable columns.  The new constraint will allow unlimited inserts of any key with one more null columns, but will limit insert of keys with no null columns to 1 unique value per table.&lt;/p&gt;

&lt;p&gt;There is no change to existing or newly created unique indexes on null columns (as opposed to unique constraints on null columns).  Also there is no change to existing or newly created constraints on keys with no nullable columns.&lt;/p&gt;</description>
                <environment>all</environment>
        <key id="12386534">DERBY-3330</key>
            <summary>provide support for unique constraint over keys that include one or more nullable columns.</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="anurag">Anurag Shekhar</assignee>
                                    <reporter username="anurag">Anurag Shekhar</reporter>
                        <labels>
                    </labels>
                <created>Thu, 17 Jan 2008 19:41:16 +0000</created>
                <updated>Mon, 25 Nov 2013 20:30:48 +0000</updated>
                            <resolved>Fri, 10 Oct 2008 18:31:14 +0100</resolved>
                                    <version>10.4.1.3</version>
                                    <fixVersion>10.4.1.3</fixVersion>
                                    <component>SQL</component>
                    <component>Store</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>2</watches>
                                                                                                            <comments>
                            <comment id="12560055" author="anurag" created="Thu, 17 Jan 2008 19:47:57 +0000"  >&lt;p&gt;This issue started as a part of Derby-2212 but latter it was discussed that its safer to provide this functionality just by having unique constraint over null able columns and behavior of index is left unchanged.&lt;/p&gt;

&lt;p&gt;Please read comments in Derby-2212 for the background information about this issue.&lt;/p&gt;</comment>
                            <comment id="12560070" author="anurag" created="Thu, 17 Jan 2008 20:22:03 +0000"  >&lt;p&gt;I am following Mike&apos;s approach ie internally unique constraint will &lt;br/&gt;
be backed by no unique index but during insert, checking the &lt;br/&gt;
immediate left and right slot to find duplicate (if there is no null &lt;br/&gt;
in the new key). If a duplicate key is found it the insert will be rejected. &lt;/p&gt;

&lt;p&gt;I will be introducing a new attribute in BTree to tell the insert routine &lt;br/&gt;
that its not a non unique index but almost unique index. New &lt;br/&gt;
attribute in BTree will be a persistant attribute so the file system will &lt;br/&gt;
not be compatible with the older versions and will require a hard upgrade &lt;br/&gt;
routine to migrate the old indexes to new version.&lt;/p&gt;

&lt;p&gt;While creating the constraint on a table with existing records &lt;br/&gt;
merge short is perform to sort the keys before creating index. A &lt;br/&gt;
new merge short class will be required to sort this almost unique &lt;br/&gt;
index (allowing duplicates only if there is null in it).&lt;/p&gt;</comment>
                            <comment id="12560322" author="anurag" created="Fri, 18 Jan 2008 10:03:34 +0000"  >&lt;p&gt;I am running the tests and will be updating the patch based on the test results.&lt;/p&gt;

&lt;p&gt;Description of patch&lt;br/&gt;
modified files &lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/sql/compile/CreateIndexNode.java&lt;br/&gt;
java/engine/org/apache/derby/impl/sql/compile/TableElementList.java&lt;br/&gt;
java/engine/org/apache/derby/impl/sql/execute/GenericConstantActionFactory.java&lt;br/&gt;
Added new methods to support almost unique index for unique constraint&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/sql/execute/CreateIndexConstantAction.java&lt;br/&gt;
Added new CreateIndexConstantAction method to support a new parameter (almost unique) for indexes. This property is stored and used while executing this action.&lt;br/&gt;
execute method of this class uses this property to use AlmostUniqueIndexSortObserver and AlmostUniqueMergeSort. This two classes provide special sorting routine which considers two row as duplicate only if all the key parts are non null.&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/store/access/sort/MergeSort.java&lt;br/&gt;
changed the scope of few attributes to protected so that AlmostUniqueMergeSort can  access them.&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/store/access/sort/ExternalSortFactory.java&lt;br/&gt;
removed final to allow AlmostUniqueExternalSortFactory to extend from it.&lt;br/&gt;
moved creation of MergeSort to a protected method so that extending class &lt;br/&gt;
can return a different class.&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/store/access/btree/BTree.java&lt;br/&gt;
added a new property almostUnique and getter and setters for the same.&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/store/access/btree/BTreeController.java&lt;br/&gt;
added a new private method to compare the record with immediate left and right records to check for duplicate.&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/store/access/btree/index/B2I.java&lt;br/&gt;
added code to store and retrieve new attribute &quot;almostUnique&quot; to the file system.&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/iapi/store/access/AccessFactoryGlobals.java&lt;br/&gt;
added property string for AlmostUniqueExternalSortFactory.&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/modules.properties&lt;br/&gt;
Added entry for AlmostUniqueExternalSortFactory.&lt;/p&gt;



&lt;p&gt;New files&lt;br/&gt;
java/engine/org/apache/derby/impl/sql/execute/AlmostUniqueIndexSortObserver.java&lt;br/&gt;
This class implements duplicate checking routine to reject non null duplicate keys.&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/store/access/sort/AlmostUniqueExternalSortFactory.java&lt;br/&gt;
This class extends from ExternalSortFactory and overrides getMergeSort methods to return AlmostUniqueMergeSort.&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/store/access/sort/AlmostUniqueMergeSort.java&lt;br/&gt;
This class extends MergeSort and overrides compare methods to ignore last keypart (location) while checking for duplicate keys.&lt;/p&gt;
</comment>
                            <comment id="12561275" author="anurag" created="Tue, 22 Jan 2008 09:26:35 +0000"  >&lt;p&gt;I have done some cleanup in this patch. This patch also includes fixes based on the failures in regression tests. I still have failures in regression tests. I will posting another patch after fixing them.&lt;/p&gt;

&lt;p&gt;This patch has following changes since the last time.&lt;/p&gt;

&lt;p&gt;1. Modified IndexRowGenerator to keep the information if this represents an almost unique index. This information is used by IndexChanger to deffer the inserts for update in case of almost unique index (in addition to unique index).&lt;/p&gt;

&lt;p&gt;2. Modified BTreeControler.compareLeftAndRightSiblings to use newly introduced methods to get the record at left and right. These two methods check for deleted record and continue to move to previous (in case of right next) record till it finds a valid record.&lt;/p&gt;

&lt;p&gt;I have also identified the code changed required for soft upgrade (marked with comments)&lt;/p&gt;</comment>
                            <comment id="12561757" author="anurag" created="Wed, 23 Jan 2008 18:26:11 +0000"  >&lt;p&gt;This patches fixes all the failures in test suite cased by this &lt;br/&gt;
work except for upgrades tests. I am still having failures and &lt;br/&gt;
errors in upgrade tests because this patch introduces extra &lt;br/&gt;
attribute in BTree and IndexRowGenerator.&lt;/p&gt;

&lt;p&gt;II am also seeing one failure in &lt;br/&gt;
org.apache.derbyTesting.functionTests.tests.lang.PrimaryKeyTest.testKeyConstraintsImpliesNotNull but I am getting this error in fresh checkout too.&lt;/p&gt;

&lt;p&gt;I have made changes nist.dml019.out in group by tests.&lt;br/&gt;
Currently Unique constraint is backed by unique index &lt;br/&gt;
and group by clause on unique index internally uses distinct &lt;br/&gt;
scan resulting in sorted results. After changing backing &lt;br/&gt;
index from unique index to almost unique index distinct &lt;br/&gt;
index wasn&apos;t used and results appear in random order (similar&lt;br/&gt;
 to group by clause on non unique indexes). I have modified the&lt;br/&gt;
 out file to match the output of select with group by clause.&lt;/p&gt;

&lt;p&gt;This results in deviation from current behavior but group by &lt;br/&gt;
without order by clause need not be sorted so portable &lt;br/&gt;
application will not be using this behavior or derby. Derby &lt;br/&gt;
manuals also don&apos;t promise this behavior.&lt;/p&gt;

&lt;p&gt;This change in behavior doesn&apos;t mean that nist test is failing &lt;br/&gt;
as the test iis supposed to be checking only for the number &lt;br/&gt;
of rows and not their order.&lt;/p&gt;</comment>
                            <comment id="12561976" author="anurag" created="Thu, 24 Jan 2008 08:51:04 +0000"  >&lt;p&gt;derby-3330-testcase.diff has a test case to test unique constraint on nullable column. &lt;/p&gt;

&lt;p&gt;change between derby-3330v3.diff derby-3330v4.diff &lt;br/&gt;
Fixed one bug related to deleted keys exposed by the above test case.&lt;/p&gt;</comment>
                            <comment id="12562025" author="anurag" created="Thu, 24 Jan 2008 12:01:38 +0000"  >&lt;p&gt;Revised functional spec from derby-2212&lt;/p&gt;</comment>
                            <comment id="12562638" author="mikem" created="Fri, 25 Jan 2008 19:55:19 +0000"  >&lt;p&gt;here are some initial comments on the derby-3330v4.diff patch&lt;/p&gt;

&lt;p&gt;overall:&lt;br/&gt;
o almost unique, doesn&apos;t seem like a good name for this.  And I didn&apos;t see&lt;br/&gt;
  good documentation in the code explaining what this means.  Unfortunately&lt;br/&gt;
  could not think of something less wordy than AllowMulipleNullsInUnique.&lt;/p&gt;

&lt;p&gt;o not sure what you are using for tab/spaces, see derby web site for following&lt;br/&gt;
  existing conventions in the code.  may seem minor but inconsistent tab/indent&lt;br/&gt;
  makes stuff unreadable.  Derby code that has tab indentation expects 4 spaces&lt;br/&gt;
  for those tabs.&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/sql/compile/CreateIndexNode.java&lt;br/&gt;
o no comments explaining new parameter and what false means.  &lt;br/&gt;
  CreateindexConstantAction also has no comments about the parameter either.&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/sql/execute/CreateIndexConstantAction.java&lt;br/&gt;
o inconsistent formatting with rest of file for new CreateIndexConstantAction&lt;br/&gt;
  routine, so does not indent same as rest.&lt;/p&gt;

&lt;p&gt;o Why did you add whole new routine rather than add single parameter to &lt;br/&gt;
  existing routine and update other references.  I think it is really error&lt;br/&gt;
  prone to have 2 routines with same name and just differ by 12 or 13 &lt;br/&gt;
  params.  &lt;/p&gt;

&lt;p&gt;o no comments about almostUnique, some doc in the CreateIndexConstantAction &lt;br/&gt;
  call and some comment following the existing code when property is set up&lt;br/&gt;
  would be appropriate.&lt;/p&gt;

&lt;p&gt;o This line looks unused:&lt;br/&gt;
  Properties sortProperty = null; &lt;br/&gt;
  it looks later like you use &quot;properties&quot; but other code seems to think that&lt;br/&gt;
  this may be null sometimes.&lt;/p&gt;

&lt;p&gt;o the tabbing/indentation inconsistency makes the sort part almost unreadable.&lt;br/&gt;
  no comments for added sort logic.&lt;/p&gt;


&lt;p&gt;java/engine/org/apache/derby/impl/sql/compile/TableElementList.java&lt;br/&gt;
o bad indentation&lt;br/&gt;
o looks like you removed check for null but left comments that we would check&lt;br/&gt;
  for null.  &lt;br/&gt;
o again no added comments for all changes to this file.&lt;/p&gt;

&lt;p&gt;o need some explanation of what the added code is doing here.  What is the&lt;br/&gt;
  purpose of the else part of if (constraintDN.constraintType ==&lt;br/&gt;
          DataDictionary.UNIQUE_CONSTRAINT)?&lt;/p&gt;


&lt;p&gt;java/engine/org/apache/derby/impl/sql/execute/IndexChanger.java&lt;br/&gt;
o no comments in changed code&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/sql/execute/GenericConstantActionFactory.java&lt;br/&gt;
o bad indentation&lt;br/&gt;
o no comments&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/sql/catalog/DataDictionaryImpl.java&lt;br/&gt;
o bad indentation&lt;br/&gt;
o todo left in code, looks like needs to be resolved before checkin&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/store/access/sort/ExternalSortFactory.java&lt;br/&gt;
o bad indentation&lt;br/&gt;
o need some documentation on what changes to mergesort are doing.  &lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/store/access/btree/BTree.java&lt;br/&gt;
o bad indentation&lt;br/&gt;
o no comments for any change to file&lt;/p&gt;

&lt;p&gt;java/engine/org/apache/derby/impl/store/access/btree/BTreeController.java&lt;br/&gt;
o a bunch of imports added that look unnecessary, ie. Time, TimeStampe, Calendar, ...&lt;br/&gt;
o brace style inconsistent with rest of routine.&lt;/p&gt;

&lt;p&gt;o getPreviousRecord()&lt;br/&gt;
  o what is the expected behavior on latch waits?&lt;br/&gt;
  o Does not follow latch/latch deadlock avoidance protocol - must not wait on&lt;br/&gt;
    latch while holding latch while traveling left in tree.  &lt;br/&gt;
  o no handling of getting and releasing latches during search.&lt;br/&gt;
  o see B2IRowLocking3.java!searchLeftAndLockPreviousKey for example of code&lt;br/&gt;
    that searches left in btree.  &lt;br/&gt;
  o What kind of locking will the various isolation levels need for your checking&lt;br/&gt;
    of left and right keys?  Is holding the latch while checking good enough?  I&lt;br/&gt;
    don&apos;t know right now.&lt;br/&gt;
  o note the trickiest part of this is if you have to give up the latch while&lt;br/&gt;
    waiting then you have to restart entire search of the tree to find where to&lt;br/&gt;
    do the insert because you don&apos;t have latch.&lt;br/&gt;
  o remember that you may have to search left many pages to find a data row.&lt;/p&gt;

&lt;p&gt;  o i don&apos;t think you should be searching for &quot;undeleted&quot;, deleted records &lt;br/&gt;
    still count toward the integrity of the tree.  Without getting locks it&lt;br/&gt;
    is impossible to know if the records marked deleted are committed deleted&lt;br/&gt;
    or not.  Imagine if you skip a marked deleted record that would have caused&lt;br/&gt;
    a constraint violation, and then that xact backs out it would then mark&lt;br/&gt;
    the row as valid and now you would have 2 records that fail the constraint.&lt;/p&gt;


&lt;p&gt;getNextRecord()&lt;br/&gt;
  o what is expected behavior of latch waits?&lt;br/&gt;
  o what is expected behavior if routine has to visit N right leaves (ie. will&lt;br/&gt;
    routine hold all latches until end of transaction)?  &lt;br/&gt;
  o as in getPreviousRecord() i think it should not special case deleted rows&lt;br/&gt;
  o remember you may have to search right many pages to find row in edge case.&lt;/p&gt;

&lt;p&gt;compareLeftAndRightSiblings()&lt;br/&gt;
  o likely code to deal with lost latches would go into this routine and callers.&lt;br/&gt;
  o no need to call runtime_mem.get_template(getRawTran()) twice.  Once you &lt;br/&gt;
    call it you have a template.  Just reuse the template.&lt;/p&gt;

&lt;p&gt;  o there should be some comments somewhere explaining why just checking left&lt;br/&gt;
    and right siblings works for what you are trying to achieve.&lt;/p&gt;


&lt;p&gt;o i have to think about it some more but the places you added the&lt;br/&gt;
if (compareLeftAndRightSiblings(rowToInsert,&lt;br/&gt;
            insert_slot, targetleaf))&lt;br/&gt;
        return ConglomerateController.ROWISDUPLICATE;&lt;br/&gt;
  don&apos;t seem optimal.  I would like to see the code only called in the &lt;br/&gt;
  almost unique case, so we don&apos;t affect the behavior of existing indexes at&lt;br/&gt;
  all.&lt;/p&gt;



&lt;p&gt;java/engine/org/apache/derby/impl/store/access/btree/index/B2I.java&lt;br/&gt;
o it is critical to properly document changes to ondisk format of store objects,&lt;br/&gt;
  doesn&apos;t look like any work here done.  I know from existing comments that&lt;br/&gt;
  upgrade still does not work so maybe you are planning more here.&lt;/p&gt;

&lt;p&gt;o The model has been to add new stuff at the end rather than in the middle.  &lt;/p&gt;

&lt;p&gt;o so far I haven&apos;t seen what is going to stop this from being created in soft&lt;br/&gt;
  upgrade.&lt;/p&gt;


&lt;p&gt;java/engine/org/apache/derby/modules.properties&lt;br/&gt;
o did you consider just altering the existing sort to take an additional&lt;br/&gt;
  startup parameter rather than extending and creating a new module to sort?&lt;br/&gt;
  just would be interested to know why one approach vs. the other.&lt;/p&gt;


&lt;p&gt;java/engine/org/apache/derby/catalog/types/IndexDescriptorImpl.java&lt;br/&gt;
o bad indent in places&lt;br/&gt;
o as todo&apos;s point out, need soft upgrade support&lt;/p&gt;
</comment>
                            <comment id="12562643" author="mikem" created="Fri, 25 Jan 2008 20:03:33 +0000"  >&lt;p&gt;comments of functional spec/hard upgrade section:&lt;br/&gt;
It says:&lt;br/&gt;
During had upgrade existing backing indexes will be dropped and recreated as almost unique indexes. It will be possible to create unique constraint over nullable column in upgraded data base. After hard upgrade user will able to create unique constraint over nullable columns and will also be able to drop not null constraints even if the column is part of a unique constraint.&lt;/p&gt;

&lt;p&gt;This is not what I expected and I believe is unnecessary and not a good idea.  Because the feature only affects constraints on&lt;br/&gt;
nullable columns which could never exist before the upgrade there should be nothing necessary to drop/recreate.  Once a hard&lt;br/&gt;
upgrade has happenned then the new backing index for unique constraint over null columns will be enabled.   Nothing should &lt;br/&gt;
&quot;automatically&quot; get dropped and recreated as an almost unique index.&lt;/p&gt;

&lt;p&gt;Also there are still a number of gramatical and spelling errors in the functional spec.&lt;/p&gt;</comment>
                            <comment id="12562999" author="anurag" created="Sun, 27 Jan 2008 15:29:24 +0000"  >&lt;p&gt;Fixed typos in functional specs.&lt;/p&gt;</comment>
                            <comment id="12563119" author="anurag" created="Mon, 28 Jan 2008 11:23:56 +0000"  >&lt;p&gt;thanks Mike for looking at the patch and detailed comments&lt;br/&gt;
I am explaining few points in this comment and will get back &lt;br/&gt;
about rest of the comments&lt;/p&gt;

&lt;p&gt;overall:&lt;br/&gt;
o almost unique, doesn&apos;t seem like a good name for this.  And I didn&apos;t see&lt;br/&gt;
  good documentation in the code explaining what this means.  Unfortunately&lt;br/&gt;
  could not think of something less wordy than AllowMulipleNullsInUnique.&lt;/p&gt;

&lt;p&gt;Shall I change it to UniqueWhenNotNull ?&lt;/p&gt;

&lt;p&gt;o not sure what you are using for tab/spaces, see derby web site for following&lt;br/&gt;
  existing conventions in the code.  may seem minor but inconsistent tab/indent&lt;br/&gt;
  makes stuff unreadable.  Derby code that has tab indentation expects 4 spaces&lt;br/&gt;
  for those tabs.&lt;/p&gt;

&lt;p&gt;I will check the indentations and fix them.&lt;/p&gt;



&lt;p&gt;o i have to think about it some more but the places you added the&lt;br/&gt;
if (compareLeftAndRightSiblings(rowToInsert,&lt;br/&gt;
            insert_slot, targetleaf))&lt;br/&gt;
        return ConglomerateController.ROWISDUPLICATE;&lt;br/&gt;
  don&apos;t seem optimal.  I would like to see the code only called in the &lt;br/&gt;
  almost unique case, so we don&apos;t affect the behavior of existing indexes at&lt;br/&gt;
  all.&lt;/p&gt;

&lt;p&gt;I will change it to check for new index before calling compareLeftAndRightSiblings.&lt;/p&gt;



&lt;p&gt;java/engine/org/apache/derby/impl/store/access/btree/index/B2I.java&lt;br/&gt;
o it is critical to properly document changes to ondisk format of store objects,&lt;br/&gt;
  doesn&apos;t look like any work here done.  I know from existing comments that&lt;br/&gt;
  upgrade still does not work so maybe you are planning more here.&lt;/p&gt;

&lt;p&gt;o The model has been to add new stuff at the end rather than in the middle.  &lt;/p&gt;

&lt;p&gt;I will be fixing it in my new patch.&lt;/p&gt;

&lt;p&gt;o so far I haven&apos;t seen what is going to stop this from being created in soft&lt;br/&gt;
  upgrade.&lt;/p&gt;

&lt;p&gt;I am adding a new class B2I_10_3 which will be used in case of soft upgrades.&lt;br/&gt;
 I will add comments about disk format. &lt;/p&gt;


&lt;p&gt;java/engine/org/apache/derby/modules.properties&lt;br/&gt;
o did you consider just altering the existing sort to take an additional&lt;br/&gt;
  startup parameter rather than extending and creating a new module to sort?&lt;br/&gt;
  just would be interested to know why one approach vs. the other.&lt;/p&gt;

&lt;p&gt;The sorting will be required while creating the constraint only. For rest of the &lt;br/&gt;
execution it acts like a non unique index. By adding a new module I felt I won&apos;t &lt;br/&gt;
be touching the execution path of other functionality (like select) and they will &lt;br/&gt;
retain the their performance. &lt;br/&gt;
But I can merge this code with exiting sorting routine if you feel that will be better&lt;br/&gt;
way of handing it. &lt;/p&gt;</comment>
                            <comment id="12563473" author="anurag" created="Tue, 29 Jan 2008 11:19:29 +0000"  >&lt;p&gt;Thanks Mike for pointing out issues related to locking and also about the way &lt;br/&gt;
I have handled deleted row.&lt;/p&gt;

&lt;p&gt;I went through the code you have have asked me to look for reference and also the doIns code. This is what I think I should be doing.&lt;/p&gt;

&lt;p&gt;Step 1. Find the slot where new row can be inserted.&lt;br/&gt;
Step 2. Get the left row (without checking for deleted row) if there is a match try to &lt;br/&gt;
hold a lock. If lock is obtained without releasing the latch no other transaction is &lt;br/&gt;
working on it and it should be a deleted row. return error if its not. &lt;br/&gt;
If latch was released tree has under gone some changes and start with step 1.&lt;/p&gt;

&lt;p&gt;Step3. Repeat step 2 for right row.&lt;/p&gt;

&lt;p&gt;I am checking out B2IRowLocking3.searchLeftAndLockPreviousKey and will be&lt;br/&gt;
 posting about locking scheme and effect of isolation level shortly.&lt;/p&gt;</comment>
                            <comment id="12564253" author="mikem" created="Thu, 31 Jan 2008 01:11:58 +0000"  >&lt;p&gt;At this point you should somehow document the implementation that you are&lt;br/&gt;
planning to support the functional spec.  That way I can comment on whether&lt;br/&gt;
or not I think it should work.  It is hard just going from your patch with&lt;br/&gt;
almost no comments.  I suggested the approach, and am having a hard time&lt;br/&gt;
remembering at this point - imagine what other reviewers are going through.&lt;/p&gt;

&lt;p&gt;With regard to this specific question, it depends on what rows you are&lt;br/&gt;
going to support in the new tree.  To make it easier to talk about let&apos;s&lt;br/&gt;
just consider the simplest case of a single key index.  Then with respect&lt;br/&gt;
to &quot;deleted&quot; rows will you ever support duplicate entries in the tree,&lt;br/&gt;
as below:&lt;/p&gt;

&lt;p&gt;deleted bit key     rowlocation&lt;br/&gt;
----------- &amp;#8212;     -----------&lt;br/&gt;
false       null    1,7&lt;br/&gt;
false       null    1,8&lt;br/&gt;
true        a       1,9&lt;br/&gt;
false       a       1,10&lt;/p&gt;

&lt;p&gt;I think the algorithms and edge cases are probably easier if you keep the&lt;br/&gt;
rule that disregarding the deleted bit, there can never be a duplicate non-null&lt;br/&gt;
key in the tree.  This makes it easier to deal with uncommitted transactions and&lt;br/&gt;
duplicates and deleted rows.  If you pick this rule then you should read and&lt;br/&gt;
understand the code in BTreeController that deals with this case in the&lt;br/&gt;
old indexes.  This code starts with the comment:&lt;br/&gt;
// If the row is there already, simply undelete it.&lt;br/&gt;
// The rationale for this is, since the index does&lt;br/&gt;
// not support duplicates, the only way we could ...&lt;/p&gt;

&lt;p&gt;Remember that getting a lock on a deleted row does not mean it is a committed&lt;br/&gt;
deleted row, it may have been deleted by the current transaction.&lt;/p&gt;

&lt;p&gt;Probably the most straightforward is to follow what we do currently for&lt;br/&gt;
unique indexes, but apply it to this new index which allows duplicate null&apos;s&lt;br/&gt;
but non duplicate non-null.&lt;/p&gt;

&lt;p&gt;I don&apos;t know the exact answer on locking, it is complicated as we have never locked&lt;br/&gt;
rows to the right of a row during an insert before.  This can have some negative concurrency&lt;br/&gt;
aspects.&lt;/p&gt;</comment>
                            <comment id="12564437" author="anurag" created="Thu, 31 Jan 2008 18:05:39 +0000"  >&lt;p&gt;Thanks Mike in taking time to explain the nuances of locking in such a clear and detailed manner. I will shortly post a document explaining the following issues related to my patch&lt;br/&gt;
1.How insert is handled.&lt;br/&gt;
2.How sorting is performed (while creating the unique constraint).&lt;br/&gt;
3.How soft upgrade will work.&lt;/p&gt;

&lt;p&gt;I have written the routine to perform comparison while inserting.  this routine is called only if all the parts of the new key are non null. This routine is called for both keys (left and right of the position identified to insert)&lt;/p&gt;

&lt;p&gt;1.If no match return&lt;br/&gt;
2.if there is match check if its already deleted &lt;br/&gt;
3.if not deleted there return a match (will result in exception)&lt;br/&gt;
4.if deleted try getting a lock on it&lt;br/&gt;
5.if lock is obtained without releasing the latch (means without waiting) the key was deleted withing current transaction.&lt;br/&gt;
6.if lock is obtained and latch is released the lock was held by some other transaction and might have caused change in tree. Insert process will be restarted again to locate the position for new key.&lt;/p&gt;

&lt;p&gt;While fetching the left and right records I am not checking for deleted bit any more but checking for it only after finding a match. The fetched record is locked only if a match is found and its a deleted record and in that case also the lock will be held only if the key was deleted within same transaction. In case its deleted from another transaction page latch will be released and it will ultimately result in rescanning the tree for insert position.&lt;/p&gt;

&lt;p&gt;I am attaching a diff for BtreeController.java (I haven&apos;t yet implemented the left locking protocol) Please let me know If I am doing it right.&lt;/p&gt;
</comment>
                            <comment id="12564740" author="anurag" created="Fri, 1 Feb 2008 12:44:06 +0000"  >&lt;p&gt;Attaching the implementation documents. I will merge it with the functional spec after reviews.&lt;/p&gt;</comment>
                            <comment id="12568844" author="anurag" created="Thu, 14 Feb 2008 09:47:06 +0000"  >&lt;p&gt;This patch includes following changes since v4 &lt;br/&gt;
1. Fixed Indentation issues&lt;br/&gt;
2. Added comments for new methods attributes and some code changes&lt;br/&gt;
3. Added code for soft upgrade&lt;br/&gt;
4.Removed unnecessary imports.&lt;br/&gt;
5. Modified left and right sibling comparison (details to follow).&lt;br/&gt;
6. Moved new attribute to end of the BTree file format.&lt;br/&gt;
7. Added comments about  new file format.&lt;br/&gt;
8. Added new classes to support soft upgrade (as described in implementation spec).&lt;/p&gt;

&lt;p&gt;Pending task&lt;br/&gt;
Hard upgrade&lt;/p&gt;</comment>
                            <comment id="12568850" author="anurag" created="Thu, 14 Feb 2008 09:58:07 +0000"  >&lt;p&gt;Details about changes in java/engine/org/apache/derby/impl/store/access/btree/BTreeController.java &lt;/p&gt;

&lt;p&gt;The new code doesn&apos;t checks for deleted records. So while looking for left and right sibling there won&apos;t be any need to traverse multiple pages (at the most one pages to left if the new slot is 1st slot of the page or one page of the right if the new slot is the last slot of the page will be latched). &lt;br/&gt;
Steps for duplicate detection is as follows&lt;/p&gt;

&lt;p&gt;1. Get the previous record (may or may not be from same page)&lt;br/&gt;
2. if there the two record are different unlatch page and return NO_MATCH&lt;br/&gt;
3. if these to match obtain the lock on exiting record&lt;br/&gt;
4. if lock is obtained after wait (latch lost) tree might have been modified start with locating he slot of new record&lt;br/&gt;
5. If the locked record is deleted return no match else return match&lt;/p&gt;

&lt;p&gt;do the above for record at right again.&lt;/p&gt;</comment>
                            <comment id="12568879" author="anurag" created="Thu, 14 Feb 2008 11:16:07 +0000"  >&lt;p&gt;Impact of isolation level&lt;/p&gt;

&lt;p&gt;The records involved (new record and duplicate ) are always locked for update&lt;br/&gt;
which insures that there is exclusive lock on the record , irrespective of the isolation.&lt;br/&gt;
So nothing special need to be done with respect to isolation level.&lt;/p&gt;</comment>
                            <comment id="12569949" author="mikem" created="Mon, 18 Feb 2008 17:03:38 +0000"  >&lt;p&gt;o although unlikely a legal state for a leaf page is to have a control row, but no other rows.  It can&lt;br/&gt;
get this way if the deleted space background thread is able to reclaim the committed deleted rows, but can&apos;t get table level lock to merge the empty leaf page.  Thus to handle this one must be ready when scanning left and/or right to the next page looking for a row to need to visit multiple&lt;br/&gt;
pages.&lt;/p&gt;

&lt;p&gt;o with respect to isolation level.  What kind of locking will you be doing on the rows that you are&lt;br/&gt;
checking left and right?  If you are locking those rows, how long will you hold those locks?  The&lt;br/&gt;
search to the right is especially interesting as previously we would never have locked any row&lt;br/&gt;
to the right of an insert.  With previous key locking used for isolation level implementation the code&lt;br/&gt;
currently may or may not lock the left key, depending on isolation level.&lt;/p&gt;</comment>
                            <comment id="12569987" author="anurag" created="Mon, 18 Feb 2008 19:15:36 +0000"  >&lt;p&gt;Thanks Mike for pointing out the possibility of having empty page and hence need to scan multiple page. &lt;br/&gt;
I will reintroduce the code for the same. I will add code to keep moving left (or right) till a row is found or no more leaf is available. &lt;/p&gt;

&lt;p&gt;Locking of left or right row is attempted only if there is a duplicate is found. In that case &lt;br/&gt;
a. The transaction was deleted in same transaction &amp;#8211; So its already locked within same transaction&lt;br/&gt;
b. Is deleted in some other transaction - It will result in losing the latch and a rescan will performed to identify the slot (no lock)&lt;/p&gt;

&lt;p&gt;c. Is an valid row - an exception will be thrown and lock will be released immediately.&lt;/p&gt;


&lt;p&gt;Irrespective of the isolation level only update lock is requested. But the actual locking is performed only in case c and that too for a very short time, I think it won&apos;t have much impact on performance. &lt;/p&gt;</comment>
                            <comment id="12571023" author="anurag" created="Thu, 21 Feb 2008 11:51:47 +0000"  >&lt;p&gt;This patch includes hard upgrade (Upgrade test from 10.3.1.4 and  10.1.3.1runs without fails).&lt;/p&gt;

&lt;p&gt;Description of Hard upgrade&lt;/p&gt;

&lt;p&gt;Hard upgrade makes following changes &lt;br/&gt;
1. Updates B2I class by adding extra attribute (uniquewhenNotNull)&lt;br/&gt;
2. Updates format id.&lt;br/&gt;
3. Updates ConglomerateDescriptor of all updated Conglomerates to &lt;br/&gt;
user new version of IndexDescriptorImpl&lt;/p&gt;

&lt;p&gt;Unique index meant to be backing index of UniqueConstraint is updated to &lt;br/&gt;
become UniqueWhenNotNull index (nUniqueColumn is set to nKeyFields - 1&lt;br/&gt;
 and uniquewhen not null is set to true). For other indexes uniqueWhenNotNull&lt;br/&gt;
 attribute is set to false.&lt;/p&gt;

&lt;p&gt;Hard upgrade is initiated from DataDictionaryImpl.upgradeConglomerate &lt;br/&gt;
(new method). This method calles another newly intoroduced method &lt;br/&gt;
getAllConglomerates to get the list of conglomerate and updates them &lt;br/&gt;
by calling TransaCtioncontroller.updateUniquenessOfConglomerate &lt;br/&gt;
which internally calls Conglomerate.updateUniqueness to &lt;br/&gt;
conglomerate attributes.&lt;/p&gt;


&lt;p&gt;I will be posting one more patch after introducing multipage page &lt;br/&gt;
scan while checking for duplicates.&lt;/p&gt;</comment>
                            <comment id="12571300" author="anurag" created="Fri, 22 Feb 2008 08:06:29 +0000"  >&lt;p&gt;This page include the code to scan multiple slot/page if the slot identified immediate left and right returns null. It continues to scan (lef in case privious and right in case of next record) unless a valid record is found in a slot or no more pages are left to check.&lt;/p&gt;

&lt;p&gt;Every time the scan moves to a new page the latch on the privious page is released (unless the previous page has the slot  identified to insert the new record). &lt;/p&gt;

&lt;p&gt;All junit test suites are running without any failure.&lt;/p&gt;</comment>
                            <comment id="12571466" author="anurag" created="Fri, 22 Feb 2008 17:07:37 +0000"  >&lt;p&gt;In this patch (derby-3330v8.diff) I have modified upgrade routine to &lt;br/&gt;
upgrade only the backing indexes of unique constraint. Other &lt;br/&gt;
indexes are left unchanged.&lt;/p&gt;

&lt;p&gt;DataDictionaryImpl.getAllConglomerates (introduced in derby-3330v6.dif) is &lt;br/&gt;
no more required so I have taken it off.&lt;/p&gt;

&lt;p&gt;Tests are running without any error or failures. &lt;/p&gt;</comment>
                            <comment id="12571506" author="mikem" created="Fri, 22 Feb 2008 18:16:08 +0000"  >&lt;p&gt;please update your implementation spec to include your plan for hard upgrade.  Once this is done it should be easier to &lt;br/&gt;
both review the plan and whether the code does what you have said is the plan.&lt;/p&gt;</comment>
                            <comment id="12571510" author="mikem" created="Fri, 22 Feb 2008 18:23:03 +0000"  >&lt;p&gt;comment on implementation details:&lt;br/&gt;
While creating the unique constraint null checking is now conditional (only for the older version of Data Dictionary). In case of older version Data Dictionary the backing index created is an unique index. &lt;/p&gt;

&lt;p&gt;In order to not cause performance degredation for existing unique constraints I would have expected the constraint creation code to use the old unique index for non-null columns and use the new index for null columns.   The unique&lt;br/&gt;
index is going to perform somewhat better as it will have less checking to do (for instance on insert it will not have to&lt;br/&gt;
check if nulls are in the key and do extra searching).  Also it will make it likely that only new applications that use the new&lt;br/&gt;
feature will see any new problems introduced by the new index.  Existing applications will continue to use the old&lt;br/&gt;
code.&lt;/p&gt;</comment>
                            <comment id="12571524" author="anurag" created="Fri, 22 Feb 2008 18:55:32 +0000"  >&lt;p&gt;Updated version Implementation Details.&lt;/p&gt;

&lt;p&gt;Added Hard Upgrade Section&lt;br/&gt;
Updated to indicate that comparing with left and right record while inserting might result in traversing multiple pages.&lt;/p&gt;</comment>
                            <comment id="12571729" author="anurag" created="Sat, 23 Feb 2008 12:52:31 +0000"  >&lt;p&gt;I have removed hard upgrade code from derby-3330v9.diff. Now the hard upgrade. For now it won;t be possible to make columns null able if they were set as not null while creating the constraint. I will be submitting another patch to allow that.&lt;br/&gt;
This patch (derby-3330v9.diff) contains code do create unique constraint over null able columns, soft upgrade, and test case for unique constraint. &lt;/p&gt;

&lt;p&gt;Description of the patch can be found in the UniqueConstraint_Implementation_V2.html. &lt;/p&gt;

&lt;p&gt;Tests are running without any failures or error.&lt;/p&gt;

</comment>
                            <comment id="12571734" author="anurag" created="Sat, 23 Feb 2008 13:09:13 +0000"  >&lt;p&gt;updated hard upgrade section.&lt;/p&gt;</comment>
                            <comment id="12573028" author="mikem" created="Wed, 27 Feb 2008 19:09:44 +0000"  >&lt;p&gt;do you know why the master for dml019 changed?  &lt;br/&gt;
Index: java/testing/org/apache/derbyTesting/functionTests/master/dml019.out&lt;br/&gt;
===================================================================&lt;br/&gt;
&amp;#8212; java/testing/org/apache/derbyTesting/functionTests/master/dml019.out&lt;br/&gt;
(revision 630309)&lt;br/&gt;
+++ java/testing/org/apache/derbyTesting/functionTests/master/dml019.out&lt;br/&gt;
(working copy)&lt;br/&gt;
@@ -82,18 +82,18 @@&lt;br/&gt;
           GROUP BY PNUM,EMPNUM,HOURS;&lt;br/&gt;
 EM&amp;amp;|PN&amp;amp;|HOURS&lt;br/&gt;
 --------------&lt;br/&gt;
-E1 |P1 |40&lt;br/&gt;
-E1 |P2 |20&lt;br/&gt;
-E1 |P3 |80&lt;br/&gt;
-E1 |P4 |20&lt;br/&gt;
+E2 |P1 |40&lt;br/&gt;
+E4 |P4 |40&lt;br/&gt;
 E1 |P5 |12&lt;br/&gt;
+E4 |P5 |80&lt;br/&gt;
 E1 |P6 |12&lt;br/&gt;
-E2 |P1 |40&lt;br/&gt;
-E2 |P2 |80&lt;br/&gt;
 E3 |P2 |20&lt;br/&gt;
+E1 |P4 |20&lt;br/&gt;
+E1 |P1 |40&lt;br/&gt;
 E4 |P2 |20&lt;br/&gt;
-E4 |P4 |40&lt;br/&gt;
-E4 |P5 |80&lt;br/&gt;
+E1 |P2 |20&lt;br/&gt;
+E2 |P2 |80&lt;br/&gt;
+E1 |P3 |80&lt;br/&gt;
 ij&amp;gt; &amp;#8211; PASS:0077 If 12 rows are selected ?&lt;/p&gt;

&lt;p&gt; &amp;#8211; END TEST &amp;gt;&amp;gt;&amp;gt; 0077 &amp;lt;&amp;lt;&amp;lt; END TEST&lt;br/&gt;
@@ -105,18 +105,18 @@&lt;br/&gt;
           GROUP BY EMPNUM,PNUM,HOURS;&lt;br/&gt;
 PN&amp;amp;|EM&amp;amp;&lt;br/&gt;
 -------&lt;br/&gt;
-P1 |E1&lt;br/&gt;
-P2 |E1&lt;br/&gt;
-P3 |E1&lt;br/&gt;
-P4 |E1&lt;br/&gt;
+P1 |E2&lt;br/&gt;
+P4 |E4&lt;br/&gt;
 P5 |E1&lt;br/&gt;
+P5 |E4&lt;br/&gt;
 P6 |E1&lt;br/&gt;
-P1 |E2&lt;br/&gt;
-P2 |E2&lt;br/&gt;
 P2 |E3&lt;br/&gt;
+P4 |E1&lt;br/&gt;
+P1 |E1&lt;br/&gt;
 P2 |E4&lt;br/&gt;
-P4 |E4&lt;br/&gt;
-P5 |E4&lt;br/&gt;
+P2 |E1&lt;br/&gt;
+P2 |E2&lt;br/&gt;
+P3 |E1&lt;br/&gt;
 ij&amp;gt; &amp;#8211; PASS:0078 If 12 rows are selected  ?&lt;/p&gt;

&lt;p&gt; &amp;#8211; END TEST &amp;gt;&amp;gt;&amp;gt; 0078 &amp;lt;&amp;lt;&amp;lt; END TEST&lt;/p&gt;</comment>
                            <comment id="12573032" author="anurag" created="Wed, 27 Feb 2008 19:15:21 +0000"  >&lt;p&gt;dml019 test group by clause of unique constraint. When unique constraint &lt;br/&gt;
was backed by unique index, distinct scan  was used but after making it non &lt;br/&gt;
unique constraint this was not the case so the results are not ordered. &lt;/p&gt;

&lt;p&gt;I have checked the test suite from nist web site and it mandates only &lt;br/&gt;
number of rows and not their sequence. &lt;/p&gt;</comment>
                            <comment id="12573077" author="mikem" created="Wed, 27 Feb 2008 21:43:12 +0000"  >&lt;p&gt;I am running a set of tests on the v9 patch and will post results when they are done.  I am reviewing the v9 patch currently, but will likely concentrate on the store level changes.  If there is anyone with time to review the language level code that would be good.   Especially would like help verifying that the language catalog upgrade code looks right - I have not done that before.&lt;/p&gt;</comment>
                            <comment id="12573084" author="djd" created="Wed, 27 Feb 2008 22:12:37 +0000"  >&lt;p&gt;I think the upgrade handling of IndexDescriptorImpl is too complex.&lt;/p&gt;

&lt;p&gt;IndexDescriptorImpl uses a FormatableHashtable to store some of its state, the format of this can handle additional or missing keys. Thus the additional boolean required by this change can simply be added to the hash table, so the writeExternal has an additional:&lt;/p&gt;

&lt;p&gt;     fh.putBoolean (&quot;isUniqueWhenNotNull&quot;, isUniqueWhenNotNull);&lt;/p&gt;

&lt;p&gt;and the readExternal can have:&lt;/p&gt;

&lt;p&gt;   if (fh.containsKey(&quot;isUniqueWhenNotNull&quot;)&lt;br/&gt;
       isUniqueWhenNotNull = fh.getBoolean(&quot;isUniqueWhenNotNull&quot;);&lt;br/&gt;
   else&lt;br/&gt;
       isUniqueWhenNotNull = ?? ; // what ever is the correct value for old indexes.&lt;/p&gt;

&lt;p&gt;Of course good to comment the real code with when &amp;amp; why these changes were made.&lt;/p&gt;</comment>
                            <comment id="12573085" author="anurag" created="Wed, 27 Feb 2008 22:13:25 +0000"  >&lt;p&gt;Changes in this  (derby-3330v10.diff) patch since (derby-3330v9.diff)&lt;/p&gt;

&lt;p&gt;Modified java/engine/org/apache/derby/impl/sql/compile/TableElementList.java to introduce a new method to check if any of the column in the constraint definition can have null value. This method is used while creating backing index for unique constraint and if all columns are non null able a backing unique index is created. If any of the column are null able a non unique index with uniqueWhenNotNull set to true.&lt;/p&gt;

&lt;p&gt;nist script dml019.out doesn&apos;t requires any change now.&lt;/p&gt;

&lt;p&gt;I haven&apos;t finished running tests on this patch.&lt;/p&gt;</comment>
                            <comment id="12573108" author="dibyendumajumdar" created="Thu, 28 Feb 2008 00:17:27 +0000"  >&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I could be talking nonsense here so please tell me to shut up if I have got the wrong end of the issue. &lt;/p&gt;

&lt;p&gt;If I understand correctly, one of the requirements is to allow multiple rows to be inserted where the index is unique and all columns are null. This doesn&apos;t work currently because such rows will be considered duplicates.&lt;/p&gt;

&lt;p&gt;Thinking very naively, I would implement this as follows:&lt;/p&gt;

&lt;p&gt;I am assuming that when index rows are stored, Derby always stores an additional column containing the row location, regardless of the type of index.&lt;br/&gt;
Also that the search algorithm is uniform for both unique and non-unique indexes, with the only difference being that the unique index searches do not consider the extra row location column.&lt;br/&gt;
Following is invalid if above assumptions are not true.&lt;/p&gt;

&lt;p&gt;To get the desired behaviour, I would simply change the comparison logic as follows:&lt;/p&gt;

&lt;p&gt;a) If non-unique index, no change.&lt;br/&gt;
b) If unique index, and all indexable columns are null, then compare the extra (last)  (row location) column.&lt;br/&gt;
c) The else case for unique index will remain the same as now.&lt;/p&gt;

&lt;p&gt;If the key comparison routine always used above logic, would it not give desired behaviour without requiring any significant changes to the existing implementation?&lt;/p&gt;

&lt;p&gt;As I said, I may totally off track here, so please feel free to tell me to shut up.&lt;/p&gt;</comment>
                            <comment id="12573113" author="mikem" created="Thu, 28 Feb 2008 00:54:56 +0000"  >&lt;p&gt;From running the v9 patch on ibm15 jvm against a windows XP laptop I got 1 failure in the junit tests and 6 failures in the old style tests - i will attach a copy of the results for the old style test failures.  Are all tests passing in your environment with this patch?   I will try to run another set of tests over night with your latest patch - but do post what environment you are running the tests on and if they all pass or not with the v10 patch.&lt;/p&gt;

&lt;p&gt;junit failure:&lt;br/&gt;
There was 1 failure:&lt;br/&gt;
1) dml019(org.apache.derbyTesting.functionTests.tests.nist.NistScripts)junit.fra&lt;br/&gt;
mework.ComparisonFailure: Output at line 85 expected:&amp;lt;...1 |4...&amp;gt; but was:&amp;lt;...2&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8...&amp;gt;&lt;br/&gt;
    at org.apache.derbyTesting.functionTests.util.CanonTestCase.compareCanon(Can&lt;br/&gt;
onTestCase.java:100)&lt;br/&gt;
    at org.apache.derbyTesting.functionTests.util.ScriptTestCase.runTest(ScriptT&lt;br/&gt;
estCase.java:124)&lt;br/&gt;
    at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:101)&lt;br/&gt;
    at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)&lt;br/&gt;
    at junit.extensions.TestSetup$1.protect(TestSetup.java:19)&lt;br/&gt;
    at junit.extensions.TestSetup.run(TestSetup.java:23)&lt;br/&gt;
    at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)&lt;br/&gt;
    at junit.extensions.TestSetup$1.protect(TestSetup.java:19)&lt;br/&gt;
    at junit.extensions.TestSetup.run(TestSetup.java:23)&lt;br/&gt;
    at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)&lt;br/&gt;
    at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)&lt;br/&gt;
    at junit.extensions.TestSetup$1.protect(TestSetup.java:19)&lt;br/&gt;
    at junit.extensions.TestSetup.run(TestSetup.java:23)&lt;br/&gt;
    at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)&lt;br/&gt;
    at junit.extensions.TestSetup$1.protect(TestSetup.java:19)&lt;br/&gt;
    at junit.extensions.TestSetup.run(TestSetup.java:23)&lt;br/&gt;
    at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)&lt;br/&gt;
    at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)&lt;br/&gt;
    at junit.extensions.TestSetup$1.protect(TestSetup.java:19)&lt;br/&gt;
    at junit.extensions.TestSetup.run(TestSetup.java:23)&lt;br/&gt;
    at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)&lt;br/&gt;
    at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)&lt;br/&gt;
    at junit.extensions.TestSetup$1.protect(TestSetup.java:19)&lt;br/&gt;
    at junit.extensions.TestSetup.run(TestSetup.java:23)&lt;br/&gt;
    at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;The following tests failed, will attach complete diff:&lt;br/&gt;
derbyall/derbyall.fail:lang/altertable.sql&lt;br/&gt;
derbyall/derbyall.fail:lang/db2Compatibility.sql&lt;br/&gt;
derbyall/derbyall.fail:lang/subqueryFlattening.sql&lt;br/&gt;
derbyall/derbyall.fail:tools/dblook_test.java&lt;br/&gt;
derbyall/derbynetclientmats/derbynetmats.fail:derbynet/dblook_test_net.java&lt;br/&gt;
derbyall/storeall/storeall.fail:store/rollForwardRecovery.sql&lt;/p&gt;</comment>
                            <comment id="12573114" author="mikem" created="Thu, 28 Feb 2008 00:56:30 +0000"  >&lt;p&gt;report of diffs on ibm15 jvm running on xp laptop using version 9 patch.&lt;/p&gt;</comment>
                            <comment id="12573151" author="djd" created="Thu, 28 Feb 2008 04:42:02 +0000"  >&lt;p&gt;Dibyendu wrote:&lt;/p&gt;

&lt;p&gt;&amp;gt; one of the requirements is to allow multiple rows to be inserted where the index is unique and all columns are null.&lt;/p&gt;

&lt;p&gt;but not the only requirement &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;In a unique constraint these key columns are allowed:&lt;/p&gt;

&lt;p&gt;   Smith, NULL&lt;br/&gt;
   Smith, NULL&lt;br/&gt;
   Smith, NULL&lt;/p&gt;

&lt;p&gt;A unique index (from existing CREATE INDEX) would only allow one row with Smith,NULL&lt;/p&gt;


</comment>
                            <comment id="12573241" author="anurag" created="Thu, 28 Feb 2008 12:06:21 +0000"  >&lt;p&gt;Description of patch (derby-3330v11.diff) &lt;/p&gt;

&lt;p&gt;Now the backing index for unique constraint, if all &lt;br/&gt;
participating columns are not null able, will be a unique index.&lt;br/&gt;
For now its not possible to set columns as null able after &lt;br/&gt;
creating unique constraint (&lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3456&quot; title=&quot;Allow removing not null from collumns particpating in unique constraint.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3456&quot;&gt;&lt;del&gt;DERBY-3456&lt;/del&gt;&lt;/a&gt; addresses this). &lt;/p&gt;

&lt;p&gt;I have removed IndexDescriptorImpl_10_3 and handling &lt;br/&gt;
additional attribute the way Dan has recommend. &lt;/p&gt;

&lt;p&gt;I am able to run junit tests without any failure.&lt;/p&gt;

&lt;p&gt;derbyall harness tests has two failure&lt;br/&gt;
1. lang/db2Compatibility.sql&lt;br/&gt;
I have attached a separate diff (db2Compatibility.diff) to update the out files.&lt;br/&gt;
I am not sure if we should continue to call this test as db2Compatibility as this &lt;br/&gt;
test is not ensuring compatibility anymore (able to create unique constraint &lt;br/&gt;
over null able fields)&lt;/p&gt;

&lt;p&gt;2.tools/derbyrunjartest.java&lt;br/&gt;
This failure was because of a missing class file in derbytools.jar &lt;br/&gt;
(org.apache.derby.impl.tools.run). I am getting this problem in a &lt;br/&gt;
fresh workspace too. So It might be something to do with my &lt;br/&gt;
build environment and not the patch.&lt;/p&gt;

&lt;p&gt;I have modified following files in harness test&lt;/p&gt;

&lt;p&gt;1. org/apache/derbyTesting/functionTests/tests/lang/subqueryFlattening.sql&lt;br/&gt;
2. org/apache/derbyTesting/functionTests/master/subqueryFlattening.out&lt;/p&gt;

&lt;p&gt;I have removed the additional test for unique constraint over null able field. &lt;br/&gt;
This creation was supposed to fail and the output query tree was based on no&lt;br/&gt;
additional constraint. After allowing unique constraint over null able field &lt;br/&gt;
an additional index was introduced which changed the query tree. After removing&lt;br/&gt;
the statement to create unique constraint over null able field I am getting &lt;br/&gt;
same query tree as expected.&lt;/p&gt;

&lt;p&gt;3. org/apache/derbyTesting/functionTests/master/altertable.out&lt;/p&gt;

&lt;p&gt;Original out file was expecting the creation of unique constraint to &lt;br/&gt;
fail over null able fields. Updated out file to expect it to succeed.&lt;/p&gt;

&lt;p&gt;Other failures in harness test were because of change in backing index (from &lt;br/&gt;
unique to non unique) for unique constraint over not null columns. They disappeared &lt;br/&gt;
after making changes related to backing index.&lt;/p&gt;
</comment>
                            <comment id="12573245" author="anurag" created="Thu, 28 Feb 2008 12:18:22 +0000"  >&lt;p&gt;db2Compatibility.diff&lt;br/&gt;
diff file to update db2Compatibility.out. &lt;/p&gt;
</comment>
                            <comment id="12573324" author="anurag" created="Thu, 28 Feb 2008 15:40:51 +0000"  >&lt;p&gt;derby-3330v12.diff&lt;/p&gt;

&lt;p&gt;fixed indentation issues and added comment in IndexDescriptorImpl.&lt;br/&gt;
As the changes are minor (only indentation and comments) I haven&apos;t run&lt;br/&gt;
all the test just upgrade and lang junit suites.&lt;/p&gt;</comment>
                            <comment id="12573347" author="djd" created="Thu, 28 Feb 2008 16:41:30 +0000"  >&lt;p&gt;Thanks for cleaning up the IndexDescriptor upgrade related code, makes it look much cleaner.&lt;/p&gt;

&lt;p&gt;A minor issue I have that if needed can be handled after any patch is applied is the naming in the code of the new style of unique index.&lt;/p&gt;

&lt;p&gt;The common theme is &quot;uniqueWhenNotNull&quot;, when I first looked at the code I thought this was the other way around since for index definitions I tend to think of the DDL, not the row values. Thus:&lt;/p&gt;

&lt;p&gt;   isUnique() is true for indexes where the columns are defined NOT NULL&lt;/p&gt;

&lt;p&gt;   isUniqueWhenNotNull() is true for indexes where the columns are nullable (but unique when the column values do not contain NULLs).&lt;/p&gt;

&lt;p&gt;See how that can be confusing to code readers who see the code without having been immersed in developing the code.&lt;/p&gt;

&lt;p&gt;Not sure of a better name, re-writing to be a positive statement (always clearer) but still referring to the values would be:&lt;br/&gt;
    isUniqueWithDuplicateNulls()&lt;/p&gt;

&lt;p&gt;or a positive statement referring to the column types:&lt;br/&gt;
   isUniqueWithNullableColumns()&lt;/p&gt;

&lt;p&gt;I think a change in name would be good for the long term readability of the code, again it can be a follow on patch, fairly easy to do with IDE refactoring.&lt;/p&gt;

&lt;p&gt;One more aside, it would be good to expand the definition of isUnique() and the current isUniqueWhenNotNull() in IndexDescriptor to indicate any relationship between them, e.g. is isUnique() true if isUniqueWhenNotNull() is true?&lt;/p&gt;</comment>
                            <comment id="12573365" author="anurag" created="Thu, 28 Feb 2008 17:28:22 +0000"  >&lt;p&gt;UniqueWithDuplicateNulls explains the actual behavior than &lt;br/&gt;
uniqueWhenNotNull. Thanks for  suggesting it.&lt;br/&gt;
I will replace uniqueWhenNotNull by this. &lt;br/&gt;
In my next patch (or the follow up patch is there is no further issue in &lt;br/&gt;
my latest patch) i will replace the index name and will explain the the &lt;br/&gt;
relation between unique and UniqueWithDuplicateNulls.&lt;/p&gt;
</comment>
                            <comment id="12573369" author="anurag" created="Thu, 28 Feb 2008 17:30:28 +0000"  >&lt;p&gt;uniqueWhenNotNull attribute (in B2I and IndexDescritor) is ignored if isUnique is true. uniqueWhenNotNull is effective only if the the index is non unique type. &lt;br/&gt;
I will add this explanation in comments.&lt;/p&gt;</comment>
                            <comment id="12573450" author="anurag" created="Thu, 28 Feb 2008 21:06:53 +0000"  >&lt;p&gt;please ignore  derby-3330v12.diff . It had a conflict with one of the recent patches and test suite didn&apos;t get updated. I will be uploading a new patch.&lt;/p&gt;</comment>
                            <comment id="12573488" author="anurag" created="Thu, 28 Feb 2008 22:14:37 +0000"  >&lt;p&gt;changes in derby-3330v13.diff &lt;/p&gt;

&lt;p&gt;1. replaced uniqueWhenNotNull by uniqueWithDuplicateNulls. &lt;br/&gt;
2. added description about relation ship between unique and uniqueWithDuplicateNulls.&lt;br/&gt;
3. Added entry for NullableUniqueConstraintTest in lang._Suite (this was lost due to one of the conflicts)&lt;/p&gt;

&lt;p&gt;Upgrade test (from 10.3.1.4) runs without failure.&lt;br/&gt;
lang._Suite fails with 6 failures in LangScripts. I am getting these failures in fresh work space. (few hours back there was no failures in lang._Suite)&lt;/p&gt;</comment>
                            <comment id="12573671" author="anurag" created="Fri, 29 Feb 2008 10:47:07 +0000"  >&lt;p&gt;junit.all and derbyall tests are running fine with derby-3330v13.diff.&lt;/p&gt;

&lt;p&gt;derbyall has some failures also visible in tinderbox. &lt;br/&gt;
One additional failure I am getting is  tools/derbyrunjartest.java which fails with &lt;br/&gt;
same error in my fresh work space too.&lt;/p&gt;

&lt;p&gt;db2Compatibility.diff is not valid anymore it has conflicting failures with some changes.  I will &lt;br/&gt;
create a new patch once lang/db2Compatibility.sql is clean in tinderbox.&lt;/p&gt;

&lt;p&gt;As of now there are no pending issues in derby-3330v13.diff&lt;/p&gt;</comment>
                            <comment id="12573917" author="anurag" created="Fri, 29 Feb 2008 19:32:11 +0000"  >&lt;p&gt;description of db2Compatibility-v2.diff&lt;/p&gt;

&lt;p&gt;removed test case for unique constraint over null able columns and updated out files accordingly.&lt;/p&gt;</comment>
                            <comment id="12574816" author="mikem" created="Tue, 4 Mar 2008 01:42:07 +0000"  >&lt;p&gt;I am looking at committing a version of the latest changes, once they pass a set of tests for me and my final review.  If anyone has any reservations about this going in, let me know.  Overall I think the changes now only affect only the new &lt;br/&gt;
functionality so even if I find some non-test related problems I am likely to commit to make it easier to address the remaining issues.&lt;/p&gt;</comment>
                            <comment id="12575074" author="mikem" created="Tue, 4 Mar 2008 17:48:53 +0000"  >&lt;p&gt;revision 633560 checked into trunk:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3330&quot; title=&quot;provide support for unique constraint over keys that include one or more nullable columns.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3330&quot;&gt;&lt;del&gt;DERBY-3330&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
committed on behalf of Anurag Shekhar&lt;/p&gt;

&lt;p&gt;Committed modified versions of patch derby-3330v13.diff and&lt;br/&gt;
db2Compatibility-v2.diff.  The modifications are mostly changed and/or&lt;br/&gt;
added comments along with some code formatting changes to make the&lt;br/&gt;
new code match the surrounding code style.&lt;/p&gt;

&lt;p&gt;This checkin adds the functionality to&lt;br/&gt;
create unique constraints on a key that contains one or more nullable&lt;br/&gt;
columns.  This constraint will all inserts of all keys that contain&lt;br/&gt;
one or more columns with the null value.  All keys that contain no columns&lt;br/&gt;
with null values are constrained to be unique in the table.&lt;/p&gt;

&lt;p&gt;The underlying implementation for this new type of unique constraint uses&lt;br/&gt;
the existing btree non-unique index with a small modification to do&lt;br/&gt;
checking at insert time to provide the described unique behavior for null&lt;br/&gt;
and non-null keys.  The sorter has also been modified to provide this&lt;br/&gt;
support for creating the index.&lt;/p&gt;</comment>
                            <comment id="12575075" author="mikem" created="Tue, 4 Mar 2008 17:50:37 +0000"  >&lt;p&gt;Here are some comments that were still unresolved in the submitted patch, but didn&apos;t seem big enough to hold up the patch and can be addressed with a subsequent patch.&lt;/p&gt;

&lt;p&gt;CreateIndexConstantAction.java -&lt;br/&gt;
    use of properties?  Some of the existing code seems to sometimes expect&lt;br/&gt;
    a properties passed in.  Your new code will overwrite the saved copy of&lt;br/&gt;
    the properties to pass needed info to the new sort routine.  I don&apos;t&lt;br/&gt;
    know when a property may be passed in and lost.  I think you just want&lt;br/&gt;
    to create a new variable for sort_properties.&lt;/p&gt;

&lt;p&gt;sort changes&lt;br/&gt;
    I don&apos;t like that the implementation of unique merge sort knows about&lt;br/&gt;
    row location last column.  The intent of the sorted is to be somewhat&lt;br/&gt;
    general purpose so it would be better to somehow encode that info into&lt;br/&gt;
    the startup parameters.  I think the null special handling is located&lt;br/&gt;
    in the right place, ie. in the new sort impl.&lt;/p&gt;

&lt;p&gt;    A comment explaining the why of these 2 lines would be nice in&lt;br/&gt;
    UniqueWithDuplicateNullMergeSort.java would be nice.&lt;/p&gt;

&lt;p&gt;    if (i == colsToCompare - 1 &amp;amp;&amp;amp; nonull)&lt;br/&gt;
            return 0;&lt;/p&gt;

&lt;p&gt;BTreeController.java&lt;br/&gt;
    Can the second call to the following code be optimized, is it necessary?&lt;br/&gt;
    maybe a comment here would help.&lt;/p&gt;

&lt;p&gt;    if (getConglomerate().isUniqueWithDuplicateNulls()) &lt;/p&gt;
{
        int ret = compareLeftAndRightSiblings(rowToInsert,
                    insert_slot, targetleaf);
        if (ret == MATCH_FOUND)
                    return ConglomerateController.ROWISDUPLICATE;
        if (ret == RESCAN_REQUIRED)
                    continue;
    }

&lt;p&gt;B2I.java&lt;br/&gt;
    I updated the upgrade comments, especially for the change in behavior for&lt;br/&gt;
    the 10.3 formats.  You should review these to make sure they are what&lt;br/&gt;
    you expect.&lt;/p&gt;

&lt;p&gt;IndexDescriptorImpl.java&lt;br/&gt;
    Should change following to match new naming:&lt;br/&gt;
    sb.append (&quot;ALMOST UNIQUE&quot;);&lt;/p&gt;

&lt;p&gt;    The following is a wrong (repeated same test), but I didn&apos;t change -&lt;br/&gt;
    wanted to give you a chance to look at it.  Not sure what it affects, if&lt;br/&gt;
    it is a bug would be nice to have a test case that shows the problem.&lt;/p&gt;

&lt;p&gt;    Wasn&apos;t sure if it wanted another different term, probably wants to be a&lt;br/&gt;
    test for the new attribute.&lt;/p&gt;

&lt;p&gt;    if ((id.isUnique == this.isUnique) &amp;amp;&amp;amp;&lt;br/&gt;
            (id.isUnique == this.isUnique) &amp;amp;&amp;amp;&lt;/p&gt;

&lt;p&gt;BTreeController.java&lt;br/&gt;
    I think there may be some edge case stuff missing from the searches, I&lt;br/&gt;
    will look more later, but it looks like a good basis for the new&lt;br/&gt;
    functionality so rather see it get checked in and more eyes on it.&lt;br/&gt;
    Again now that new searches only happen on new nullable constraints there&lt;br/&gt;
    is less risk to existing functionality.&lt;/p&gt;


&lt;p&gt;I don&apos;t see upgrade tests, are they in a different JIRA/patch?&lt;/p&gt;</comment>
                            <comment id="12575079" author="anurag" created="Tue, 4 Mar 2008 17:56:46 +0000"  >&lt;p&gt;Thanks Mike for guiding me through this issue and for the commit.&lt;br/&gt;
I will submit follow up patch to address your comments.&lt;/p&gt;

&lt;p&gt;Upgrade tests and also the tests related to indexes you had suggested are part of &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3456&quot; title=&quot;Allow removing not null from collumns particpating in unique constraint.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3456&quot;&gt;&lt;del&gt;DERBY-3456&lt;/del&gt;&lt;/a&gt;. &lt;/p&gt;</comment>
                            <comment id="12575261" author="anurag" created="Wed, 5 Mar 2008 07:55:01 +0000"  >&lt;p&gt;description of derby-3330-UpgradeTests.diff &lt;/p&gt;

&lt;p&gt;This patch has following tests&lt;/p&gt;

&lt;p&gt;tests for unique constraint&lt;br/&gt;
1. Create a unique constraint in lower version of derby&lt;br/&gt;
2. Test the above constraint in soft upgrade mode.&lt;br/&gt;
3. create a new unique constraint in soft upgrade mode.: Shouldn&apos;t able to create   &lt;br/&gt;
    unique constraint over nullable columns.&lt;br/&gt;
4. test the above constraint in post soft upgrade mode (running under lower version)&lt;/p&gt;

&lt;p&gt;tests for index&lt;br/&gt;
This test is for indexes in different modes. Different types are indexes are created &lt;br/&gt;
during&lt;br/&gt;
1. Create (running under older version)&lt;br/&gt;
2. Soft Upgrade mode&lt;br/&gt;
3. Post soft upgrade mode &lt;br/&gt;
4. Hard upgrade mode&lt;/p&gt;

&lt;p&gt;In all these phases the indexes created in previous phases are tested.&lt;/p&gt;

&lt;p&gt;The types of indexes created in each phases are &lt;br/&gt;
1. Unique index over not null field&lt;br/&gt;
2. Unique Index over null able field&lt;br/&gt;
3. Non Unique constraint over not null field&lt;br/&gt;
4. Non Unique constraint over null able field.&lt;/p&gt;</comment>
                            <comment id="12575436" author="anurag" created="Wed, 5 Mar 2008 17:58:37 +0000"  >&lt;p&gt;CreateIndexConstantAction.java -&lt;br/&gt;
    use of properties? Some of the existing code seems to sometimes expect&lt;br/&gt;
    a properties passed in. Your new code will overwrite the saved copy of&lt;br/&gt;
    the properties to pass needed info to the new sort routine. I don&apos;t&lt;br/&gt;
    know when a property may be passed in and lost. I think you just want&lt;br/&gt;
    to create a new variable for sort_properties.&lt;/p&gt;

&lt;p&gt;This piece of code is unnecessary. I had added it initially for some debugging&lt;br/&gt;
 purpose and forgot to remove.  Sorry about it. I will take it off.&lt;/p&gt;

&lt;p&gt;sort changes&lt;br/&gt;
    I don&apos;t like that the implementation of unique merge sort knows about&lt;br/&gt;
    row location last column. The intent of the sorted is to be somewhat&lt;br/&gt;
    general purpose so it would be better to somehow encode that info into&lt;br/&gt;
    the startup parameters. I think the null special handling is located&lt;br/&gt;
    in the right place, ie. in the new sort impl.&lt;/p&gt;

&lt;p&gt;    A comment explaining the why of these 2 lines would be nice in&lt;br/&gt;
    UniqueWithDuplicateNullMergeSort.java would be nice.&lt;/p&gt;

&lt;p&gt;    if (i == colsToCompare - 1 &amp;amp;&amp;amp; nonull)&lt;br/&gt;
            return 0;&lt;/p&gt;

&lt;p&gt;I will add comment in my follow up patch and will also check how can I make sort &lt;br/&gt;
independent of information about location.&lt;/p&gt;

&lt;p&gt;BTreeController.java&lt;br/&gt;
    Can the second call to the following code be optimized, is it necessary?&lt;br/&gt;
    maybe a comment here would help.&lt;/p&gt;

&lt;p&gt;    if (getConglomerate().isUniqueWithDuplicateNulls()) &lt;/p&gt;
{
        int ret = compareLeftAndRightSiblings(rowToInsert,
                    insert_slot, targetleaf);
        if (ret == MATCH_FOUND)
                    return ConglomerateController.ROWISDUPLICATE;
        if (ret == RESCAN_REQUIRED)
                    continue;
    }

&lt;p&gt;It shouldn&apos;t return from this code but should set &lt;br/&gt;
return value to ConglomerateController.ROWISDUPLICATE, so that necessary cleanup of latch&lt;br/&gt;
 is performed. &lt;/p&gt;

&lt;p&gt;B2I.java&lt;br/&gt;
    I updated the upgrade comments, especially for the change in behavior for&lt;br/&gt;
    the 10.3 formats. You should review these to make sure they are what&lt;br/&gt;
    you expect.&lt;/p&gt;

&lt;p&gt;It looks good. Its exact description of what will happen during soft &lt;br/&gt;
and hard upgrade. Thanks a lot for adding this.&lt;/p&gt;

&lt;p&gt;IndexDescriptorImpl.java&lt;br/&gt;
    Should change following to match new naming:&lt;br/&gt;
    sb.append (&quot;ALMOST UNIQUE&quot;);&lt;/p&gt;

&lt;p&gt;I will change this.&lt;/p&gt;

&lt;p&gt;    The following is a wrong (repeated same test), but I didn&apos;t change -&lt;br/&gt;
    wanted to give you a chance to look at it. Not sure what it affects, if&lt;br/&gt;
    it is a bug would be nice to have a test case that shows the problem.&lt;/p&gt;

&lt;p&gt;    Wasn&apos;t sure if it wanted another different term, probably wants to be a&lt;br/&gt;
    test for the new attribute.&lt;/p&gt;

&lt;p&gt;    if ((id.isUnique == this.isUnique) &amp;amp;&amp;amp;&lt;br/&gt;
            (id.isUnique == this.isUnique) &amp;amp;&amp;amp;&lt;/p&gt;

&lt;p&gt;This should be checking for uniqueWithDuplicateNull. I will update it.&lt;/p&gt;

&lt;p&gt;BTreeController.java&lt;br/&gt;
    I think there may be some edge case stuff missing from the searches, I&lt;br/&gt;
    will look more later, but it looks like a good basis for the new&lt;br/&gt;
    functionality so rather see it get checked in and more eyes on it.&lt;br/&gt;
    Again now that new searches only happen on new nullable constraints there&lt;br/&gt;
    is less risk to existing functionality.&lt;/p&gt;

&lt;p&gt;I will go though the code and try to identify the problem areas.&lt;/p&gt;


&lt;p&gt;I don&apos;t see upgrade tests, are they in a different JIRA/patch?&lt;/p&gt;

&lt;p&gt;I have attached tests in derby-3330-UpgradeTests.diff&lt;/p&gt;

&lt;p&gt;I am working on the followup patch and will upload it asap.&lt;/p&gt;</comment>
                            <comment id="12575709" author="anurag" created="Thu, 6 Mar 2008 13:51:31 +0000"  >&lt;p&gt;Issues addressed in derby-3330_followup_1.diff&lt;/p&gt;

&lt;p&gt;CreateIndexConstantAction.java &lt;/p&gt;

&lt;p&gt;I have changed the name of the variable and added comment to explain what its meant for.&lt;br/&gt;
I got confused while commenting last time. This property is required if &lt;br/&gt;
TransactionCoordinator has to select the non default Sorter.&lt;/p&gt;

&lt;p&gt;sort changes&lt;/p&gt;

&lt;p&gt;I have updated compare method and it doesn&apos;t need to assume location column. But it still&lt;br/&gt;
has information about nulls not being equal. &lt;br/&gt;
I am checking how to remove this information from comparison. It appears to me that I can remove &lt;br/&gt;
this custom compare method and use the existing but that miy need some change which might effect &lt;br/&gt;
other part of code.I will wait for 10.4 branching and will work for it in the trunk.&lt;/p&gt;



&lt;p&gt;BTreeController.java&lt;/p&gt;

&lt;p&gt;I haven&apos;t optimized it yet. But instead of returning error code setting the ret value so the latch &lt;br/&gt;
is cleared before return.&lt;/p&gt;


&lt;p&gt;IndexDescriptorImpl.java&lt;/p&gt;

&lt;p&gt;Updated both the place (using new name in toString () and using the new attribute in equals methods).&lt;/p&gt;

&lt;p&gt;BTreeController.java&lt;br/&gt;
I am still checking it out and will submit new follow up if I find any problem areas.&lt;/p&gt;

&lt;p&gt;junit suites.All is running without any failure with this patch.&lt;/p&gt;</comment>
                            <comment id="12575824" author="anurag" created="Thu, 6 Mar 2008 18:46:01 +0000"  >&lt;p&gt;Updated implementation doc&lt;br/&gt;
Added a section about shared backing index.&lt;br/&gt;
Added a section about making column nullable&lt;/p&gt;</comment>
                            <comment id="12575835" author="mikem" created="Thu, 6 Mar 2008 19:08:47 +0000"  >&lt;p&gt;I am currently looking at the new patches in this issue and will commit as appropriate after review and running tests.&lt;/p&gt;</comment>
                            <comment id="12575854" author="mikem" created="Thu, 6 Mar 2008 19:50:27 +0000"  >&lt;p&gt;In the derby-3330_followup_1.diff I don&apos;t think the sort changes will work correctly.  In the &lt;br/&gt;
 uniqueWithDuplicateNulls we need the sorter to sort on the rowlocation column also in the &lt;br/&gt;
case where there are 2 rows that otherwise are duplicate by store null comparison standards.&lt;br/&gt;
Imagine the case of a table with a single column nullable index that has a million rows all&lt;br/&gt;
with null.  Order does not really matter for user, but when the base row is deleted the system&lt;br/&gt;
will want to exactly find the matching (null, (page 5, row7)) index entry and if the rows are not&lt;br/&gt;
properly sorted on the row location then the btree search for this row will probably fail.&lt;/p&gt;

&lt;p&gt;So what we want from sorter if N is the number of columns including the row location column:&lt;br/&gt;
1) sort on N columns&lt;br/&gt;
2) if any column has a null don&apos;t do any duplicate checking&lt;br/&gt;
3) if no column has a null then duplicate checking based on leading N-1 columns&lt;/p&gt;

&lt;p&gt;It would nice to have a test that verified the sorting is correct when there are many duplicate nulls.  It is a little &lt;br/&gt;
tricky to get a good test case as the normal case is for rows scanned from a heap to build an index to have &lt;br/&gt;
rowlocations in ascending order - but we should not be counting on that.   I will have to think about this.  I don&apos;t&lt;br/&gt;
know if once you get the sorter to go external with multiple merge runs I think it will shuffle the rows from input&lt;br/&gt;
order based on what sort keys you told it to consider.   We should verify that the existing checked in code handles&lt;br/&gt;
this case correctly.&lt;/p&gt;</comment>
                            <comment id="12575860" author="mikem" created="Thu, 6 Mar 2008 20:11:15 +0000"  >&lt;p&gt;looking at it more carefully, would it be possible to not have any sorter changes and handle the required functionality in the&lt;br/&gt;
new UniqueWithDuplicateNullsIndexSortObserver ?  Basically use the existing sorter to sort on all columns and then in the observer look at each row and if it has a null let it through.  If it doesn&apos;t have a null compare it with the next row and throw an error if it has a duplicate violation?   I know there is some existing code for doing this kind of compare - see &lt;br/&gt;
CardinalityCounter.java.  &lt;/p&gt;
</comment>
                            <comment id="12575862" author="anurag" created="Thu, 6 Mar 2008 20:15:42 +0000"  >&lt;p&gt;Thanks Mike for the review.&lt;/p&gt;

&lt;p&gt;Looks like the earlier (before the follow up changes) sorter routine was doing right thing. &lt;br/&gt;
if had same compare routine from UniqueSort with additional entry for non nulls at the beginning of comparison loop &lt;/p&gt;

&lt;p&gt;            if (i == colsToCompare - 1 &amp;amp;&amp;amp; nonull)&lt;br/&gt;
                return 0;&lt;/p&gt;

&lt;p&gt;So if the comparison has reached till the last entry (location) and there is no null found so far it will consider the rows as duplicate. If one of the part was null (nonull will be false) the it will go ahead and compare the location too. &lt;/p&gt;

&lt;p&gt;I will revert this change from the follow up patch and update sorting with comments in my new follow up patch. &lt;/p&gt;

&lt;p&gt;I will also try to come up with a good tests for scenario you explained. &lt;/p&gt;
</comment>
                            <comment id="12575863" author="anurag" created="Thu, 6 Mar 2008 20:21:51 +0000"  >&lt;p&gt;looking at it more carefully, would it be possible to not have any sorter changes and handle the required functionality in the&lt;br/&gt;
new UniqueWithDuplicateNullsIndexSortObserver ?&lt;/p&gt;

&lt;p&gt;I think it can be done. I started to do this initially but I was getting some assertion failures at a different location (while constructing the BTree). I am sure it would have been a small issue to fix but I felt little nervous about changing something which might effect some other functionality. I plan to work on it but after the 10.4 branch is separated from trunk. &lt;/p&gt;</comment>
                            <comment id="12575872" author="mikem" created="Thu, 6 Mar 2008 20:34:15 +0000"  >&lt;p&gt;Here is the modified followup patch that I am looking at committing if it passes tests - tests running now.  It has all your followup changes except the sorter changes.  It has some spelling/comment fixes also.  &lt;br/&gt;
If no other problems are found with existing sorter implementation I am ok leaving it for now the way it is, if there are new problems I think the sort observer solution is cleaner for the future.&lt;/p&gt;

&lt;p&gt;If you have some added comments for the sorter file just submit them as a separate patch, and I can commit those easily without worrying about test running.&lt;/p&gt;</comment>
                            <comment id="12575882" author="anurag" created="Thu, 6 Mar 2008 20:57:01 +0000"  >&lt;p&gt;Added comments in UniqueWithDuplicateNullsMergeSort.java&lt;/p&gt;</comment>
                            <comment id="12575928" author="mikem" created="Thu, 6 Mar 2008 22:35:18 +0000"  >&lt;p&gt;i have committed a modified version of the sortercomments.diff patch.&lt;/p&gt;</comment>
                            <comment id="12576041" author="mikem" created="Fri, 7 Mar 2008 05:21:36 +0000"  >&lt;p&gt;I have committed the derby-3330_followup_1_modified.diff patch to the trunk.  I believe this is the last outstanding patch for this JIRA, so unchecking patch available.&lt;/p&gt;</comment>
                            <comment id="12583451" author="bryanpendleton" created="Sun, 30 Mar 2008 15:51:45 +0100"  >&lt;p&gt;I came across this interesting discussion of the behavior of NULLs and UNIQUE constraints&lt;br/&gt;
in various database systems, and thought it might be interesting in the context of this&lt;br/&gt;
discussion: &lt;a href=&quot;http://www.sqlite.org/nulls.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.sqlite.org/nulls.html&lt;/a&gt;&lt;/p&gt;
</comment>
                            <comment id="12626501" author="kristwaa" created="Thu, 28 Aug 2008 10:23:51 +0100"  >&lt;p&gt;Does anyone know the status of this issue and it sub issues?&lt;br/&gt;
Has the work been completed, so that the Jiras can be resolved/closed? (update fix version as well)&lt;/p&gt;</comment>
                            <comment id="12638529" author="sola" created="Fri, 10 Oct 2008 11:43:32 +0100"  >&lt;p&gt;Does anyone know when this and  &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-2212&quot; title=&quot;Add &amp;quot;Unique where not null&amp;quot; to create index&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-2212&quot;&gt;DERBY-2212&lt;/a&gt; make it to a release?&lt;/p&gt;

&lt;p&gt;This is a very important part of functionality and it is really bad that it is not Oracle/PostgreSQL compliant, since Derby is often used as a development database or single-user production database in applications which use Oracle/PostgreSQL for multi-user production databases. With a behavioral difference like this, Derby cannot be used in this scenario since those apps usually complex enough to use this db feature.&lt;/p&gt;

&lt;p&gt;I just bumped into it when my application became complex enough to use unique indexes on NULLable columns. I have used the oracle-like unique index behavior since ages on Oracle and PG and now I don&apos;t know how to support it on Derby. Obviously, it can be replaced only with complex application logic.&lt;/p&gt;</comment>
                            <comment id="12638532" author="kristwaa" created="Fri, 10 Oct 2008 11:57:53 +0100"  >&lt;p&gt;Have you tried the 10.4.2.0 release?&lt;br/&gt;
The functionality made it into 10.4, see release notes &lt;a href=&quot;http://db.apache.org/derby/releases/release-10.4.1.3.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://db.apache.org/derby/releases/release-10.4.1.3.html&lt;/a&gt; - &quot;New Features&quot;.&lt;/p&gt;

&lt;p&gt;However, I think the relevant issues in Jira are a bit out of sync with the reality, which is why I raised the issue of updating them.&lt;/p&gt;</comment>
                            <comment id="12638597" author="mikem" created="Fri, 10 Oct 2008 18:31:14 +0100"  >&lt;p&gt;I committed a bunch of this work.  I believe this can be resolved/closed with all the work checked into 10.4.  &lt;/p&gt;</comment>
                            <comment id="12698634" author="myrna" created="Tue, 14 Apr 2009 03:58:38 +0100"  >&lt;p&gt;As the functionality made it into 10.4.1.3, marking as fixed in 10.4.1.3.&lt;/p&gt;</comment>
                            <comment id="13831879" author="jira-bot" created="Mon, 25 Nov 2013 20:30:48 +0000"  >&lt;p&gt;Commit 1545394 from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dagw&quot; class=&quot;user-hover&quot; rel=&quot;dagw&quot;&gt;Dag H. Wanvik&lt;/a&gt; in branch &apos;code/trunk&apos;&lt;br/&gt;
[ &lt;a href=&quot;https://svn.apache.org/r1545394&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://svn.apache.org/r1545394&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-532&quot; title=&quot;Support deferrable constraints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-532&quot;&gt;&lt;del&gt;DERBY-532&lt;/del&gt;&lt;/a&gt; Support deferrable constraints&lt;/p&gt;

&lt;p&gt;Patch derby-532-post-scan-4 implements basic support for deferred&lt;br/&gt;
constraints for PRIMARY KEY and UNIQUE constraints. Deferrable&lt;br/&gt;
constraints are not enabled by default yet; one needs to set a&lt;br/&gt;
property to try the feature: &quot;derby.constraintsTesting&quot;.&lt;/p&gt;

&lt;p&gt;This patch enables deferred constraints for:&lt;/p&gt;

&lt;p&gt;    a) primary key constraints&lt;br/&gt;
    b) unique constraint with not nullable columns&lt;br/&gt;
    c) unique constraint with nullable columns&lt;/p&gt;

&lt;p&gt;by new logic in insertion and sorts.&lt;/p&gt;

&lt;p&gt;The patch includes relaxing the constraint at insertion and update&lt;br/&gt;
time, as well as adding a constraint to an existing table. &lt;/p&gt;

&lt;p&gt;Derby treats constraints a) and b) the same, and in the code these are&lt;br/&gt;
marked as &quot;unique&quot; when they are not deferrable (as in existing code).&lt;/p&gt;

&lt;p&gt;Constraint type c) is currently marked as&lt;br/&gt;
&quot;uniqueWithDuplicateNulls&quot;. Insert/update of these is implemented in&lt;br/&gt;
the BTree by including the RowLocation of the base row in the set of&lt;br/&gt;
keys in the index row (&lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3330&quot; title=&quot;provide support for unique constraint over keys that include one or more nullable columns.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3330&quot;&gt;&lt;del&gt;DERBY-3330&lt;/del&gt;&lt;/a&gt;). This makes them trivially unique,&lt;br/&gt;
but there is an extra code path in BTreeController that checks&lt;br/&gt;
neighbor rows for duplicates, and only allows insertion if the key&lt;br/&gt;
contains a null. When adding a constraint to an existing table, these&lt;br/&gt;
are handled by a specially crafted sorter&lt;br/&gt;
(UniqueWithDuplicateNullsMergeSort).&lt;/p&gt;

&lt;p&gt;The implementation of insert/update of deferrable indexes is based on&lt;br/&gt;
a similar approach, i.e. by backing with a non-unique index, and checking &lt;br/&gt;
duplicates in the language layer, notably IndexChanger.&lt;/p&gt;

&lt;p&gt;In IndexChanger, after inserting a row, we check if it is unique by&lt;br/&gt;
performing a scan of the BTree. A time-out here leads to a pessimistic&lt;br/&gt;
assumption that there is a duplicate. Duplicate key values are saved&lt;br/&gt;
until checking time (usually commit time), when a new scan is&lt;br/&gt;
performed to validate the uniqueness property.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;This means a) and b) if deferrable are no longer marked &amp;quot;unique&amp;quot;&amp;#93;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;Deferrable indexes are not shared.&lt;/p&gt;

&lt;p&gt;If there are duplicates and we have deferred constraint mode (a&lt;br/&gt;
dynamic session property), we save the duplicate index row in a disk&lt;br/&gt;
based hash table (DeferredDuplicates#rememberDuplicate).&lt;/p&gt;

&lt;p&gt;For a) and b), constraints which are deferrable are marked as&lt;br/&gt;
&quot;uniqueDeferrable&quot; and &quot;hasDeferrableChecking&quot;. Constraints of type c)&lt;br/&gt;
which are deferrable are marked &quot;uniqueWithDuplicateNulls&quot; and&lt;br/&gt;
&quot;hasDeferrableChecking&quot;. These marks determines the code paths&lt;br/&gt;
used. Note that existing indexes and non-deferrable constraint do not&lt;br/&gt;
get a new code path, which should preserve correctness and performance&lt;br/&gt;
of those.&lt;/p&gt;

&lt;p&gt;Now, with these markers in place, deferral of checks happens in three&lt;br/&gt;
places:&lt;/p&gt;

&lt;p&gt;    {{ IndexChanger#insertAndCheckDups}}&lt;/p&gt;

&lt;p&gt;    {{CreateIndexConstantAction#executeConstantAction +&lt;br/&gt;
     MergeSort#compare and UniqueWithDuplicateNullsMergeSort#compare }}&lt;/p&gt;

&lt;p&gt;    &lt;tt&gt;InsertResultSet#setUpAllSorts&lt;/tt&gt;&lt;/p&gt;


&lt;p&gt;The former is active for deferral under INSERT and UPDATE. The middle&lt;br/&gt;
when adding a deferrable constraint to an existing table, when we sort&lt;br/&gt;
existing rows detecting any duplicates. The last is used when importing&lt;br/&gt;
rows.&lt;/p&gt;

&lt;p&gt;At transaction commit (1), or when the constraint mode for a deferred&lt;br/&gt;
constraint is changed back to immediate (2), we validate the&lt;br/&gt;
constraint (DeferredDuplicates#validate) by replaying the hash table&lt;br/&gt;
and scanning the index for the duplicate index rows to ascertain there&lt;br/&gt;
are none, or else we have an error: transaction or statement severity&lt;br/&gt;
respectively for (1) and (2).&lt;/p&gt;

&lt;p&gt;The constraint mode is a SQL session level variable, and inside&lt;br/&gt;
routines (nested connections), we push this on the stack. This means&lt;br/&gt;
change of the constraint mode inside nested connections will be popped&lt;br/&gt;
on routine exit. If, as part of this, a constraint changes from&lt;br/&gt;
deferred to immediate mode, we also validate it for correctness. If&lt;br/&gt;
this fail, the transaction rolls back&lt;br/&gt;
We needed to do this from a newly introduced method,&lt;br/&gt;
GenericLanguageConnectionContext#popNestedSessionContext. This&lt;br/&gt;
pops the SQL session context.&lt;br/&gt;
That hook is called from GenericPreparedStatement#executeStmt. As a&lt;br/&gt;
part of this effort, we also renamed #setupNestedSessionContext to&lt;br/&gt;
#pushNestedSessionContext.&lt;/p&gt;

&lt;p&gt;The patch also adds support for checking deferred constraints in&lt;br/&gt;
xa_prepare and xa_commit (.., true), cf. specification attached to the&lt;br/&gt;
JIRA issue.&lt;/p&gt;

&lt;p&gt;Concurrency: if a transaction gets a lock time-out when trying to&lt;br/&gt;
establish if a row just inserted is a duplicate (another transaction&lt;br/&gt;
may have just inserted a row with a similar index key), we use a&lt;br/&gt;
pessimistics assumption and add that key to the set of keys to be&lt;br/&gt;
checked at commit time. If a key can&apos;t be grabbed then, a time-out is&lt;br/&gt;
thrown. We plan to add an optimized scan to avoid waiting for the lock&lt;br/&gt;
at insertion time, cf &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-6419&quot; title=&quot;Make BTree scan honor  OPENMODE_LOCK_NOWAIT for row locks.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-6419&quot;&gt;&lt;del&gt;DERBY-6419&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The &quot;not enforced&quot; feature is not yet implemented in this patch.&lt;/p&gt;

&lt;p&gt;Several new test cases been added to ConstraintCharacteristicsTest to&lt;br/&gt;
test these basic behaviors.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12390350">DERBY-3502</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12390770">DERBY-3523</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12359789">DERBY-2212</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12374485" name="BTreeController.diff" size="9865" author="anurag" created="Thu, 31 Jan 2008 18:05:39 +0000"/>
                            <attachment id="12374153" name="FunctionalSpec_DERBY-3330-V2.html" size="7345" author="anurag" created="Sun, 27 Jan 2008 15:29:24 +0000"/>
                            <attachment id="12373919" name="FunctionalSpec_DERBY-3330.html" size="7096" author="anurag" created="Thu, 24 Jan 2008 12:01:33 +0000"/>
                            <attachment id="12374544" name="UniqueConstraint_Implementation.html" size="15198" author="anurag" created="Fri, 1 Feb 2008 12:44:06 +0000"/>
                            <attachment id="12376251" name="UniqueConstraint_Implementation_V2.html" size="12411" author="anurag" created="Fri, 22 Feb 2008 18:55:32 +0000"/>
                            <attachment id="12376309" name="UniqueConstraint_Implementation_V3.html" size="10656" author="anurag" created="Sat, 23 Feb 2008 13:09:13 +0000"/>
                            <attachment id="12377272" name="UniqueConstraint_Implementation_V4.html" size="13254" author="anurag" created="Thu, 6 Mar 2008 18:46:01 +0000"/>
                            <attachment id="12376862" name="db2Compatibility-v2.diff" size="2904" author="anurag" created="Fri, 29 Feb 2008 19:32:11 +0000"/>
                            <attachment id="12376712" name="db2Compatibility.diff" size="1793" author="anurag" created="Thu, 28 Feb 2008 12:18:22 +0000"/>
                            <attachment id="12377142" name="derby-3330-UpgradeTests.diff" size="9734" author="anurag" created="Wed, 5 Mar 2008 07:55:01 +0000"/>
                            <attachment id="12373910" name="derby-3330-testcase.diff" size="18951" author="anurag" created="Thu, 24 Jan 2008 08:51:04 +0000"/>
                            <attachment id="12373494" name="derby-3330.diff" size="29572" author="anurag" created="Fri, 18 Jan 2008 10:03:33 +0000"/>
                            <attachment id="12377257" name="derby-3330_followup_1.diff" size="5629" author="anurag" created="Thu, 6 Mar 2008 13:51:30 +0000"/>
                            <attachment id="12377281" name="derby-3330_followup_1_modified.diff" size="6297" author="mikem" created="Thu, 6 Mar 2008 20:34:15 +0000"/>
                            <attachment id="12376674" name="derby-3330v10.diff" size="88451" author="anurag" created="Wed, 27 Feb 2008 22:13:25 +0000"/>
                            <attachment id="12376711" name="derby-3330v11.diff" size="84324" author="anurag" created="Thu, 28 Feb 2008 12:06:21 +0000"/>
                            <attachment id="12376736" name="derby-3330v12.diff" size="84206" author="anurag" created="Thu, 28 Feb 2008 15:40:51 +0000"/>
                            <attachment id="12376773" name="derby-3330v13.diff" size="90248" author="anurag" created="Thu, 28 Feb 2008 22:14:37 +0000"/>
                            <attachment id="12373736" name="derby-3330v2.diff" size="39013" author="anurag" created="Tue, 22 Jan 2008 09:26:35 +0000"/>
                            <attachment id="12373854" name="derby-3330v3.diff" size="40214" author="anurag" created="Wed, 23 Jan 2008 18:26:11 +0000"/>
                            <attachment id="12373909" name="derby-3330v4.diff" size="40218" author="anurag" created="Thu, 24 Jan 2008 08:51:04 +0000"/>
                            <attachment id="12375565" name="derby-3330v5.diff" size="85537" author="anurag" created="Thu, 14 Feb 2008 09:47:04 +0000"/>
                            <attachment id="12376120" name="derby-3330v6.diff" size="104583" author="anurag" created="Thu, 21 Feb 2008 11:51:47 +0000"/>
                            <attachment id="12376205" name="derby-3330v7.diff" size="105610" author="anurag" created="Fri, 22 Feb 2008 08:06:29 +0000"/>
                            <attachment id="12376240" name="derby-3330v8.diff" size="103908" author="anurag" created="Fri, 22 Feb 2008 17:07:37 +0000"/>
                            <attachment id="12376302" name="derby-3330v9.diff" size="88053" author="anurag" created="Sat, 23 Feb 2008 12:52:31 +0000"/>
                            <attachment id="12376682" name="derbyall_report.txt" size="19254" author="mikem" created="Thu, 28 Feb 2008 00:56:30 +0000"/>
                            <attachment id="12377283" name="sortercomments.diff" size="1261" author="anurag" created="Thu, 6 Mar 2008 20:57:01 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12389384">DERBY-3456</subtask>
                            <subtask id="12389676">DERBY-3473</subtask>
                            <subtask id="12389678">DERBY-3474</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>28.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 25 Jan 2008 19:55:19 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>30812</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310090" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Issue &amp; fix info</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10101"><![CDATA[Release Note Needed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy0lt3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>37351</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            </customfields>
    </item>
</channel>
</rss>