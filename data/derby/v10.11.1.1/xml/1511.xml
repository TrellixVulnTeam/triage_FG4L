<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:33:42 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-1511/DERBY-1511.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-1511] SELECT clause without a WHERE, causes an Exception when extracting a Blob from a database</title>
                <link>https://issues.apache.org/jira/browse/DERBY-1511</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;An exception occurs when extracting a Blob from a database. &lt;/p&gt;

&lt;p&gt;The following code, will ALWAYS fail with the Exception:&lt;/p&gt;

&lt;p&gt;java.io.IOException: ERROR 40XD0: Container has been closed&lt;br/&gt;
        at org.apache.derby.impl.store.raw.data.OverflowInputStream.fillByteHold&lt;br/&gt;
er(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.store.raw.data.BufferedByteHolderInputStream.re&lt;br/&gt;
ad(Unknown Source)&lt;br/&gt;
        at java.io.DataInputStream.read(Unknown Source)&lt;br/&gt;
        at java.io.FilterInputStream.read(Unknown Source)&lt;br/&gt;
        at java.io.ObjectInputStream$PeekInputStream.read(Unknown Source)&lt;br/&gt;
        at java.io.ObjectInputStream$PeekInputStream.readFully(Unknown Source)&lt;br/&gt;
        at java.io.ObjectInputStream$BlockDataInputStream.readDoubles(Unknown So&lt;br/&gt;
urce)&lt;br/&gt;
        at java.io.ObjectInputStream.readArray(Unknown Source)&lt;br/&gt;
        at java.io.ObjectInputStream.readObject0(Unknown Source)&lt;br/&gt;
        at java.io.ObjectInputStream.readObject(Unknown Source)&lt;br/&gt;
        at BlobTest.readRows(BlobTest.java:82)&lt;br/&gt;
        at BlobTest.main(BlobTest.java:24)&lt;/p&gt;

&lt;p&gt;CODE:&lt;/p&gt;

&lt;p&gt;import java.io.*;&lt;br/&gt;
import java.sql.*;&lt;br/&gt;
import java.util.*;&lt;/p&gt;

&lt;p&gt;public class BlobTest&lt;br/&gt;
{&lt;br/&gt;
  private static final String TABLE1 = &quot;CREATE TABLE TABLE_1 ( &quot;&lt;br/&gt;
                                     + &quot;ID INTEGER NOT NULL, &quot;&lt;br/&gt;
                                     + &quot;COL_2 INTEGER NOT NULL, &quot;&lt;br/&gt;
                                     + &quot;PRIMARY KEY (ID) )&quot;;&lt;/p&gt;

&lt;p&gt;  private static final String TABLE2 = &quot;CREATE TABLE TABLE_2 ( &quot;&lt;br/&gt;
                                     + &quot;ID INTEGER NOT NULL, &quot;&lt;br/&gt;
                                     + &quot;COL_BLOB BLOB, &quot;&lt;br/&gt;
                                     + &quot;PRIMARY KEY (ID) )&quot;;&lt;/p&gt;

&lt;p&gt;  public static void main(String... args) {&lt;br/&gt;
    try &lt;/p&gt;
{
      createDBandTables();
      Connection con = getConnection();

      addRows(con, 10000, 1);
      addRows(con, 10000, 2);
      readRows(con, 1);

      con.close();
    }
&lt;p&gt;    catch(Exception exp) &lt;/p&gt;
{
      exp.printStackTrace();
    }
&lt;p&gt;  }&lt;/p&gt;

&lt;p&gt;  private static void addRows(Connection con, int size, int id) &lt;br/&gt;
                                                         throws Exception&lt;/p&gt;
  {
    String sql = &quot;INSERT INTO TABLE_1 VALUES(?, ?)&quot;;

    PreparedStatement pstmt = con.prepareStatement(sql);
    pstmt.setInt(1, id);
    pstmt.setInt(2, 2);
    pstmt.executeUpdate();
    pstmt.close();

    double[] array = new double[size];
    array[size-1] = 1.23;

    sql = &quot;INSERT INTO TABLE_2 VALUES(?, ?)&quot;;

    pstmt = con.prepareStatement(sql);
    pstmt.setInt(1, id);

    ByteArrayOutputStream byteStream = new ByteArrayOutputStream();
    ObjectOutputStream objStream = new ObjectOutputStream(byteStream);
    objStream.writeObject(array);         // Convert object to byte stream 
    objStream.flush();
    objStream.close();

    byte[] bytes = byteStream.toByteArray();

    ByteArrayInputStream inStream = new ByteArrayInputStream(bytes);

    pstmt.setBinaryStream(2, inStream, bytes.length);
    pstmt.executeUpdate();
    pstmt.close();
  }

&lt;p&gt;  private static void readRows(Connection con, int id) throws Exception&lt;br/&gt;
  {&lt;br/&gt;
    String sql = &quot;SELECT * FROM TABLE_2&quot;;&lt;br/&gt;
//    String sql = &quot;SELECT * FROM TABLE_2 WHERE ID &amp;gt; 0&quot;;&lt;/p&gt;

&lt;p&gt;    Statement stmt = con.createStatement();&lt;/p&gt;

&lt;p&gt;    ResultSet rs = stmt.executeQuery(sql);&lt;/p&gt;

&lt;p&gt;    while (rs.next()) &lt;/p&gt;
{
      rs.getInt(1);

      InputStream stream = rs.getBinaryStream(2);

      ObjectInputStream objStream = new ObjectInputStream(stream);

      Object obj = objStream.readObject();

      double[] array = (double[]) obj;

      System.out.println(array.length);

      readTable1(con, id);
    }
&lt;p&gt;    rs.close();&lt;br/&gt;
    stmt.close();&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;  private static void readTable1(Connection con, int id) throws Exception {&lt;br/&gt;
    String sql = &quot;SELECT ID FROM TABLE_1 WHERE ID=&quot; + id;    &lt;/p&gt;

&lt;p&gt;    Statement stmt = con.createStatement();&lt;/p&gt;

&lt;p&gt;    ResultSet rs = stmt.executeQuery(sql);&lt;/p&gt;

&lt;p&gt;    if (rs.next()) {&lt;br/&gt;
    }&lt;br/&gt;
    rs.close();&lt;br/&gt;
    stmt.close();&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;  private static Connection getConnection() throws Exception &lt;/p&gt;
{
    String driver=&quot;org.apache.derby.jdbc.EmbeddedDriver&quot;;

    Properties p = System.getProperties();
    p.put(&quot;derby.system.home&quot;, &quot;C:\\databases\\sample&quot;);
    
    Class.forName(driver);

    String url = &quot;jdbc:derby:derbyBlob&quot;;
    Connection con = DriverManager.getConnection(url);

    return con;
  }

&lt;p&gt;  private static void createDBandTables() throws Exception &lt;/p&gt;
{
    String driver=&quot;org.apache.derby.jdbc.EmbeddedDriver&quot;;

    Properties p = System.getProperties();
    p.put(&quot;derby.system.home&quot;, &quot;C:\\databases\\sample&quot;);
    
    Class.forName(driver);

    String url = &quot;jdbc:derby:derbyBlob;create=true&quot;;
    Connection con = DriverManager.getConnection(url);

    Statement stmt = con.createStatement();

    stmt.execute(TABLE1);
    stmt.execute(TABLE2);

    stmt.close();
    con.close();
  }
&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;However if the selection clause is changed from:&lt;/p&gt;

&lt;p&gt;    String sql = &quot;SELECT * FROM TABLE_2&quot;;&lt;br/&gt;
TO&lt;br/&gt;
    String sql = &quot;SELECT * FROM TABLE_2 WHERE ID &amp;gt; 0&quot;;&lt;/p&gt;

&lt;p&gt;The code works without Exception.&lt;/p&gt;


&lt;p&gt;Output from: java org.apache.derby.tools.sysinfo &lt;br/&gt;
------------------ Java Information ------------------ &lt;br/&gt;
Java Version: 1.5.0_05 &lt;br/&gt;
Java Vendor: Sun Microsystems Inc. &lt;br/&gt;
Java home: C:\Program Files\Java\jre1.5.0_05 &lt;br/&gt;
Java classpath: C:\tools\derby\db-derby-10.1.2.1-bin\lib\derby.jar;C:\tools\der &lt;br/&gt;
by\db-derby-10.1.2.1-bin\lib\derbytools.jar; &lt;br/&gt;
OS name: Windows XP &lt;br/&gt;
OS architecture: x86 &lt;br/&gt;
OS version: 5.1 &lt;br/&gt;
Java user name: David &lt;br/&gt;
Java user home: C:\Documents and Settings\David &lt;br/&gt;
Java user dir: C:\david\novice\derby &lt;br/&gt;
java.specification.name: Java Platform API Specification &lt;br/&gt;
java.specification.version: 1.5 &lt;br/&gt;
--------- Derby Information -------- &lt;br/&gt;
JRE - JDBC: J2SE 5.0 - JDBC 3.0 &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;C:\tools\derby\db-derby-10.1.2.1-bin\lib\derby.jar&amp;#93;&lt;/span&gt; 10.1.2.1 - (330608) &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;C:\tools\derby\db-derby-10.1.2.1-bin\lib\derbytools.jar&amp;#93;&lt;/span&gt; 10.1.2.1 - (330608) &lt;br/&gt;
------------------------------------------------------ &lt;br/&gt;
----------------- Locale Information ----------------- &lt;br/&gt;
------------------------------------------------------ &lt;/p&gt;</description>
                <environment>Windows XP</environment>
        <key id="12346012">DERBY-1511</key>
            <summary>SELECT clause without a WHERE, causes an Exception when extracting a Blob from a database</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="knutanders">Knut Anders Hatlen</assignee>
                                    <reporter username="heath_david">David Heath</reporter>
                        <labels>
                            <label>LOB</label>
                    </labels>
                <created>Fri, 14 Jul 2006 18:20:46 +0100</created>
                <updated>Mon, 17 Jun 2013 10:19:11 +0100</updated>
                            <resolved>Thu, 16 Sep 2010 13:58:40 +0100</resolved>
                                    <version>10.1.2.1</version>
                                    <fixVersion>10.7.1.1</fixVersion>
                                    <component>Store</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12422298" author="kmarsden" created="Thu, 20 Jul 2006 01:07:09 +0100"  >&lt;p&gt;Do you see this issue with autocommit off?&lt;/p&gt;</comment>
                            <comment id="12422368" author="andreask" created="Thu, 20 Jul 2006 10:17:26 +0100"  >&lt;p&gt;Yes.&lt;/p&gt;

&lt;p&gt;If you modify the code, and replace readTable1(..) with con.commit(), you will see this issue with autocommit off:&lt;/p&gt;

&lt;p&gt;The problem seems to be related to BulkTableScanResultSet. On the first call to next() it builds an array of rows (rowArray), and feeds the result set with rows from that array. However, after a commit, the Conglomerate is closed. The BulkTableScanResultSet will continue to feed rows from the rowArray, and the BLOB columns in these rows depend on reading data from the Conglomerate (which is closed).&lt;/p&gt;

&lt;p&gt;When adding a WHERE clause, the engine will not use BulkTableScanResultSet. Also if the statement has concurrency CONCUR_UPDATABLE, the engine will not use BulkTableScanResultSet.&lt;/p&gt;
</comment>
                            <comment id="12542903" author="knutanders" created="Thu, 15 Nov 2007 22:37:45 +0000"  >&lt;p&gt;Would it make sense to force the use of TableScanResultSet instead of BulkTableScanResultSet when the result contains long columns? I ran the test case successfully with this diff applied (BulkTableScanResultSet with rowsPerRead==1 means that it behaves exactly like TableScanResultSet):&lt;/p&gt;

&lt;p&gt;&amp;#8212; BulkTableScanResultSet.java	(revision 593240)&lt;br/&gt;
+++ BulkTableScanResultSet.java	(working copy)&lt;br/&gt;
@@ -128,7 +128,7 @@&lt;br/&gt;
 			lockMode,&lt;br/&gt;
 			tableLocked,&lt;br/&gt;
 			isolationLevel,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;rowsPerRead,&lt;br/&gt;
+			  /&lt;b&gt;rowsPerRead&lt;/b&gt;/ 1,&lt;br/&gt;
 			oneRowScan,&lt;br/&gt;
 			optimizerEstimatedRowCount,&lt;br/&gt;
 			optimizerEstimatedCost);&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12797364" author="tna" created="Wed, 6 Jan 2010 22:37:42 +0000"  >&lt;p&gt;I&apos;m not sure if it&apos;s the same issue but I&apos;ve consistently running into &quot;ERROR 40XD0: Container has been closed &quot;&lt;/p&gt;

&lt;p&gt;I can&apos;t provide SQL code to reproduce the problem because I wrote the code in groovy and it generates the SQL, but I&apos;m basically running something along these lines:&lt;/p&gt;

&lt;p&gt;for each row in (select * from tableA)&lt;br/&gt;
  ...&lt;br/&gt;
  select count(id) &amp;gt; 0 from tableB where name = &apos;somename&apos;&lt;br/&gt;
  insert into tableB (...) values...&lt;br/&gt;
  insert into tableC (...) values...&lt;br/&gt;
end&lt;/p&gt;

&lt;p&gt;tableB has ~140k rows with a varchar(32000) field which is sometimes completely full.&lt;br/&gt;
The loop would always break on row with id X, but it&apos;s not the row that&apos;s the problem. if I replace (select * from tableA) with (select * from tableA where id = X), it works just fine. It seems that derby only breaks after a certain number of iterations. I wanted to get a better feeling of what the problem was and I believe there were no errors when I commented out the insert statements.&lt;/p&gt;

&lt;p&gt;Now, I have tried embedded mode and network client mode as well as different derby versions (10.3 and 10.5.3), but I have seen no difference in behaviour. I&apos;ve also attempted to set autocommit to false and explicitly commit after inserts (someone suggested it as a workaround somewhere) without result.&lt;br/&gt;
I&apos;ve spent a day and a half debugging this and finally migrated the data to PostgreSQL where it now works flawlessly.&lt;/p&gt;

&lt;p&gt;This is the definition of tableA:&lt;/p&gt;

&lt;p&gt;create table article (&lt;br/&gt;
id int,&lt;br/&gt;
id_article_type int,&lt;br/&gt;
summary varchar(1024),&lt;br/&gt;
content varchar(32672), &amp;#8211; need a lot of space&lt;br/&gt;
)&lt;/p&gt;

&lt;p&gt;That&apos;s about it...I can&apos;t re-run the application any more without a significant effort so I can&apos;t provide the exact stack trace, but hope this is detailed enough.&lt;/p&gt;</comment>
                            <comment id="12797602" author="dagw" created="Thu, 7 Jan 2010 11:46:33 +0000"  >&lt;p&gt;Thanks for documenting this, Tomislav. Hopefully, your information can help us make a repro of this issue.&lt;/p&gt;</comment>
                            <comment id="12877487" author="knutanders" created="Thu, 10 Jun 2010 17:59:25 +0100"  >&lt;p&gt;I&apos;m attaching a JUnit regression test case that exposes this bug.&lt;/p&gt;</comment>
                            <comment id="12878591" author="knutanders" created="Mon, 14 Jun 2010 15:27:50 +0100"  >&lt;p&gt;I&apos;m attaching a patch that disables bulk fetch if the table scan returns BLOBs or CLOBs. This makes the repro run cleanly. I haven&apos;t run any other tests yet.&lt;/p&gt;</comment>
                            <comment id="12878614" author="kristwaa" created="Mon, 14 Jun 2010 16:21:02 +0100"  >&lt;p&gt;The attached patch looks good to me. It will be interesting to how/if performance is affected by this (I think I&apos;m aware of an internal test that would reveal this).&lt;/p&gt;

&lt;p&gt;Just as a side note, I guess another option would be to hide locators that aren&apos;t ready for deallocation. This does however sound like an error-prone approach, adding further complexity in this area.&lt;/p&gt;

&lt;p&gt;Given that the tests run without failure, and that the performance for selecting LOBs doesn&apos;t degrade too much, +1 to commit.&lt;br/&gt;
I think a small performance degradation is to prefer over a non-working query, especially since bulk fetch is disabled for other types of queries anyway.&lt;/p&gt;</comment>
                            <comment id="12878924" author="knutanders" created="Tue, 15 Jun 2010 11:34:11 +0100"  >&lt;p&gt;Thanks for looking at the patch, Kristian. I&apos;ll see if I can come up with some numbers that describe the performance impact. Speaking of performance, disabling bulk-fetch is probably only necessary when using holdable cursors (the default), since non-holdable cursors won&apos;t even allow you to execute next() after a commit. But, as far as I can tell, the compiled plans can be shared between statements that produce holdable cursors and statements that produce non-holdable cursors, so I don&apos;t think it&apos;s possible to predict the holdability of the cursor at compile time.&lt;/p&gt;

&lt;p&gt;The previous patch made two test cases in BlobClob4BlobTest fail: testNegativeTestDerby265Blob and testNegativeTestDerby265Clob. In both cases the tests failed because they expected a &quot;container closed&quot; exception in queries similar to the one reported here. I&apos;m uploading a new patch (1b) that makes BlobClob4BlobTest expect these test cases to execute cleanly.&lt;/p&gt;</comment>
                            <comment id="12887697" author="knutanders" created="Tue, 13 Jul 2010 10:12:43 +0100"  >&lt;p&gt;I ran some tests which performed table scans on a table with 100MB of BLOB data. The attached graph shows the results for various record sizes. In short, disabling bulk fetch seems to have a large impact on small records (~75% reduction with record size 100 bytes), whereas there&apos;s little difference for records &amp;gt; ~30K. In fact, for large records, disabling bulk fetch seems to improve the performance marginally.&lt;/p&gt;

&lt;p&gt;Reduced table scan performance for small LOBs would probably be acceptable because (a) full table scan should be avoided in the first place if performance is important, and (b) for that small records VARCHAR and VARCHAR FOR BIT DATA should be preferred to CLOB and BLOB. But since this fix is only needed for holdable cursors, we could delay the disabling of bulk fetching to runtime so that we can check the holdability first, and only disable it if the cursor is holdable. Then the users would be given an option (use a non-holdable cursor) that didn&apos;t require changes to their queries or database schema if some of their queries slow down. We could document this in a release note. How does that sound?&lt;/p&gt;</comment>
                            <comment id="12887704" author="kristwaa" created="Tue, 13 Jul 2010 10:49:31 +0100"  >&lt;p&gt;Thanks for obtaining hard facts, Knut &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I&apos;m +0.9 for the current approach, since I agree most users shouldn&apos;t be affected, and +1 for the even better approach you suggested in your last comment (assuming the decision can be taken easily at runtime).&lt;/p&gt;</comment>
                            <comment id="12887709" author="knutanders" created="Tue, 13 Jul 2010 11:15:57 +0100"  >&lt;p&gt;There is of course also the option of trying to make the pre-fetched LOBs survive the commit, which wouldn&apos;t affect anyone at all, but I suspect that&apos;s somewhat more involved, so I haven&apos;t looked into that option. But if we just get a fix in for the bug first, with a documented workaround for those who see an unacceptable performance hit, we could always revisit the issue to improve the performance for the holdable case later.&lt;/p&gt;</comment>
                            <comment id="12887814" author="mikem" created="Tue, 13 Jul 2010 16:55:30 +0100"  >&lt;p&gt;+1 to fixing the current bug as described (if you can do it only for holdable case that would be best),&lt;br/&gt;
as it best to get a fix in that makes queries run, even at cost of some performance loss.&lt;br/&gt;
But do log a linked improvement JIRA to fix this issue in some way that does not require disabling&lt;br/&gt;
bulk fetch.  The blob holders should be improved to withstand the closing of the underlying containers,&lt;br/&gt;
but this is best approached as a feature level task in a new release.  &lt;/p&gt;</comment>
                            <comment id="12907220" author="knutanders" created="Wed, 8 Sep 2010 14:58:36 +0100"  >&lt;p&gt;Here&apos;s an updated patch that only disables bulk fetch if the table contains LOB columns and the cursor is holdable. I&apos;ve only run BLOBTest on it yet. Will start the full regression test suite.&lt;/p&gt;</comment>
                            <comment id="12907591" author="knutanders" created="Thu, 9 Sep 2010 12:00:25 +0100"  >&lt;p&gt;Many of the tests failed with the 1c patch. I&apos;ll investigate and come up with a new patch.&lt;/p&gt;</comment>
                            <comment id="12908000" author="knutanders" created="Fri, 10 Sep 2010 13:34:33 +0100"  >&lt;p&gt;It looks like all the failures with the 1c patch were caused by NullPointerExceptions in FromTable.hasLargeObjectColumns(). The tests failed when the FromBaseTable was located below an IndexRowToBaseRowResultSet. The problem was that the last column of the FBT will have a CurrentRowLocationNode, which is not an SQL type and hence getType() returns null. A value that doesn&apos;t have a type cannot be a large object column, so I think this can be fixed simply by skipping the columns that don&apos;t have a type.&lt;/p&gt;</comment>
                            <comment id="12908044" author="knutanders" created="Fri, 10 Sep 2010 15:52:12 +0100"  >&lt;p&gt;Uploading a new patch 1d which fixes the NPE in the previous patch.&lt;/p&gt;

&lt;p&gt;The patch adds a boolean parameter to BulkTableScanResultSet which tells whether bulk fetch must be disabled for holdable cursor. At runtime, BulkTableScanResultSet will check that flag and, if requested, disable bulk fetching (by setting bulk fetch size to 1) if the cursor is holdable.&lt;/p&gt;

&lt;p&gt;All the regression tests ran cleanly with this patch. I&apos;ve also tested some table scans with small (10 bytes) BLOBs and verified that there&apos;s no performance hit with non-holdable cursors. Holdable cursors still see a performance degradation with small LOBs in the cases where it used bulk scans before.&lt;/p&gt;</comment>
                            <comment id="12909305" author="knutanders" created="Tue, 14 Sep 2010 17:21:18 +0100"  >&lt;p&gt;Attaching a release note.&lt;/p&gt;</comment>
                            <comment id="12910137" author="knutanders" created="Thu, 16 Sep 2010 13:58:40 +0100"  >&lt;p&gt;Committed revision 997722.&lt;/p&gt;

&lt;p&gt;I&apos;ve filed &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-4800&quot; title=&quot;Allow bulk scan of LOB tables with holdable cursors&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-4800&quot;&gt;DERBY-4800&lt;/a&gt; for the improvements needed in order to re-enable bulk scans with holdable cursors.&lt;/p&gt;

&lt;p&gt;Marking this issue as resolved.&lt;/p&gt;</comment>
                            <comment id="13685154" author="knutanders" created="Mon, 17 Jun 2013 10:19:11 +0100"  >&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;bulk update&amp;#93;&lt;/span&gt; Close all resolved issues that haven&apos;t been updated for more than one year.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12399400">DERBY-3749</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12429122">DERBY-4294</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12474281">DERBY-4800</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12447022" name="derby-1511-1a.diff" size="3523" author="knutanders" created="Mon, 14 Jun 2010 15:27:50 +0100"/>
                            <attachment id="12447123" name="derby-1511-1b.diff" size="7170" author="knutanders" created="Tue, 15 Jun 2010 11:34:11 +0100"/>
                            <attachment id="12454110" name="derby-1511-1c.diff" size="13426" author="knutanders" created="Wed, 8 Sep 2010 14:58:35 +0100"/>
                            <attachment id="12454109" name="derby-1511-1c.stat" size="797" author="knutanders" created="Wed, 8 Sep 2010 14:58:35 +0100"/>
                            <attachment id="12454300" name="derby-1511-1d.diff" size="13535" author="knutanders" created="Fri, 10 Sep 2010 15:52:12 +0100"/>
                            <attachment id="12449329" name="perf.png" size="6312" author="knutanders" created="Tue, 13 Jul 2010 10:12:43 +0100"/>
                            <attachment id="12454547" name="releaseNote.html" size="5276" author="knutanders" created="Tue, 14 Sep 2010 17:21:18 +0100"/>
                            <attachment id="12446774" name="test.diff" size="1963" author="knutanders" created="Thu, 10 Jun 2010 17:59:25 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310200" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Bug behavior facts</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10365"><![CDATA[Crash]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 20 Jul 2006 00:07:09 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>22548</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310090" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Issue &amp; fix info</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10422"><![CDATA[High Value Fix]]></customfieldvalue>
    <customfieldvalue key="10424"><![CDATA[Repro attached]]></customfieldvalue>
    <customfieldvalue key="10427"><![CDATA[Workaround attached]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy0ojz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>37796</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310050" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Urgency</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10052"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>