<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:19:11 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-4677/DERBY-4677.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-4677] SYSCS_COMPRESS_TABLE disables unique constraints</title>
                <link>https://issues.apache.org/jira/browse/DERBY-4677</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;It appears that running SYSCS_UTIL.SYSCS_COMPRESS_TABLE on a table with a null-able unique constraint will disable the unique constraint. The script&lt;br/&gt;
below should reproduce the problem. The expected behaviour is for the second insert to fail due to the unique constraint but instead it is allowed. The second insert will fail as expected if either the call to SYSCS_COMPRESS_TABLE is skipped or if the column is declared NOT NULL.&lt;/p&gt;

&lt;p&gt;I have reproduced the problem using embedded Derby 10.5.1.1, 10.5.3.0 and 10.6.1.0 using ij.&lt;/p&gt;

&lt;p&gt;CREATE TABLE TABLE1(NAME1 INT UNIQUE);&lt;/p&gt;

&lt;p&gt;CALL SYSCS_UTIL.SYSCS_COMPRESS_TABLE(&apos;APP&apos;, &apos;TABLE1&apos;, 1);&lt;/p&gt;

&lt;p&gt;INSERT INTO TABLE1(NAME1) VALUES(1);&lt;/p&gt;

&lt;p&gt;INSERT INTO TABLE1(NAME1) VALUES(1);&lt;/p&gt;

&lt;p&gt;SELECT * FROM TABLE1;&lt;/p&gt;

&lt;p&gt;DROP TABLE TABLE1;&lt;/p&gt;</description>
                <environment>Output of sysinfo:&lt;br/&gt;
------------------ Java Information ------------------&lt;br/&gt;
Java Version:    1.6.0_20&lt;br/&gt;
Java Vendor:     Sun Microsystems Inc.&lt;br/&gt;
Java home:       C:\Program Files (x86)\Java\jre6&lt;br/&gt;
Java classpath:  .;C:\Program Files (x86)\Java\jre6\lib\ext\QTJava.zip;C:\Users\BMASON\Sandbox\libs\db-derby-10.6.1.0-bin\bin\../lib/derby.jar;C:\Users\BMASON\Sandbox\libs\db-derby-10.6.1.0-bin\bin\../lib/derbynet.jar;C:\Users\BMASON\Sandbox\libs\db-derby-10.6.1.0-bin\bin\../lib/derbyclient.jar;C:\Users\BMASON\Sandbox\libs\db-derby-10.6.1.0-bin\bin\../lib/derbytools.jar&lt;br/&gt;
OS name:         Windows 7&lt;br/&gt;
OS architecture: x86&lt;br/&gt;
OS version:      6.1&lt;br/&gt;
Java user name:  bmason&lt;br/&gt;
Java user home:  C:\Users\BMASON&lt;br/&gt;
Java user dir:   C:\Users\BMASON\Sandbox\libs\db-derby-10.6.1.0-bin\bin&lt;br/&gt;
java.specification.name: Java Platform API Specification&lt;br/&gt;
java.specification.version: 1.6&lt;br/&gt;
java.runtime.version: 1.6.0_20-b02&lt;br/&gt;
--------- Derby Information --------&lt;br/&gt;
JRE - JDBC: Java SE 6 - JDBC 4.0&lt;br/&gt;
[C:\Users\BMASON\Sandbox\libs\db-derby-10.6.1.0-bin\lib\derby.jar] 10.6.1.0 - (938214)&lt;br/&gt;
[C:\Users\BMASON\Sandbox\libs\db-derby-10.6.1.0-bin\lib\derbytools.jar] 10.6.1.0 - (938214)&lt;br/&gt;
[C:\Users\BMASON\Sandbox\libs\db-derby-10.6.1.0-bin\lib\derbynet.jar] 10.6.1.0 - (938214)&lt;br/&gt;
[C:\Users\BMASON\Sandbox\libs\db-derby-10.6.1.0-bin\lib\derbyclient.jar] 10.6.1.0 - (938214)&lt;br/&gt;
------------------------------------------------------&lt;br/&gt;
----------------- Locale Information -----------------&lt;br/&gt;
Current Locale :  [English/New Zealand [en_NZ]]&lt;br/&gt;
Found support for locale: [cs]&lt;br/&gt;
	 version: 10.6.1.0 - (938214)&lt;br/&gt;
Found support for locale: [de_DE]&lt;br/&gt;
	 version: 10.6.1.0 - (938214)&lt;br/&gt;
Found support for locale: [es]&lt;br/&gt;
	 version: 10.6.1.0 - (938214)&lt;br/&gt;
Found support for locale: [fr]&lt;br/&gt;
	 version: 10.6.1.0 - (938214)&lt;br/&gt;
Found support for locale: [hu]&lt;br/&gt;
	 version: 10.6.1.0 - (938214)&lt;br/&gt;
Found support for locale: [it]&lt;br/&gt;
	 version: 10.6.1.0 - (938214)&lt;br/&gt;
Found support for locale: [ja_JP]&lt;br/&gt;
	 version: 10.6.1.0 - (938214)&lt;br/&gt;
Found support for locale: [ko_KR]&lt;br/&gt;
	 version: 10.6.1.0 - (938214)&lt;br/&gt;
Found support for locale: [pl]&lt;br/&gt;
	 version: 10.6.1.0 - (938214)&lt;br/&gt;
Found support for locale: [pt_BR]&lt;br/&gt;
	 version: 10.6.1.0 - (938214)&lt;br/&gt;
Found support for locale: [ru]&lt;br/&gt;
	 version: 10.6.1.0 - (938214)&lt;br/&gt;
Found support for locale: [zh_CN]&lt;br/&gt;
	 version: 10.6.1.0 - (938214)&lt;br/&gt;
Found support for locale: [zh_TW]&lt;br/&gt;
	 version: 10.6.1.0 - (938214)&lt;br/&gt;
------------------------------------------------------&lt;br/&gt;
</environment>
        <key id="12465329">DERBY-4677</key>
            <summary>SYSCS_COMPRESS_TABLE disables unique constraints</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mamtas">Mamta A. Satoor</assignee>
                                    <reporter username="b.mason@adinstruments.com">Brett Mason</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 May 2010 04:06:11 +0100</created>
                <updated>Mon, 17 Jun 2013 10:19:34 +0100</updated>
                            <resolved>Wed, 23 Jun 2010 21:26:04 +0100</resolved>
                                    <version>10.4.1.3</version>
                    <version>10.4.2.0</version>
                    <version>10.4.2.1</version>
                    <version>10.5.1.1</version>
                    <version>10.5.2.0</version>
                    <version>10.5.3.0</version>
                    <version>10.6.1.0</version>
                                    <fixVersion>10.4.2.1</fixVersion>
                    <fixVersion>10.5.3.1</fixVersion>
                    <fixVersion>10.6.2.1</fixVersion>
                    <fixVersion>10.7.1.1</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="12873123" author="mamtas" created="Fri, 28 May 2010 20:35:47 +0100"  >&lt;p&gt;I see that this fails even with 10.4.2.1 Prior to 10.4, it was to define a unique constraint, one also was required to define it not null column.  So, the above test case does not work prior to 10.4 unless the create table is defined as CREATE TABLE TABLE1(NAME1 INT UNIQUE NOT NULL); &lt;/p&gt;

&lt;p&gt;But starting with 10.4, the above test case indeed fails. It has something to do with allow a column to be unique without requiring it to be non-null. Haven&apos;t looked at the cause of failure in the code yet.&lt;/p&gt;</comment>
                            <comment id="12875166" author="mamtas" created="Thu, 3 Jun 2010 16:56:38 +0100"  >&lt;p&gt;Just to be little more clear, if the index is non-nullable, then compress does not break it. I tested this on 10.1 and onwards upto trunk, So the behavior for non-nullable indexes hasn&apos;t changed. &lt;/p&gt;

&lt;p&gt;Nullable indexes on the other hand do not work after compress. Nullable indexes must have been introduced in 10.4 because such an index can&apos;t be created prior to 10.4. But doing a compress on table with nullable index appear to break those indexes. I will look into the code to see what is going on.&lt;/p&gt;</comment>
                            <comment id="12875310" author="mamtas" created="Thu, 3 Jun 2010 22:45:05 +0100"  >&lt;p&gt;For compress table, code in AlterTableConstantAction kicks in to drop and recreate the indexes. When recreating the indexes, we forgot to take into account the property &quot;uniqueWithDuplicateNulls&quot; when asking store to recreate the index. For a new nullable index, CreateIndexConstantAction has following code for dbs at 10.4 and higher levels&lt;br/&gt;
	indexProperties.put( &quot;uniqueWithDuplicateNulls&quot;, Boolean.toString(true));&lt;br/&gt;
But in AlterTableConstantAction, we did not check if the index is of type nullable unique and never set the property&lt;br/&gt;
&quot;uniqueWithDuplicateNulls&quot;.&lt;/p&gt;

&lt;p&gt;Following simple code change in AlterTableConstantActionhas fixed the problem, but the bigger issue is there might be databases lying around with duplicate values when the user thought that unique indexes were defined on their tables.&lt;br/&gt;
	if(cd.getIndexDescriptor().isUniqueWithDuplicateNulls())&lt;/p&gt;
	{
		properties.put( &quot;uniqueWithDuplicateNulls&quot;, Boolean.toString(true));
	}

&lt;p&gt;The other troubling issue is are there other places in the code where we have forgotten about this property while recreating the indexes.&lt;/p&gt;</comment>
                            <comment id="12875320" author="mikem" created="Thu, 3 Jun 2010 23:03:48 +0100"  >&lt;p&gt;What happened was that store basically was instructed to build a non-unique index, and it did so.  I agree with the proposed fix, and will review when a patch is submitted.&lt;/p&gt;

&lt;p&gt;Note that this fix only will correct the issue for future compress calls.  Whatever has happened in the past will remain broken, until the user takes&lt;br/&gt;
some action.  It will be hard to determine if the broken index exists.  One&lt;br/&gt;
can run a query to see if a candidate index exists (basically is there a unique&lt;br/&gt;
index that contains nullable columns), but I can&apos;t think of a generic way to &lt;br/&gt;
tell if compress has been run and broken the index.&lt;/p&gt;

&lt;p&gt;I believe if the user has not inserted any duplicates, than another call to offline compress using a version with the bug will fix the problem.&lt;/p&gt;

&lt;p&gt;If the user has inserted duplicate data into the index after compress broke&lt;br/&gt;
the index, then automatic cleanup is not going to work.  Once a fix has&lt;br/&gt;
been proposed we should verify the error that arises in this case.  And also verify that in this case the compress gets at least a statement level error backing out whatever the intermediate work that was done before failing.  Maybe &lt;br/&gt;
we can even catch the exception at appropriate places in the code and&lt;br/&gt;
raise a new error giving instructions on what needs to be done.&lt;/p&gt;</comment>
                            <comment id="12875323" author="mikem" created="Thu, 3 Jun 2010 23:11:32 +0100"  >&lt;p&gt;I did a quick search in the execute directory and there looks like there are two other cases in InsertResultSet, involving the bulk insert and bulk replace optimizations.  It would be good if test cases for these paths were also generated.  I think this means that we could also have broke the indexes on a insert as select into an empty table.  &lt;/p&gt;

&lt;p&gt;I looked at all the other places in the code that set &quot;nUniqueColumns&quot; and did not see any other problems.&lt;/p&gt;</comment>
                            <comment id="12875485" author="mamtas" created="Fri, 4 Jun 2010 06:10:16 +0100"  >&lt;p&gt;I wanted to try out the case where because of the bug in Derby, you are able to insert duplicate rows after compress table even though the table has unique nullable index defined on it. Next, I fixed the Derby code to properly copy the unique nullable property during index recreation time of the compress table process. I ran the buggy database with the new Derby code on my machine. First I inserted more duplicate rows(because store still thinks the index is not unique from the compress earlier with the buggy Derby version), and then did compress on the table. After this compress, I can&apos;t insert any more duplicate row. Interestingly enough though, no errors were raised during compress because of the duplicate rows. I will look into the code why we do not run into problems during index recreation when there are duplicate rows in the table.&lt;/p&gt;

&lt;p&gt; Following are the exact steps followed for this testing&lt;/p&gt;

&lt;p&gt;Build Derby code based on the trunk codeline. This Derby version has the bug which allows duplicate rows after compress table. Use this buggy Derby version to run following ij scripts which shows that duplicate rows are allowed&lt;br/&gt;
$ java -Dij.exceptionTrace=true org.apache.derby.tools.ij&lt;br/&gt;
ij version 10.7&lt;br/&gt;
ij&amp;gt; connect &apos;jdbc:derby:testDB4677;create=true&apos;;&lt;br/&gt;
ij&amp;gt; CREATE TABLE TABLE1(NAME1 INT UNIQUE);&lt;br/&gt;
0 rows inserted/updated/deleted&lt;br/&gt;
ij&amp;gt; CALL SYSCS_UTIL.SYSCS_COMPRESS_TABLE(&apos;APP&apos;, &apos;TABLE1&apos;, 1);&lt;br/&gt;
0 rows inserted/updated/deleted&lt;br/&gt;
ij&amp;gt; INSERT INTO TABLE1(NAME1) VALUES(1);&lt;br/&gt;
1 row inserted/updated/deleted&lt;br/&gt;
ij&amp;gt; INSERT INTO TABLE1(NAME1) VALUES(1);&lt;br/&gt;
1 row inserted/updated/deleted&lt;br/&gt;
ij&amp;gt; SELECT * FROM TABLE1;&lt;br/&gt;
NAME1&lt;br/&gt;
-----------&lt;br/&gt;
1&lt;br/&gt;
1&lt;/p&gt;

&lt;p&gt;2 rows selected&lt;br/&gt;
ij&amp;gt; exit;&lt;/p&gt;

&lt;p&gt;Notice the duplicate rows in TABLE1 in the above ij session.&lt;/p&gt;

&lt;p&gt;Next, in my trunk codeline, fix AlterTableConstantAction to use the unique nullable property during index recreation if the index was defined unique nullable. This is done when the table is compressed. &lt;/p&gt;

&lt;p&gt;When I run the above db with this fixed code, it first allows duplicate row creations because I have not yet run compress table. &lt;br/&gt;
$ java -Dij.exceptionTrace=true org.apache.derby.tools.ij&lt;br/&gt;
ij version 10.7&lt;br/&gt;
ij&amp;gt; connect &apos;jdbc:derby:testDB4677;create=true&apos;;&lt;br/&gt;
WARNING 01J01: Database &apos;testDB4677&apos; not created, connection made to existing da&lt;br/&gt;
tabase instead.&lt;br/&gt;
ij&amp;gt; INSERT INTO TABLE1(NAME1) VALUES(1);&lt;br/&gt;
1 row inserted/updated/deleted&lt;br/&gt;
ij&amp;gt; SELECT * FROM TABLE1;&lt;br/&gt;
NAME1&lt;br/&gt;
-----------&lt;br/&gt;
1&lt;br/&gt;
1&lt;br/&gt;
1&lt;/p&gt;

&lt;p&gt;3 rows selected&lt;/p&gt;

&lt;p&gt;But once I do compress table, now we start disallowing creation of further duplicate rows. &lt;br/&gt;
ij&amp;gt; CALL SYSCS_UTIL.SYSCS_COMPRESS_TABLE(&apos;APP&apos;, &apos;TABLE1&apos;, 1);&lt;br/&gt;
0 rows inserted/updated/deleted&lt;br/&gt;
ij&amp;gt; SELECT * FROM TABLE1;&lt;br/&gt;
NAME1&lt;br/&gt;
-----------&lt;br/&gt;
1&lt;br/&gt;
1&lt;br/&gt;
1&lt;/p&gt;

&lt;p&gt;3 rows selected&lt;br/&gt;
ij&amp;gt; INSERT INTO TABLE1(NAME1) VALUES(1);&lt;br/&gt;
ERROR 23505: The statement was aborted because it would have caused a duplicate key value in a unique or primary key constraint or unique index identified by &apos;SQL100603220123640&apos; defined on &apos;TABLE1&apos;.&lt;/p&gt;

&lt;p&gt;But I had thought that with my changes, the compress table operation would fail because of the duplicate rows but it does not fail. I will look further into this.&lt;/p&gt;</comment>
                            <comment id="12875522" author="mikem" created="Fri, 4 Jun 2010 09:03:56 +0100"  >&lt;p&gt;I thought it would fail also, maybe compress is optimized to not do the duplicate checking on index rebuild since it &quot;knows&quot; that there were no duplicates before.  I would concentrate on fixing the bugs first.   This behavior is probably not worth changing and we should come up with some other way to catch the bad duplicates that were inserted. One option would be a real drop and recreate of the index should find the problem.&lt;/p&gt;

&lt;p&gt;To track this down you could compare the code that is in create index to the code that is in alter table.  I think there is some call back that is used to check duplicates.&lt;/p&gt;</comment>
                            <comment id="12876369" author="mamtas" created="Mon, 7 Jun 2010 20:10:19 +0100"  >&lt;p&gt;I researched the code Create Index code and Alter Table code and found that for Create Index, we generate different SortObserver(s) depending on the type of the index. If it is a unique non-nullable index, then Create index creates UniqueIndexSortObserver. For a unique nullable index, it creates UniqueWithDuplicateNullsIndexSortObserver. For non-unique indexes, BasicSortObserver gets created. Alter Table on the other hand creates BasicSortObserver for all kinds of indexes and that is why the duplicates don&apos;t get caught for unique indexes. As Mike suggested, this may have been a conscious decision since the assumption was made that there were no duplicates before. &lt;/p&gt;

&lt;p&gt;For now, I will leave this assumption as it is. I will go and focus back on two InsertResultSet cases where we don&apos;t seem to be using uniqueWithDuplicateNulls. &lt;/p&gt;</comment>
                            <comment id="12877622" author="mamtas" created="Fri, 11 Jun 2010 00:16:07 +0100"  >&lt;p&gt;Attachine patch, DERBY4677_diff_patch1.txt, which involves transferring unique nullable properties from sql layer to store layer. System catalogs have the information correct, but unique nullability information was not getting transferred to store during btree recreation in case of compress table and bulk insert operations. Please share any comments you may have. Thanks&lt;/p&gt;</comment>
                            <comment id="12877631" author="mamtas" created="Fri, 11 Jun 2010 00:35:08 +0100"  >&lt;p&gt;Forgot to mention that I got one failure when I ran junit All suite. When I ran the replication suite by itself, I didn&apos;t see the failure again. Not sure if the following failure is a known intermittent failure. derbyall ran fine with no errors&lt;br/&gt;
1) testReplication_Local_1_Indexing(org.apache.derbyTesting.functionTests.tests.replicationTests.ReplicationRun_Local_1Indexing)junit.framework.ComparisonFailure: Unexpected SQL state. expected:&amp;lt;...0&amp;gt; but was:&amp;lt;...1&amp;gt;&lt;br/&gt;
	at org.apache.derbyTesting.junit.BaseJDBCTestCase.assertSQLState(BaseJDBCTestCase.java:762)&lt;br/&gt;
	at org.apache.derbyTesting.junit.BaseJDBCTestCase.assertSQLState(BaseJDBCTestCase.java:811)&lt;br/&gt;
	at org.apache.derbyTesting.functionTests.tests.replicationTests.ReplicationRun.failOver_direct(ReplicationRun.java:1385)&lt;br/&gt;
	at org.apache.derbyTesting.functionTests.tests.replicationTests.ReplicationRun.failOver(ReplicationRun.java:1314)&lt;br/&gt;
	at org.apache.derbyTesting.functionTests.tests.replicationTests.ReplicationRun_Local_1Indexing.testReplication_Local_1_Indexing(ReplicationRun_Local_1Indexing.java:97)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:48)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:37)&lt;br/&gt;
	at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:109)&lt;br/&gt;
	at org.apache.derbyTesting.functionTests.tests.replicationTests.ReplicationRun.runBare(ReplicationRun.java:207)&lt;br/&gt;
	at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)&lt;br/&gt;
	at junit.extensions.TestSetup$1.protect(TestSetup.java:19)&lt;br/&gt;
	at junit.extensions.TestSetup.run(TestSetup.java:16)&lt;br/&gt;
Caused by: java.sql.SQLException: DERBY SQL error: SQLCODE: -1, SQLSTATE: XRE21, SQLERRMC: Error occurred while performing failover for database &apos;C:\p4clients\svnmain\client4\trunk\systest\out142\db_master\wombat&apos;, Failover attempt was aborted.::SQLSTATE: XRE04Connection lost for replicated database &apos;null&apos;.&lt;br/&gt;
	at org.apache.derby.client.am.SQLExceptionFactory40.getSQLException(SQLExceptionFactory40.java:96)&lt;br/&gt;
	at org.apache.derby.client.am.SqlException.getSQLException(SqlException.java:358)&lt;br/&gt;
	at org.apache.derby.jdbc.ClientDriver.connect(ClientDriver.java:149)&lt;br/&gt;
	at java.sql.DriverManager.getConnection(DriverManager.java:317)&lt;br/&gt;
	at java.sql.DriverManager.getConnection(DriverManager.java:273)&lt;br/&gt;
	at org.apache.derbyTesting.functionTests.tests.replicationTests.ReplicationRun.failOver_direct(ReplicationRun.java:1372)&lt;br/&gt;
	... 31 more&lt;br/&gt;
Caused by: org.apache.derby.client.am.SqlException: DERBY SQL error: SQLCODE: -1, SQLSTATE: XRE21, SQLERRMC: Error occurred while performing failover for database &apos;C:\p4clients\svnmain\client4\trunk\systest\out142\db_master\wombat&apos;, Failover attempt was aborted.::SQLSTATE: XRE04Connection lost for replicated database &apos;null&apos;.&lt;br/&gt;
	at org.apache.derby.client.am.Connection.completeSqlca(Connection.java:2118)&lt;br/&gt;
	at org.apache.derby.client.net.NetConnectionReply.parseRdbAccessFailed(NetConnectionReply.java:541)&lt;br/&gt;
	at org.apache.derby.client.net.NetConnectionReply.parseAccessRdbError(NetConnectionReply.java:434)&lt;br/&gt;
	at org.apache.derby.client.net.NetConnectionReply.parseACCRDBreply(NetConnectionReply.java:297)&lt;br/&gt;
	at org.apache.derby.client.net.NetConnectionReply.readAccessDatabase(NetConnectionReply.java:121)&lt;br/&gt;
	at org.apache.derby.client.net.NetConnection.readSecurityCheckAndAccessRdb(NetConnection.java:834)&lt;br/&gt;
	at org.apache.derby.client.net.NetConnection.flowSecurityCheckAndAccessRdb(NetConnection.java:758)&lt;br/&gt;
	at org.apache.derby.client.net.NetConnection.flowUSRIDONLconnect(NetConnection.java:591)&lt;br/&gt;
	at org.apache.derby.client.net.NetConnection.flowConnect(NetConnection.java:398)&lt;br/&gt;
	at org.apache.derby.client.net.NetConnection.&amp;lt;init&amp;gt;(NetConnection.java:218)&lt;br/&gt;
	at org.apache.derby.client.net.NetConnection40.&amp;lt;init&amp;gt;(NetConnection40.java:77)&lt;br/&gt;
	at org.apache.derby.client.net.ClientJDBCObjectFactoryImpl40.newNetConnection(ClientJDBCObjectFactoryImpl40.java:269)&lt;br/&gt;
	at org.apache.derby.jdbc.ClientDriver.connect(ClientDriver.java:83)&lt;br/&gt;
	... 34 more&lt;/p&gt;</comment>
                            <comment id="12877966" author="mikem" created="Fri, 11 Jun 2010 22:11:21 +0100"  >&lt;p&gt;I have reviewed the  	DERBY4677_diff_patch1.txt patch, and the fix and the tests look good to me.  +1 on committing it to trunk and after it passes tests across platforms backporting as appropriate.&lt;/p&gt;

&lt;p&gt;There should be a good release note describing the corruption and that the fix does not actually fix the existing problems, just stops it from happening in the future.  Seems like a drop and recreate of unique indexes on nullable columns is only guaranteed way to fix existing issues.  And the recreate index will fail if the bug has allowed unique violations.  There may be a query one can write to identify unique violations, but it may be tricky as DERBY may optimize based on &quot;knowing&quot; there can&apos;t be unique violations.  &lt;/p&gt;</comment>
                            <comment id="12878704" author="mamtas" created="Mon, 14 Jun 2010 20:10:16 +0100"  >&lt;p&gt;Attaching the release note. Please let me know if there are any comments to it.&lt;/p&gt;</comment>
                            <comment id="12879681" author="mamtas" created="Thu, 17 Jun 2010 07:08:40 +0100"  >&lt;p&gt;Committed changes into trunk(revision 954544) and 10.5(revision  955487) so far. Working on backporting to other affected codelines.&lt;/p&gt;</comment>
                            <comment id="12880006" author="mamtas" created="Fri, 18 Jun 2010 00:44:50 +0100"  >&lt;p&gt;Backported change into 10.6 codeline with revision 955790.&lt;/p&gt;</comment>
                            <comment id="12880887" author="mamtas" created="Mon, 21 Jun 2010 17:38:06 +0100"  >&lt;p&gt;Attaching an updated release note. Please review to see if you have any comments.&lt;/p&gt;

&lt;p&gt;Also, a little bit more information on the stored procedures that would cause this bug to allow duplicates.&lt;br/&gt;
  A unique nullable index can be defined in one of the following 2 ways&lt;br/&gt;
	CREATE TABLE TABLE1(NAME1 INT UNIQUE); &lt;br/&gt;
		OR&lt;br/&gt;
	CREATE TABLE TABLE1(NAME1 INT constraint uniq_null UNIQUE); &lt;/p&gt;

&lt;p&gt;A table compress can be done using procedure. SYSCS_UTIL.SYSCS_COMPRESS_TABLE. eg&lt;br/&gt;
	CALL SYSCS_UTIL.SYSCS_COMPRESS_TABLE(&apos;APP&apos;, &apos;TABLE1&apos;, 1)&lt;/p&gt;

&lt;p&gt; A bulk insert into a table can be done using procedure SYSCS_UTIL.SYSCS_IMPORT_TABLE. The bulk insert can either REPLACE the existing contents of the table or it can add to the existing contents of the table. The intention of which bulk insert is intended is indicated by the last parameter to the procedure call. &lt;br/&gt;
	eg of bulk insert with REPLACE option&lt;br/&gt;
	call SYSCS_UTIL.SYSCS_IMPORT_TABLE(&apos;APP&apos;, &apos;TABLE1&apos; , &apos;data.txt&apos; , null, null, &apos;utf-8&apos;, 1)&lt;br/&gt;
	eg of bulk insert with INSERT option&lt;br/&gt;
	call SYSCS_UTIL.SYSCS_IMPORT_TABLE(&apos;APP&apos;, &apos;TABLE1&apos; , &apos;data.txt&apos; , null, null, &apos;utf-8&apos;, 0)&lt;br/&gt;
Bulk insert caused problems with unique nullable indexes only for the following 2 scenarios&lt;br/&gt;
1)When bulk insert with REPLACE is being done with 0 rows from the data file. It does not matter if the table was empty before bulk insert with REPLACE.&lt;br/&gt;
2)When bulk insert with INSERT is being done on an empty table with multiple rows from the data file.&lt;/p&gt;</comment>
                            <comment id="12881165" author="knutanders" created="Tue, 22 Jun 2010 12:03:40 +0100"  >&lt;p&gt;Hi Mamta,&lt;/p&gt;

&lt;p&gt;The release note looks good to me. Thanks for writing it. Two small comments:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;I think the summary is supposed to be a one-liner. I suggest that it is changed to &quot;Unique nullable constraint may be disabled after compress or import operations&quot; and that the details are moved to the sections below.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;typo: &quot;may find that duplicates rows exist&quot; - duplicates -&amp;gt; duplicate&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12881853" author="mamtas" created="Wed, 23 Jun 2010 21:17:43 +0100"  >&lt;p&gt;Attaching another update to release note based on the feedback from Knut.&lt;/p&gt;
</comment>
                            <comment id="12882856" author="knutanders" created="Sat, 26 Jun 2010 18:01:16 +0100"  >&lt;p&gt;Thanks, Mamta!&lt;/p&gt;</comment>
                            <comment id="12907397" author="lilywei" created="Wed, 8 Sep 2010 21:11:35 +0100"  >&lt;p&gt;Change the reference 10.4.2.1 from 10.4.x.x per Rick&apos;s suggestion for release note 10.6.2.0 (refer &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-4878&quot; title=&quot;Silence sanity info message when running &amp;quot;ant -q&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-4878&quot;&gt;&lt;del&gt;DERBY-4878&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;</comment>
                            <comment id="13685287" author="knutanders" created="Mon, 17 Jun 2013 10:19:34 +0100"  >&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;bulk update&amp;#93;&lt;/span&gt; Close all resolved issues that haven&apos;t been updated for more than one year.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12446809" name="DERBY4677_diff_patch1.txt" size="8851" author="mamtas" created="Fri, 11 Jun 2010 00:16:07 +0100"/>
                            <attachment id="12446810" name="DERBY4677_stat_patch1.txt" size="370" author="mamtas" created="Fri, 11 Jun 2010 00:16:07 +0100"/>
                            <attachment id="12454149" name="releaseNote.html" size="3891" author="lilywei" created="Wed, 8 Sep 2010 21:11:35 +0100"/>
                            <attachment id="12447876" name="releaseNote.html" size="3891" author="mamtas" created="Wed, 23 Jun 2010 21:17:43 +0100"/>
                            <attachment id="12447606" name="releaseNote.html" size="3979" author="mamtas" created="Mon, 21 Jun 2010 17:38:06 +0100"/>
                            <attachment id="12447055" name="releaseNote.html" size="4018" author="mamtas" created="Mon, 14 Jun 2010 20:10:16 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310200" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Bug behavior facts</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10364"><![CDATA[Data corruption]]></customfieldvalue>
    <customfieldvalue key="10367"><![CDATA[Deviation from standard]]></customfieldvalue>
    <customfieldvalue key="10421"><![CDATA[Seen in production]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 28 May 2010 19:35:47 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>24405</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310090" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Issue &amp; fix info</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10101"><![CDATA[Release Note Needed]]></customfieldvalue>
    <customfieldvalue key="10424"><![CDATA[Repro attached]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy0oyv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>37863</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            </customfields>
    </item>
</channel>
</rss>