<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:09:16 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-3347/DERBY-3347.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-3347] ERROR XSDB3: Container information cannot change once written</title>
                <link>https://issues.apache.org/jira/browse/DERBY-3347</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;We are using derby as an embedded DB for our data collection server. During an endurance test when we do around 270 inserts and 9 updates per second, for about a week, I ocasionally see the error below in the deby log (and nothing else beside this).&lt;/p&gt;

&lt;p&gt;This is a vanilla installation, we run derby embedded with no extra configuration.  I can confirm that there is no memory problem, the heap usage seems constant over time.&lt;/p&gt;

&lt;p&gt;Can somebody provide some more information regarding the effects of this error? By looking at the stacktrace, it looks like a checkpoint operation is aborted due to some inconsistency in the internal data structure. If the error does not repeat immediately, does it mean that the next checkpoint is successful and there is no data loss? &lt;/p&gt;

&lt;p&gt;I can&apos;t provide a test case for that, the error happens after about 1-2 day of running our software. I will rerun the test with the debug jars to capture the line numbers in the stacktrace.  Also, I&apos;m starting another test with 10.2.2.0, to see if this problem was introduced in the latest version.&lt;/p&gt;

&lt;p&gt;There are another two bugs referring to this error, (&lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-2284&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/DERBY-2284&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3087&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/DERBY-3087&lt;/a&gt;) but they seem to happen in response to some client action. This use case is a bit different, the client keeps inserting and updating records for several days in a steady manner and at some point the error pops up.&lt;/p&gt;


&lt;p&gt;And lastly, here is the exception:&lt;/p&gt;


&lt;p&gt;Checkpoint Daemon caught standard exception&lt;/p&gt;

&lt;p&gt;------------  BEGIN ERROR STACK -------------&lt;/p&gt;

&lt;p&gt;ERROR XSDB3: Container information cannot change once written: was 0, now 80&lt;br/&gt;
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.AllocPage.WriteContainerInfo(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.FileContainer.writeHeader(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.RAFContainer.writeRAFHeader(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.RAFContainer.clean(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.services.cache.CachedItem.clean(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.services.cache.Clock.cleanCache(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.services.cache.Clock.cleanAll(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.checkpoint(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.log.LogToFile.checkpointWithTran(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.log.LogToFile.checkpoint(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.RawStore.checkpoint(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.log.LogToFile.performWork(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.services.daemon.BasicDaemon.serviceClient(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.services.daemon.BasicDaemon.work(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:619)&lt;/p&gt;


&lt;p&gt;------------  END ERROR STACK -------------&lt;/p&gt;
</description>
                <environment>Windows 2003 Server&lt;br/&gt;
Sun Java 1.6.0_03</environment>
        <key id="12386981">DERBY-3347</key>
            <summary>ERROR XSDB3: Container information cannot change once written</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="knutanders">Knut Anders Hatlen</assignee>
                                    <reporter username="bcalmac">Bogdan Calmac</reporter>
                        <labels>
                    </labels>
                <created>Wed, 23 Jan 2008 22:36:18 +0000</created>
                <updated>Fri, 21 Jan 2011 17:51:20 +0000</updated>
                            <resolved>Mon, 14 Apr 2008 11:17:04 +0100</resolved>
                                    <version>10.3.1.4</version>
                    <version>10.3.2.1</version>
                                    <fixVersion>10.3.3.0</fixVersion>
                    <fixVersion>10.4.1.3</fixVersion>
                    <fixVersion>10.5.1.1</fixVersion>
                                    <component>Store</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12562082" author="bcalmac" created="Thu, 24 Jan 2008 14:39:29 +0000"  >&lt;p&gt;All right, I was able to reproduce the problem using the debug jars for 10.3.2.1, the error happened 4 times over last night. The 10.2.2.0 test went fine so far, so this might be a problem introduced in 10.3. Another thing I want to mention is that the test runs on a quad core CPU, so this could be a concurrency issue. And now here is the stacktrace with line numbers:&lt;/p&gt;

&lt;p&gt;Checkpoint Daemon caught standard exception&lt;/p&gt;

&lt;p&gt;------------  BEGIN ERROR STACK -------------&lt;/p&gt;

&lt;p&gt;ERROR XSDB3: Container information cannot change once written: was 0, now 80&lt;br/&gt;
	at org.apache.derby.iapi.error.StandardException.newException(StandardException.java:301)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.AllocPage.WriteContainerInfo(AllocPage.java:575)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.FileContainer.writeHeader(FileContainer.java:900)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.RAFContainer.writeRAFHeader(RAFContainer.java:690)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.RAFContainer.clean(RAFContainer.java:534)&lt;br/&gt;
	at org.apache.derby.impl.services.cache.CachedItem.clean(CachedItem.java:173)&lt;br/&gt;
	at org.apache.derby.impl.services.cache.Clock.cleanCache(Clock.java:1381)&lt;br/&gt;
	at org.apache.derby.impl.services.cache.Clock.cleanAll(Clock.java:619)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.checkpoint(BaseDataFileFactory.java:1202)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.log.LogToFile.checkpointWithTran(LogToFile.java:1521)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.log.LogToFile.checkpoint(LogToFile.java:1360)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.RawStore.checkpoint(RawStore.java:440)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.log.LogToFile.performWork(LogToFile.java:3411)&lt;br/&gt;
	at org.apache.derby.impl.services.daemon.BasicDaemon.serviceClient(BasicDaemon.java:331)&lt;br/&gt;
	at org.apache.derby.impl.services.daemon.BasicDaemon.work(BasicDaemon.java:668)&lt;br/&gt;
	at org.apache.derby.impl.services.daemon.BasicDaemon.run(BasicDaemon.java:394)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:619)&lt;/p&gt;


&lt;p&gt;------------  END ERROR STACK -------------&lt;/p&gt;</comment>
                            <comment id="12562101" author="knutanders" created="Thu, 24 Jan 2008 15:36:33 +0000"  >&lt;p&gt;Just guessing here... The numbers 0 and 80 make me suspect that this is an issue with borrowedSpace. I think those are the only valid values for borrowedSpace. &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3099&quot; title=&quot;Possible bug in interaction with buffer manager causing pages not to be freed on rollback to savepoint&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3099&quot;&gt;&lt;del&gt;DERBY-3099&lt;/del&gt;&lt;/a&gt; made some changes to the space calculation in AllocPage and may be the culprit. It was introduced in 10.3.2.1. Though, &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-2284&quot; title=&quot;OnlineBackupTest1 fails with ERROR XSDB3: Container information cannot change once written: was 0, now 80&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-2284&quot;&gt;&lt;del&gt;DERBY-2284&lt;/del&gt;&lt;/a&gt; is reported against 10.3.1.4, so it might be something else that&apos;s causing it. Bogdan, is it possible for you to run with Derby 10.3.1.4 and see if the same happens there?&lt;/p&gt;

&lt;p&gt;There is also another bug, &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3116&quot; title=&quot;totalSpace not properly initialized in AllocPage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3116&quot;&gt;&lt;del&gt;DERBY-3116&lt;/del&gt;&lt;/a&gt;, which mentions incorrect space calculation involving borrowedSpace. It has a patch attached. If it&apos;s not too much trouble for you, it would be very interesting if you could download the 10.3.2.1 sources, apply the &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3116&quot; title=&quot;totalSpace not properly initialized in AllocPage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3116&quot;&gt;&lt;del&gt;DERBY-3116&lt;/del&gt;&lt;/a&gt; patch and see if that fixes your problem.&lt;/p&gt;</comment>
                            <comment id="12562136" author="bcalmac" created="Thu, 24 Jan 2008 17:20:04 +0000"  >&lt;p&gt;Sure, I&apos;ll go ahead with your suggestions and let you know how it goes.&lt;/p&gt;</comment>
                            <comment id="12563169" author="bcalmac" created="Mon, 28 Jan 2008 15:31:22 +0000"  >&lt;p&gt;All right, I&apos;ve run the endurance test for 10.3.1.4 and 10.3.2.1 + 3116 and the error is still there, numerous times. &lt;/p&gt;

&lt;p&gt;This is a pretty serious issue in terms of reliability. Another thing is that after a bunch of these errors the server blows up with JDBC exceptions (probably because the failed checkpoints).&lt;/p&gt;</comment>
                            <comment id="12563467" author="knutanders" created="Tue, 29 Jan 2008 10:57:46 +0000"  >&lt;p&gt;Thanks for taking the time to run these experiments, Bogdan!&lt;/p&gt;

&lt;p&gt;At least, now we know the problem is not caused by &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3099&quot; title=&quot;Possible bug in interaction with buffer manager causing pages not to be freed on rollback to savepoint&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3099&quot;&gt;&lt;del&gt;DERBY-3099&lt;/del&gt;&lt;/a&gt; or &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3116&quot; title=&quot;totalSpace not properly initialized in AllocPage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3116&quot;&gt;&lt;del&gt;DERBY-3116&lt;/del&gt;&lt;/a&gt;, and we know that it must have been introduced some time after 10.2.2.0 and before 10.3.1.4.&lt;/p&gt;

&lt;p&gt;One thing I know was changed in that area of the code in that period, is that RAFContainer started using java.nio.* to allow parallel reads and writes on JVMs that support nio. It is possible to force the use of the old mechanism by deleting or commenting out the following lines in java/engine/org/apache/derby/modules.properties and rebuilding derby.jar:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;store data using a StorageFactory&lt;/li&gt;
	&lt;li&gt;Enhanced version using NIO API; requires Java 1.4&lt;br/&gt;
derby.module.rawStore.data.genericJ4=org.apache.derby.impl.store.raw.data.BaseDataFileFactoryJ4&lt;br/&gt;
derby.env.jdk.rawStore.data.genericJ4=4&lt;br/&gt;
derby.env.classes.rawStore.data.genericJ4=java.nio.Buffer&lt;br/&gt;
cloudscape.config.rawStore.data.genericJ4=derby&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;It would be great if you could make that change and rerun your test.&lt;/p&gt;</comment>
                            <comment id="12564546" author="knutanders" created="Thu, 31 Jan 2008 23:24:46 +0000"  >&lt;p&gt;Marking the issue as a regression since it is reported to work on Derby 10.2.2.0.&lt;/p&gt;</comment>
                            <comment id="12564970" author="bcalmac" created="Fri, 1 Feb 2008 23:03:14 +0000"  >&lt;p&gt;I&apos;ve started the test for 10.3.2.1 without NIO and in the first 8 hours I got the exception below. I will have to stop the test tonight and restart it on Monday. I&apos;ll keep you posted how it goes.&lt;/p&gt;

&lt;p&gt;2008-02-01 20:31:59.903 GMT Thread&lt;span class=&quot;error&quot;&gt;&amp;#91;derby.rawStoreDaemon,5,derby.daemons&amp;#93;&lt;/span&gt; Cleanup action starting&lt;br/&gt;
java.lang.NullPointerException&lt;br/&gt;
	at org.apache.derby.impl.store.access.btree.ControlRow.getControlRowForPage(ControlRow.java:878)&lt;br/&gt;
	at org.apache.derby.impl.store.access.btree.ControlRow.get(ControlRow.java:844)&lt;br/&gt;
	at org.apache.derby.impl.store.access.btree.ControlRow.get(ControlRow.java:820)&lt;br/&gt;
	at org.apache.derby.impl.store.access.btree.BTreePostCommit.purgeRowLevelCommittedDeletes(BTreePostCommit.java:462)&lt;br/&gt;
	at org.apache.derby.impl.store.access.btree.BTreePostCommit.performWork(BTreePostCommit.java:278)&lt;br/&gt;
	at org.apache.derby.impl.services.daemon.BasicDaemon.serviceClient(BasicDaemon.java:331)&lt;br/&gt;
	at org.apache.derby.impl.services.daemon.BasicDaemon.work(BasicDaemon.java:668)&lt;br/&gt;
	at org.apache.derby.impl.services.daemon.BasicDaemon.run(BasicDaemon.java:394)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:619)&lt;br/&gt;
Cleanup action completed&lt;/p&gt;</comment>
                            <comment id="12571439" author="bcalmac" created="Fri, 22 Feb 2008 15:21:37 +0000"  >&lt;p&gt;Since 10.3.2.1 without NIO is not a tested combination as illustrated by the exception above (so I wouldn&apos;t use it in productions), I continued testing 10.3.2.1 and 10.2.2.0 side by side. &lt;/p&gt;

&lt;p&gt;One interesting thing that I noticed is that the test is successful if the maximum heap memory is small. With only 128M, 10.3.2.1 did not fail for a week. But with 800M (or 512M in the original tests) the error comes up consistently. Could it be related to weak/soft references?&lt;/p&gt;

&lt;p&gt;Is there somebody familiar enough with the code to try to look into this at code level? This seems like a pretty important reliability bug to me, so I will try to debug the code, but it will be a while before I become comfortable with the code base.&lt;/p&gt;</comment>
                            <comment id="12575880" author="dyret" created="Thu, 6 Mar 2008 20:44:27 +0000"  >&lt;p&gt;The call stack in your comment from 2008-02-01 looks like &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3362&quot; title=&quot;ControlRow NPE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3362&quot;&gt;&lt;del&gt;DERBY-3362&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12578061" author="kmarsden" created="Wed, 12 Mar 2008 23:00:37 +0000"  >&lt;p&gt;Bogden, can you try the latest on the 10.3 branch, now that &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3362&quot; title=&quot;ControlRow NPE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3362&quot;&gt;&lt;del&gt;DERBY-3362&lt;/del&gt;&lt;/a&gt; has been fixed&lt;br/&gt;
and see if you still see the problem?&lt;/p&gt;</comment>
                            <comment id="12578066" author="bcalmac" created="Wed, 12 Mar 2008 23:13:23 +0000"  >&lt;p&gt;Sure, I can try it, but &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3362&quot; title=&quot;ControlRow NPE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3362&quot;&gt;&lt;del&gt;DERBY-3362&lt;/del&gt;&lt;/a&gt; has probably nothing to do with the original problem. My comment from Feb 1st refers to another issue that prevented me from running the test.&lt;/p&gt;</comment>
                            <comment id="12578068" author="bcalmac" created="Wed, 12 Mar 2008 23:16:42 +0000"  >&lt;p&gt;Would it be valuable to still disable NIO at code level or should I use the unmodified 10.3 branch?&lt;/p&gt;</comment>
                            <comment id="12578070" author="kmarsden" created="Wed, 12 Mar 2008 23:19:20 +0000"  >&lt;p&gt;I think it would be valuable to try with NIO disabled.  As I understand it you were blocked from doing that experiment because of &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3362&quot; title=&quot;ControlRow NPE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3362&quot;&gt;&lt;del&gt;DERBY-3362&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12578075" author="bcalmac" created="Wed, 12 Mar 2008 23:36:06 +0000"  >&lt;p&gt;Yes, that is correct. OK.&lt;/p&gt;</comment>
                            <comment id="12581535" author="bcalmac" created="Mon, 24 Mar 2008 13:55:56 +0000"  >&lt;p&gt;I have run my test for a week with the 10.3.2.1 SVN and NIO disabled and the error did not occur. So then we can throw a guess that the issue is related to concurrency in the new code based on NIO.&lt;/p&gt;</comment>
                            <comment id="12584749" author="kmarsden" created="Wed, 2 Apr 2008 21:06:07 +0100"  >&lt;p&gt;There is another user that may be hitting this same issue.  The trace is &lt;br/&gt;
ERROR XSDB3: Container information cannot change once written: was 0, now 80&lt;br/&gt;
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.AllocPage.WriteContainerInfo(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.FileContainer.writeHeader(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.RAFContainer.writeRAFHeader(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.RAFContainer.clean(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.services.cache.CachedItem.clean(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.services.cache.Clock.cleanCache(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.services.cache.Clock.cleanAll(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.checkpoint(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.log.LogToFile.checkpointWithTran(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.log.LogToFile.checkpoint(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.RawStore.checkpoint(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.log.LogToFile.performWork(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.services.daemon.BasicDaemon.serviceClient(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.services.daemon.BasicDaemon.work(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:801)&lt;/p&gt;

&lt;p&gt;Would it be worthwhile to have a runtime option (something you can put in the derby.properties) to disable NIO or does anyone have ideas on how to proceed with this issue?&lt;/p&gt;</comment>
                            <comment id="12584834" author="myrna" created="Wed, 2 Apr 2008 23:14:31 +0100"  >&lt;p&gt;I&apos;d think an option to disable the NIO as a workaround until something better can be found may be helpful to the users hitting this. (Although possibly not so helpful to whomever will pick this up to fix).&lt;/p&gt;</comment>
                            <comment id="12586767" author="knutanders" created="Tue, 8 Apr 2008 12:54:43 +0100"  >&lt;p&gt;I think I see how this can happen.&lt;/p&gt;

&lt;p&gt;When we read or write through the page cache, we use FileChannels to&lt;br/&gt;
allow multiple threads to access the same data file in parallel (after&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-801&quot; title=&quot;Allow parallel access to data files.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-801&quot;&gt;&lt;del&gt;DERBY-801&lt;/del&gt;&lt;/a&gt;). The first alloc page in a file can also be accessed&lt;br/&gt;
directly by the container object (via the container cache), in which&lt;br/&gt;
case RandomAccessFile.seek() + read/write is used instead of&lt;br/&gt;
FileChannel.&lt;/p&gt;

&lt;p&gt;Theoretically, this should work because the FileChannel operations use&lt;br/&gt;
absolute positions and should therefore not influence the positioning&lt;br/&gt;
of the read/write performed by the container object, and&lt;br/&gt;
synchronization ensures that RAF.seek+read/write only happens in one&lt;br/&gt;
thread at a time. However, it seems like on some platforms&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; the&lt;br/&gt;
position of the RandomAccessFile object can be changed when operations&lt;br/&gt;
using absolute positioning are performed on the FileChannel object&lt;br/&gt;
returned by getChannel() on the RAF. I guess this is to be expected,&lt;br/&gt;
since FileChannel&apos;s javadoc only guarantees that the operations on a&lt;br/&gt;
FileChannel object are thread safe, not that a mix of operations on&lt;br/&gt;
FileChannel objects and RandomAccessFile objects is thread safe.&lt;/p&gt;

&lt;p&gt;So what I think is happening, is that the check point code is cleaning&lt;br/&gt;
the container cache. At the same time, the page cache initiates the&lt;br/&gt;
cleaning of a page in the same container as the container cache is&lt;br/&gt;
cleaning, resulting in a FileChannel operation which changes the&lt;br/&gt;
position of the RandomAccessFile used by the container cache. The&lt;br/&gt;
subsequent call to RandomAccessFile.readFully() therefore reads data&lt;br/&gt;
from the wrong position in the file. When the container cache later&lt;br/&gt;
attempts to write the data back to the file, the inconsistency is&lt;br/&gt;
detected and the XSDB3 error is raised.&lt;/p&gt;

&lt;p&gt;I believe that we can fix this issue by rewriting the parts that don&apos;t&lt;br/&gt;
yet use FileChannel, so that FileChannel is used consistently and the&lt;br/&gt;
thread-safety guarantees in FileChannel&apos;s javadoc apply.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; Some platforms == Windows. I&apos;ve also tested it on Linux and&lt;br/&gt;
Solaris, and there the position on the RandomAccessFile doesn&apos;t seem&lt;br/&gt;
to be affected by operations using absolute positions.&lt;/p&gt;</comment>
                            <comment id="12586787" author="thomanie" created="Tue, 8 Apr 2008 14:02:02 +0100"  >&lt;p&gt;Knut,&lt;/p&gt;

&lt;p&gt;Do you think that this, or a rather similar scenario, could also be the reason for some of the checksum inconsistencies that have been reported lately? &lt;br/&gt;
I&apos;m envisioning a scenario where instead of a parallel cache clean, there&apos;s a parallel flush and/or checksum calculation performed by the checkpoint and file cache, and ultimately causing the wrong checksum to be flushed to disk?&lt;/p&gt;

&lt;p&gt;Most inconsistencies seem to be related to windows, and different RandomAccessFile behaviour may possibly be the culprit?&lt;/p&gt;

&lt;p&gt;Just an idea...&lt;/p&gt;</comment>
                            <comment id="12586790" author="dyret" created="Tue, 8 Apr 2008 14:23:13 +0100"  >&lt;p&gt;Knut, I see that you have assigned yourself to this issue. Does that mean you have a fix in the pipe line? If it could be merged to 10.4 fairly soon, I think we should consider spinning another RC with this fix...&lt;/p&gt;</comment>
                            <comment id="12586801" author="knutanders" created="Tue, 8 Apr 2008 14:53:26 +0100"  >&lt;p&gt;Thomas:&lt;br/&gt;
&amp;gt; Do you think that this, or a rather similar scenario, could also be the reason for some of the checksum inconsistencies that have been reported lately?&lt;/p&gt;

&lt;p&gt;Yes, that could be the reason, at least if the checksum inconsistencies happen on page 0 (which is the first alloc page). There also are a lot of reports about EOFException thrown by RandomAccessFile.readFully() in FileContainer.getEmbryonicPage() (all seen on Windows only) which I think are likely caused by the same problem.&lt;/p&gt;

&lt;p&gt;Dyre: Yes, I have a patch in the pipeline. I haven&apos;t tested it yet, but I&apos;ll do so and post it tomorrow. I&apos;ll leave it up to you to decide whether it is worth a new RC. If it fixes these problems, I think it is worth it, but it is probably difficult to verify the fix that quickly.&lt;/p&gt;</comment>
                            <comment id="12586856" author="knutanders" created="Tue, 8 Apr 2008 16:51:44 +0100"  >&lt;p&gt;Here&apos;s a preview patch for those who are interested. It is not ready for commit (the regression tests haven&apos;t completed yet, the code needs more comments, and some old comments need to be updated), but it should give an impression of how I&apos;m planning to solve it. Basically, it factors out the occurrences of RandomAccessFile.seek()+read/write in FileChannel into separate methods that can be overridden by the RAFContainer4 class and replaced with FileChannel calls. I also needed to change the way RAFContainer4 initialized the field ourChannel, since with these changes it is too late to initialize it at the end of createContainer() and openContainer().&lt;/p&gt;</comment>
                            <comment id="12587104" author="knutanders" created="Wed, 9 Apr 2008 10:24:34 +0100"  >&lt;p&gt;Another related problem:&lt;/p&gt;

&lt;p&gt;Before &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-801&quot; title=&quot;Allow parallel access to data files.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-801&quot;&gt;&lt;del&gt;DERBY-801&lt;/del&gt;&lt;/a&gt;, there would be only one thread reading/writing the same data file at a time. After &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-801&quot; title=&quot;Allow parallel access to data files.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-801&quot;&gt;&lt;del&gt;DERBY-801&lt;/del&gt;&lt;/a&gt;, there could be many threads accessing the same data file concurrently, but this should be OK since they would access different pages (read/write to the same page will be serialized by BasePage.setExclusive()). There is however no mechanism, as far as I can see, that prevents concurrent updates of the container information in page 0 and normal page updates that touch page 0. So I think it is possible that updates to the container information section of page 0 are lost because concurrent updates of AllocPage 0 overwrite the new information with the old value. We probably need to find a way to prevent AllocPage 0 from being cleaned while the container is being cleaned (that is, RAFContainer4.writePage(pageId=0) and RAFContainer.writeRAFHeader() must be serialized somehow).&lt;/p&gt;</comment>
                            <comment id="12587111" author="knutanders" created="Wed, 9 Apr 2008 10:30:33 +0100"  >&lt;p&gt;The preview patch caused two failures in derbyall on Solaris 10 with JDK 6. unit/recoveryTest.unit and store/dropcrash2.java failed with an assert failure in AllocPage.ReadContainerInfo(): ASSERT FAILED N not what is expected : 0&lt;/p&gt;</comment>
                            <comment id="12587189" author="knutanders" created="Wed, 9 Apr 2008 14:38:24 +0100"  >&lt;p&gt;Attaching an updated preview patch, still not ready for commit. The updated patch fixes the assert failures seen in the recovery tests. The problem was that the new methods in RAFContainer4 used the FileChannel associated with RAFContainer.fileData instead of the FileChannel associated with the file argument. The fileData field and the file argument are normally the same object, but not when a container is stubbified, so redo of DROP TABLE operations would fail. Now the recovery tests pass.&lt;/p&gt;</comment>
                            <comment id="12587602" author="knutanders" created="Thu, 10 Apr 2008 12:39:36 +0100"  >&lt;p&gt;I&apos;ve added more comments and attached a new patch (d3347-1a) which is ready for review. It only addresses the problem with the mix of old-style I/O and NIO on some platforms. The problem with multiple threads accessing page 0 concurrently will have to be fixed in a follow-up patch.&lt;/p&gt;</comment>
                            <comment id="12587625" author="knutanders" created="Thu, 10 Apr 2008 13:53:47 +0100"  >&lt;p&gt;I&apos;m also attaching a patch (d3347-2a) for the problem with concurrent I/O operations on page 0.&lt;/p&gt;

&lt;p&gt;This patch adds a wrapper around the methods readPage() and writePage() in RAFContainer4. If the page that is accessed is FileContainer.FIRST_ALLOC_PAGE_NUMBER, the method calls are synchronized on the container object, and therefore behave just like their non-NIO counterparts in RAFContainer. Since the code that accesses the container information on the first alloc page also is synchronized on the container object, this means that we never have two threads accessing the first alloc page concurrently. For the rest of the pages, the synchronization is not necessary, since they can only be accessed through the page cache and therefore no two threads access the same page concurrently.&lt;/p&gt;

&lt;p&gt;I haven&apos;t run the regression tests on this patch yet.&lt;/p&gt;</comment>
                            <comment id="12587823" author="dagw" created="Fri, 11 Apr 2008 01:59:16 +0100"  >&lt;p&gt;I don&apos;t know this code area very well, so caveats apply &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Patch 1: Analysis that some read/writes use FileChannel to access&lt;br/&gt;
  first page while others use the RandomAccessFile methods directly&lt;br/&gt;
  (and hence no guarantee for serializability) seems correct to&lt;br/&gt;
  me. Refactoring to remedy that looks good.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;  The cleanup on use/initialization of FileChannel is good, too.&lt;/p&gt;

&lt;p&gt;  RAFContainer4#write has lost a check for getCommittedDropState(). Is&lt;br/&gt;
  this intentional?&lt;/p&gt;

&lt;p&gt;  Naming: FileContainer#readHeader doesn&apos;t do any reading any longer,&lt;br/&gt;
  since it no longer calls getEmbryonicPage. This is slightly&lt;br/&gt;
  confusing.&lt;/p&gt;

&lt;p&gt;  BTW: (not introduced by this patch, but I noticed so I thought I&apos;d&lt;br/&gt;
  mention it) RAFContainer4 (in contrast to RAFContainer) allocates an&lt;br/&gt;
  encryption buffer for every page write. Guess it needs to since the&lt;br/&gt;
  write method is not synchronized (and can thus not use the dedicated&lt;br/&gt;
  buffer safely). Since such objects can be large, maybe a pool would be good?&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Patch 2:&lt;br/&gt;
  Although after patch 1, writeRAFHeader always uses FileChannel I/O&lt;br/&gt;
  now, I agree there is a chance for the race you suggest. The patch&lt;br/&gt;
  is simple and looks good to me. &lt;br/&gt;
  +1&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Good detective work, Knut!&lt;/p&gt;
</comment>
                            <comment id="12587887" author="knutanders" created="Fri, 11 Apr 2008 09:50:31 +0100"  >&lt;p&gt;Thanks for reviewing the patch, Dag!&lt;/p&gt;

&lt;p&gt;&amp;gt; RAFContainer4#write has lost a check for getCommittedDropState(). Is&lt;br/&gt;
&amp;gt; this intentional?&lt;/p&gt;

&lt;p&gt;Good catch! No, it wasn&apos;t intentional. The new patch (1b) reintroduces the check, and also reintroduces the assert for !getCommittedDropState() in readPage().&lt;/p&gt;

&lt;p&gt;&amp;gt; Naming: FileContainer#readHeader doesn&apos;t do any reading any longer,&lt;br/&gt;
&amp;gt; since it no longer calls getEmbryonicPage. This is slightly&lt;br/&gt;
&amp;gt; confusing.&lt;/p&gt;

&lt;p&gt;Agreed, I think. Although the two methods it still invokes are called ReadContainerInfo() and readHeaderFromArray(), so I think there is some justification for keeping &quot;read&quot; in its name. If we come up with a better name, we can always rename it later.&lt;/p&gt;

&lt;p&gt;&amp;gt; BTW: (not introduced by this patch, but I noticed so I thought I&apos;d&lt;br/&gt;
&amp;gt; mention it) RAFContainer4 (in contrast to RAFContainer) allocates an&lt;br/&gt;
&amp;gt; encryption buffer for every page write. Guess it needs to since the&lt;br/&gt;
&amp;gt; write method is not synchronized (and can thus not use the dedicated&lt;br/&gt;
&amp;gt; buffer safely). Since such objects can be large, maybe a pool would be good?&lt;/p&gt;

&lt;p&gt;(I guess you meant &quot;every encrypted page write&quot;, not &quot;every page write&quot;...)&lt;/p&gt;

&lt;p&gt;Yes, that was also commented in the review of &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-801&quot; title=&quot;Allow parallel access to data files.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-801&quot;&gt;&lt;del&gt;DERBY-801&lt;/del&gt;&lt;/a&gt;, and &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-2086&quot; title=&quot;Build a resource pooling subsystem to facilitate object reuse and concurrency&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-2086&quot;&gt;&lt;del&gt;DERBY-2086&lt;/del&gt;&lt;/a&gt; was logged for it.&lt;/p&gt;</comment>
                            <comment id="12587889" author="knutanders" created="Fri, 11 Apr 2008 09:54:37 +0100"  >&lt;p&gt;The 1b patch replaces the 1a patch. It only contains one change: The checks/asserts for getCommittedDropState() are reintroduced in readPage()/writePage().&lt;/p&gt;</comment>
                            <comment id="12587898" author="knutanders" created="Fri, 11 Apr 2008 10:47:33 +0100"  >&lt;p&gt;I committed the 2a patch to trunk with revision 647091.&lt;/p&gt;

&lt;p&gt;I have started the regression tests on the 1b patch as well. The changes from 1a are minimal, so I plan to commit it if the tests pass.&lt;/p&gt;</comment>
                            <comment id="12587928" author="dagw" created="Fri, 11 Apr 2008 12:21:35 +0100"  >&lt;p&gt;&amp;gt; Agreed, I think. Although the two methods it still invokes are called&lt;br/&gt;
&amp;gt; ReadContainerInfo() and readHeaderFromArray(), so I think there is&lt;br/&gt;
&amp;gt; some justification for keeping &quot;read&quot; in its name. If we come up with&lt;br/&gt;
&amp;gt; a better name, we can always rename it later.&lt;/p&gt;

&lt;p&gt;Yes, I notices there are several existing methods in there that are&lt;br/&gt;
called read&amp;lt;Something&amp;gt; and write&amp;lt;Something&amp;gt; that do no I/O, but just&lt;br/&gt;
analyze or format bytes arrays. It would be good to cleanup this code&lt;br/&gt;
some, but I am OK with deferring for now.&lt;/p&gt;

&lt;p&gt;This comment in the StorageRandomAccessFile abstraction is also less&lt;br/&gt;
precise/correct after the advent of RAFContainer4 as a user of&lt;br/&gt;
StorageRandomAccessFile:&lt;/p&gt;

&lt;p&gt; &quot;An implementation of StorageRandomAccessFile need not be thread&lt;br/&gt;
 safe. The database engine single-threads access to each&lt;br/&gt;
 StorageRandomAccessFile instance. Two threads will not access the&lt;br/&gt;
 same StorageRandomAccessFile instance at the same time.&quot;&lt;/p&gt;

&lt;p&gt;After you reintroduced the getCommittedDropState checks,&lt;br/&gt;
+1 to the first patch as well!&lt;/p&gt;</comment>
                            <comment id="12587948" author="knutanders" created="Fri, 11 Apr 2008 13:52:31 +0100"  >&lt;p&gt;Thanks again, Dag. Patch 1b has been committed with revision 647139.&lt;/p&gt;

&lt;p&gt;I agree that the code and comments in this area would benefit from an overhaul. The abstractions in the original code were obviously chosen to match the RandomAccessFile way of accessing the data files, and the NIO code doesn&apos;t fit very well into that model. Some of the comments added as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-801&quot; title=&quot;Allow parallel access to data files.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-801&quot;&gt;&lt;del&gt;DERBY-801&lt;/del&gt;&lt;/a&gt; also mention that a restructuring of the interfaces would be beneficial.&lt;/p&gt;

&lt;p&gt;Regarding the comment in StorageRandomAccessFile, I think it&apos;s correct, actually. The only parts of a StorageRandomAccessFile that need to be thread safe, are the methods on the FileChannel object returned by the getChannel() method. However, the SRAF interface doesn&apos;t know anything about FileChannel or getChannel(), it&apos;s just RAFContainer4 that knows that some SRAF implementations are subclasses of java.io.RAF, and therefore manages to retrieve FileChannels from them. None of the SRAF methods are ever called concurrently on the same object.&lt;/p&gt;</comment>
                            <comment id="12587955" author="knutanders" created="Fri, 11 Apr 2008 14:04:52 +0100"  >&lt;p&gt;I guess we should try to back-port the fix at least to 10.4. It would be great if we could get the fix verified first, but lacking a reliable repro that may be difficult.&lt;/p&gt;</comment>
                            <comment id="12587989" author="dyret" created="Fri, 11 Apr 2008 15:45:17 +0100"  >&lt;p&gt;+1 to merging to 10.4 (I added 10.4.1.2 as a fix-version, and have canceled the ongoing vote on 10.4.1.1 on derby-dev). &lt;/p&gt;</comment>
                            <comment id="12588128" author="knutanders" created="Fri, 11 Apr 2008 22:18:04 +0100"  >&lt;p&gt;I have merged the fixes to the 10.4 branch (revisions 647310 and 647312).&lt;br/&gt;
I&apos;m leaving the issue open for now, since the fix hasn&apos;t been verified.&lt;/p&gt;</comment>
                            <comment id="12588145" author="bcalmac" created="Fri, 11 Apr 2008 22:56:11 +0100"  >&lt;p&gt;I can rerun my endurance test next week using 10.4.&lt;/p&gt;</comment>
                            <comment id="12588163" author="knutanders" created="Sat, 12 Apr 2008 00:04:52 +0100"  >&lt;p&gt;Thanks Bogdan, that would be great!&lt;/p&gt;</comment>
                            <comment id="12588198" author="kmarsden" created="Sat, 12 Apr 2008 05:29:57 +0100"  >&lt;p&gt;In working on another issue I hit this bug and thought I would post my program in case it can be expanded to become a more reliable reproduction.   You run it with the number of threads as an argument and might want to bump up memory e.g.&lt;/p&gt;

&lt;p&gt;java -Xmx512M MiniStress 50&lt;/p&gt;

&lt;p&gt;I ran the program once to the end without error and then reran on the same db and got the error.  I  haven&apos;t yet updated up to get the fix.  &lt;br/&gt;
I ran it on my dual core Windows XP box with Sun jdk 1.6.  Maybe on a box with more CPU&apos;s it will pop the bug more reliably.&lt;/p&gt;

&lt;p&gt;Here is the trace from the derby.log&lt;/p&gt;

&lt;p&gt;------------  BEGIN SHUTDOWN ERROR STACK -------------&lt;/p&gt;


&lt;p&gt;ERROR XSDG1: Page Page(1039,Container(0, 5856)) could not be written to disk, please check if disk is full.&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.iapi.error.StandardException.newException(StandardException.java:296)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.data.CachedPage.writePage(CachedPage.java:824)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.data.CachedPage.clean(CachedPage.java:605)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.services.cache.ConcurrentCache.cleanAndUnkeepEntry(ConcurrentCache.java:551)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.services.cache.ClockPolicy.rotateClock(ClockPolicy.java:476)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.services.cache.ClockPolicy.insertEntry(ClockPolicy.java:176)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.services.cache.ConcurrentCache.insertIntoFreeSlot(ConcurrentCache.java:208)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.services.cache.ConcurrentCache.find(ConcurrentCache.java:284)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.data.FileContainer.getUserPage(FileContainer.java:2412)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.data.FileContainer.getPage(FileContainer.java:2462)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.data.BaseContainerHandle.getPage(BaseContainerHandle.java:319)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.access.btree.ControlRow.get(ControlRow.java:833)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.access.btree.ControlRow.get(ControlRow.java:820)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.access.btree.BTreePostCommit.doShrink(BTreePostCommit.java:123)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.access.btree.BTreePostCommit.performWork(BTreePostCommit.java:249)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.xact.Xact.postTermination(Xact.java:2045)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.xact.Xact.completeCommit(Xact.java:818)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.xact.Xact.commit(Xact.java:854)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.xact.Xact.commit(Xact.java:649)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.access.RAMTransaction.commit(RAMTransaction.java:1964)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.sql.conn.GenericLanguageConnectionContext.doCommit(GenericLanguageConnectionContext.java:1211)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.sql.conn.GenericLanguageConnectionContext.userCommit(GenericLanguageConnectionContext.java:1031)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.jdbc.TransactionResourceImpl.commit(TransactionResourceImpl.java:237)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.jdbc.EmbedConnection.commit(EmbedConnection.java:1661)&lt;/p&gt;

&lt;p&gt;	at WorkerThread.run(WorkerThread.java:24)&lt;/p&gt;

&lt;p&gt;Caused by: java.nio.channels.ClosedChannelException&lt;/p&gt;

&lt;p&gt;	at sun.nio.ch.FileChannelImpl.ensureOpen(FileChannelImpl.java:91)&lt;/p&gt;

&lt;p&gt;	at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:642)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.data.RAFContainer4.writeFull(RAFContainer4.java:397)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.data.RAFContainer4.writePage(RAFContainer4.java:291)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.data.CachedPage.writePage(CachedPage.java:782)&lt;/p&gt;

&lt;p&gt;	... 23 more&lt;/p&gt;

&lt;p&gt;============= begin nested exception, level (1) ===========&lt;/p&gt;

&lt;p&gt;java.nio.channels.ClosedChannelException&lt;/p&gt;

&lt;p&gt;	at sun.nio.ch.FileChannelImpl.ensureOpen(FileChannelImpl.java:91)&lt;/p&gt;

&lt;p&gt;	at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:642)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.data.RAFContainer4.writeFull(RAFContainer4.java:397)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.data.RAFContainer4.writePage(RAFContainer4.java:291)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.data.CachedPage.writePage(CachedPage.java:782)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.data.CachedPage.clean(CachedPage.java:605)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.services.cache.ConcurrentCache.cleanAndUnkeepEntry(ConcurrentCache.java:551)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.services.cache.ClockPolicy.rotateClock(ClockPolicy.java:476)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.services.cache.ClockPolicy.insertEntry(ClockPolicy.java:176)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.services.cache.ConcurrentCache.insertIntoFreeSlot(ConcurrentCache.java:208)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.services.cache.ConcurrentCache.find(ConcurrentCache.java:284)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.data.FileContainer.getUserPage(FileContainer.java:2412)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.data.FileContainer.getPage(FileContainer.java:2462)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.data.BaseContainerHandle.getPage(BaseContainerHandle.java:319)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.access.btree.ControlRow.get(ControlRow.java:833)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.access.btree.ControlRow.get(ControlRow.java:820)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.access.btree.BTreePostCommit.doShrink(BTreePostCommit.java:123)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.access.btree.BTreePostCommit.performWork(BTreePostCommit.java:249)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.xact.Xact.postTermination(Xact.java:2045)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.xact.Xact.completeCommit(Xact.java:818)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.xact.Xact.commit(Xact.java:854)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.raw.xact.Xact.commit(Xact.java:649)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.store.access.RAMTransaction.commit(RAMTransaction.java:1964)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.sql.conn.GenericLanguageConnectionContext.doCommit(GenericLanguageConnectionContext.java:1211)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.sql.conn.GenericLanguageConnectionContext.userCommit(GenericLanguageConnectionContext.java:1031)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.jdbc.TransactionResourceImpl.commit(TransactionResourceImpl.java:237)&lt;/p&gt;

&lt;p&gt;	at org.apache.derby.impl.jdbc.EmbedConnection.commit(EmbedConnection.java:1661)&lt;/p&gt;

&lt;p&gt;	at WorkerThread.run(WorkerThread.java:24)&lt;/p&gt;

&lt;p&gt;============= end nested exception, level (1) ===========&lt;/p&gt;




&lt;p&gt;------------  END SHUTDOWN ERROR STACK -------------&lt;/p&gt;



</comment>
                            <comment id="12588203" author="mikem" created="Sat, 12 Apr 2008 06:59:20 +0100"  >&lt;p&gt;The most likely way this bug will show up is concurrent writes to page 0.  But the bug may not be recognized for a long time as it only corrupts the on disk page, while the page is cache is likely&lt;br/&gt;
fine (i am not sure of this but seems possible).   This bug in particular affects  page 0, which happens to be accessed a lot and thus is in cache a lot.   So best way to catch it, is as Kathey observed - &lt;br/&gt;
run your concurrent test and then shutdown completely and then start up again and check.  Easiest&lt;br/&gt;
way to check is just to run the consistency checker against any tables you might be testing against.&lt;/p&gt;</comment>
                            <comment id="12588302" author="kmarsden" created="Sat, 12 Apr 2008 20:01:44 +0100"  >&lt;p&gt;Thanks Mike for the info.  I updated the program to shutdown the db when done and check the tables.  I can reproduce corruption in page 0 pretty reliably with 100 threads.  I am going to update my client now and see if the problem goes away with the fix.&lt;/p&gt;
</comment>
                            <comment id="12588392" author="kmarsden" created="Sun, 13 Apr 2008 14:39:04 +0100"  >&lt;p&gt;I ran the program more than a dozen times without error with the fix after getting corruption 3/3 times without the fix.  So the fix looks good from this case&apos;s perspective.  Attached is the updated program that does the shutdown and table check MiniStress.zip.  Maybe someone that runs stress tests could incorporate something similar.&lt;/p&gt;</comment>
                            <comment id="12588534" author="knutanders" created="Mon, 14 Apr 2008 11:17:04 +0100"  >&lt;p&gt;Thanks for taking the time to test the fix, Kathey!&lt;br/&gt;
I haven&apos;t been able to reproduce the problem myself, but I&apos;m marking the issue as resolved based on your testing. If Bogdan&apos;s testing shows that it&apos;s not fixed, we can reopen it.&lt;/p&gt;</comment>
                            <comment id="12588623" author="kmarsden" created="Mon, 14 Apr 2008 17:29:05 +0100"  >&lt;p&gt;Knut, do you plan to backport this fix to 10.3?&lt;/p&gt;</comment>
                            <comment id="12589022" author="knutanders" created="Tue, 15 Apr 2008 11:57:39 +0100"  >&lt;p&gt;Merged the fixes to the 10.3 branch and committed revision 648210.&lt;/p&gt;</comment>
                            <comment id="12589276" author="mikem" created="Wed, 16 Apr 2008 00:16:59 +0100"  >&lt;p&gt;Trying to figure out what to tell 10.3 users that may have hit this.  Does anyone have a db that they can boot that has a table that gets this error on access.  Can you drop the index or table if it gets this error?  If you get this error during recovery you are going to have to go to backup, but i am hoping that if the error is on an index we can figure out some way to just be able to drop and recreate the index.  &lt;/p&gt;

&lt;p&gt;How likely is this error to have caused more than page 0 to be corrupted?  Does the unintended i/o interaction have a chance to push a write that was supposed to start at offset 0 to somewhere later thus causing it to overwrite page 1?&lt;/p&gt;</comment>
                            <comment id="12589445" author="knutanders" created="Wed, 16 Apr 2008 08:23:35 +0100"  >&lt;p&gt;I&apos;m not sure (since I haven&apos;t been able to reproduce the problem myself) but I don&apos;t think you&apos;ll be able to drop the table/index. I think DROP TABLE will open the container it&apos;s about to drop, and then it&apos;ll also read the container information stored in page 0.&lt;/p&gt;

&lt;p&gt;I also think it is possible that the problem with mixing FileChannel operations and RandomAccessFile.seek() can cause corruption on any page in the container, although based on the reports, it seems like page 0 is the most likely one to be hit.&lt;/p&gt;

&lt;p&gt;I&apos;m attaching the program I used to track down the problem (no Derby code, only pure file operations), FileOffset.java. It runs 10 threads that write at random positions in a file using a FileChannel, while the main thread runs a loop with RAF.seek(0L) + sleep() + RAF.getFilePointer(). On Solaris and Linux, getFilePointer() always returns 0, but on Windows it frequently returns other values pointing at random positions in the file (only tested with Sun&apos;s JVMs). So it is quite possible that a write occurs at the wrong position and corrupts another page than page 0.&lt;/p&gt;

&lt;p&gt;The other problem (concurrent access to page 0 by container cache and page cache) can only hit page 0, I believe.&lt;/p&gt;</comment>
                            <comment id="12593010" author="knutanders" created="Tue, 29 Apr 2008 14:26:54 +0100"  >&lt;p&gt;Attaching a release note.&lt;/p&gt;</comment>
                            <comment id="12593012" author="bryanpendleton" created="Tue, 29 Apr 2008 14:38:43 +0100"  >&lt;p&gt;Is it true that this problem only affected Windows platforms? If so, would this be worth including in the note?&lt;/p&gt;</comment>
                            <comment id="12593019" author="knutanders" created="Tue, 29 Apr 2008 15:14:15 +0100"  >&lt;p&gt;It is true that parts of the problem didn&apos;t seem to happen on Solaris and Linux, whereas it did on Windows (see the attached FileOffset.java). But I only tried it on a limited set of JVM&apos;s, so I can&apos;t say definitely that it&apos;s not a problem on any JVM on any other OS than Windows.&lt;/p&gt;

&lt;p&gt;Also, the possibility of overwriting parts of page 0 with old data due to lack of synchronization between page writes and container meta-data writes, is not limited to a single platform.&lt;/p&gt;</comment>
                            <comment id="12593571" author="bcalmac" created="Thu, 1 May 2008 17:31:00 +0100"  >&lt;p&gt;I&apos;ve run our endurance test for about a week using 10.4 svn 648059 and it was solid as a rock.&lt;/p&gt;</comment>
                            <comment id="12593588" author="knutanders" created="Thu, 1 May 2008 18:23:17 +0100"  >&lt;p&gt;Thanks for testing it, Bogdan! I&apos;m glad it solved your problems.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12377586">DERBY-3052</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12361805">DERBY-2284</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12368029">DERBY-2589</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12369901">DERBY-2677</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12380962">DERBY-3143</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12386968">DERBY-3344</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12388496">DERBY-3411</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12379122">DERBY-3087</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12393398">DERBY-3607</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12393605">DERBY-3611</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12369901">DERBY-2677</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12393395">DERBY-3606</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12380254" name="FileOffset.java" size="1679" author="knutanders" created="Wed, 16 Apr 2008 08:23:35 +0100"/>
                            <attachment id="12380004" name="MiniStress.zip" size="3246" author="kmarsden" created="Sun, 13 Apr 2008 14:39:04 +0100"/>
                            <attachment id="12379827" name="d3347-1a.diff" size="18025" author="knutanders" created="Thu, 10 Apr 2008 12:39:36 +0100"/>
                            <attachment id="12379828" name="d3347-1a.stat" size="306" author="knutanders" created="Thu, 10 Apr 2008 12:39:36 +0100"/>
                            <attachment id="12379908" name="d3347-1b.diff" size="18008" author="knutanders" created="Fri, 11 Apr 2008 09:54:37 +0100"/>
                            <attachment id="12379836" name="d3347-2a.diff" size="2588" author="knutanders" created="Thu, 10 Apr 2008 13:53:47 +0100"/>
                            <attachment id="12379729" name="d3347-preview.diff" size="13932" author="knutanders" created="Wed, 9 Apr 2008 14:38:24 +0100"/>
                            <attachment id="12379664" name="d3347-preview.diff" size="14026" author="knutanders" created="Tue, 8 Apr 2008 16:51:44 +0100"/>
                            <attachment id="12381104" name="releaseNote.html" size="5109" author="knutanders" created="Tue, 29 Apr 2008 14:26:54 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310200" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Bug behavior facts</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10420"><![CDATA[Regression]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 24 Jan 2008 15:36:33 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23586</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310090" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Issue &amp; fix info</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10101"><![CDATA[Release Note Needed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy0lrr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>37345</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            </customfields>
    </item>
</channel>
</rss>