<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:48:35 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-3625/DERBY-3625.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-3625] XSDA3 error in concateTests in lang.LangHarnessJavaTest caused by bug in SYSCS_UTIL.SYSCS_INPLACE_COMPRESS_TABLE()</title>
                <link>https://issues.apache.org/jira/browse/DERBY-3625</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;I saw this test fail once with a similar error to &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3180&quot; title=&quot;error XSDA3 when test is executing SYSCS_INPLACE_COMPRESS_TABLE in specific situation&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3180&quot;&gt;&lt;del&gt;DERBY-3180&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3381&quot; title=&quot;&amp;quot;ERROR XSDA3: Limitation: Record cannot be updated or inserted due to lack of space on the page....&amp;quot; in suites.All&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3381&quot;&gt;&lt;del&gt;DERBY-3381&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Unfortunately, possibly because it&apos;s an old harness test, the db and derby.log were not saved in the &apos;fail&apos; directory.&lt;br/&gt;
All I have is the stack trace from the output:&lt;/p&gt;

&lt;p&gt;1) concateTests(org.apache.derbyTesting.functionTests.tests.lang.LangHarnessJavaTest)java.sql.SQLException: Limitation: Record cannot be updated or inserted due to lack of space on the page. Use the parameters derby.storage.pageSize and/or derby.storage.pageReservedSpace to work around this limitation.&lt;br/&gt;
	at java.lang.Throwable.&amp;lt;init&amp;gt;(Throwable.java:196)&lt;br/&gt;
	at java.lang.Exception.&amp;lt;init&amp;gt;(Exception.java:41)&lt;br/&gt;
	at java.sql.SQLException.&amp;lt;init&amp;gt;(SQLException.java:40)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedSQLException.&amp;lt;init&amp;gt;(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeStatement(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedCallableStatement.executeStatement(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derbyTesting.junit.CleanDatabaseTestSetup.compressObjects(CleanDatabaseTestSetup.java:267)&lt;br/&gt;
	at org.apache.derbyTesting.junit.CleanDatabaseTestSetup.cleanDatabase(CleanDatabaseTestSetup.java:166)&lt;br/&gt;
	at org.apache.derbyTesting.junit.CleanDatabaseTestSetup.setUp(CleanDatabaseTestSetup.java:109)&lt;br/&gt;
	at junit.extensions.TestSetup$1.protect(TestSetup.java:18)&lt;br/&gt;
	at junit.extensions.TestSetup.run(TestSetup.java:23)&lt;br/&gt;
	at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)&lt;br/&gt;
Caused by: ERROR XSDA3: Limitation: Record cannot be updated or inserted due to lack of space on the page. Use the parameters derby.storage.pageSize and/or derby.storage.pageReservedSpace to work around this limitation.&lt;br/&gt;
	at java.lang.Throwable.&amp;lt;init&amp;gt;(Throwable.java:196)&lt;br/&gt;
	at java.lang.Exception.&amp;lt;init&amp;gt;(Exception.java:41)&lt;br/&gt;
	at org.apache.derby.iapi.error.StandardException.&amp;lt;init&amp;gt;(Unknown Source)&lt;br/&gt;
	at org.apache.derby.iapi.error.StandardException.&amp;lt;init&amp;gt;(Unknown Source)&lt;br/&gt;
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.CopyRowsOperation.writeOptionalDataToBuffer(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.CopyRowsOperation.&amp;lt;init&amp;gt;(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.LoggableActions.actionCopyRows(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.BasePage.copyInto(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.BasePage.copyAndPurge(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.StoredPage.moveRecordForCompressAtSlot(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.heap.HeapCompressScan.fetchRowsForCompress(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.heap.HeapCompressScan.fetchNextGroup(Unknown Source)&lt;br/&gt;
	at org.apache.derby.iapi.db.OnlineCompress.defragmentRows(Unknown Source)&lt;br/&gt;
	at org.apache.derby.iapi.db.OnlineCompress.compressTable(Unknown Source)&lt;br/&gt;
	at org.apache.derby.catalog.SystemProcedures.SYSCS_INPLACE_COMPRESS_TABLE(Unknown Source)&lt;br/&gt;
	at org.apache.derby.exe.ac4388a4aax0119x3203xfc8fx0000783ef2472.g0(Unknown Source)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at org.apache.derby.impl.services.reflect.ReflectMethod.invoke(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.CallStatementResultSet.open(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)&lt;br/&gt;
	... 24 more&lt;/p&gt;</description>
                <environment>iseries, ibm1.5.:&lt;br/&gt;
java version &amp;quot;1.5.0&amp;quot;&lt;br/&gt;
Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_13-b05)&lt;br/&gt;
Classic VM (build 1.5, build JDK-1.5, native threads, jitc_de)&lt;br/&gt;
</environment>
        <key id="12394048">DERBY-3625</key>
            <summary>XSDA3 error in concateTests in lang.LangHarnessJavaTest caused by bug in SYSCS_UTIL.SYSCS_INPLACE_COMPRESS_TABLE()</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mikem">Mike Matrigali</assignee>
                                    <reporter username="myrna">Myrna van Lunteren</reporter>
                        <labels>
                    </labels>
                <created>Wed, 16 Apr 2008 00:01:16 +0100</created>
                <updated>Thu, 13 Jan 2011 21:43:43 +0000</updated>
                            <resolved>Wed, 2 Jul 2008 04:55:51 +0100</resolved>
                                    <version>10.4.1.3</version>
                                    <fixVersion>10.3.3.1</fixVersion>
                    <fixVersion>10.4.2.0</fixVersion>
                    <fixVersion>10.5.1.1</fixVersion>
                                    <component>Store</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12600971" author="kmarsden" created="Fri, 30 May 2008 01:00:15 +0100"  >&lt;p&gt;The error comes in the compression of  the SYS.SYSDEPENDS table.&lt;br/&gt;
The compress occurs in CleanDatabaseTestSetup.setup() not in teardown() so the objects that just got dropped and are now being compressed are probably from the test before which is unfortunately the nist scripts (a lot of scripts).&lt;/p&gt;
</comment>
                            <comment id="12601189" author="mikem" created="Fri, 30 May 2008 17:19:36 +0100"  >&lt;p&gt;Is it still the case that no derby.log or database is left around to look at after the bug happens?  It would&lt;br/&gt;
be interesting to know if running the compress again also fails.  My guess is that it would and looking&lt;br/&gt;
at the state of the table would make it easier to understand why.&lt;/p&gt;

&lt;p&gt;If that is not possible then somehow dumping a lot more information may help.  I would usually put&lt;br/&gt;
this in a SANE bracket and just dump the info to the log - but again if we can&apos;t get the log that might not&lt;br/&gt;
help.  The kind of info that would be interesting is a dump of the source page, dump of the dest page,&lt;br/&gt;
dump of the row being moved, maybe dump of the table level properties like page size, reserved space.&lt;br/&gt;
What I would mostly be looking at is the lengths involved rather than the data.  Seeing if there is possibly&lt;br/&gt;
an off by one or off by a lot.&lt;/p&gt;

&lt;p&gt;I would probably concentrate on the StoredPage!moveRecordForCompressAtSlot() routine, catching&lt;br/&gt;
the &quot;generic&quot; exception being thrown from deeper down and print the info.  This routine try&apos;s 3 different&lt;br/&gt;
ways to find a page to move a row to.  In the first 2 is calls spaceForCopy() to see if there room and it&lt;br/&gt;
should be maintaining a latch on the page for the actual insert so unless there is a bug in latching the&lt;br/&gt;
bug is probably in spaceForCopy().  toString in StoredPage has code to dump the page. printing just&lt;br/&gt;
the row size from the routine may be enough.  Just to eliminate possibilities it might be interesting&lt;br/&gt;
to know which of the 3 cases the dest page came from - for instance if it came from the 3rd case then&lt;br/&gt;
spaceForCopy() can&apos;t be the bug.&lt;/p&gt;</comment>
                            <comment id="12601196" author="mikem" created="Fri, 30 May 2008 17:53:17 +0100"  >&lt;p&gt;If this is just a math bug (and not a thread interaction timing issue), then the following kind of test should&lt;br/&gt;
reproduce but probably takes some playing around to get the row sizes right for whatever page size you&lt;br/&gt;
pick.  &lt;/p&gt;

&lt;p&gt;High level:&lt;br/&gt;
create a 2 page table.  On first page vary the amount of free space by 1 byte every loop through the&lt;br/&gt;
test.  On the second page have a single row that will be moved by compress table for each try.&lt;/p&gt;

&lt;p&gt;details - here&apos;s one way to loop and test all the cases of filling a page, there are probably more elegant ways, or you could play around with a test looking in toString() from page to find exactly the interesting&lt;br/&gt;
lengths of rows:&lt;br/&gt;
pick some row size that you are going to move, let&apos;s say 100 bytes (this could also be variable for even&lt;br/&gt;
more exaustive test).  Each loop will drop/create the table (maybe there is a way around this).&lt;br/&gt;
pick a row something like 2 column with int key and clob data.  1st row inserted should exactly&lt;br/&gt;
mach the TEST row.  Vary the size of the 2nd row by &lt;br/&gt;
one byte each time, if you load ascii data into the clob then stored size of row will go up 1 byte for &lt;br/&gt;
each character.  The idea is to start with the 2nd row big enough such that insert of another TEST&lt;br/&gt;
row will not fit on the 1st page, and then the varying should inch you up to the interesting edge conditions&lt;br/&gt;
of completely full page in no reserved space case and full with respect to reserved space in other case.&lt;/p&gt;

&lt;p&gt;Finally insert 3rd row that should match in length to TEST row.    and commit.  The goal at this point&lt;br/&gt;
is to have a 2 page heap table with 2 rows on page 0 and 1 row on page 1.  &lt;/p&gt;

&lt;p&gt;delete 1st TEST row, commit.&lt;/p&gt;

&lt;p&gt;run inplace compress.  This should first purge the 1st row in the purge phase, and then try to move the&lt;br/&gt;
last row on page 1 to page 0.  &lt;/p&gt;

&lt;p&gt;updating the space eater row will eat into reserved space which may also be an interesting test, but is different than dropping and recreating the table.  &lt;/p&gt;
</comment>
                            <comment id="12601223" author="kmarsden" created="Fri, 30 May 2008 20:05:08 +0100"  >&lt;p&gt;Thanks Mike for the useful information. I will work first on getting the log output.&lt;/p&gt;

&lt;p&gt;Attached is the derby.log and the database.  I tried connecting to the database with ij and compressing the table and it compressed ok.   This database is actually after that compress. Let me know if you need a db before the compress and I will try to get that.&lt;/p&gt;

&lt;p&gt;Kathey&lt;/p&gt;</comment>
                            <comment id="12601234" author="kmarsden" created="Fri, 30 May 2008 20:49:44 +0100"  >&lt;p&gt;Reattaching log and database on which compress has not been run.  This came from just running a modified lang suite in which we don&apos;t run any tests after the failing test.&lt;/p&gt;

</comment>
                            <comment id="12601251" author="kmarsden" created="Fri, 30 May 2008 22:05:18 +0100"  >&lt;p&gt;I printed the source and destination page and the row_size. The log is attached in derby_log_wdebug.zip  I wasn&apos;t quite sure how to get the table properties from this context.&lt;/p&gt;

&lt;p&gt;This is the code I added:&lt;br/&gt;
      try &lt;/p&gt;
{
                	copyAndPurge(dest_page, slot, 1, dest_slot);
                }
&lt;p&gt; catch (StandardException e) {&lt;br/&gt;
                	if (SanityManager.DEBUG)&lt;/p&gt;
                	{
                		SanityManager.DEBUG_PRINT(&quot;row_size&quot;, &quot;&quot; + row_size);
                		SanityManager.DEBUG_PRINT(&quot;dest_page&quot;, dest_page.toString());
                		SanityManager.DEBUG_PRINT(&quot;src_page&quot;, this.toString());
                	}                	
&lt;p&gt;                	throw e;                	&lt;br/&gt;
                }&lt;/p&gt;

&lt;p&gt;Please let me know if something else/more  would be more useful.&lt;/p&gt;</comment>
                            <comment id="12601261" author="mikem" created="Fri, 30 May 2008 22:29:02 +0100"  >&lt;p&gt;From the latest log I am going to guess the problem has to do with mismatch on reserved space calculation.  The row size is 91 and there are 97 bytes on page so it seems like it should fit.  But the &lt;br/&gt;
calculation in CopyRowsOperation is more complicated.  If you can reproduce it again and get a dump&lt;br/&gt;
of information from that routine it would confirm.&lt;/p&gt;

&lt;p&gt;The interesting code is in CopyRowsOperation:&lt;br/&gt;
// page is the destination page.&lt;br/&gt;
if (!page.spaceForCopy(num_rows, spaceNeeded))&lt;/p&gt;
{
    throw StandardException.newException(
            SQLState.DATA_NO_SPACE_FOR_RECORD);
}

&lt;p&gt;dumping out the spaceNeeded variable and the reservedSpace array would help.&lt;/p&gt;</comment>
                            <comment id="12601266" author="mikem" created="Fri, 30 May 2008 22:47:44 +0100"  >&lt;p&gt;For this page size (4k), the slot entry size is 6 bytes so from the dumped calculation it should fit exactly - so&lt;br/&gt;
there may be an off by one error somewhere or maybe a &amp;gt; where there should be &amp;gt;=  or something like that.&lt;br/&gt;
it&apos;s all guesses but since it happens so infrequently seems more likely special case for exactly fitting then generic problem with accounting for reserved space - but don&apos;t know.  &lt;/p&gt;

&lt;p&gt;It is probably worth adding dumps of the following 2 to the page header dumping in StoredPage, they&lt;br/&gt;
are really container level info but doesn&apos;t hurt to add them to the sanity toString for the page.&lt;br/&gt;
spareSpace &lt;br/&gt;
minimumRecordSize  &lt;/p&gt;</comment>
                            <comment id="12601279" author="kmarsden" created="Fri, 30 May 2008 23:37:26 +0100"  >&lt;p&gt;Here is the subset of the log with the spaceNeeded and reservedSpace.  We seem to be off by one in space needed.&lt;/p&gt;

&lt;p&gt;DEBUG spaceNeeded OUTPUT: &lt;/p&gt;
{ 92 }
&lt;p&gt;DEBUG reservedSpace OUTPUT: &lt;/p&gt;
{ 0 }
&lt;p&gt;DEBUG row_size OUTPUT: 91&lt;br/&gt;
...&lt;/p&gt;
</comment>
                            <comment id="12601301" author="mikem" created="Sat, 31 May 2008 00:32:21 +0100"  >&lt;p&gt;I think i understand what is going on, and the previous test description probably does not cause this&lt;br/&gt;
bug.  Not sure what right fix is yet.&lt;/p&gt;

&lt;p&gt;I went back to the original page dumps, and think I know the problem.  Compress is using the old length&lt;br/&gt;
to find a suitable page, but it turns out the length of the row is actually variable because the record id is&lt;br/&gt;
changing.  In this case the soruce page record id is 40 and the next record id on the dest page is 69.&lt;/p&gt;

&lt;p&gt;For complete doc on record format see javadoc in StoredPage at top - search for Record &amp;amp; Field Format.&lt;br/&gt;
but short answer is that records include a record header (StoredRecordHeader) and &lt;br/&gt;
StoredRecordHeader writes out the record id using a Compressed Int (see CompressedNumber) and&lt;br/&gt;
the break down for size for the compressed number is:&lt;/p&gt;

&lt;p&gt;    /**&lt;br/&gt;
        Write a compressed integer only supporting signed values.&lt;br/&gt;
        Formats are (with x representing value bits):&lt;br/&gt;
        &amp;lt;PRE&amp;gt;&lt;br/&gt;
        1 Byte - 00xxxxxx                              Represents the value &amp;lt;= 63 (0x3f)&lt;br/&gt;
        2 Byte - 01xxxxxx xxxxxxxx                     Represents the value &amp;gt; 63 &amp;amp;&amp;amp; &amp;lt;= 16383 (0x3fff)&lt;br/&gt;
        4 byte - 1xxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx   Represents the value &amp;gt; 16383 &amp;amp;&amp;amp; &amp;lt;= MAX_INT&lt;br/&gt;
        &amp;lt;/PRE&amp;gt;&lt;/p&gt;


&lt;p&gt;        @exception IOException value is negative or an exception was thrown by a&lt;br/&gt;
 method on out.&lt;br/&gt;
    */&lt;/p&gt;</comment>
                            <comment id="12601307" author="mikem" created="Sat, 31 May 2008 00:58:34 +0100"  >&lt;p&gt;One option is to only allow compress to pick pages that will handle worst case expansion, so do something &lt;br/&gt;
like the following in moveRecordForCompressAtSlot().&lt;/p&gt;

&lt;p&gt;dest_row_size = row_size + StoredRecordHeader.MAX_RECORD_ID_INCREASE where the new constant is 3.&lt;/p&gt;

&lt;p&gt;or do something more dynamic to get it exactly right (variable names/fields are not right)&lt;br/&gt;
dest_row_size = row_size + StoredRecordHeader.size_of_recordid(destpage.nextid) - StoredRecordHeader.size_of_recordid(source record id).   &lt;br/&gt;
The StoredRecordHeader.size() has code to do this kind of stuff for the whole record header.&lt;/p&gt;

&lt;p&gt;The copy record code existed before compress but it&apos;s usage never ran into this issue.  It was only used&lt;br/&gt;
during a btree split, so all records would always be going to a new page.  So in that case all the destination&lt;br/&gt;
record id&apos;s had to be either the same or smaller than the source id&apos;s as we only split and move rows to &lt;br/&gt;
a new page.  &lt;/p&gt;</comment>
                            <comment id="12601310" author="mikem" created="Sat, 31 May 2008 01:08:25 +0100"  >&lt;p&gt;I believe there is another bug in this code, in the final try at finding a page to move the row to we try and&lt;br/&gt;
get an empty page.  The assumption was that the copy would always work to an empty page, but for the same reason as described above the copy of the row to an empty page&lt;br/&gt;
may not work if the new page is actually a reclaimed page which in the past has used up record id&apos;s.  So&lt;br/&gt;
the same spaceForCopy check should be added to it as the above 2, and if it does not work just set&lt;br/&gt;
the candidate page to null and fall through.&lt;/p&gt;</comment>
                            <comment id="12601316" author="bryanpendleton" created="Sat, 31 May 2008 02:06:33 +0100"  >&lt;p&gt;Just making sure I understand: the old record ID was 40, and thus fit in a&lt;br/&gt;
single byte in the StoredRecordHeader, while the new record ID was 69,&lt;br/&gt;
which takes &lt;b&gt;two&lt;/b&gt; bytes in the StoredRecordHeader?&lt;/p&gt;</comment>
                            <comment id="12609788" author="mikem" created="Wed, 2 Jul 2008 04:55:51 +0100"  >&lt;p&gt;Fix has been applied to trunk, 10.4, and 10.3 codeline.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12381963">DERBY-3180</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12387764">DERBY-3381</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12381963">DERBY-3180</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12387764">DERBY-3381</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12383144" name="derby_log_wdebug.zip" size="1298031" author="kmarsden" created="Fri, 30 May 2008 22:05:18 +0100"/>
                            <attachment id="12383152" name="derby_log_wdebug2.zip" size="8176" author="kmarsden" created="Fri, 30 May 2008 23:37:26 +0100"/>
                            <attachment id="12383136" name="derbylog.zip" size="1291422" author="kmarsden" created="Fri, 30 May 2008 20:49:44 +0100"/>
                            <attachment id="12383137" name="wombat.zip" size="767392" author="kmarsden" created="Fri, 30 May 2008 20:49:44 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310200" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Bug behavior facts</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10369"><![CDATA[Regression Test Failure]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 30 May 2008 00:00:15 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23752</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy0njj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>37632</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            </customfields>
    </item>
</channel>
</rss>