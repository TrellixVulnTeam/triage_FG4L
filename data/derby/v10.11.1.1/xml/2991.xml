<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:15:45 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-2991/DERBY-2991.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-2991] Index split deadlock</title>
                <link>https://issues.apache.org/jira/browse/DERBY-2991</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;After doing dome research on the mailing list, it appears that the index split deadlock is a known behaviour, so I will start by describing the theoretical problem first and then follow with the details of my test case.&lt;/p&gt;

&lt;p&gt;If you have concurrent select and insert transactions on the same table, the observed locking behaviour is as follows:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the select transaction acquires an S lock on the root block of the index and then waits for an S lock on some uncommitted row of the insert transaction&lt;/li&gt;
	&lt;li&gt;the insert transaction acquires X locks on the inserted records and if it needs to do an index split creates a sub-transaction that tries to acquire an X lock on the root block of the index&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In summary: INDEX LOCK followed by ROW LOCK + ROW LOCK followed by INDEX LOCK = deadlock&lt;/p&gt;

&lt;p&gt;In the case of my project this is an important issue (lack of concurrency after being forced to use table level locking) and I would like to contribute to the project and fix this issue (if possible). I was wondering if someone that knows the code can give me a few pointers on the implications of this issue:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Is this a limitation of the top-down algorithm used?&lt;/li&gt;
	&lt;li&gt;Would fixing it require to use a bottom up algorithm for better concurrency (which is certainly non trivial)?&lt;/li&gt;
	&lt;li&gt;Trying to break the circular locking above, I would first question why does the select transaction need to acquire (and hold) a lock on the root block of the index. Would it be possible to ensure the consistency of the select without locking the index?&lt;/li&gt;
&lt;/ul&gt;


&lt;hr /&gt;

&lt;p&gt;The attached test (InsertSelectDeadlock.java) tries to simulate a typical data collection application, it consists of: &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;an insert thread that inserts records in batch&lt;/li&gt;
	&lt;li&gt;a select thread that &apos;processes&apos; the records inserted by the other thread: &apos;select * from table where id &amp;gt; ?&apos;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The derby log provides detail about the deadlock trace and stacktraces_during_deadlock.txt shows that the inser thread is doing an index split.&lt;/p&gt;

&lt;p&gt;The test was run on 10.2.2.0 and 10.3.1.4 with identical behaviour.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Bogdan Calmac.&lt;/p&gt;</description>
                <environment>Windows XP, Java 6</environment>
        <key id="12375269">DERBY-2991</key>
            <summary>Index split deadlock</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="knutanders">Knut Anders Hatlen</assignee>
                                    <reporter username="bcalmac">Bogdan Calmac</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 Aug 2007 05:09:28 +0100</created>
                <updated>Thu, 2 May 2013 03:29:19 +0100</updated>
                            <resolved>Wed, 18 Mar 2009 16:32:00 +0000</resolved>
                                    <version>10.2.2.0</version>
                    <version>10.3.1.4</version>
                    <version>10.4.2.0</version>
                                    <fixVersion>10.5.1.1</fixVersion>
                                    <component>Store</component>
                        <due></due>
                            <votes>13</votes>
                                    <watches>10</watches>
                                                                <comments>
                            <comment id="12517433" author="bcalmac" created="Fri, 3 Aug 2007 05:11:07 +0100"  >&lt;p&gt;The test demonstrationg the deadlock&lt;/p&gt;</comment>
                            <comment id="12517434" author="bcalmac" created="Fri, 3 Aug 2007 05:11:56 +0100"  >&lt;p&gt;The deadlock trace&lt;/p&gt;</comment>
                            <comment id="12517435" author="bcalmac" created="Fri, 3 Aug 2007 05:12:52 +0100"  >&lt;p&gt;The stacktrace before deadlock indicating an index split&lt;/p&gt;</comment>
                            <comment id="12517516" author="johnemb" created="Fri, 3 Aug 2007 13:34:53 +0100"  >&lt;p&gt;This is an interesting case which reminds me (but is different from) a deadlock issue I encountered in a long-running test not so long ago. I was not able to reproduce the deadlock, but we suspect that there may be a bug in the code that creates the deadlock message about the lock cycles, see &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-2877&quot; title=&quot;Print the entire lock list when a deadlock occurs and deadlock tracing is on&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-2877&quot;&gt;&lt;del&gt;DERBY-2877&lt;/del&gt;&lt;/a&gt; for details.&lt;/p&gt;

&lt;p&gt;This test (InsertSelectDeadlock.java) is interesting because you get a lock timeout message rather than a deadlock message (even if you add a deadlockTimeout property with a lower value than the waitTimeout property - I&apos;ve tried), although in practice this is a deadlock. &lt;/p&gt;

&lt;p&gt;Also, even if derby.language.logStatementText is set to true (I edited the test class to do that), you don&apos;t get any more information about the offending statement which (presumably) holds an exclusive lock on the index root (1,1).&lt;/p&gt;

&lt;p&gt;Here&apos;s the relevant information extracted from the derby.log Bogdan attached:&lt;/p&gt;

&lt;p&gt;XID       |TYPE         |MODE|LOCKCOUNT|LOCKNAME|STATE|INDEXNAME          |&lt;br/&gt;
---------------------------------------------------------------------------&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;
		&lt;ul&gt;
			&lt;li&gt;The following row is the victim ***&lt;br/&gt;
279       |ROW          |S   |0        |(1,7)   |WAIT |NULL               |&lt;/li&gt;
			&lt;li&gt;The above row is the victim ***&lt;br/&gt;
269       |ROW          |X   |1        |(1,7)   |GRANT|NULL               |&lt;br/&gt;
282       |ROW          |X   |0        |(1,1)   |WAIT |SQL070802115706620 |&lt;br/&gt;
279       |ROW          |S   |1        |(1,1)   |GRANT|SQL070802115706620 |&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;(I excluded things like tabletype (always T) and tablename (always TRACK_EVENT)).&lt;/p&gt;

&lt;p&gt;The transactions above are probably:&lt;/p&gt;

&lt;p&gt;XID 279: select * from TRACK_EVENT where ID &amp;gt; ?&lt;br/&gt;
XID 269: insert into TRACK_EVENT values (?,?,?,?,?,?,?,?,?,?,?,?,?,?)&lt;br/&gt;
XID 282: &lt;span class=&quot;error&quot;&gt;&amp;#91;index btree split?&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;We are assuming (based on the stack traces) that XID 269 has spawned another transaction, XID 282, which is trying to modify the index, but is not allowed to because XID 279 is already holding an S (Shared) lock on it. I guess derby does not recognize this as a deadlock because the index-modifying transaction has a completely different transaction number. So, in systems that don&apos;t have deadlockTrace enabled, deadlocks may be camouflaged as lock wait timeouts.&lt;/p&gt;

&lt;p&gt;I was kind of hoping that this comment would help so that more people could understand these issues, hence increasing the chances of getting them fixed (or, at the least, improving related documentation). I&apos;m sorry for not being able to work out a solution or provide answers to Bogdan&apos;s questions at this point, but I&apos;m hoping someone else will be assisting soon.&lt;/p&gt;</comment>
                            <comment id="12520535" author="knutanders" created="Fri, 17 Aug 2007 13:39:07 +0100"  >&lt;p&gt;&amp;gt; - Trying to break the circular locking above, I would first question&lt;br/&gt;
&amp;gt;   why does the select transaction need to acquire (and hold) a lock&lt;br/&gt;
&amp;gt;   on the root block of the index.&lt;/p&gt;

&lt;p&gt;B-tree scans lock the leaf node on which they are currently positioned&lt;br/&gt;
(in your case the root node is probably also a leaf node) so that they&lt;br/&gt;
don&apos;t have to reposition if they lose the latch on the page. The scan&lt;br/&gt;
always releases the latch on the B-tree leaf if it has to wait for a&lt;br/&gt;
row lock. The latch is released in order to prevent deadlocks. Since&lt;br/&gt;
the page is not latched while the scan waits for the row lock, the row&lt;br/&gt;
might have moved to another page in the index and therefore the scan&lt;br/&gt;
would have to start a new search to reposition on the row. The shared&lt;br/&gt;
lock on the B-tree leaf ensures that the row is not moved off the&lt;br/&gt;
current page so that the repositioning isn&apos;t needed. Since the lock on&lt;br/&gt;
the leaf node is shared, it allows more concurrency than if the&lt;br/&gt;
(exclusive) latch were kept. But since the lock on the leaf is more or&lt;br/&gt;
less like a shared latch, there&apos;s still a possibility for deadlocks if&lt;br/&gt;
the B-tree needs to be restructured (like the split deadlock you&apos;re&lt;br/&gt;
seeing).&lt;/p&gt;

&lt;p&gt;&amp;gt; Would it be possible to ensure the consistency of the select without&lt;br/&gt;
&amp;gt; locking the index?&lt;/p&gt;

&lt;p&gt;I think so, if the select transaction had a way to reposition the scan&lt;br/&gt;
after it got the row lock it was waiting for. The current code just&lt;br/&gt;
checks the leaf page again to find the row, since it knows it can&apos;t&lt;br/&gt;
have moved to another page. If there weren&apos;t a lock on the index page,&lt;br/&gt;
the scan would need to detect that the row had moved and start a new&lt;br/&gt;
search from the root node.&lt;/p&gt;

&lt;p&gt;I don&apos;t know enough about this area of the code to say whether or not&lt;br/&gt;
it is doable, or how much work it is. Hopefully, someone more&lt;br/&gt;
knowledgeable will chime in with more details.&lt;/p&gt;</comment>
                            <comment id="12520891" author="kurti" created="Sat, 18 Aug 2007 21:21:35 +0100"  >&lt;p&gt;Happens with 10.3.1.4 as well&lt;/p&gt;</comment>
                            <comment id="12520892" author="kurti" created="Sat, 18 Aug 2007 21:23:46 +0100"  >&lt;p&gt;Simplified testcase with only one column.&lt;/p&gt;</comment>
                            <comment id="12520894" author="kurti" created="Sat, 18 Aug 2007 21:24:45 +0100"  >&lt;p&gt;I&apos;ve got the same problem nearly every day in my application, therefore I simplified the example file from the mailinglist. I did also try it with MySQL without a deadlock.&lt;/p&gt;</comment>
                            <comment id="12523844" author="johnemb" created="Thu, 30 Aug 2007 13:38:53 +0100"  >&lt;p&gt;Related mailing list threads on derby-user, primo August 2007:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.nabble.com/lock-escalation-and-deadlocks-t4197785.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.nabble.com/lock-escalation-and-deadlocks-t4197785.html&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://www.nabble.com/Concurrent-select-and-insert-deadlock-on-index-t4204088.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.nabble.com/Concurrent-select-and-insert-deadlock-on-index-t4204088.html&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12523850" author="bcalmac" created="Thu, 30 Aug 2007 14:49:42 +0100"  >&lt;p&gt;The first thread (&lt;a href=&quot;http://www.nabble.com/lock-escalation-and-deadlocks-t4197785.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.nabble.com/lock-escalation-and-deadlocks-t4197785.html&lt;/a&gt; ) is just my wrong interpretation of the cause, so can be discarded.&lt;/p&gt;</comment>
                            <comment id="12542746" author="naka" created="Thu, 15 Nov 2007 12:05:11 +0000"  >&lt;p&gt;Hello.&lt;/p&gt;

&lt;p&gt;Reading the code of Repro program, &lt;br/&gt;
I found the situation that insert thread inserts &lt;b&gt;multiple rows&lt;/b&gt; in a transaction for times &lt;br/&gt;
while select thread selects &lt;b&gt;rows in a range condition&lt;/b&gt; results in scanning index for same table.&lt;/p&gt;

&lt;p&gt;I think the problem is that&lt;br/&gt;
inserting multiple row in a transaction make multiple locks for data rows and index rows ,&lt;br/&gt;
and then, &lt;br/&gt;
those locks causes deadlock between selecting same table,&lt;br/&gt;
because operation of selecting rows for range condition also needs locks for data rows and index rows in scanned range.&lt;/p&gt;


&lt;p&gt;I think there exists two ways to walk around for this situation.&lt;/p&gt;

&lt;p&gt;1:&lt;br/&gt;
Do not insert multiple rows in a transaction, &lt;br/&gt;
when selecting rows of same table in a range condition simultaneously, &lt;br/&gt;
as the Repro program.&lt;br/&gt;
I tried changing tracksPerBatch as 1 and &lt;br/&gt;
the deadlock problem of Repro program was resolved.&lt;/p&gt;

&lt;p&gt;2:&lt;br/&gt;
Loosen transaction isolation level.&lt;br/&gt;
I tried conn.setTransactionIsolation( Connection.TRANSACTION_READ_UNCOMMITTED ) and &lt;br/&gt;
the deadlock problem of Repro program was resolved.&lt;/p&gt;


&lt;p&gt;I&apos;m not sure those walk around is suitable for your case, &lt;br/&gt;
but I hope it helps you.&lt;/p&gt;


&lt;p&gt;I also think feature like hint for sql may be helpful in those case.&lt;br/&gt;
If we can suppress the use of index for select operation with hint, &lt;br/&gt;
we could also escape the problem using that feature.&lt;/p&gt;</comment>
                            <comment id="12542750" author="kurti" created="Thu, 15 Nov 2007 12:24:12 +0000"  >&lt;p&gt;I Tomohito,&lt;/p&gt;

&lt;p&gt;in my application, every insert is done on its own and the isolation is set to READ_UNCOMMITTED. Still the very same deadlock happens, although it needs several days and thousands of inserts and selects to manifest.&lt;/p&gt;

&lt;p&gt;The main difference of my application is, that the database is embedded, but accessed embedded and via the network. Do you think it would solve the problems if I&apos;d only use the network access? Or does there is no difference?&lt;/p&gt;</comment>
                            <comment id="12542757" author="naka" created="Thu, 15 Nov 2007 12:37:53 +0000"  >&lt;p&gt;Well ....&lt;br/&gt;
I set transaction isolation level of both select and insert operations to TRANSACTION_READ_UNCOMMITTED.&lt;br/&gt;
In that situation, I didn&apos;t see dead lock problem.&lt;/p&gt;

&lt;p&gt;I&apos;m not sure your situation exactly other than uploaded program...&lt;/p&gt;

&lt;p&gt;I don&apos;t think your problem have something to do with embedded or network server/client,&lt;br/&gt;
though I don&apos;t think using embedded mode via network file sharing system is good practice ....&lt;/p&gt;

</comment>
                            <comment id="12542769" author="kristwaa" created="Thu, 15 Nov 2007 13:16:30 +0000"  >&lt;p&gt;As a data point for Kurts last comment/question, I don&apos;t think accessing the database using only the client driver matters either.&lt;br/&gt;
I do sometimes see the deadlock in an application where all clients are using the client driver.&lt;br/&gt;
In this application only one row is inserted per transaction as well, but in addition there is a multi-row select and a single-row delete.&lt;/p&gt;

&lt;p&gt;In my case I was able to tune other parts of the application to work around the problem, but I am unable to tell exactly what caused the problem.&lt;br/&gt;
For your information, it is running with READ_COMMITTED (or REPEATABLE_READ), the load could be said to be medium+ and the table itself is normally pretty small (less than 1000 rows, can be down to a few hundreds).&lt;/p&gt;</comment>
                            <comment id="12542781" author="naka" created="Thu, 15 Nov 2007 13:50:54 +0000"  >&lt;p&gt;My recognition for this issue is that &lt;br/&gt;
Derby uses locks for table and index as a way to realize isolation of transaction and&lt;br/&gt;
cares needs to be taken for those locks.&lt;/p&gt;

&lt;p&gt;I found information around lock for index at next url.&lt;br/&gt;
&lt;a href=&quot;http://db.apache.org/derby/papers/btree_package.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://db.apache.org/derby/papers/btree_package.html&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12542953" author="oysteing" created="Fri, 16 Nov 2007 04:53:03 +0000"  >&lt;p&gt;See the analysis made by Knut Anders above (17/Aug/07).  This is a deadlock between an index scan that has shared locked a special row of the page to avoid that the row it is waiting for is moved to another page.  When another transaction needs to split the page, it creates a deadlock since the splitter needs this special lock in order to perform the split.  Hence, I think all isolation levels except READ UNCOMMITTED will have this problem.   (Since for all other isolation levels the scanner will have to wait for the exclusive lock of the inserter).&lt;/p&gt;

&lt;p&gt;As Knut Anders say, this deadlock could be avoided if the scanner did not lock this special row, but instead had some way to detect that the row has moved, and then renavigate from the root in such cases.  I would think something similar happens during rollback where an index  row may have moved due to page splits between do and undo.  Maybe something similar could be done here.  I think there are parts to this:&lt;/p&gt;

&lt;p&gt;  1. When a scan needs to wait for a lock, instead of locking this special row, it copies the key of the row so that when it has acquired the lock it is waiting for, it can restart the scan using this key.  &lt;/p&gt;

&lt;p&gt;  2. In order to detect when a renavigation is needed, the page needs to have some kind of state id that indicates whether a renavigation may be needed.  That is, should some row move off the page or in other ways have their address change, the state id will be incremented.  This way the scanner, by copying the current state id before it is suspended, can detect whether the page has changed.  (One need to consider whether this state id is something that needs to be persisted on the page or whether it can just reside in memory.  It depends on whether it may occur that the page is no longer in the page cache when the scan resumes.)&lt;/p&gt;



</comment>
                            <comment id="12542990" author="kurti" created="Fri, 16 Nov 2007 08:10:42 +0000"  >&lt;p&gt;Sorry for the noise, but my application even gets the deadlock with&lt;/p&gt;

&lt;p&gt;Connection.TRANSACTION_READ_UNCOMMITTED&lt;/p&gt;

&lt;p&gt;Unfortunately it is a mail cluster and it only gets this with 200+ simultaneous mail connections after several hours/days, so it is somehow hard to create a reproducing example. But I get it every second day, so I can easily verify any fix.&lt;/p&gt;</comment>
                            <comment id="12543058" author="naka" created="Fri, 16 Nov 2007 12:38:27 +0000"  >&lt;p&gt;I might be bound by idea of lock for scanning index ...&lt;br/&gt;
My concern is about situation when the range of index, where are already scanned, are restructured.&lt;/p&gt;

&lt;p&gt;That situation would result &lt;br/&gt;
that rows fetched before the restructuring operation done are not based on restructured index &lt;br/&gt;
though rows fetched after restructuring operation done are based on.&lt;/p&gt;


&lt;p&gt;Thinking that, I think lock is needed for index to be scanned, at least if transaction isolation level is Serializable.&lt;/p&gt;</comment>
                            <comment id="12543077" author="naka" created="Fri, 16 Nov 2007 14:05:44 +0000"  >&lt;p&gt;I found what I was confused ...&lt;/p&gt;

&lt;p&gt;Lock for scanning index is held only for &lt;b&gt;current position&lt;/b&gt;.&lt;br/&gt;
I confused as locks are held for not only current position but also scanned range.&lt;/p&gt;

&lt;p&gt;Reading code of BTreeScan#posotionAtNextPage,&lt;br/&gt;
lock for current page are unlocked when proceeding to next page. &lt;/p&gt;</comment>
                            <comment id="12543340" author="naka" created="Sun, 18 Nov 2007 04:18:02 +0000"  >&lt;p&gt;&amp;gt; One need to consider whether this state id is something that needs to be persisted on the page or whether it can just reside in memory. It depends on whether it may occur that the page is no longer in the page cache when the scan resumes.&lt;/p&gt;

&lt;p&gt;It would be needed for thestate id discussed here to be persisted.&lt;br/&gt;
According to the code of StoredPage#releaseExclusive() method, page cache are removed from CacheManager when the page is unlatched.&lt;/p&gt;

&lt;p&gt;org.apache.derby.impl.store.raw.data.StoredPage#releaseExclusive() :&lt;br/&gt;
    /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Ensure that the page is released from the cache when it is unlatched.&lt;br/&gt;
     *&lt;/li&gt;
	&lt;li&gt;@see org.apache.derby.impl.store.raw.data.BasePage#releaseExclusive&lt;br/&gt;
     *&lt;br/&gt;
     **/&lt;br/&gt;
	protected void releaseExclusive()
	{
		super.releaseExclusive();

		pageCache.release(this);
	}&lt;/li&gt;
&lt;/ul&gt;

</comment>
                            <comment id="12543363" author="knutanders" created="Sun, 18 Nov 2007 10:04:44 +0000"  >&lt;p&gt;The page is not removed from the page cache when it is unlatched, but its keep count is decremented, so it is possible that someone else has removed it when the scan is resumed.&lt;/p&gt;

&lt;p&gt;BasePage already has a pageVersion field, but it&apos;s only incremented when a logged action is performed on the page. I assume there also are unlogged actions that may move the row off the page?&lt;/p&gt;</comment>
                            <comment id="12543575" author="naka" created="Mon, 19 Nov 2007 14:34:34 +0000"  >&lt;p&gt;I found methods of StoredPage, which update contents of page, call logAction method which also bump pageVersion value.&lt;br/&gt;
Because index is in stored page,  I think any actions which move the row off the page are handled using those methods in StoredPage and are logged.&lt;/p&gt;
</comment>
                            <comment id="12543576" author="oysteing" created="Mon, 19 Nov 2007 14:41:55 +0000"  >&lt;p&gt;I think pageVersion is bumped on all (logged) changes to the page.  The ideal here would be a version number that is only bumped when a row is moved.  Otherwise, most re-navigations would happen when not necessary.   Given that an exclusive lock normally leads to the an update, one might as well do an unconditional re-navigation after having waited instead of basing it on pageVersion.&lt;/p&gt;</comment>
                            <comment id="12543589" author="knutanders" created="Mon, 19 Nov 2007 15:11:28 +0000"  >&lt;p&gt;Could we then have a variable which contains the last page version on which a row was moved, but not store the value to disk? Then the waiter could do something like&lt;/p&gt;

&lt;p&gt;    long savedVersion = pageVersion;&lt;br/&gt;
    waitForLock();&lt;br/&gt;
    if (lastRowMove == UNINITIALIZED) &lt;/p&gt;
{
        // page was evicted from the page cache while we were waiting,
        // row might have moved
        renavigate();
    }
&lt;p&gt; else if (lastRowMove &amp;gt; savedVersion) &lt;/p&gt;
{
        // a row has been moved while we were waiting
        renavigate();
    }
&lt;p&gt; else &lt;/p&gt;
{
        // row has not moved
    }

&lt;p&gt;Then we only renavigate when a row has moved or the page has been removed from the cache.&lt;/p&gt;</comment>
                            <comment id="12543590" author="oysteing" created="Mon, 19 Nov 2007 15:19:57 +0000"  >&lt;p&gt;Knut Anders Hatlen (JIRA) wrote:&lt;/p&gt;

&lt;p&gt;&amp;gt; Then we only renavigate when a row has moved or the page has been removed from the cache.&lt;/p&gt;

&lt;p&gt;I think that is a good idea.&lt;/p&gt;</comment>
                            <comment id="12543596" author="naka" created="Mon, 19 Nov 2007 15:30:54 +0000"  >&lt;p&gt;I think lastRowMove is needed to be instance variable of page cache object ...&lt;br/&gt;
Here we encounter removed cache problem again ....&lt;/p&gt;
</comment>
                            <comment id="12543603" author="naka" created="Mon, 19 Nov 2007 16:03:57 +0000"  >&lt;p&gt;Oh I understand.&lt;br/&gt;
Taking removal of page cache as need for renavigate.&lt;/p&gt;</comment>
                            <comment id="12543867" author="naka" created="Tue, 20 Nov 2007 11:26:01 +0000"  >&lt;p&gt;I found there exists confusion yet...&lt;/p&gt;

&lt;p&gt;&amp;gt;    long savedVersion = pageVersion; &lt;br/&gt;
&amp;gt;    waitForLock(); &lt;br/&gt;
&amp;gt;    if (lastRowMove == UNINITIALIZED) &lt;/p&gt;
{ 
&amp;gt;        // page was evicted from the page cache while we were waiting, 
&amp;gt;        // row might have moved 
&amp;gt;        renavigate(); 
&amp;gt;    }
&lt;p&gt; else if (lastRowMove &amp;gt; savedVersion) &lt;/p&gt;
{ 
&amp;gt;        // a row has been moved while we were waiting 
&amp;gt;        renavigate(); 
&amp;gt;    }
&lt;p&gt; else &lt;/p&gt;
{ 
&amp;gt;        // row has not moved 
&amp;gt;    }
&lt;p&gt; &lt;/p&gt;

&lt;p&gt;&amp;gt;    waitForLock(); &lt;/p&gt;

&lt;p&gt;We were thinking about not locking the row.&lt;br/&gt;
Then I think this plan is impossible.&lt;/p&gt;
</comment>
                            <comment id="12543873" author="naka" created="Tue, 20 Nov 2007 11:48:32 +0000"  >&lt;p&gt;I read current code (and Knuts comment) that shared lock is gotten instead of latch of page and &lt;br/&gt;
the chance to release the latch are given to escape deadlock through trial for lock&lt;br/&gt;
in order to escape deadlock.&lt;/p&gt;

&lt;p&gt;If we don&apos;t get shared lock any more in program, we can do for escaping deadlock is just release the latch.&lt;/p&gt;

&lt;p&gt;Releasing the latch may results the StoredPage, which also means latch for Page, to be removed.&lt;/p&gt;

&lt;p&gt;If the PageCache is not removed, we can use lastRowMove of StoredPage as above.&lt;br/&gt;
If the PageCache is removed, there are three cases.&lt;br/&gt;
1: Only scanning index operation held latch and PageCache was removed. The row is not moved.&lt;br/&gt;
2: Other operation also held latch and move the row and release the latch and PageCache was removed.&lt;br/&gt;
3: Other operation also held latch and does not move the row but store something and release the latch and PageCache was removed.&lt;/p&gt;

&lt;p&gt;Seeing page version of loaded PageCache, we can distinguish 1 from others.&lt;br/&gt;
I think it would be not so awful to check rows in page to know 2 or 3.&lt;/p&gt;</comment>
                            <comment id="12543877" author="naka" created="Tue, 20 Nov 2007 12:16:59 +0000"  >&lt;p&gt;I think code would be like this.&lt;br/&gt;
I think we also need to see contents of page if cache was removed once.&lt;/p&gt;

&lt;p&gt;    long savedVersion = pageVersion; &lt;br/&gt;
    page.unlatch()    &lt;br/&gt;
    page = null;&lt;br/&gt;
               &amp;lt;snip&amp;gt;&lt;/p&gt;

&lt;p&gt;     //Where need to see the row&lt;br/&gt;
     page = getFromCache()&lt;/p&gt;

&lt;p&gt;     if (page == null) { &lt;br/&gt;
         page = getFromStorage()&lt;/p&gt;

&lt;p&gt;         if( page.pageVersion == savedVersion )&lt;/p&gt;
{
            // row has not moved 
         }else if( checkRowMoved(page) )&lt;br/&gt;
            renavigate(); &lt;br/&gt;
         }else{
            // row has not moved 
         }

&lt;p&gt;     } else if(page.lastRowMove == UNINITIALIZED ){  // This can be true if cache of page was removed once and loaded again.&lt;br/&gt;
         if( checkRowMoved(page))&lt;/p&gt;
{ // The cache was removed after row moved.
            renavigate(); 
         }
&lt;p&gt;else&lt;/p&gt;
{
            // row has not moved 
         }

&lt;p&gt;     } else if (page.lastRowMove &amp;gt; savedVersion) &lt;/p&gt;
{ 
         // a row has been moved while we were waiting 
         renavigate(); 
     }
&lt;p&gt; else &lt;/p&gt;
{ 
         // row has not moved 
     }
&lt;p&gt; &lt;/p&gt;</comment>
                            <comment id="12641834" author="knutanders" created="Wed, 22 Oct 2008 15:00:00 +0100"  >&lt;p&gt;I&apos;m hoping to find some time to investigate this issue.&lt;/p&gt;

&lt;p&gt;So far, only one suggestion for how we can fix this has come up. The&lt;br/&gt;
basic idea is that we don&apos;t set the scan lock to protect the scan&lt;br/&gt;
position, and instead we reposition the scan if we need to wait for a&lt;br/&gt;
lock and therefore have released the latch on the index leaf.&lt;/p&gt;

&lt;p&gt;Most of the discussion has been about how we can avoid the&lt;br/&gt;
repositioning when it&apos;s not needed, and I think we have a reasonably&lt;br/&gt;
good understanding of how we can do that by having a (non-persistent)&lt;br/&gt;
field in the page objects that give us a version number after which it&lt;br/&gt;
is guaranteed that no row has moved off the page.&lt;/p&gt;

&lt;p&gt;Earlier in the discussion we have said that this field should have a&lt;br/&gt;
special value to tell that it&apos;s uninitialized when the page is faulted&lt;br/&gt;
in to the page cache. After some more thinking, I now believe it would&lt;br/&gt;
be more reasonable to initialize it to the current version of the&lt;br/&gt;
page. Otherwise, the field would be uninitialized for most of the&lt;br/&gt;
cached pages, and it wouldn&apos;t help us avoiding repositioning most of&lt;br/&gt;
the time.&lt;/p&gt;

&lt;p&gt;What hasn&apos;t been discussed yet, is how we can do the repositioning&lt;br/&gt;
when we don&apos;t have the scan lock. &#216;ystein mentioned that the scan&lt;br/&gt;
could copy the key when it needs to wait for a lock, and use the key&lt;br/&gt;
to reposition itself in the B-tree. I think that sounds like a good&lt;br/&gt;
approach, but there are some things that are not quite clear to me:&lt;/p&gt;

&lt;p&gt;1) Would copying the key work for non-unique indexes as well? I guess&lt;br/&gt;
so since the non-unique indexes seem to append the RecordId to the&lt;br/&gt;
key.&lt;/p&gt;

&lt;p&gt;2) How stable are the RecordIds? Can they be changed by other&lt;br/&gt;
operations than compress table?&lt;/p&gt;

&lt;p&gt;3) If the isolation level is READ_COMMITTED or higher, the open scans&lt;br/&gt;
would have an intentional read lock on the table, so even without the&lt;br/&gt;
scan locks compress table shouldn&apos;t be able to change the RecordIds&lt;br/&gt;
while a scan is waiting for a lock (the intentional read lock should&lt;br/&gt;
block compress table when it attempts to write lock the table). But&lt;br/&gt;
would this work in READ_UNCOMMITTED? Or rather, does it work correctly&lt;br/&gt;
in READ_UNCOMMITTED today? READ_UNCOMMITTED doesn&apos;t set shared locks,&lt;br/&gt;
so I would assume that it doesn&apos;t set any shared scan locks either.&lt;/p&gt;

&lt;p&gt;Comments and suggestions would be appreciated. I&apos;ll do some more&lt;br/&gt;
digging and report back with my findings.&lt;/p&gt;</comment>
                            <comment id="12642440" author="knutanders" created="Fri, 24 Oct 2008 12:07:14 +0100"  >&lt;p&gt;It looks like READ_UNCOMMITTED transactions also obtain an IS lock on the tables they are scanning, and if they&apos;re performing an index scan an S lock on the scan control row. I think this means that the RecordId will not change because of compress table performed in another transaction while there&apos;s an open scan. I&apos;m not sure if that&apos;s always true if inplace compress table is performed in the same transaction, but it seems like at least the purging is performed in a nested transaction and will time out on getting an exclusive lock if the parent transaction has an open scan on that table.&lt;/p&gt;</comment>
                            <comment id="12646901" author="knutanders" created="Wed, 12 Nov 2008 14:05:33 +0000"  >&lt;p&gt;We already have code to save the position by key and reposition using&lt;br/&gt;
the saved key (methods savePosition() and reposition() in&lt;br/&gt;
BTreeScan). Currently, we only save the key on transaction borders so&lt;br/&gt;
that we can reposition a holdable cursor after a commit. This is&lt;br/&gt;
needed because transactions release all their locks on commit, scan&lt;br/&gt;
locks included.&lt;/p&gt;

&lt;p&gt;I think it should be possible to use the same logic to save the&lt;br/&gt;
position within a transaction. The current position of an index scan&lt;br/&gt;
is stored in a BTreeRowPosition object, either as a Page/RecordId pair&lt;br/&gt;
which requires a scan protection lock, or as a key value. Every time&lt;br/&gt;
the access layer is reentered, reposition() is called which either&lt;br/&gt;
just reacquires the latch on the page (if there&apos;s a scan lock) or&lt;br/&gt;
repositions from the root of the B-tree (if there&apos;s no scan lock).&lt;/p&gt;

&lt;p&gt;So I think that if we find a way to ensure that we always save the&lt;br/&gt;
position by key when we&apos;re about to release the latch on a leaf page&lt;br/&gt;
(either because we cannot obtain a lock immediately, or because we&apos;re&lt;br/&gt;
leaving the access layer), the repositioning code should work more or&lt;br/&gt;
less as it is.&lt;/p&gt;

&lt;p&gt;I&apos;m hoping that saving the key each time we release the latch doesn&apos;t&lt;br/&gt;
have a too heavy impact on single-threaded performance. For short&lt;br/&gt;
keys, it should be relatively cheap, and the cost of saving the key&lt;br/&gt;
may be outweighed by what we save by not having to maintain the scan&lt;br/&gt;
protection lock.&lt;/p&gt;

&lt;p&gt;With the optimizations suggested for the repositioning in earlier&lt;br/&gt;
comments, I believe that the repositioning will not be more expensive&lt;br/&gt;
than today in the common case where the page hasn&apos;t been split.&lt;/p&gt;

&lt;p&gt;I&apos;d welcome any comments and suggestions on how to implement this.&lt;/p&gt;</comment>
                            <comment id="12650107" author="stuckman" created="Mon, 24 Nov 2008 04:50:53 +0000"  >&lt;p&gt;I&apos;m also affected by this issue, and I&apos;d like to note that a concurrent select and update can cause the undesired behavior, not just a concurrent select and insert.&lt;/p&gt;

&lt;p&gt;Summary:&lt;br/&gt;
Even using READ_COMMITTED, a single non-updatable SELECT and a single UPDATE statement can deadlock against each other when an index includes the updated column.&lt;/p&gt;

&lt;p&gt;My test case uses the following table and index:&lt;br/&gt;
CREATE TABLE urls (urlid INTEGER NOT NULL PRIMARY KEY, url VARCHAR(2048) NOT NULL UNIQUE, site INTEGER, expectation INTEGER, jobflag CHAR DEFAULT &apos;N&apos;); CREATE INDEX findurlbysiteandjob ON urls(site,jobflag);&lt;/p&gt;

&lt;p&gt;My test case creates two threads and executes the following statements until they deadlock against each other:&lt;br/&gt;
UPDATE urls SET jobflag=? WHERE urlid=?	&lt;br/&gt;
SELECT urlid,url,expectation FROM urls WHERE site=?&lt;/p&gt;

&lt;p&gt;The test eventually deadlocks with the following transaction and lock table&lt;br/&gt;
contents:&lt;br/&gt;
XID     TYPE  MODE TABLENAME LOCKNAME  STATE TABLETYPE  LOCKCOUNT  INDEXNAME&lt;br/&gt;
2217109 ROW   S    URLS      (13,1)    GRANT T          1 FINDURLBYSITEANDJOB&lt;br/&gt;
2217114 ROW   X    URLS      (13,1)    WAIT  T          0 FINDURLBYSITEANDJOB&lt;br/&gt;
2217113 ROW   S    URLS      (15,1)    GRANT T          1 FINDURLBYSITEANDJOB&lt;br/&gt;
2217113 ROW   X    URLS      (3,132)   GRANT T          3          null&lt;br/&gt;
2217109 ROW   S    URLS      (3,132)   WAIT  T          0          null&lt;br/&gt;
2217109 TABLE IS   URLS      Tablelock GRANT T          2          null&lt;br/&gt;
2217113 TABLE IX   URLS      Tablelock GRANT T          4          null&lt;br/&gt;
2217114 TABLE IX   URLS      Tablelock GRANT T          1          null&lt;br/&gt;
2217113 ROW   S    URLS      (6,1)     GRANT T          1 SQL081111021116970&lt;/p&gt;

&lt;p&gt;XID     GLOBAL_XID  USERNAME TYPE                 STATUS  FIRST_INSTANT SQL_TEXT&lt;br/&gt;
2217115 null        APP      UserTransaction      IDLE    null select * from SYSCS_DIAG.TRANSACTION_TABLE&lt;br/&gt;
2217114 null        APP      InternalTransaction  ACTIVE  null UPDATE urls SET jobflag=? WHERE urlid=?&lt;br/&gt;
2217113 null        APP      UserTransaction      ACTIVE  (526,52925) UPDATE urls SET jobflag=? WHERE urlid=?&lt;br/&gt;
2069160 null        null     SystemTransaction    IDLE    null          null&lt;br/&gt;
2217109 null        APP      UserTransaction      ACTIVE  null&lt;/p&gt;


&lt;p&gt;1. The SELECT statement begins to execute and the cursor is stepping through the result set. The results are derived from index FINDURLBYSITEANDJOB as expected.&lt;br/&gt;
2. The UPDATE statement begins to execute. The row to be updated is the row immediately after the SELECT statement&apos;s cursor. The row is locked and updated.&lt;br/&gt;
3. The UPDATE statement must modify the index structure (tree rebalancing or similar?). It must lock the row that the SELECT statement&apos;s cursor is currently occupying. It cannot do this, so the transaction waits.&lt;br/&gt;
4. The SELECT statement is ready to advance the cursor. However, it cannot advance the cursor because the UPDATE statement has locked the next row. The transaction waits and we have a deadlock.&lt;/p&gt;

&lt;p&gt;Apparently, the only way to avoid this deadlock is to LOCK TABLE before updating.&lt;/p&gt;</comment>
                            <comment id="12650164" author="knutanders" created="Mon, 24 Nov 2008 10:56:51 +0000"  >&lt;p&gt;Attaching an experimental patch (d2991-preview-1a.diff) to show how&lt;br/&gt;
I&apos;m planning to fix the deadlock.&lt;/p&gt;

&lt;p&gt;The patch makes the B-tree scans save the scan position and release&lt;br/&gt;
the scan lock if they release the latch in the middle of the&lt;br/&gt;
scan. Although the patch doesn&apos;t remove the use of scan locks, it does&lt;br/&gt;
make sure that no transaction holds the scan lock on a page without&lt;br/&gt;
holding the latch on the same page, so the scan locks don&apos;t have any&lt;br/&gt;
effect anymore.&lt;/p&gt;

&lt;p&gt;The code to save the position and reposition could be used more or&lt;br/&gt;
less in its current state. Some small adjustments needed to be made:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;The existing savePosition methods couldn&apos;t be used directly since&lt;br/&gt;
    one of them assumed that the page was not latched when called, and&lt;br/&gt;
    the other one was meant to be called from other transactions that&lt;br/&gt;
    needed to tell the scan to save its position if it happened to be&lt;br/&gt;
    positioned on a given page. A new variant of savePosition was&lt;br/&gt;
    added. I believe that both of the old ones can be removed now,&lt;br/&gt;
    since the position will already have been saved and they won&apos;t&lt;br/&gt;
    have any work to do, but I need to check that.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;savePosition/reposition needed to save/restore information about&lt;br/&gt;
    whether or not the row at the current position was locked (which&lt;br/&gt;
    is available from scan_position.current_rh when the scan is&lt;br/&gt;
    positioned). This information wasn&apos;t need earlier since the scan&lt;br/&gt;
    position would only be saved on transactions boundaries, in which&lt;br/&gt;
    case the locks would be released.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The final solution should of course also remove the scan locks and&lt;br/&gt;
include the earlier discussed optimization to prevent unnecessary&lt;br/&gt;
repositioning when no rows have been moved off the page.&lt;/p&gt;

&lt;p&gt;I ran the attached repro (InsertSelectDeadlock.java) and didn&apos;t see&lt;br/&gt;
any timeouts when the patch was applied.&lt;/p&gt;

&lt;p&gt;I have also run the full regression test suite. suites.All ran&lt;br/&gt;
cleanly. Derbyall had five failures in the store tests:&lt;/p&gt;

&lt;p&gt;store/RowLockIso.sql&lt;br/&gt;
store/rlliso2multi.sql&lt;br/&gt;
store/rlliso3multi.sql&lt;br/&gt;
store/readlocks.sql&lt;br/&gt;
unit/T_b2i.unit&lt;/p&gt;

&lt;p&gt;The first four of them failed because (a) lock table dumps didn&apos;t&lt;br/&gt;
contain scan locks any longer, and (b) some inserts didn&apos;t fail with a&lt;br/&gt;
timeout trying to obtain the scan lock. These sound like expected&lt;br/&gt;
changes in behaviour and should probably be fixed by updating the&lt;br/&gt;
canons.&lt;/p&gt;

&lt;p&gt;The last failure (unit/T_b2i.unit) was caused by some debug code that&lt;br/&gt;
is only enabled when running that test. The debug code simulates that&lt;br/&gt;
the latch is lost, but it has not been updated to save the position&lt;br/&gt;
before it releases the latch, so an assert is triggered when we later&lt;br/&gt;
try to reposition. This should be fixed by changing the method&lt;br/&gt;
OpenBTree.test_errors so that it saves the position if needed.&lt;/p&gt;

&lt;p&gt;It would be great if someone could take a look at the patch and verify&lt;br/&gt;
that I&apos;m on the right track and that I&apos;m not missing something&lt;br/&gt;
essential.&lt;/p&gt;</comment>
                            <comment id="12651108" author="knutanders" created="Wed, 26 Nov 2008 19:03:20 +0000"  >&lt;p&gt;Attaching an updated preview patch (d2991-preview-1b.diff). Now all&lt;br/&gt;
the regression tests run cleanly. Differences from the previous patch:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;updated store tests so that they didn&apos;t expect scan locks in the&lt;br/&gt;
    lock table dumps or conflicts on the scan lock&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ensured that OpenBTree.test_errors() would save the position if&lt;br/&gt;
    the condition that is simulated would have resulted in the&lt;br/&gt;
    position being saved&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;verified that the existing savePosition methods could be removed,&lt;br/&gt;
    as I indicated in the previous comment, and removed the&lt;br/&gt;
    methods. This also made it possible to remove the methods from&lt;br/&gt;
    interfaces and no-op implementations of these methods in other&lt;br/&gt;
    scan types.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12651519" author="knutanders" created="Fri, 28 Nov 2008 10:44:58 +0000"  >&lt;p&gt;Here&apos;s a new update (preview-1c).&lt;/p&gt;

&lt;p&gt;In this patch, I have removed the locking of the scan protection&lt;br/&gt;
handle completely. This also led to the removal of some debug code&lt;br/&gt;
used to simulate wait and/or deadlock when locking the scan, and&lt;br/&gt;
therefore the test cases in T_b2i that expected this debug code to&lt;br/&gt;
run also had to be removed.&lt;/p&gt;

&lt;p&gt;I ran some simple performance tests to get an impression of how the&lt;br/&gt;
performance is affected (used o.a.derbyTesting.perf.clients.Runner).&lt;/p&gt;

&lt;p&gt;For single-record selects on primary key (-load sr_select) the&lt;br/&gt;
throughput was increased by 5-10%. I suppose this improvement is seen&lt;br/&gt;
because we no longer spend any time on obtaining and releasing the&lt;br/&gt;
scan locks. And since there&apos;s no saving of position or repositioning&lt;br/&gt;
happening with this load, no extra overhead is introduced.&lt;/p&gt;

&lt;p&gt;For 1000x10000 index joins (-load index_join) the throughput was down&lt;br/&gt;
15% (single-threaded) to 45% (multi-threaded). These operations&lt;br/&gt;
release the latch on the leaf frequently (once every 16 rows in the&lt;br/&gt;
index scans), which would mean that a costly renavigation in the&lt;br/&gt;
B-tree would happen very often. Additionally, the renavigation would&lt;br/&gt;
increase the contention on the root node of the B-tree, which is&lt;br/&gt;
probably why the performance drop is greater in the multi-threaded&lt;br/&gt;
scenario.&lt;/p&gt;

&lt;p&gt;Since some operations may see a significant performance drop, I think&lt;br/&gt;
the previously discussed optimization to prevent unnecessary&lt;br/&gt;
renavigation needs to be implemented before we can consider the patch&lt;br/&gt;
ready for commit.&lt;/p&gt;

&lt;p&gt;The patch is starting to get big, but I&apos;m not sure how to split it up&lt;br/&gt;
in smaller increments without temporarily degrading the performance of&lt;br/&gt;
the trunk. The patch currently removes a lot more code than it adds,&lt;br/&gt;
though, so the size of the patch doesn&apos;t tell the whole truth. The&lt;br/&gt;
inserted/deleted ratio is about 1/7, as seen by&lt;/p&gt;

&lt;p&gt;$ svn diff | diffstat | tail -1&lt;br/&gt;
 27 files changed, 196 insertions&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/add.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;, 1410 deletions&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/forbidden.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I&apos;ll be away next week and will probably not have much time to work on&lt;br/&gt;
this issue, but I will read my mail and try to answer questions.&lt;/p&gt;</comment>
                            <comment id="12651592" author="bryanpendleton" created="Fri, 28 Nov 2008 16:12:32 +0000"  >&lt;p&gt;Thanks for running the performance tests. It seems like the cases&lt;br/&gt;
where you are seeing some performance problems are mostly those&lt;br/&gt;
cases where the deadlocks were occurring. Since a small&lt;br/&gt;
performance penalty is vastly superior to a deadlock, I think it would&lt;br/&gt;
be reasonable to accept that penalty if the deadlocks are greatly&lt;br/&gt;
reduced or (hopefully) eliminated.&lt;/p&gt;</comment>
                            <comment id="12652417" author="knutanders" created="Tue, 2 Dec 2008 16:12:01 +0000"  >&lt;p&gt;I agree that the overhead would be acceptable if it had (almost) only&lt;br/&gt;
affected those situations where a deadlock could occur, but now&lt;br/&gt;
there&apos;s an overhead in other situations as well.&lt;/p&gt;

&lt;p&gt;A B-tree scan may release the latch on the current leaf page in the&lt;br/&gt;
following situations:&lt;/p&gt;

&lt;p&gt;1) When a lock cannot be obtained without waiting&lt;/p&gt;

&lt;p&gt;2) When no more rows should be returned by the scan (current key &amp;gt;&lt;br/&gt;
stop key)&lt;/p&gt;

&lt;p&gt;3) After a bulk fetch (where a bulk contains from 1 row to 16 rows)&lt;/p&gt;

&lt;p&gt;4) When the end of the current leaf has been reached and the next leaf&lt;br/&gt;
has been latched&lt;/p&gt;

&lt;p&gt;With the latest patch, we save the current position by key in (1) and&lt;br/&gt;
(3). In (2) it&apos;s not needed because the scan is complete and no&lt;br/&gt;
repositioning will ever be attempted. In (4) it&apos;s not needed since&lt;br/&gt;
we&apos;re now successfully positioned on the first row on the next page.&lt;/p&gt;

&lt;p&gt;The only situation in which a deadlock can occur, is (1), but we&lt;br/&gt;
currently always reposition by renavigating the B-tree after having&lt;br/&gt;
saved the position by key, so the overhead is also seen in&lt;br/&gt;
(3). Unfortunately, almost any query that reads more than 16 rows from&lt;br/&gt;
an index will be hit by this.&lt;/p&gt;

&lt;p&gt;I&apos;m planning to update the experimental patch with the discussed&lt;br/&gt;
optimization so that we don&apos;t need to renavigate the B-tree when&lt;br/&gt;
repositioning in the common case. If that&apos;s successful, we can revisit&lt;br/&gt;
whether the patch should be split and reviewed/committed in smaller&lt;br/&gt;
pieces. If we have a proof of concept in place that shows that the&lt;br/&gt;
performance issues are solvable, it might be acceptable to commit a&lt;br/&gt;
partial solution that causes performance regressions for some&lt;br/&gt;
operations for a shorter period of time (a week or so) before we&lt;br/&gt;
commit the final patch.&lt;/p&gt;</comment>
                            <comment id="12652969" author="kmarsden" created="Wed, 3 Dec 2008 20:56:23 +0000"  >&lt;p&gt;Thanks Knut for working on this issue.  I know it is important to several users.    For one of those users, Myrna backported the 1c patch  along with the fix for &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-2878&quot; title=&quot;Scan protection handle could be cached in BasePage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-2878&quot;&gt;&lt;del&gt;DERBY-2878&lt;/del&gt;&lt;/a&gt; to 10.3  to try out (Thanks Myrna).  The user reported that it resolved all of their lock timeouts due to this issue and passed their regression tests.  So great work Knut!    We also have a request to backport this once done all the way to 10.1 for a user locked into that version.  So my questions are:&lt;/p&gt;

&lt;p&gt;1)  Do you have any kind of general estimate when the final patch might be ready for trunk?&lt;br/&gt;
2)  Do you have any reservations or concerns about my trying to backport the fix once complete to older codelines? Do you know if that is even feasible for 10.1?&lt;br/&gt;
3) Is there anything that I can do to help with this issue?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;

&lt;p&gt;Kathey&lt;/p&gt;
</comment>
                            <comment id="12652990" author="mikem" created="Wed, 3 Dec 2008 21:49:24 +0000"  >&lt;p&gt;I am concerned about performance of always saving full key.  This is going to cause both cpu and memory problems(garbage collection).  As originally designed it was expected that this path would be rare so no optimization was ever done.  The save by id path was the one optimized.&lt;/p&gt;

&lt;p&gt;Did you ever consider fixing by only changing the deadlock case, ie always giving up the scan position lock when one has to wait on a lock?  This case should be rare, compared with the very normal case of group scan which happens by default for any scan of btree returning more than 16 rows for one query.&lt;/p&gt;

&lt;p&gt;sorry for late comment, was out on vacation when you started on this.&lt;/p&gt;</comment>
                            <comment id="12653039" author="mikem" created="Wed, 3 Dec 2008 23:12:34 +0000"  >&lt;p&gt;After reviewing the current patch, this does not look like a change appropriate for a backport.  It is already 5000 lines of diffs and changes a basic concurrency building block of the btree code.  Getting rid of the scan lock if it can be done with little or no performance penality does look like a good feature for a major release.  It will simplify a lot of code, but would like to see a lot of testing before it gets into an official derby release.  &lt;/p&gt;

&lt;p&gt;I do agree this is a good direction.  Some of the code that originally depended on the scan protection lock no longer needs to as part of work that was later done to support the read uncommitted isolation level.  Off the top of my head my areas of concern would be that the following operations work correctly in all combinations without the concurrency protection provided by the scan protection lock (I think they are ok as they should be protected by latches, but just get worried removing locking from these operations):&lt;br/&gt;
split&lt;br/&gt;
merge&lt;br/&gt;
reclaim deleted rows&lt;/p&gt;

&lt;p&gt;Another area that might be worth thinking about is to make sure the code that get&apos;s previous key locks for serializable is still right without the scan protection lock.  Need to make sure an intervening split which previously was not possible does not break this code.&lt;/p&gt;

&lt;p&gt;This stuff is hard to test for, I will think about these operations and see if there is any hidden dependency or if they only got the scan protection lock to enable the scan optimization. &lt;/p&gt;

&lt;p&gt;I definitely do worry about having to copy around the full key every time one gives up the latch.  Given the current store interface we can&apos;t keep references so we have to allocate &lt;br/&gt;
objects.  This in the worst case can lead to allocation/copies for every index reference in a query and can quickly add up which was why the additional complicaiton of the scan lock was added in the first place.  It would be interesting to understand the performance overhead of the copy vs. the extra search.  As I understand it the proposed optimization would in the &quot;usual&quot; case as long as the page remained in memory eliminate the scan but would not eliminate the copy.   Probably the worst case is long keys (maybe multi-part) and maybe datatypes that require object allocations every time they are copied (like decimal).&lt;/p&gt;</comment>
                            <comment id="12653364" author="knutanders" created="Thu, 4 Dec 2008 17:07:31 +0000"  >&lt;p&gt;Thanks to all of you for looking at this.&lt;/p&gt;

&lt;p&gt;To Kathey&apos;s questions, I will get back to working on this issue next&lt;br/&gt;
week and hope to have optimized the patch further and tested it some&lt;br/&gt;
more by the end of that week. It&apos;s difficult to say when a fix can be&lt;br/&gt;
committed to trunk, as it depends on whether we find the suggested&lt;br/&gt;
approach acceptable or if we need to find another way to fix it. And&lt;br/&gt;
as Mike mentioned more testing is needed in any case. I do hope we can&lt;br/&gt;
come up with an approach everyone feels comfortable with in the next&lt;br/&gt;
couple of weeks before the holiday season, and then get it implemented&lt;br/&gt;
and properly tested in January. I agree with Mike though, that it&apos;s&lt;br/&gt;
probably too risky to backport the fix, unless we end up with&lt;br/&gt;
something simpler than the current proposal. Not that I&apos;m planning to&lt;br/&gt;
introduce any bugs, but since it changes some fundamental assumptions&lt;br/&gt;
in a critical part of the system, I wouldn&apos;t feel all that comfortable&lt;br/&gt;
with backporting it.&lt;/p&gt;

&lt;p&gt;To Mike&apos;s questions:&lt;/p&gt;

&lt;p&gt;Yes, I think it is possible to only save the position in situations&lt;br/&gt;
that could cause deadlocks. That would mean that we only save the&lt;br/&gt;
position if we need to wait for a lock. One possible complication is&lt;br/&gt;
that it&apos;s not necessarily the scan that&apos;s waiting for a lock that&apos;s&lt;br/&gt;
holding the scan lock that causes the deadlock. Therefore we would&lt;br/&gt;
need to save the position in all the open B-tree scans in the&lt;br/&gt;
transaction when a lock cannot be granted immediately. And this must&lt;br/&gt;
be done for all locks that we wait on, not only locks in B-tree scans,&lt;br/&gt;
so it will add complexity to code outside the B-tree code as&lt;br/&gt;
well. Given that this increases the complexity and removing the scan&lt;br/&gt;
locks reduces the complexity, I&apos;d prefer a solution where the scan&lt;br/&gt;
locks are removed completely if it can be done with acceptable&lt;br/&gt;
performance.&lt;/p&gt;

&lt;p&gt;As to the performance, I hope that it will be possible to measure the&lt;br/&gt;
actual cost of copying the key once I have removed the expensive and&lt;br/&gt;
unnecessary renavigation. You are right that the suggested&lt;br/&gt;
optimization will only save the renavigation, not the copying. Some&lt;br/&gt;
thoughts/guesses:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The current code that saves the key always allocates a new&lt;br/&gt;
    DataValueDescriptor array and populates it with empty&lt;br/&gt;
    DataValueDescriptors of the correct type. It shouldn&apos;t be&lt;br/&gt;
    necessary to do this more than once per scan. That could save much&lt;br/&gt;
    allocation/gc work.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;When we save the key, we retrieve it by calling fetchFromSlot(),&lt;br/&gt;
    which will deserialize the value of the key from the page. I think&lt;br/&gt;
    that this is causing the same work to be performed twice when we&lt;br/&gt;
    save the position in methods like BTreeForwardScan.fetchRows(), at&lt;br/&gt;
    least when the scan is returning the full key, and we could&lt;br/&gt;
    probably make this more efficient.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;What we save by not obtaining/releasing the scan lock includes 2-3&lt;br/&gt;
    lookups in a global hashtable per leaf page, which could give an&lt;br/&gt;
    extra benefit in a multi-threaded scenario.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;It&apos;s not clear to me that the size of the key is significant. The&lt;br/&gt;
    cost of the scan lock is constant per page. Since a bigger key&lt;br/&gt;
    means fewer keys per page, the cost of copying keys should also be&lt;br/&gt;
    more or less constant per page. So the ratio between the cost&lt;br/&gt;
    saved and the cost added may not be that much affected by the size&lt;br/&gt;
    of the key.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;One of the worst cases is probably where extra qualification of&lt;br/&gt;
    the row is needed. Like &quot;SELECT index_column FROM t WHERE&lt;br/&gt;
    length(index_column) = 10&quot;, in which case I think we&apos;ll release&lt;br/&gt;
    the latch, and therefore also save the key, for every row in the&lt;br/&gt;
    index.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The suggestions for new tests look reasonable to me. The current&lt;br/&gt;
regression tests probably don&apos;t test that the current position has&lt;br/&gt;
been moved to another page while we didn&apos;t hold the latch, since those&lt;br/&gt;
situations would have resulted in a lock timeout before. So we&lt;br/&gt;
basically need to have tests for split/merge/reclaim for every call to&lt;br/&gt;
reposition() in the code. Will need to think more about how to do&lt;br/&gt;
that. Thanks for raising the concern for the previous key locking as&lt;br/&gt;
well.&lt;/p&gt;</comment>
                            <comment id="12657001" author="knutanders" created="Tue, 16 Dec 2008 14:57:01 +0000"  >&lt;p&gt;Attaching a new preview patch (1d) that implements the optimization&lt;br/&gt;
which prevents the expensive repositioning when no rows have been&lt;br/&gt;
moved off the page. I haven&apos;t done any serious testing of the&lt;br/&gt;
correctness in all scenarios, I&apos;m just posting it so that we can get&lt;br/&gt;
more information about the performance impact of saving the position.&lt;/p&gt;

&lt;p&gt;As an initial test, I reran the index-join test that I mentioned&lt;br/&gt;
earlier and that showed a significant decrease in performance with the&lt;br/&gt;
preview-1c patch. With the preview-1d patch, I&apos;m not able to see any&lt;br/&gt;
decrease (the numbers are actually slightly better with the 1d patch&lt;br/&gt;
than with trunk, though I&apos;m not sure whether it&apos;s significant). Below&lt;br/&gt;
are the results for 1, 2, 4, 8 and 16 concurrent threads for the 1d&lt;br/&gt;
patch (rows prefixed with &apos;d2991&apos;) and trunk (rows prefixed with&lt;br/&gt;
&apos;trunk&apos;). The AVG_TPS column shows the number of transactions per&lt;br/&gt;
second, all configurations were run 30 times (each test run had 30 sec&lt;br/&gt;
warmup and 45 sec steady state) and the AVG_TPS column shows the&lt;br/&gt;
average from the 30 runs.&lt;/p&gt;

&lt;p&gt;JAR       |THREADS    |AVG_TPS               &lt;br/&gt;
---------------------------------------------&lt;br/&gt;
d2991     |1          |136.3599695946353     &lt;br/&gt;
trunk     |1          |136.0475449900022     &lt;br/&gt;
d2991     |2          |265.9779264453826     &lt;br/&gt;
trunk     |2          |262.8875064800415     &lt;br/&gt;
d2991     |4          |262.95638006368955    &lt;br/&gt;
trunk     |4          |255.46471154558247    &lt;br/&gt;
d2991     |8          |256.97232845038025    &lt;br/&gt;
trunk     |8          |252.92527586462265    &lt;br/&gt;
d2991     |16         |256.84847624018147    &lt;br/&gt;
trunk     |16         |254.06894019626188    &lt;/p&gt;

&lt;p&gt;I will see if I can write some more specific tests that test the other&lt;br/&gt;
possible worst-case scenarios suggested in earlier comments.&lt;/p&gt;

&lt;p&gt;What the patch does, is that it saves the version of the page in the&lt;br/&gt;
BTreeRowPosition object before it saves the page, and each time rows&lt;br/&gt;
can be moved off the page (in operations that previously acquired an&lt;br/&gt;
exclusive scan lock) this is flagged in the in-memory representation&lt;br/&gt;
of the page. BTreeScan.reposition() will first match the version in&lt;br/&gt;
BTreeRowPosition with the flagged version number on the page, and will&lt;br/&gt;
only reposition by key if the page has been flagged after the position&lt;br/&gt;
was saved. Pages are automatically flagged with the current version&lt;br/&gt;
when they are fetched into the cache, so we&apos;ll always reposition by&lt;br/&gt;
key if the page has been evicted from the cache after we saved the&lt;br/&gt;
position.&lt;/p&gt;

&lt;p&gt;The patch also makes savePosition() reuse the DataValueDescriptor&lt;br/&gt;
object in which the key is stored, so that it&apos;s only allocated once&lt;br/&gt;
per scan.&lt;/p&gt;

&lt;p&gt;Currently, the patch does not handle the case where the page has&lt;br/&gt;
disappeared when we reposition (only happens with holdable cursors&lt;br/&gt;
after a commit followed by truncate table, I think) or the case where&lt;br/&gt;
the leaf page has turned into a branch page while we waited. These&lt;br/&gt;
problems led to four failures in derbyall and four failures in&lt;br/&gt;
suites.All.&lt;/p&gt;</comment>
                            <comment id="12657838" author="knutanders" created="Thu, 18 Dec 2008 18:16:05 +0000"  >&lt;p&gt;Here&apos;s a small performance test that I wrote. It extends the JDBCPerfTestCase class in the JUnit framework. All the tests use a table with 1000 rows. The table has 13 columns: one VARCHAR(10), one VARCHAR(100), one VARCHAR(1000) and ten DECIMAL(10,10). Each single VARCHAR column has an index, one compound index is covering all the VARCHAR columns, there&apos;s an index on one of the DECIMAL columns, and there&apos;s one covering all the DECIMAL columns. For each index, there&apos;s a test case that simply runs through the entire index.&lt;/p&gt;

&lt;p&gt;After a couple of repeated runs I can&apos;t say that saving the position looks more expensive than locking the scan. Actually, the tests appear to perform slightly better when the position is saved, at least that&apos;s what it looks like in my environment (OpenSolaris 2008.11, Java 1.6.0_10). (Except that in some cases it fails because the JUnit framework compresses all the tables before starting the test, and the problem with pages changing from leaf to branch mentioned in my previous comment surfaces.) I&apos;ll need to run the tests more in order to say anything for sure. I will do that and report back.&lt;/p&gt;

&lt;p&gt;Does anyone have suggestions for any other performance tests we should run to check if this is an appropriate path to follow?&lt;/p&gt;</comment>
                            <comment id="12658152" author="mikem" created="Fri, 19 Dec 2008 18:55:18 +0000"  >&lt;p&gt;that&apos;s great news on initial performance comparisons.  &lt;/p&gt;

&lt;p&gt;I am not sure if the following will do better, but it is what I thought of.  It seems like the worst case would be cases where we move the scan a lot without having latch on page.  ie. case where we get one row at a time from the page.  So I would suggest using the bulk fetch property to only get 1 row at a time:&lt;br/&gt;
CALL SYSCS_UTIL.SYSCS_SET_DATABASE_PROPERTY(&apos;derby.language.bulkFetchDefault&apos;,&apos;1&apos;);&lt;/p&gt;

&lt;p&gt;1000 rows does not seem like enough data to do a test.  One of the problems with the new approach, especially with something like decimal is that there is going to be extra object allocation per row.  So you want enough rows to see what effect it might have on GC.  I usually tried to make sure performance test took at least a second, and maybe 60 seconds&lt;br/&gt;
for at least a one time run.  &lt;/p&gt;

&lt;p&gt;Is a read only test  affected by pages going out of cache?  From your description I don&apos;t think so unless you get very strange cache behavior in that the scan current page goes out of cache during the scan of that page.  But might be worth showing that a both approaches perform same on a scan of a&lt;br/&gt;
table that is bigger than the cache when the scan is executed multiple times in a row.&lt;/p&gt;


&lt;p&gt;Should there be something that exercises the worst case where  the page is updated?  Again for this having a bigger dataset wil cause more overhead for the &lt;br/&gt;
search.   For this maybe something like a 2 part key with first part being as the current test&lt;br/&gt;
and the second part being an int and the test runs a cursor through the table and after reading each index row then updates the second part of the key by minus one, likely leaving the key on the same page - but not putting the scan into an infinite loop.   Make sure the cursor choice is one which goes to the table every time, not one that caches the&lt;br/&gt;
values in the client somehow.   &lt;/p&gt;</comment>
                            <comment id="12658493" author="knutanders" created="Mon, 22 Dec 2008 10:21:11 +0000"  >&lt;p&gt;I had the JUnit test running repeatedly over the weekend, 300 times&lt;br/&gt;
for each configuration to get a more reliable average. I&apos;ve summarized&lt;br/&gt;
the results in the table below. Positive values in the increase column&lt;br/&gt;
means that trunk is faster, negative values means that the patched&lt;br/&gt;
version is faster.&lt;/p&gt;

&lt;p&gt;TEST                |TRUNK_TIME |PATCHED_TI&amp;amp;|INCREASE   |INCREASE_PERCENT      &lt;br/&gt;
-------------------------------------------------------------------------------&lt;br/&gt;
decimal10columns    |17752      |17761      |9          |0.0506985128436277    &lt;br/&gt;
decimal1column      |4875       |4842       |-33        |-0.676923076923075    &lt;br/&gt;
varchar10           |4586       |4517       |-69        |-1.5045791539467945   &lt;br/&gt;
varchar100          |7288       |7185       |-103       |-1.4132821075740987   &lt;br/&gt;
varchar1000         |35977      |37008      |1031       |2.865719765405683     &lt;br/&gt;
varcharAll          |41502      |42701      |1199       |2.8890173967519583    &lt;/p&gt;

&lt;p&gt;Not much difference between them. For smaller keys, it seems like&lt;br/&gt;
saving the position is slightly cheaper, whereas for larger keys it&lt;br/&gt;
appears to be slightly more expensive.&lt;/p&gt;</comment>
                            <comment id="12658514" author="knutanders" created="Mon, 22 Dec 2008 11:43:19 +0000"  >&lt;p&gt;Thanks for your comments, Mike.&lt;/p&gt;

&lt;p&gt;&amp;gt; I am not sure if the following will do better, but it is what I&lt;br/&gt;
&amp;gt; thought of. It seems like the worst case would be cases where we&lt;br/&gt;
&amp;gt; move the scan a lot without having latch on page. ie. case where we&lt;br/&gt;
&amp;gt; get one row at a time from the page. So I would suggest using the&lt;br/&gt;
&amp;gt; bulk fetch property to only get 1 row at a time: CALL&lt;br/&gt;
&amp;gt; SYSCS_UTIL.SYSCS_SET_DATABASE_PROPERTY(&apos;derby.language.bulkFetchDefault&apos;,&apos;1&apos;);&lt;/p&gt;

&lt;p&gt;Thanks, I wasn&apos;t aware of that property. I&apos;ll do some experiments with&lt;br/&gt;
it.&lt;/p&gt;

&lt;p&gt;&amp;gt; 1000 rows does not seem like enough data to do a test. One of the&lt;br/&gt;
&amp;gt; problems with the new approach, especially with something like&lt;br/&gt;
&amp;gt; decimal is that there is going to be extra object allocation per&lt;br/&gt;
&amp;gt; row. So you want enough rows to see what effect it might have on&lt;br/&gt;
&amp;gt; GC.&lt;/p&gt;

&lt;p&gt;I picked 1000 rows to make sure that we had at least a couple of full&lt;br/&gt;
index pages in each of the test cases. I assumed that having multiple&lt;br/&gt;
iterations on a smaller number of rows would have about the same&lt;br/&gt;
effect on GC as fewer iterations on a larger data set.&lt;/p&gt;

&lt;p&gt;&amp;gt; I usually tried to make sure performance test took at least a&lt;br/&gt;
&amp;gt; second, and maybe 60 seconds for at least a one time run.&lt;/p&gt;

&lt;p&gt;The tests mentioned in my previous comment had a fixed number of&lt;br/&gt;
iterations, so the total time for each test case varied between 20 and&lt;br/&gt;
150 seconds depending on key size. (The times in milliseconds in the&lt;br/&gt;
table must be multiplied by four to get the actual time spent because&lt;br/&gt;
of the way the framework runs the tests.) I can also try some longer&lt;br/&gt;
runs.&lt;/p&gt;

&lt;p&gt;&amp;gt; Is a read only test affected by pages going out of cache? From your&lt;br/&gt;
&amp;gt; description I don&apos;t think so unless you get very strange cache&lt;br/&gt;
&amp;gt; behavior in that the scan current page goes out of cache during the&lt;br/&gt;
&amp;gt; scan of that page.&lt;/p&gt;

&lt;p&gt;That&apos;s correct. Read only tests should not be affected by pages going&lt;br/&gt;
out of the cache. Even if the current page goes out while we don&apos;t&lt;br/&gt;
hold the latch, they shouldn&apos;t be affected unless there has been a&lt;br/&gt;
modification on the page after the latch was released. In that case&lt;br/&gt;
the page will have the dirty flag in addition to the recently-used&lt;br/&gt;
flag, so it&apos;s highly unlikely that it will be chosen for eviction.&lt;/p&gt;

&lt;p&gt;&amp;gt; But might be worth showing that a both approaches&lt;br/&gt;
&amp;gt; perform same on a scan of a table that is bigger than the cache when&lt;br/&gt;
&amp;gt; the scan is executed multiple times in a row.&lt;/p&gt;

&lt;p&gt;Good point. I&apos;ll run such a test.&lt;/p&gt;

&lt;p&gt;&amp;gt; Should there be something that exercises the worst case where the&lt;br/&gt;
&amp;gt; page is updated? Again for this having a bigger dataset wil cause&lt;br/&gt;
&amp;gt; more overhead for the search. For this maybe something like a 2 part&lt;br/&gt;
&amp;gt; key with first part being as the current test and the second part&lt;br/&gt;
&amp;gt; being an int and the test runs a cursor through the table and after&lt;br/&gt;
&amp;gt; reading each index row then updates the second part of the key by&lt;br/&gt;
&amp;gt; minus one, likely leaving the key on the same page - but not putting&lt;br/&gt;
&amp;gt; the scan into an infinite loop. Make sure the cursor choice is one&lt;br/&gt;
&amp;gt; which goes to the table every time, not one that caches the values&lt;br/&gt;
&amp;gt; in the client somehow.&lt;/p&gt;

&lt;p&gt;I think I understand what you&apos;re suggesting, but a couple of questions&lt;br/&gt;
just to make sure that I&apos;m not missing the point:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the purpose of this test is to check that we don&apos;t perform any&lt;br/&gt;
    repositioning by key just because there has been an update on the&lt;br/&gt;
    page?&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;by making sure that the client doesn&apos;t cache the values, you&lt;br/&gt;
    basically mean that bulk fetch should be disabled? So setting&lt;br/&gt;
    derby.language.bulkFetchDefault or perhaps using an updatable&lt;br/&gt;
    cursor and positioned updates should do the trick?&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12658895" author="knutanders" created="Tue, 23 Dec 2008 17:06:13 +0000"  >&lt;p&gt;I checked in the performance test with revision 729039.&lt;/p&gt;</comment>
                            <comment id="12659168" author="knutanders" created="Wed, 24 Dec 2008 23:06:15 +0000"  >&lt;p&gt;Here are the results from running the same tests with derby.language.bulkFetchDefault=1 (20 runs with each configuration):&lt;/p&gt;

&lt;p&gt;TEST                |TRUNK_TIME |PATCHED_TI&amp;amp;|INCREASE   |INC_PERCENT           &lt;br/&gt;
-------------------------------------------------------------------------------&lt;br/&gt;
decimal10columns    |28390      |33116      |4726       |16.646706586826348    &lt;br/&gt;
decimal1column      |16638      |17997      |1359       |8.168049044356293     &lt;br/&gt;
varchar10           |15062      |16426      |1364       |9.055902270614792     &lt;br/&gt;
varchar100          |18655      |21829      |3174       |17.014205306888233    &lt;br/&gt;
varchar1000         |47123      |70214      |23091      |49.001549137363924    &lt;br/&gt;
varcharAll          |52362      |78693      |26331      |50.286467285436       &lt;/p&gt;

&lt;p&gt;When bulk fetch is disabled, saving the position by key is clearly more expensive for these scans. With small keys, the extra cost appears to be moderate, but with large keys it is quite high.&lt;/p&gt;</comment>
                            <comment id="12659315" author="knutanders" created="Sat, 27 Dec 2008 09:07:51 +0000"  >&lt;p&gt;In BTreeForwardScan.fetchRows() we have already fetched the key (or&lt;br/&gt;
parts of the key) before we save the position. So I experimented with&lt;br/&gt;
copying the key instead of re-reading the entire record. The copying&lt;br/&gt;
was performed by iterating over fetch_row and calling setValue() on&lt;br/&gt;
each element of scan_position.current_positionKey. This eliminated&lt;br/&gt;
much of the overhead. A rerun of the JUnit test with&lt;br/&gt;
derby.language.bulkFetchDefault=1 gave these results (average of 20&lt;br/&gt;
runs for each configuration):&lt;/p&gt;


&lt;p&gt;TEST                |TRUNK_TIME |PATCHED_TI&amp;amp;|INCREASE   |INC_PERCENT  &lt;br/&gt;
----------------------------------------------------------------------&lt;br/&gt;
decimal10columns    |28427      |29727      |1300       |4.5731173    &lt;br/&gt;
decimal1column      |16572      |16890      |318        |1.9188993    &lt;br/&gt;
varchar10           |14715      |15673      |958        |6.5103636    &lt;br/&gt;
varchar100          |18378      |19472      |1094       |5.9527693    &lt;br/&gt;
varchar1000         |47092      |51618      |4526       |9.610974     &lt;br/&gt;
varcharAll          |52457      |57628      |5171       |9.857598     &lt;/p&gt;

&lt;p&gt;This will of course only work if the entire key is fetched by the&lt;br/&gt;
scan. A proper solution would have to read the missing parts of the&lt;br/&gt;
key if only parts of it are used by the scan.&lt;/p&gt;</comment>
                            <comment id="12660782" author="knutanders" created="Mon, 5 Jan 2009 15:13:32 +0000"  >&lt;p&gt;I have taken another look at the previous key locking. If the latches&lt;br/&gt;
are released when we&apos;re searching backward for the previous key, it&lt;br/&gt;
seems like we&apos;ll rescan the tree, so it doesn&apos;t seem like we&apos;re&lt;br/&gt;
depending on the scan lock. Some relevant code fragments and comments:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;BTreeController.doIns():&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    while (true)&lt;br/&gt;
    {&lt;br/&gt;
    .&lt;br/&gt;
    .&lt;br/&gt;
    .&lt;br/&gt;
        // Row locking - first lock row previous to row being inserted:&lt;br/&gt;
    .&lt;br/&gt;
    .&lt;br/&gt;
    .&lt;br/&gt;
        if (latch_released)&lt;/p&gt;
        {
            // Had to release latch in order to get the lock, probably 
            // because of a forward scanner, research tree, and try again.
            targetleaf = null;
            continue;
        }

&lt;ul&gt;
	&lt;li&gt;B2IRowLocking3._lockScanRow():&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    if (pos.current_slot == 0)&lt;br/&gt;
    {&lt;br/&gt;
        // this call will take care of searching left in the btree&lt;br/&gt;
        // to find the previous row to lock, 0 is the control row and&lt;br/&gt;
        // not a valid thing to lock as a previous key.&lt;/p&gt;

&lt;p&gt;        // it is ok to call the non-scan as this is just a special&lt;br/&gt;
        // case of a previous key lock call.  The only scan code that&lt;br/&gt;
        // will call this routine with slot == 0 will retry if this&lt;br/&gt;
        // routine returns that a latch was released.&lt;/p&gt;

&lt;p&gt;        latch_released = &lt;br/&gt;
            !lockNonScanPreviousRow(&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;B2IRowLocking3.lockNonScanPreviousRow():&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    // RESOLVE RLL (mikem) - NO RECORD_ID PROTECTION IN EFFECT.&lt;br/&gt;
    // caller must research, get new locks if this routine &lt;br/&gt;
    // releases latches.&lt;br/&gt;
    ret_status = this.searchLeftAndLockPreviousKey(&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;B2IRowLocking3.searchLeftAndLockPreviousKey():&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;If along the search a latch has to be waited on then latches are&lt;/li&gt;
	&lt;li&gt;released and a wait is performed, and &quot;false&quot; status is returned to&lt;/li&gt;
	&lt;li&gt;caller.  In this case the routine can no longer be sure of it&apos;s current&lt;/li&gt;
	&lt;li&gt;position and may have to retry the whole operation.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12661220" author="mikem" created="Tue, 6 Jan 2009 17:44:22 +0000"  >&lt;p&gt;sorry for late reply, was out and away from computer end of the year.&lt;br/&gt;
&amp;gt; I think I understand what you&apos;re suggesting, but a couple of questions&lt;br/&gt;
&amp;gt; just to make sure that I&apos;m not missing the point:&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; - the purpose of this test is to check that we don&apos;t perform any&lt;br/&gt;
&amp;gt; repositioning by key just because there has been an update on the&lt;br/&gt;
&amp;gt; page?&lt;br/&gt;
yes.  I must be misunderstanding the current patch, I thought it would&lt;br/&gt;
research on an update of the page.  probably worth measuring but not a lot&lt;br/&gt;
of different cases if the design does not expect a research.  I was trying&lt;br/&gt;
to force a measurement of worst case where a search would happen after every&lt;br/&gt;
row.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; - by making sure that the client doesn&apos;t cache the values, you&lt;br/&gt;
&amp;gt; basically mean that bulk fetch should be disabled? So setting&lt;br/&gt;
&amp;gt; derby.language.bulkFetchDefault or perhaps using an updatable&lt;br/&gt;
&amp;gt; cursor and positioned updates should do the trick?&lt;br/&gt;
My comment was about making the tree bigger.  Not necessarily to not cache&lt;br/&gt;
the tree, but by making there be more levels in the tree then it will cost&lt;br/&gt;
more to research the tree from the top.  Again was just wanting to know the&lt;br/&gt;
worst case penalty.  Maybe you could add a short comment about in which&lt;br/&gt;
cases we will research the tree with the new scheme vs. the old scheme.&lt;/p&gt;

&lt;p&gt;The test I was suggesting I think could be done with updatable cursor and&lt;br/&gt;
positioned updates, as long as the properties of the cursor are such that&lt;br/&gt;
each next goes to the database.   There are some cursor settings where&lt;br/&gt;
caching will happen in the client and nothing you do to the database after&lt;br/&gt;
each row fetch will get you into the btree research code that we are trying&lt;br/&gt;
to exercise.&lt;/p&gt;</comment>
                            <comment id="12661235" author="mikem" created="Tue, 6 Jan 2009 18:13:02 +0000"  >&lt;p&gt;concerning the latest performance results, I am still concerned as I believe the bulkfetch=1 case simulates the path that nested loop joins take, so may affect a lot of normal query behavior.  But your latest optimization looks promising, I would not be surprised if &lt;br/&gt;
there was some optimization that could be made in the copying of one DataValueDescriptor to another.  &lt;/p&gt;

&lt;p&gt;Do you know if in the char/varchar case if the source DVD is already in String form (vs raw character array).&lt;/p&gt;</comment>
                            <comment id="12661580" author="knutanders" created="Wed, 7 Jan 2009 14:05:51 +0000"  >&lt;p&gt;Thanks for clarifying the comments about the tests, Mike. I&apos;ll make&lt;br/&gt;
the modifications and come back with the results.&lt;/p&gt;

&lt;p&gt;&amp;gt; Maybe you could add a short comment about in which cases we will&lt;br/&gt;
&amp;gt; research the tree with the new scheme vs. the old scheme.&lt;/p&gt;

&lt;p&gt;The old scheme (current Derby) will research the tree in these&lt;br/&gt;
situations:&lt;/p&gt;

&lt;p&gt;  a) Locks (scan lock, row lock or prev key lock) could not be obtained&lt;br/&gt;
     immediately when positioning at the start of the scan&lt;/p&gt;

&lt;p&gt;  b) Transaction was committed after we released the latch (then&lt;br/&gt;
     there&apos;s no scan lock protecting the position anymore)&lt;/p&gt;

&lt;p&gt;  c) Some other operation within the same transaction caused a split&lt;br/&gt;
     on the page we were positioned on after we released the latch&lt;br/&gt;
     (scan lock doesn&apos;t protect us against changes in the same&lt;br/&gt;
     transaction)&lt;/p&gt;

&lt;p&gt;The new scheme will research the tree in situation (a) above, and&lt;br/&gt;
additionally:&lt;/p&gt;

&lt;p&gt;  d) A row was moved off the page after we released the latch (caused&lt;br/&gt;
     by split or purge)&lt;/p&gt;

&lt;p&gt;  e) The current page was updated (any update, as long as the page&lt;br/&gt;
     version was changed) &lt;b&gt;and&lt;/b&gt; evicted from the page cache after we&lt;br/&gt;
     released the latch&lt;/p&gt;

&lt;p&gt;&amp;gt; Do you know if in the char/varchar case if the source DVD is already&lt;br/&gt;
&amp;gt; in String form (vs raw character array).&lt;/p&gt;

&lt;p&gt;It is still in raw form when the value is copied, but it will be&lt;br/&gt;
converted to string form SQLChar.setFrom(DVD) calls getString() on the&lt;br/&gt;
DVD. In the tests I&apos;ve run till now, it shouldn&apos;t matter since we&apos;ll&lt;br/&gt;
end up calling DVD.getString() from EmbedRS.getString() on all the&lt;br/&gt;
strings anyway, and the two SQLChar instances share the same immutable&lt;br/&gt;
String instance. In other cases it could matter, so it would be better&lt;br/&gt;
if we could share the char array between the two SQLChar objects and&lt;br/&gt;
avoid the allocation of the String. Not sure if this is safe,&lt;br/&gt;
though. SQLChar treats the raw char array as an immutable data type in&lt;br/&gt;
most cases, but not in normalize().&lt;/p&gt;

&lt;p&gt;It&apos;s the same with the DECIMAL tests. The source DVD is in raw form&lt;br/&gt;
(byte[] + int) and is converted to a BigDecimal that&apos;s shared between&lt;br/&gt;
the two SQLDecimal instances.&lt;/p&gt;

&lt;p&gt;The cheapest way to copy the key would probably be to have a method in&lt;br/&gt;
the Page interface that could copy the raw row to a byte array. We&lt;br/&gt;
would only have to deserialize the key if repositioning was needed,&lt;br/&gt;
and we would only need one extra object allocation per scan in the&lt;br/&gt;
normal case (unless the byte buffer we allocated the first time was&lt;br/&gt;
too small). Is that an option? The methods to serialize and&lt;br/&gt;
deserialize DVDs are public methods of all DVDs (writeExternal() and&lt;br/&gt;
writeExternal()), so it&apos;s not really like it would be exposing&lt;br/&gt;
implementation details in interface methods.&lt;/p&gt;</comment>
                            <comment id="12661938" author="knutanders" created="Thu, 8 Jan 2009 11:02:42 +0000"  >&lt;p&gt;Thinking more about it, copying the raw bytes from the page array would probably only be cheaper if the materialized values created by copying the keys were not going to be used later. So in the tests that I have run till now it shouldn&apos;t be any cheaper at all, since the objects we allocate when we copy the key would have been allocated later anyway. Might be worth a try if everything else fails, though.&lt;/p&gt;</comment>
                            <comment id="12662370" author="knutanders" created="Fri, 9 Jan 2009 13:55:43 +0000"  >&lt;p&gt;There must be something wrong with the test results I posted on&lt;br/&gt;
27/Dec/08.&lt;/p&gt;

&lt;p&gt;First of all, they don&apos;t really make any sense. Why should the&lt;br/&gt;
overhead of saving the position be greater for VARCHAR(1000) than for&lt;br/&gt;
VARCHAR(10)? Since the String object that we generate when we copy the&lt;br/&gt;
key is shared between the source DVD and the target DVD, and the&lt;br/&gt;
source DVD saves the same amount of work when it later needs to return&lt;br/&gt;
the String to the user, the overhead per row should be proportional to&lt;br/&gt;
the number of columns in the key, not to the size of the columns in&lt;br/&gt;
the key. And since reading longer values is more expensive than&lt;br/&gt;
reading shorter values, the relative overhead should be smaller rather&lt;br/&gt;
than greater for VARCHAR(1000).&lt;/p&gt;

&lt;p&gt;Secondly, I see the exact same results when I compare a clean trunk&lt;br/&gt;
with another clean trunk. For some reason, the runs (1, 3, 5, ...)&lt;br/&gt;
consistently show significantly better performance than the runs (2,&lt;br/&gt;
4, 6, ...). But it turns out that if I remove the database directory&lt;br/&gt;
between each run, I get much more stable results. I&apos;ve got no idea why&lt;br/&gt;
this happens. Perhaps something CleanDatabaseTestSetup or some other&lt;br/&gt;
part of the test framework does?&lt;/p&gt;

&lt;p&gt;Anyway, no matter what&apos;s causing it, I&apos;ll need to rerun the tests and&lt;br/&gt;
let each test run create its own database. It&apos;s probably also a good&lt;br/&gt;
idea to randomize the order of the test to eliminate interference from&lt;br/&gt;
periodic/alternating factors. In the previous test runs, I ran clean,&lt;br/&gt;
patched, clean, patched, and so on, so that all the bad runs were with&lt;br/&gt;
patched jars and all the good runs were with clean jars. Perhaps I&apos;ll&lt;br/&gt;
also write a simple standalone test, so that we don&apos;t need to worry&lt;br/&gt;
about what happens in the test framework.&lt;/p&gt;</comment>
                            <comment id="12662951" author="knutanders" created="Mon, 12 Jan 2009 13:26:59 +0000"  >&lt;p&gt;Had the tests with bulk-fetch disabled running over the weekend (200&lt;br/&gt;
times with a clean trunk, 200 times patched). Now I used a standalone&lt;br/&gt;
test which did the same as the JUnit test (except from some adjusting&lt;br/&gt;
of the number of iterations to get the time more evenly distributed&lt;br/&gt;
between the test cases, and the size of the test table was increased&lt;br/&gt;
from 1000 rows to 10000 rows), and I randomized the order of the&lt;br/&gt;
tests. Now the test results look much more reasonable.&lt;/p&gt;

&lt;p&gt;The test case with a key consisting of ten DECIMAL columns shows the&lt;br/&gt;
worst performance, with a 1.9% increase in the time spent. The test&lt;br/&gt;
cases with VARCHAR(10) and VARCHAR(100) showed 1.6% and 0.9% increase&lt;br/&gt;
in time spent, respectively. The other test cases basically showed the&lt;br/&gt;
same performance for clean jars and patched jars. The table below&lt;br/&gt;
shows the average numbers (times in milliseconds) for the test runs.&lt;/p&gt;

&lt;p&gt;NAME                    |TRUNK_TIME |PATCHED_TI&amp;amp;|INCREASE   |INC_PERCENT  &lt;br/&gt;
--------------------------------------------------------------------------&lt;br/&gt;
Decimal10Columns        |81495      |83025      |1530       |1.8774158    &lt;br/&gt;
DecimalSingleColumn     |63722      |63769      |47         |0.07375789   &lt;br/&gt;
Varchar0010             |54268      |55145      |877        |1.6160537    &lt;br/&gt;
Varchar0100             |70907      |71576      |669        |0.9434894    &lt;br/&gt;
Varchar1000             |87431      |87457      |26         |0.029737735  &lt;br/&gt;
VarcharAll              |97197      |96845      |-352       |-0.3621511   &lt;/p&gt;

&lt;p&gt;Now that I&apos;ve got test results that I understand, I&apos;ll go on and add&lt;br/&gt;
the test cases Mike suggested. If we don&apos;t find any common code path&lt;br/&gt;
that&apos;s slowed down more than what the latest test run showed, I would&lt;br/&gt;
be inclined to say the overhead is acceptable, given that it fixes a&lt;br/&gt;
serious issue and that other common code paths are actually getting&lt;br/&gt;
better performance, and investigation on how to reduce the overhead&lt;br/&gt;
further could be postponed until later. But let me first see how the&lt;br/&gt;
other suggested test cases are affected.&lt;/p&gt;</comment>
                            <comment id="12666147" author="knutanders" created="Thu, 22 Jan 2009 14:09:25 +0000"  >&lt;p&gt;Updating the preview patch (1e). There are two changes from the previous preview:&lt;/p&gt;

&lt;p&gt;1) If the leaf page on which we&apos;re positioned is transformed into a branch page while we don&apos;t hold the latch, we reposition by key. This fixes eight regression test failures (ClassCastExceptions) seen with 1d. FWIW, derbyall and suites.All now run without failures.&lt;/p&gt;

&lt;p&gt;2) Copy the (possibly partial) key fetched in BTreeForwardScan when saving the position, instead of re-reading the full key from the page. If the scan just fetches a partial key, we fetch the missing parts only from the page.&lt;/p&gt;

&lt;p&gt;This is not the same patch as I used in the latest performance test runs. That patch copied the key as if the full key had been fetched by the scan. However, since the tests only scan the index and don&apos;t go to the base table, the scans don&apos;t fetch the RowLocation which is the last column in the index. So when we save the position we still need to call Page.fetchFromSlot() to get the RowLocation. So now the overhead with bulk fetch disabled is back at 1% (for large key columns) to 10% (small/many key columns). I&apos;m posting the patch for reference anyway.&lt;/p&gt;</comment>
                            <comment id="12668514" author="knutanders" created="Thu, 29 Jan 2009 16:48:10 +0000"  >&lt;p&gt;I&apos;ve tried to find out which effect the proposed solution has on&lt;br/&gt;
nested loop joins. The assumption was earlier that nested loop joins&lt;br/&gt;
would turn off bulk fetching and therefore the index scans with&lt;br/&gt;
derby.language.bulkFetchDefault=1 would give a good impression of the&lt;br/&gt;
overhead imposed by the patch.&lt;/p&gt;

&lt;p&gt;This turns out not to be the case. Nested loop joins do in fact use&lt;br/&gt;
the default bulk fetch size (16) both for accesses to the outer table&lt;br/&gt;
and to the inner table. The inner table/index is accessed through many&lt;br/&gt;
shorter scans that frequently return fewer rows than the bulk fetch&lt;br/&gt;
size. But even if that causes frequent release of latches, it doesn&apos;t&lt;br/&gt;
cause copying of the current key, since the scan is done when the&lt;br/&gt;
latch is released, and therefore we don&apos;t need the position&lt;br/&gt;
anymore. So the nested loop joins will actually get much of the&lt;br/&gt;
performance benefit observed in single-record primary key selects&lt;br/&gt;
mentioned when the preview-1c patch was uploaded.&lt;/p&gt;

&lt;p&gt;I inserted some optimizer overrides in the index_join test in&lt;br/&gt;
org.apache.derbyTesting.perf.clients.Runner to make the optimizer pick&lt;br/&gt;
a nested loop join. With the modified test, the throughput appeared to&lt;br/&gt;
increase by about 6% when the patch was applied (average of 30 runs&lt;br/&gt;
with each configuration).&lt;/p&gt;

&lt;p&gt;So here&apos;s what it looks to me as if the performance impact is:&lt;/p&gt;

&lt;p&gt;a) Short index scans get increased performance because they don&apos;t need&lt;br/&gt;
to obtain the scan lock, and because saving the position is not needed&lt;br/&gt;
since they complete before they release the latch.&lt;/p&gt;

&lt;p&gt;b) Long index scans don&apos;t get very much affected by the patch (there&apos;s&lt;br/&gt;
extra cost in saving keys, but that only happens for every 16th row,&lt;br/&gt;
and there&apos;s a per page reduction in cost by obtaining the scan lock)&lt;/p&gt;

&lt;p&gt;c) Nested loop joins use (b) to scan the outer table and (a) to scan&lt;br/&gt;
the inner table, so they should not see any negative impact&lt;/p&gt;

&lt;p&gt;d) Long index scans without bulk fetching get lower performance&lt;br/&gt;
because they save the position for every qualified row in the index&lt;/p&gt;

&lt;p&gt;So the only case identified so far which will get lower performance,&lt;br/&gt;
is (d) long index scans without bulk fetching. This kind of scan may&lt;br/&gt;
be used by updatable cursors, but I&apos;m not aware of any other kind of&lt;br/&gt;
queries that would disable bulk fetching (except when users set&lt;br/&gt;
derby.language.bulkFetchDefault, but I don&apos;t think that&apos;s a very&lt;br/&gt;
important case). The overhead appears to be in the range 1%-10%,&lt;br/&gt;
depending on the key.&lt;/p&gt;

&lt;p&gt;Unless there are other common cases that I haven&apos;t thought of, it&lt;br/&gt;
sounds like an acceptable overhead to me, given that&lt;/p&gt;

&lt;p&gt;a) updatable cursors aren&apos;t all that common, and if they are actually&lt;br/&gt;
used to update the database, the extra CPU spent by the scan will be&lt;br/&gt;
negligible&lt;/p&gt;

&lt;p&gt;b) shorter scans see a performance increase in the same order as the&lt;br/&gt;
decrease seen by longer no-bulk scans&lt;/p&gt;

&lt;p&gt;c) concurrent reads and writes don&apos;t deadlock anymore unless there&apos;s a&lt;br/&gt;
real lock conflict&lt;/p&gt;

&lt;p&gt;Comments?&lt;/p&gt;</comment>
                            <comment id="12669401" author="bryanpendleton" created="Sun, 1 Feb 2009 16:50:01 +0000"  >&lt;p&gt;I think your performance testing has been superb: detailed and thorough.&lt;/p&gt;

&lt;p&gt;I&apos;m comfortable with the performance impact of this change.&lt;/p&gt;

&lt;p&gt;The deadlock is a serious problem, experienced by many users, and I think&lt;br/&gt;
this proposed fix is great. +1 from me to proceed with committing your patch.&lt;br/&gt;
Let&apos;s get it into the codeline and start getting some wider experience with it.&lt;/p&gt;</comment>
                            <comment id="12669461" author="knutanders" created="Sun, 1 Feb 2009 22:02:15 +0000"  >&lt;p&gt;Thanks for your comments, Bryan. I agree that if we go for this approach, it is better to get the code in early to get as much testing as possible before the next release. But I think the preview patches need to be cleaned up and have some more comments before they&apos;re ready to be committed. I&apos;m also about to start writing more functional tests, as I don&apos;t trust that the existing tests exercise all the new code paths. At the very least, I would like to have tests for all calls to reposition() in situations where the calls actually lead to a full repositioning from the root of the B-tree. Most of those cases are not tested by the existing tests because they would likely have led to timeouts.&lt;/p&gt;</comment>
                            <comment id="12670426" author="mikem" created="Wed, 4 Feb 2009 19:28:16 +0000"  >&lt;p&gt;I believe we should go forward with this change in the trunk.  I also am ok with the tested &lt;br/&gt;
performance trade off&apos;s.  I don&apos;t think we should backport a change of this magnitude, I think&lt;br/&gt;
it is appropriate for a new feature release, hopefully 10.5.  I especially like that after this change&lt;br/&gt;
the code is simpler, the scan locking stuff was complicated and it is great that it can be removed&lt;br/&gt;
with performance sometimes increased and mostly not too affected.&lt;/p&gt;

&lt;p&gt;Once the change goes in there may be more work possible to improve performance, but I think&lt;br/&gt;
it is fine to get the basic stuff in now.  One thing that comes to mind is to change the default group&lt;br/&gt;
fetch size from a fixed size to a page worth.  That had always been a future direction and I think the&lt;br/&gt;
interfaces are there (ie. allow store to set the size of the fetch, and passing variable size groups back&lt;br/&gt;
to caller).  This seems even more important as once the latch is given up repositioning costs may&lt;br/&gt;
be higher than before.  &lt;/p&gt;

&lt;p&gt;Knut, I would be happy to review the entire package one more time, but would rather wait until you do&lt;br/&gt;
the cleanup you mention.  Just post a comment when you are ready.&lt;/p&gt;</comment>
                            <comment id="12670798" author="knutanders" created="Thu, 5 Feb 2009 15:44:26 +0000"  >&lt;p&gt;Thanks Mike. I agree that this change should not be back-ported. Increasing the&lt;br/&gt;
fetch size sounds like a good idea to me. I guess we should collect this and&lt;br/&gt;
other ideas in JIRA issues before we close this issue. I&apos;ll post a comment when&lt;br/&gt;
I have a cleaned up patch ready.&lt;/p&gt;</comment>
                            <comment id="12674994" author="knutanders" created="Thu, 19 Feb 2009 13:51:25 +0000"  >&lt;p&gt;Here&apos;s the first attempt to create a test that exercises the new code. It&apos;s only got two test cases for now, but I&apos;m posting it anyway. More test cases will come.&lt;/p&gt;

&lt;p&gt;Test case 1 tests the call to BTreeScan.reposition() in BTreeMaxScan.fetchMaxFromBeginning().&lt;br/&gt;
(BTreeMaxScan has another call to reposition() in fetchMax(), but as far as I can see it&apos;s impossible to reach that call, so I haven&apos;t added any test case for it.)&lt;/p&gt;

&lt;p&gt;Test case 2 tests the first call to reposition() in BTreeForwardScan.fetchRows() (there are four more in that method) when the leaf page on which the scan is positioned has been split after the position was saved. (Full repositioning from the root of the B-tree is required in this case.)&lt;/p&gt;

&lt;p&gt;#1 fails with the patch (assert in sane builds, NPE in insane builds), so there&apos;s more to investigate. It runs cleanly without the patch.&lt;/p&gt;

&lt;p&gt;#2 times out without the patch, and runs successfully with the patch.&lt;/p&gt;

&lt;p&gt;Committed revision 745866.&lt;/p&gt;</comment>
                            <comment id="12675382" author="knutanders" created="Fri, 20 Feb 2009 15:26:38 +0000"  >&lt;p&gt;Attaching a patch with more test cases for the calls to reposition() in BTreeForwardScan.fetchRows(). None of the added test cases fail on a clean trunk. One of them fails with the preview-1e patch. This is an expected failure (there&apos;s a TODO mentioning it in reposition()) where the page has disappeared because of an in-place compress before resuming the scan with a holdable cursor. It fails with an assert in sane builds when calling ControlRow.get(). I had expected it to work in insane builds, but then get() throws a NullPointerException. I guess this should either be resolved by allowing ControlRow.get() to return null when the page has disappeared, or to create a variant of ControlRow.get() which is allowed to return null.&lt;/p&gt;

&lt;p&gt;Committed the new test cases to trunk with revision 746273.&lt;/p&gt;</comment>
                            <comment id="12675848" author="knutanders" created="Mon, 23 Feb 2009 10:48:36 +0000"  >&lt;p&gt;Attaching a patch with two more test cases for BTreeForwardScan.fetchRows(). The test cases exercise the code path taken when an index scan waits for a lock and the current leaf page has been split before it wakes up. One of the test cases is for unique indexes, and the other one is for non-unique indexes (two test cases were needed since the different indexes call reposition() from different places). Both of the test cases fail (lock timeout) on a clean trunk and pass with patch 1e.&lt;/p&gt;

&lt;p&gt;Committed revision 746954.&lt;/p&gt;</comment>
                            <comment id="12676266" author="knutanders" created="Tue, 24 Feb 2009 13:26:25 +0000"  >&lt;p&gt;I&apos;ve been trying to write test cases for the rest of the calls to BTreeScan.reposition(), but I haven&apos;t managed to come up with any sensible test cases for IndexSplitDeadlockTest. Some of the calls appear to be unreachable unless we use the internal API. Others are reachable, but in order to test them better than they&apos;re already tested by other tests (for instance testing that they work if there&apos;s been a split right before the repositioning) I think we&apos;ll need to write tests against the internal API for those calls as well. I&apos;ll defer writing tests against the internal API for now (of course, suggestions of how to test them via the public API are welcome) and instead add more test cases for the places we are saving the position. I added a comment to IndexSplitDeadlockTest describing which calls to reposition() that are not explicitly tested (revision 747371).&lt;/p&gt;</comment>
                            <comment id="12676991" author="knutanders" created="Thu, 26 Feb 2009 13:22:32 +0000"  >&lt;p&gt;I&apos;m attaching a new patch (d2991-2a.diff) which has these changes&lt;br/&gt;
compared to the preview-1e patch:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;added more comments and removed mentioning of scan lock in (some of&lt;br/&gt;
  the) existing comments&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;removed the savedLockedPos flag from BTreeRowPosition and moved back&lt;br/&gt;
  to the original approach of just using current_rh != null to&lt;br/&gt;
  indicate that the row on the current position was locked. This also&lt;br/&gt;
  allows cheap repositioning by record id in more cases than before&lt;br/&gt;
  because current_rh is not null as often as it was with the&lt;br/&gt;
  preview-1e patch&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;fixed the bug exposed by testBTreeMaxScan_fetchMaxRowFromBeginning&lt;br/&gt;
  in IndexSplitDeadlockTest. The problem was that one of the methods&lt;br/&gt;
  was passed the scan_position instance variable as an argument. When&lt;br/&gt;
  that method called reopenScan(), the instance variable would be&lt;br/&gt;
  replaced, but the local variable would remain the same, and this&lt;br/&gt;
  inconsistency triggered an assert in the added code. Solved by&lt;br/&gt;
  removing the position from the argument list and instead using the&lt;br/&gt;
  instance variable directly&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;fixed the bug exposed by&lt;br/&gt;
  testBTreeForwardScan_fetchRows_resumeScanAfterCompress. Solved by&lt;br/&gt;
  fetching the page with another method that didn&apos;t fail if the page&lt;br/&gt;
  had disappeared, and reposition from the root of the B-tree if the&lt;br/&gt;
  page was removed by SYSCS_COMPRESS_TABLE.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;updated canon for store/updatelocksJDBC30.sql which has been added&lt;br/&gt;
  to derbyall recently&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I have just realized that there are some more problems that need to be&lt;br/&gt;
resolved, but I think they will have just minor effect on the patch,&lt;br/&gt;
so I&apos;m posting it anyway to allow others to take a look at it and see&lt;br/&gt;
if there are more serious problems with it.&lt;/p&gt;

&lt;p&gt;Here&apos;s a description of the changes in each file touched by the patch&lt;br/&gt;
(excluding the test files which were just updated so that they didn&apos;t&lt;br/&gt;
expect scan locks in the lock tables, and so that they didn&apos;t expect&lt;br/&gt;
index split deadlocks):&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;impl/store/access/sort/Scan.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Removed savePosition() method from the interface because the position&lt;br/&gt;
is now always saved by key when the scan doesn&apos;t hold a latch on the&lt;br/&gt;
leaf.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;impl/store/access/btree/LeafControlRow.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Removed calls to Scan.saveScanPositions() and&lt;br/&gt;
BTreeLockingPolicy.lockScan() before splitting the page, because&lt;br/&gt;
positions are always saved by the scan itself now, and because we&lt;br/&gt;
don&apos;t use scan locks anymore.&lt;/p&gt;

&lt;p&gt;Set a hint in the page object after splitting to notify the scans that&lt;br/&gt;
they must reposition from the root of the B-tree after a split.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;impl/store/access/btree/BTreeController.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Don&apos;t lock scan before purging committed deletes. Set a hint in the&lt;br/&gt;
page object to tell the scans that they must reposition from the root&lt;br/&gt;
of the B-tree since the row may not be there anymore.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;impl/store/access/btree/BTreeScan.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Remove locking/unlocking of scan.&lt;/p&gt;

&lt;p&gt;Update savePosition() to allow the position to be saved by record id&lt;br/&gt;
and by key at the same time, and make it possible to pass in a partial&lt;br/&gt;
or a full key to reduce the number of slots that must be fetched from&lt;br/&gt;
the page.&lt;/p&gt;

&lt;p&gt;Update reposition() to reposition by record id if possible and by key&lt;br/&gt;
if needed. Repositioning by record id (which is cheaper) is possible&lt;br/&gt;
if the row is guaranteed to be on the same page as when the position&lt;br/&gt;
was saved (that is, no split or purge operation has been performed on&lt;br/&gt;
the page after saving the position).&lt;/p&gt;

&lt;p&gt;Use savePositionAndReleasePage() when returning from the scan in&lt;br/&gt;
delete(), fetch(), doesCurrentPositionQualify() and&lt;br/&gt;
isCurrentPositionDeleted().&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;impl/store/access/btree/BTreeMaxScan.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Remove the BTreeRowPosition argument from fetchMaxRowFromBeginning()&lt;br/&gt;
to prevent that it goes out of sync with the instance variable&lt;br/&gt;
scan_position when reopenScan() is called. Use the fresh instance&lt;br/&gt;
variable instead.&lt;/p&gt;

&lt;p&gt;Remove references to the scan protection handle.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;impl/store/access/btree/BTreeRowPosition.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Add more state (and methods to access the state):&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;parent of the position. That is, which scan owns this&lt;br/&gt;
    position. This was needed to allow the position to be saved from&lt;br/&gt;
    some methods that didn&apos;t know which scan it belonged to. Could&lt;br/&gt;
    alternatively be solved by passing the scan as an argument to&lt;br/&gt;
    those methods (or actually to those methods and their callers)&lt;br/&gt;
    which is probably cleaner, but could be performed in a later&lt;br/&gt;
    clean-up&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;version number of the current leaf page when the position was&lt;br/&gt;
    saved (used to determine whether full repositioning is needed&lt;br/&gt;
    because of split, etc.)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;template for the key to save (to prevent allocation each time the&lt;br/&gt;
    key is saved). When the position is saved by key, this is&lt;br/&gt;
    identical to current_positionKey. A separate field was added so&lt;br/&gt;
    that we keep the object even when current_positionKey is nulled&lt;br/&gt;
    out, but a possibly cleaner solution would be to have just a flag&lt;br/&gt;
    telling whether the value in current_positionKey is valid, and&lt;br/&gt;
    never reset current_positionKey to null. Could be done in a later&lt;br/&gt;
    clean-up&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;fetch descriptor used to fetch the rest of the key in the cases&lt;br/&gt;
    where the scan has already fetched parts of the key before saving&lt;br/&gt;
    the position&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;impl/store/access/btree/BTreePostCommit.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;purgeRowLevelCommittedDeletes() sets a hint in the page object to&lt;br/&gt;
force scans to reposition from the root of the B-tree when at least&lt;br/&gt;
one row has been purged from the page.&lt;/p&gt;

&lt;p&gt;I think the same change should have been made in&lt;br/&gt;
purgeCommittedDeletes(). I missed it because the method assumed an&lt;br/&gt;
exclusive table lock and therefore didn&apos;t need a scan lock. Will&lt;br/&gt;
update the patch later.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;impl/store/access/btree/OpenBTree.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Remove references to the removed saveScanPositions() method and to the&lt;br/&gt;
protection record handle.&lt;/p&gt;

&lt;p&gt;Make the debug code that simulates release of latches save the&lt;br/&gt;
position since that&apos;s what happens if the latches really are released&lt;br/&gt;
by the production code now.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;impl/store/access/btree/index/B2IRowLockingRR.java&lt;/li&gt;
	&lt;li&gt;impl/store/access/btree/index/B2INoLocking.java&lt;/li&gt;
	&lt;li&gt;impl/store/access/btree/index/B2IRowLocking1.java&lt;/li&gt;
	&lt;li&gt;impl/store/access/btree/index/B2IRowLocking3.java&lt;/li&gt;
	&lt;li&gt;impl/store/access/btree/BTreeLockingPolicy.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Remove request_scan_lock parameter.&lt;/p&gt;

&lt;p&gt;Remove code to lock/unlock scan.&lt;/p&gt;

&lt;p&gt;Save position of scan if lock cannot be granted immediately.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;impl/store/access/btree/BTreeForwardScan.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Save position by key each time the scan returns a group of rows. Use&lt;br/&gt;
the partial (possibly full) key fetched by the scan to make the save&lt;br/&gt;
position operation cheaper.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;impl/store/access/RAMTransaction.java&lt;/li&gt;
	&lt;li&gt;impl/store/access/heap/HeapScan.java&lt;/li&gt;
	&lt;li&gt;iapi/store/access/conglomerate/ScanManager.java&lt;/li&gt;
	&lt;li&gt;iapi/store/access/conglomerate/TransactionManager.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Remove saveScanPositions()/savePosition() because the position will&lt;br/&gt;
already have been saved now since we always save the position when we&lt;br/&gt;
release the latch.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;impl/store/access/heap/HeapRowLocation.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Remove THROWASSERT from and complete implementation of&lt;br/&gt;
setFrom(DataValueDescriptor) to allow the RowLocation in the index row&lt;br/&gt;
to be copied when we save the position.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;impl/store/raw/data/BasePage.java&lt;/li&gt;
	&lt;li&gt;iapi/store/raw/Page.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Remove reference to protection record handle.&lt;/p&gt;

&lt;p&gt;Add code to set the hint that repositioning from the root of the&lt;br/&gt;
B-tree is needed.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;iapi/store/raw/RecordHandle.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Remove constant identifying the record protection handle that we no&lt;br/&gt;
longer use.&lt;/p&gt;</comment>
                            <comment id="12676998" author="knutanders" created="Thu, 26 Feb 2009 13:51:57 +0000"  >&lt;p&gt;I know there are at least a couple of issues with the 2a patch, but&lt;br/&gt;
I&apos;m setting the patch available flag anyway because I believe those&lt;br/&gt;
issues won&apos;t cause big changes to the patch, so the patch is in such a&lt;br/&gt;
state that it should be ready for review.&lt;/p&gt;

&lt;p&gt;The issues I&apos;m aware of that need to be resolved, are these:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;BTreePostCommit.purgeCommittedDeletes() needs to call&lt;br/&gt;
  Page.setRepositionNeeded() to tell index scans that they need to&lt;br/&gt;
  reposition by key. Since purgeCommittedDeletes() is only called in a&lt;br/&gt;
  separate transaction that has an exclusive table lock, I believe&lt;br/&gt;
  that this issue could only affect holdable index scans that&lt;br/&gt;
  reposition after a commit.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Some callers of BTreeScan.reposition(pos,false) have&lt;br/&gt;
  comments/asserts stating that it is impossible that the current row&lt;br/&gt;
  has been purged because they hold the scan lock. I think that it is&lt;br/&gt;
  now possible that rows are purged from the page if we released the&lt;br/&gt;
  latch, so we might need to change how they handle that situation. In&lt;br/&gt;
  most cases (except read-uncommitted scans) the scans hold a lock on&lt;br/&gt;
  the current row so that it is true that the row cannot have been&lt;br/&gt;
  purged.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Feedback on the patch as it is would be appreciated. I&apos;ll probably be&lt;br/&gt;
offline for a couple of days, so I may not respond immediately to&lt;br/&gt;
questions/comments.&lt;/p&gt;</comment>
                            <comment id="12680169" author="knutanders" created="Mon, 9 Mar 2009 15:01:14 +0000"  >&lt;p&gt;Here&apos;s an updated patch (d2991-2b.diff) which addresses the two issues I&lt;br/&gt;
mentioned that I was aware of in the 2a patch:&lt;/p&gt;

&lt;p&gt;1) Call Page.setRepositionNeeded() in BTreePostCommit.purgeCommittedDeletes()&lt;br/&gt;
when a row has been purged.&lt;/p&gt;

&lt;p&gt;2) Handle the cases where reposition() can return false (that is, second&lt;br/&gt;
argument to reposition() is false and the row on the current position has been&lt;br/&gt;
purged). This led to the following changes:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;BTreeScan.positionAtDoneScanFromClose()&lt;/li&gt;
	&lt;li&gt;BTreeScan.reopenScan()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;  Removed the calls to reposition(). The only reason I could see for these&lt;br/&gt;
  methods to call reposition() was that some implementations of&lt;br/&gt;
  BTreeLockingPolicy.unlockScanRecordAfterRead() had asserts that checked that&lt;br/&gt;
  the page of the current position was latched. Removing the calls (and the&lt;br/&gt;
  asserts) made the code simpler and removed the need for special handling if&lt;br/&gt;
  reposition() was unsuccessful.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;B2IRowLockingRR.unlockScanRecordAfterRead()&lt;/li&gt;
	&lt;li&gt;B2IRowLocking2.unlockScanRecordAfterRead()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;  Don&apos;t assert that the current leaf is latched, as there is no need for that&lt;br/&gt;
  latch in order to unlock the record. (See above.)&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;BTreeScan.delete()&lt;/li&gt;
	&lt;li&gt;BTreeScan.doesCurrentPositionQualify()&lt;/li&gt;
	&lt;li&gt;BTreeScan.fetch()&lt;/li&gt;
	&lt;li&gt;BTreeScan.isCurrentPositionDeleted()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;  Make sure that we don&apos;t try to release the latch on the current leaf unless&lt;br/&gt;
  we have actually latched it, since the leaf won&apos;t be latched if reposition()&lt;br/&gt;
  returns false. No other special handling of purged rows is needed in those&lt;br/&gt;
  methods, I think. delete() and fetch() throw an exception&lt;br/&gt;
  (AM_RECORD_NOT_FOUND) if the row has been purged, which sounds reasonable to&lt;br/&gt;
  me. doesCurrentPositionQualify() and isCurrentPositionDeleted() use the&lt;br/&gt;
  return value from reposition() to decide what they should return themselves,&lt;br/&gt;
  which also sounds fine to me (except that I would expect that&lt;br/&gt;
  isCurrentPositionDeleted() returned true if the row was purged, but currently&lt;br/&gt;
  it returns false &amp;#8211; will file a separate bug for that).&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;BTreeMaxScan.fetchMaxRowFromBeginning()&lt;/li&gt;
	&lt;li&gt;BTreeForwardScan.fetchRows()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;  If the row on the current position of the scan has been purged while we were&lt;br/&gt;
  waiting for a lock so that reposition(pos,false) returns false, we call&lt;br/&gt;
  reposition() again with second argument true to reposition on the row&lt;br/&gt;
  immediately to the left of where the purged row was supposed to be. This&lt;br/&gt;
  effectively takes one step back in the scan, so therefore we need to jump to&lt;br/&gt;
  the top of the loop&apos;s body to move one step forward past the purged row.&lt;/p&gt;

&lt;p&gt;I tested that reposition(pos,false) followed by reposition(pos,true) worked by&lt;br/&gt;
setting a breakpoint in the debugger and manually changing values in the page&lt;br/&gt;
object and in the position to make the scan code believe that the row had been&lt;br/&gt;
purged. As far as I could tell, it worked just as if the scan had found a&lt;br/&gt;
deleted row. (There are currently no tests that exercise code paths where&lt;br/&gt;
reposition() returns false, and I don&apos;t see any easy way to write a test for it&lt;br/&gt;
since it would be highly dependent on timing between user threads and service&lt;br/&gt;
threads.)&lt;/p&gt;

&lt;p&gt;This patch fixes all the issues I&apos;m aware of in the previous patch. Derbyall&lt;br/&gt;
and suites.All ran cleanly. Reviews, comments and questions would be&lt;br/&gt;
appreciated. Thanks.&lt;/p&gt;</comment>
                            <comment id="12681374" author="knutanders" created="Thu, 12 Mar 2009 16:13:53 +0000"  >&lt;p&gt;I would feel more comfortable with committing this patch if another pair of eyes had looked at it first, but since it was suggested earlier that it would be good to get the fix into the codeline as soon as possible to get more experience with it, I plan to commit the patch on Monday before the 10.5 branch is created unless I hear anything. Please let me know if you have objections to this approach. Of course, reviews and comments are welcome even after the patch has been committed.&lt;/p&gt;</comment>
                            <comment id="12682319" author="knutanders" created="Mon, 16 Mar 2009 14:03:47 +0000"  >&lt;p&gt;Committed the 2b patch with revision 754894.&lt;/p&gt;

&lt;p&gt;There still are references to the scan locks in some comments I think. I will try to track them down and update them in a follow-up.&lt;/p&gt;</comment>
                            <comment id="12682321" author="knutanders" created="Mon, 16 Mar 2009 14:16:51 +0000"  >&lt;p&gt;IndexSplitDeadlockTest has now been enabled as part of suites.All (patch test-4.diff) since the main fix has gone in. Committed revision 754900.&lt;/p&gt;</comment>
                            <comment id="12682898" author="myrna" created="Wed, 18 Mar 2009 03:37:56 +0000"  >&lt;p&gt;Can this isssue be closed as fixed in 10.5 and subsequent/remaining issues be pursued in a new JIRA?&lt;/p&gt;</comment>
                            <comment id="12683061" author="knutanders" created="Wed, 18 Mar 2009 16:32:00 +0000"  >&lt;p&gt;Yes, I think we can mark this issue as resolved now and address remaining cleanup, and bugs if they turn up, in separate issues.&lt;/p&gt;</comment>
                            <comment id="12719690" author="mamtas" created="Mon, 15 Jun 2009 19:31:39 +0100"  >&lt;p&gt;I recently merged changes for &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3926&quot; title=&quot;Incorrect ORDER BY caused by index&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3926&quot;&gt;&lt;del&gt;DERBY-3926&lt;/del&gt;&lt;/a&gt; into 10.5.1.2 codeline (revision 784809) and I ran the junit tests on the merged code. The tests finished with one &quot;A lock could not be obtained within the time requested&quot;. Kathey recommended that I post that failure here since it may be related to this jira entry. Following is the stack track from text junit runner (junit.textui.TestRunner)&lt;br/&gt;
There was 1 error:&lt;br/&gt;
1) testBTreeForwardScan_fetchRows_resumeAfterWait_nonUnique_split(org.apache.derbyTesting.functionTests.tests.store.IndexSplitDeadlockTest)java.sql.SQLException: A lock could not be obtained within the time requested&lt;br/&gt;
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(SQLExceptionFactory.java:45)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Util.java:201)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(TransactionResourceImpl.java:391)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(TransactionResourceImpl.java:346)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedConnection.handleException(EmbedConnection.java:2201)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.ConnectionChild.handleException(ConnectionChild.java:81)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedResultSet.closeOnTransactionError(EmbedResultSet.java:4338)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedResultSet.movePosition(EmbedResultSet.java:467)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedResultSet.next(EmbedResultSet.java:371)&lt;br/&gt;
        at org.apache.derbyTesting.functionTests.tests.store.IndexSplitDeadlockTest.testBTreeForwardScan_fetchRows_resumeAfterWait_nonUnique_split(IndexSplitDeadlockTest.java:489)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:79)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
        at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:106)&lt;br/&gt;
        at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)&lt;br/&gt;
        at junit.extensions.TestSetup$1.protect(TestSetup.java:19)&lt;br/&gt;
        at junit.extensions.TestSetup.run(TestSetup.java:23)&lt;br/&gt;
        at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)&lt;br/&gt;
        at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)&lt;br/&gt;
        at junit.extensions.TestSetup$1.protect(TestSetup.java:19)&lt;br/&gt;
        at junit.extensions.TestSetup.run(TestSetup.java:23)&lt;br/&gt;
        at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)&lt;br/&gt;
Caused by: ERROR 40XL1: A lock could not be obtained within the time requested at org.apache.derby.iapi.error.StandardException.newException(StandardException.java:276)&lt;br/&gt;
        at org.apache.derby.impl.services.locks.ConcurrentLockSet.lockObject(ConcurrentLockSet.java:602)&lt;br/&gt;
        at org.apache.derby.impl.services.locks.ConcurrentLockSet.zeroDurationLockObject(ConcurrentLockSet.java:855)&lt;br/&gt;
        at org.apache.derby.impl.services.locks.AbstractPool.zeroDurationlockObject(AbstractPool.java:297)&lt;br/&gt;
        at org.apache.derby.impl.store.raw.xact.RowLocking2nohold.lockRecordForRead(RowLocking2nohold.java:89)&lt;br/&gt;
        at org.apache.derby.impl.store.access.heap.HeapController.lockRow(HeapController.java:520)&lt;br/&gt;
        at org.apache.derby.impl.store.access.heap.HeapController.lockRow(HeapController.java:638)&lt;br/&gt;
        at org.apache.derby.impl.store.access.btree.index.B2IRowLocking3.lockRowOnPage(B2IRowLocking3.java:309)&lt;br/&gt;
        at org.apache.derby.impl.store.access.btree.index.B2IRowLocking3._lockScanRow(B2IRowLocking3.java:599)&lt;br/&gt;
        at org.apache.derby.impl.store.access.btree.index.B2IRowLockingRR.lockScanRow(B2IRowLockingRR.java:105)&lt;br/&gt;
        at org.apache.derby.impl.store.access.btree.BTreeForwardScan.fetchRows(BTreeForwardScan.java:305)&lt;br/&gt;
        at org.apache.derby.impl.store.access.btree.BTreeScan.fetchNextGroup(BTreeScan.java:1585)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.BulkTableScanResultSet.reloadArray(BulkTableScanResultSet.java:327)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.BulkTableScanResultSet.getNextRowCore(BulkTableScanResultSet.java:282)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.BasicNoPutResultSetImpl.getNextRow(BasicNoPutResultSetImpl.java:460)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedResultSet.movePosition(EmbedResultSet.java:427)&lt;br/&gt;
        ... 34 more&lt;/p&gt;

&lt;p&gt;FAILURES!!!&lt;br/&gt;
Tests run: 9258,  Failures: 0,  Errors: 1&lt;/p&gt;</comment>
                            <comment id="12719838" author="knutanders" created="Mon, 15 Jun 2009 23:53:04 +0100"  >&lt;p&gt;Yes, that test was added here. It requires some coordination between two threads, so my first guess would be that there is a timing issue in the test. Please file a separate JIRA issue for this failure. Thanks.&lt;/p&gt;</comment>
                            <comment id="12719859" author="mamtas" created="Tue, 16 Jun 2009 00:53:02 +0100"  >&lt;p&gt;Knut, thanks for looking at the stack trace. I added jira &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-4273&quot; title=&quot;A lock could not be obtained within the time requested error in testBTreeForwardScan_fetchRows_resumeAfterWait_nonUnique_split&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-4273&quot;&gt;&lt;del&gt;DERBY-4273&lt;/del&gt;&lt;/a&gt; for the test failure. &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12376342">DERBY-3015</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12409105">DERBY-3961</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12409105">DERBY-3961</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12427949">DERBY-4273</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12413476">DERBY-4033</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12363098" name="InsertSelectDeadlock.java" size="6184" author="bcalmac" created="Fri, 3 Aug 2007 05:11:07 +0100"/>
                            <attachment id="12364090" name="Repro2991.java" size="4500" author="kurti" created="Sat, 18 Aug 2007 21:23:46 +0100"/>
                            <attachment id="12401040" name="d2991-2a.diff" size="446294" author="knutanders" created="Thu, 26 Feb 2009 13:22:31 +0000"/>
                            <attachment id="12401041" name="d2991-2a.stat" size="2470" author="knutanders" created="Thu, 26 Feb 2009 13:22:32 +0000"/>
                            <attachment id="12401754" name="d2991-2b.diff" size="454973" author="knutanders" created="Mon, 9 Mar 2009 15:01:14 +0000"/>
                            <attachment id="12401755" name="d2991-2b.stat" size="2556" author="knutanders" created="Mon, 9 Mar 2009 15:01:14 +0000"/>
                            <attachment id="12394546" name="d2991-preview-1a.diff" size="17901" author="knutanders" created="Mon, 24 Nov 2008 10:56:51 +0000"/>
                            <attachment id="12394547" name="d2991-preview-1a.stat" size="403" author="knutanders" created="Mon, 24 Nov 2008 10:56:51 +0000"/>
                            <attachment id="12394768" name="d2991-preview-1b.diff" size="230366" author="knutanders" created="Wed, 26 Nov 2008 19:03:20 +0000"/>
                            <attachment id="12394769" name="d2991-preview-1b.stat" size="1527" author="knutanders" created="Wed, 26 Nov 2008 19:03:20 +0000"/>
                            <attachment id="12394894" name="d2991-preview-1c.diff" size="267200" author="knutanders" created="Fri, 28 Nov 2008 10:44:58 +0000"/>
                            <attachment id="12394895" name="d2991-preview-1c.stat" size="2130" author="knutanders" created="Fri, 28 Nov 2008 10:44:58 +0000"/>
                            <attachment id="12396194" name="d2991-preview-1d.diff" size="271089" author="knutanders" created="Tue, 16 Dec 2008 14:57:00 +0000"/>
                            <attachment id="12396195" name="d2991-preview-1d.stat" size="2130" author="knutanders" created="Tue, 16 Dec 2008 14:57:01 +0000"/>
                            <attachment id="12398468" name="d2991-preview-1e.diff" size="275752" author="knutanders" created="Thu, 22 Jan 2009 14:09:25 +0000"/>
                            <attachment id="12363099" name="derby.log" size="45636" author="bcalmac" created="Fri, 3 Aug 2007 05:11:56 +0100"/>
                            <attachment id="12396408" name="perftest.diff" size="9911" author="knutanders" created="Thu, 18 Dec 2008 18:16:05 +0000"/>
                            <attachment id="12363100" name="stacktraces_during_deadlock.txt" size="5508" author="bcalmac" created="Fri, 3 Aug 2007 05:12:52 +0100"/>
                            <attachment id="12400515" name="test-1.diff" size="11779" author="knutanders" created="Thu, 19 Feb 2009 13:51:25 +0000"/>
                            <attachment id="12400613" name="test-2.diff" size="8928" author="knutanders" created="Fri, 20 Feb 2009 15:26:38 +0000"/>
                            <attachment id="12400744" name="test-3.diff" size="11827" author="knutanders" created="Mon, 23 Feb 2009 10:48:36 +0000"/>
                            <attachment id="12402282" name="test-4.diff" size="853" author="knutanders" created="Mon, 16 Mar 2009 14:16:51 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>22.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 3 Aug 2007 12:34:53 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23364</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310090" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Issue &amp; fix info</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10422"><![CDATA[High Value Fix]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy0m4f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>37402</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            </customfields>
    </item>
</channel>
</rss>