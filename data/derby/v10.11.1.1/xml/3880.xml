<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:48:07 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-3880/DERBY-3880.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-3880] NPE on a query with having clause involving a join</title>
                <link>https://issues.apache.org/jira/browse/DERBY-3880</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;A simple query involving a join and having clause causes a NPE. Any subsequent executions cause severe errors. It almost looks like the underlying connection was closed out.&lt;/p&gt;

&lt;p&gt;====&lt;/p&gt;

&lt;p&gt;C:\apps\derby\db-derby-10.4.2.0-bin\db-derby-10.4.2.0-bin\bin&amp;gt;ij&lt;br/&gt;
ij version 10.4&lt;br/&gt;
ij&amp;gt; connect &apos;jdbc:derby://speed:1527/ClassicModels;user=sa;password=sa&lt;br/&gt;
&apos;;&lt;br/&gt;
ij&amp;gt; create table t1(i int, c varchar(20));&lt;br/&gt;
0 rows inserted/updated/deleted&lt;br/&gt;
ij&amp;gt; create table t2(i int, c2 varchar(20), i2 int);&lt;br/&gt;
0 rows inserted/updated/deleted&lt;br/&gt;
ij&amp;gt; insert into t1 values(1, &apos;abc&apos;);&lt;br/&gt;
1 row inserted/updated/deleted&lt;br/&gt;
ij&amp;gt; insert into t1 values(2, &apos;abc&apos;);&lt;br/&gt;
1 row inserted/updated/deleted&lt;br/&gt;
ij&amp;gt; insert into t2 values(1, &apos;xyz&apos;, 10);&lt;br/&gt;
1 row inserted/updated/deleted&lt;br/&gt;
ij&amp;gt; insert into t2 values(1, &apos;aaa&apos;, 20);&lt;br/&gt;
1 row inserted/updated/deleted&lt;br/&gt;
ij&amp;gt; insert into t2 values(2, &apos;xxx&apos;, 30);&lt;br/&gt;
1 row inserted/updated/deleted&lt;br/&gt;
ij&amp;gt; select t1.i, avg(t2.i2) from t1 inner join t2 on (t1.i = t2.i) group by t1.i&lt;br/&gt;
 having avg(t2.i2) &amp;gt; 0;&lt;br/&gt;
ERROR XJ001: DERBY SQL error: SQLCODE: -1, SQLSTATE: XJ001, SQLERRMC: java.lang.&lt;br/&gt;
NullPointerException&#182;&#182;XJ001.U&lt;/p&gt;</description>
                <environment>Windows 2003 Server </environment>
        <key id="12404477">DERBY-3880</key>
            <summary>NPE on a query with having clause involving a join</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="army">A B</assignee>
                                    <reporter username="viyer">Venkateswaran Iyer</reporter>
                        <labels>
                    </labels>
                <created>Wed, 17 Sep 2008 01:47:28 +0100</created>
                <updated>Fri, 21 Jan 2011 17:52:06 +0000</updated>
                            <resolved>Thu, 6 Nov 2008 17:33:31 +0000</resolved>
                                    <version>10.4.2.0</version>
                                    <fixVersion>10.3.3.1</fixVersion>
                    <fixVersion>10.4.2.1</fixVersion>
                    <fixVersion>10.5.1.1</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12631634" author="mamtas" created="Wed, 17 Sep 2008 04:34:52 +0100"  >&lt;p&gt;Can you please provide the complete stack trace? I ran it on trunk, but since my codeline is compiled with Sane=true, I am not running into npe, instead I am getting Assert Failures for a null object.&lt;/p&gt;

&lt;p&gt;ERROR XJ001: Java exception: &apos;ASSERT FAILED col&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt;  is null: org.apache.derby.shared.common.sanity.AssertFailure&apos;.&lt;br/&gt;
java.sql.SQLException: Java exception: &apos;ASSERT FAILED col&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt;  is null: org.apache.derby.shared.common.sanity.AssertFailure&apos;.&lt;br/&gt;
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(SQLExceptionFactory.java:45)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Util.java:87)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.Util.javaException(Util.java:244)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException (TransactionResourceImpl.java:403)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(TransactionResourceImpl.java:346)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedConnection.handleException(EmbedConnection.java:2192)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.ConnectionChild.handleException(ConnectionChild.java:81)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(EmbedStatement.java:1325)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.execute(EmbedStatement.java:625)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.execute(EmbedStatement.java:555)&lt;br/&gt;
        at org.apache.derby.impl.tools.ij.ij.executeImmediate(ij.java:329)&lt;br/&gt;
        at org.apache.derby.impl.tools.ij.utilMain.doCatch(utilMain.java:508)&lt;br/&gt;
        at org.apache.derby.impl.tools.ij.utilMain.runScriptGuts(utilMain.java:3&lt;br/&gt;
50)&lt;br/&gt;
        at org.apache.derby.impl.tools.ij.utilMain.go(utilMain.java:248)&lt;br/&gt;
        at org.apache.derby.impl.tools.ij.Main.go(Main.java:215)&lt;br/&gt;
        at org.apache.derby.impl.tools.ij.Main.mainCore(Main.java:181)&lt;br/&gt;
        at org.apache.derby.impl.tools.ij.Main.main(Main.java:73)&lt;br/&gt;
        at org.apache.derby.tools.ij.main(ij.java:59)&lt;br/&gt;
Caused by: org.apache.derby.shared.common.sanity.AssertFailure: ASSERT FAILED col&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt;  is null&lt;br/&gt;
        at org.apache.derby.shared.common.sanity.SanityManager.THROWASSERT(SanityManager.java:162)&lt;br/&gt;
        at org.apache.derby.shared.common.sanity.SanityManager.THROWASSERT(SanityManager.java:147)&lt;br/&gt;
        at org.apache.derby.impl.store.access.sort.MergeSort.checkColumnTypes(MergeSort.java:458)&lt;br/&gt;
        at org.apache.derby.impl.store.access.sort.MergeInserter.insert(MergeInserter.java:98)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.GroupedAggregateResultSet.loadSorter(GroupedAggregateResultSet.java:308)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.GroupedAggregateResultSet.openCore(GroupedAggregateResultSet.java:180)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.ProjectRestrictResultSet.openCore(P&lt;br/&gt;
rojectRestrictResultSet.java:168)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.BasicNoPutResultSetImpl.open(BasicNoPutResultSetImpl.java:245)&lt;br/&gt;
        at org.apache.derby.impl.sql.GenericPreparedStatement.execute(GenericPreparedStatement.java:384)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(EmbedStatement.java:1235)&lt;br/&gt;
        ... 10 more&lt;/p&gt;</comment>
                            <comment id="12631857" author="viyer" created="Wed, 17 Sep 2008 18:29:57 +0100"  >&lt;p&gt;Here&apos;s the complete stack:&lt;/p&gt;

&lt;p&gt;Apache Derby Network Server - 10.4.2.0 - (689064) started and ready to accept connections on port 1527 at 2008-09-16 20:19:45.296 GMT &lt;br/&gt;
----------------------------------------------------------------&lt;br/&gt;
2008-09-16 20:26:34.328 GMT:&lt;br/&gt;
 Booting Derby version The Apache Software Foundation - Apache Derby - 10.4.2.0 - (689064): instance a816c00e-011c-6cd1-8f55-00004e6b54c8&lt;br/&gt;
on database directory C:\apps\derby\db-derby-10.4.2.0-bin\db-derby-10.4.2.0-bin\bin\ClassicModels  &lt;/p&gt;

&lt;p&gt;Database Class Loader started - derby.database.classpath=&apos;&apos;&lt;br/&gt;
2008-09-16 20:27:53.890 GMT Thread&lt;span class=&quot;error&quot;&gt;&amp;#91;DRDAConnThread_3,5,main&amp;#93;&lt;/span&gt; (XID = 525), (SESSIONID = 8), (DATABASE = ClassicModels), (DRDAID = C0A82DCA.GFE0-4183842832230338175&lt;/p&gt;
{9}), Cleanup action starting&lt;br/&gt;
2008-09-16 20:27:53.890 GMT Thread&lt;span class=&quot;error&quot;&gt;&amp;#91;DRDAConnThread_3,5,main&amp;#93;&lt;/span&gt; (XID = 525), (SESSIONID = 8), (DATABASE = ClassicModels), (DRDAID = C0A82DCA.GFE0-4183842832230338175{9}
&lt;p&gt;), Failed Statement is: SELECT &quot;APP&quot;.&quot;Orders&quot;.&quot;orderNumber&quot;, AVG( &quot;APP&quot;.&quot;OrderDetails&quot;.&quot;quantityOrdered&quot; )&lt;br/&gt;
FROM (&quot;APP&quot;.&quot;Orders&quot; INNER JOIN &quot;APP&quot;.&quot;OrderDetails&quot; ON &quot;APP&quot;.&quot;Orders&quot;.&quot;orderNumber&quot; = &quot;APP&quot;.&quot;OrderDetails&quot;.&quot;orderNumber&quot; ) &lt;br/&gt;
GROUP BY &quot;APP&quot;.&quot;Orders&quot;.&quot;orderNumber&quot;&lt;br/&gt;
HAVING AVG( &quot;APP&quot;.&quot;OrderDetails&quot;.&quot;quantityOrdered&quot; ) &amp;gt; 0&lt;br/&gt;
java.lang.NullPointerException&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.BasicSortObserver.getClone(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.BasicSortObserver.insertNonDuplicateKey(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.AggregateSortObserver.insertNonDuplicateKey(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.sort.SortBuffer.insert(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.sort.MergeInserter.insert(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.GroupedAggregateResultSet.loadSorter(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.GroupedAggregateResultSet.openCore(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.ProjectRestrictResultSet.openCore(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.BasicNoPutResultSetImpl.open(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeStatement(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.drda.DRDAStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.drda.DRDAConnThread.processCommands(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.drda.DRDAConnThread.run(Unknown Source)&lt;br/&gt;
Cleanup action completed&lt;/p&gt;</comment>
                            <comment id="12634204" author="kmarsden" created="Wed, 24 Sep 2008 18:12:26 +0100"  >&lt;p&gt; This is a regression caused by &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-681&quot; title=&quot;Eliminate the parser&amp;#39;s rewriting of the abstract syntax tree for queries with GROUP BY and/or HAVING clauses&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-681&quot;&gt;&lt;del&gt;DERBY-681&lt;/del&gt;&lt;/a&gt; (svn revision 516454)&lt;/p&gt;</comment>
                            <comment id="12634206" author="kmarsden" created="Wed, 24 Sep 2008 18:13:55 +0100"  >&lt;p&gt;linking issue to &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-681&quot; title=&quot;Eliminate the parser&amp;#39;s rewriting of the abstract syntax tree for queries with GROUP BY and/or HAVING clauses&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-681&quot;&gt;&lt;del&gt;DERBY-681&lt;/del&gt;&lt;/a&gt; since it was caused by that issue.&lt;/p&gt;</comment>
                            <comment id="12634275" author="kmarsden" created="Wed, 24 Sep 2008 21:22:39 +0100"  >&lt;p&gt;If I use an implicit join:&lt;br/&gt;
select t1.i, avg(t2.i2) from t1, t2 where ( t1.i = t2.i) group by t1.i&lt;br/&gt;
 having avg(t2.i2) &amp;gt; 0;&lt;/p&gt;

&lt;p&gt;The query runs.  Can this be used as a workaround?&lt;/p&gt;</comment>
                            <comment id="12634298" author="viyer" created="Wed, 24 Sep 2008 22:13:13 +0100"  >&lt;p&gt;That should work. Thanks.&lt;/p&gt;</comment>
                            <comment id="12639647" author="kmarsden" created="Wed, 15 Oct 2008 00:49:45 +0100"  >&lt;p&gt;I have a question about virtualColumnId&apos;s for ResultColumns versus their underlying Expressions.  I am looking in the debugger in ProjectRestrictNode generateMinion where it maps the source columns. At line 1421 we have&lt;br/&gt;
		int[] mapArray = resultColumns.mapSourceColumns();&lt;/p&gt;

&lt;p&gt;The second time we hit this line we get a mapArray:&lt;span class=&quot;error&quot;&gt;&amp;#91;3, -1, 5, -1, -1, 2, -1&amp;#93;&lt;/span&gt;.  It seems that it is mapArray&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt; that is off.&lt;br/&gt;
The virtualColumnId of the the third entry of resultColumns is 3 and if I force mapArray&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt; to be 3 the query completes successfully and correctly.  The ResultColumn is an ##aggregate expression&lt;br/&gt;
ame: ##aggregate expression&lt;br/&gt;
tableName: T2&lt;br/&gt;
isNameGenerated: false&lt;br/&gt;
sourceTableName: T2&lt;br/&gt;
type: INTEGER&lt;br/&gt;
columnDescriptor: null&lt;br/&gt;
isGenerated: true&lt;br/&gt;
isGeneratedForUnmatchedColumnInInsert: false&lt;br/&gt;
isGroupingColumn: false&lt;br/&gt;
isReferenced: true&lt;br/&gt;
isRedundant: false&lt;br/&gt;
virtualColumnId: 3&lt;br/&gt;
resultSetNumber: -1&lt;br/&gt;
dataTypeServices: INTEGER&lt;/p&gt;

&lt;p&gt;The expression is a ColumnReference with sourceColumn virtualColumId 5&lt;br/&gt;
columnName: I2&lt;br/&gt;
tableNumber: 1&lt;br/&gt;
columnNumber: 3&lt;br/&gt;
replacesAggregate: false&lt;br/&gt;
tableName: T2&lt;br/&gt;
nestingLevel: 0&lt;br/&gt;
sourceLevel: 0&lt;br/&gt;
dataTypeServices: null&lt;/p&gt;

&lt;p&gt;mapSourceColumns() gets the virtualColumnId using&lt;br/&gt;
	VirtualColumnNode vcn = (VirtualColumnNode) resultColumn.getExpression();&lt;br/&gt;
        ....&lt;br/&gt;
        mapArray&lt;span class=&quot;error&quot;&gt;&amp;#91;index&amp;#93;&lt;/span&gt; = vcn.getSourceColumn().getVirtualColumnId();&lt;br/&gt;
so returns 5 in this case.&lt;/p&gt;

&lt;p&gt;So my question is what is the relationship between the ResultColumn and the source column in this case?  Is it likely that the correct thing to do for an aggregate is return the virtualColumnId of the the ResultColumn for the aggregate or was that just a coincidence in this case?&lt;/p&gt;


</comment>
                            <comment id="12640312" author="kmarsden" created="Thu, 16 Oct 2008 21:58:36 +0100"  >&lt;p&gt;I printed out the query trees for the working query versus the failing query.  The failing query uses a JoinNode and passes through the code in JoinNode.buildRCL() &lt;br/&gt;
	tmpRCL.adjustVirtualColumnIds(resultColumns.size());&lt;/p&gt;

&lt;p&gt;I noticed that if I remove this adjustment the query works, but it of course causes other problems with other queries, but perhaps there is something wrong with the VirtualColumnId adjustment.&lt;/p&gt;

&lt;p&gt;The working query doesn&apos;t use a JoinNode and so does not pass through this code and as best I can tell does not do the same adjustment elsewhere.  I don&apos;t know if any of this is helpful but I thought I would mention it.&lt;/p&gt;

</comment>
                            <comment id="12640574" author="mamtas" created="Fri, 17 Oct 2008 17:55:31 +0100"  >&lt;p&gt;Kathey, thanks for providing the working version of the query (ie the one without the explicit inner join clause). It gives something to compare the failing query against.&lt;/p&gt;

&lt;p&gt;While trying to trace through the 2 queries, I found following discripency.&lt;/p&gt;

&lt;p&gt;Both successful query and the NPE query fo through the following code path&lt;br/&gt;
Thread &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; (Suspended)	&lt;br/&gt;
	ProjectRestrictResultSet.doProjection(ExecRow) line: 514	&lt;br/&gt;
	ProjectRestrictResultSet.getNextRowCore() line: 291	&lt;br/&gt;
	GroupedAggregateResultSet.getRowFromResultSet() line: 580	&lt;br/&gt;
	GroupedAggregateResultSet.getNextRowFromRS() line: 566	&lt;br/&gt;
	GroupedAggregateResultSet.loadSorter() line: 306	&lt;br/&gt;
	GroupedAggregateResultSet.openCore() line: 180	&lt;br/&gt;
	ProjectRestrictResultSet.openCore() line: 168	&lt;br/&gt;
	ProjectRestrictResultSet(BasicNoPutResultSetImpl).open() line: 245	&lt;br/&gt;
	GenericPreparedStatement.execute(Activation, boolean, long) line: 384	&lt;br/&gt;
	EmbedStatement40(EmbedStatement).executeStatement(Activation, boolean, boolean) line: 1235	&lt;br/&gt;
	EmbedStatement40(EmbedStatement).execute(String, boolean, boolean, int, int[], String[]) line: 625	&lt;br/&gt;
	EmbedStatement40(EmbedStatement).execute(String) line: 555	&lt;br/&gt;
	ij.executeImmediate(String) line: 329	&lt;br/&gt;
	Main.go(LocalizedInput, LocalizedOutput, Properties) line: 215	&lt;br/&gt;
	utilMain.runScriptGuts() line: 350	&lt;br/&gt;
	Main.main(String[]) line: 73	&lt;br/&gt;
	utilMain.go(LocalizedInput[], LocalizedOutput, Properties) line: 248	&lt;br/&gt;
	Main.mainCore(String[], Main) line: 181	&lt;br/&gt;
	Main.main(String[]) line: 73	&lt;br/&gt;
	ij.main(String[]) line: 59	&lt;/p&gt;

&lt;p&gt;But if you examin row that results after the projection in ProjectRestrictResultSet, you will notice that the successful query has following row&lt;br/&gt;
result	ValueRow  (id=212)	&lt;/p&gt;
{ 1, NULL, 10, NULL, NULL, 10, NULL }
&lt;p&gt;whereas NPE query has following row&lt;br/&gt;
result	ValueRow  (id=251)	&lt;/p&gt;
{ 1, NULL, null, NULL, NULL, 10, NULL }	

&lt;p&gt;As you can see, the 3rd column has value of null in NPE query whereas the successful query has value 10. Will debug more to see what causes this but thought will post this piece of information.&lt;/p&gt;</comment>
                            <comment id="12641062" author="kmarsden" created="Mon, 20 Oct 2008 17:39:14 +0100"  >&lt;p&gt;Thanks Mamta for looking at this. I think the reason for the difference is that sourceRow has only 3 columns yet projectMapping has values  &lt;span class=&quot;error&quot;&gt;&amp;#91;3, -1, 5, -1, -1, 2, -1&amp;#93;&lt;/span&gt;, the third entry (5) does not refer to an actual column so when we get to &lt;br/&gt;
	result.setColumn(index + 1, sourceRow.getColumn(projectMapping&lt;span class=&quot;error&quot;&gt;&amp;#91;index&amp;#93;&lt;/span&gt;));&lt;/p&gt;

&lt;p&gt;We call ValueRow.getColumn()  which is defined as:&lt;br/&gt;
	public DataValueDescriptor	getColumn (int position) &lt;/p&gt;
{
		if (position &amp;lt;= column.length)
			return column[position-1];
		else
			return (DataValueDescriptor)null;
	}

&lt;p&gt;and return null because position is greater than column.length.&lt;/p&gt;

&lt;p&gt;I found that projectMapping is originally generated in projectRestrictNode.generateMinion() when we call &lt;br/&gt;
	int[] mapArray = resultColumns.mapSourceColumns();&lt;/p&gt;

&lt;p&gt;ResultColumnList. mapSourceColumns for the column in question  executes this code:&lt;br/&gt;
else if (resultColumn.getExpression() instanceof ColumnReference)&lt;/p&gt;
			{
				ColumnReference cr = (ColumnReference) resultColumn.getExpression();
                                .....
					// Virtual column #s are 1-based
					mapArray[index] = cr.getSource().getVirtualColumnId();
			}


&lt;p&gt;Where the resultColumn looks like:&lt;br/&gt;
	ResultColumn  (id=72)	&lt;br/&gt;
	exposedName	&quot;##aggregate expression&quot;	&lt;br/&gt;
	virtualColumnId	3	&lt;br/&gt;
	expression	ColumnReference  (id=74)	&lt;br/&gt;
		columnName	&quot;I2&quot;	&lt;br/&gt;
		source	ResultColumn  (id=76)	&lt;br/&gt;
			exposedName	&quot;I2&quot;	&lt;br/&gt;
			virtualColumnId	5	&lt;br/&gt;
			expression	VirtualColumnNode  (id=94)	&lt;br/&gt;
				sourceColumn	ResultColumn  (id=100)	&lt;br/&gt;
					exposedName	&quot;I2&quot;	&lt;br/&gt;
					virtualColumnId	2	&lt;br/&gt;
					expression	VirtualColumnNode  (id=102)	&lt;br/&gt;
						sourceColumn	ResultColumn  (id=214)	&lt;br/&gt;
							expression	VirtualColumnNode  (id=227)	&lt;br/&gt;
							virtualColumnId	2	&lt;br/&gt;
								sourceColumn	ResultColumn  (id=239)	&lt;br/&gt;
									exposedName	&quot;I2&quot;	&lt;br/&gt;
									expression	BaseColumnNode  (id=251)	&lt;br/&gt;
										columnName	&quot;I2&quot;	&lt;br/&gt;
										virtualColumnId	2	&lt;/p&gt;


&lt;p&gt;The virtualColumnId of the ColumnReference under the ##aggregate expression is &lt;b&gt;5&lt;/b&gt;, yet there are more deeply nested VirtualColumnNode&apos;s with a virtualColumnId of 2 which I think is correct.  I think I need to better understand mapSourceColumns()  and the meaning of this deeply nested ResultColumn structure to understand what&apos;s right here.&lt;/p&gt;

&lt;p&gt;Kathey&lt;/p&gt;

</comment>
                            <comment id="12641067" author="kmarsden" created="Mon, 20 Oct 2008 17:50:10 +0100"  >&lt;p&gt;Weill it looks like the indentation for my ResultColumn summary did not show up in the comment so I am attaching a file AggregateExpressionResultColumn.txt&lt;/p&gt;</comment>
                            <comment id="12642202" author="army" created="Thu, 23 Oct 2008 18:05:51 +0100"  >&lt;p&gt;Thanks for your work on this, Kathey.&lt;/p&gt;

&lt;p&gt;I spent some time looking at this, and there definitely seems to be something amiss with the virtual column ids for the aggregates, but I wasn&apos;t able to figure out what it is that&apos;s off.&lt;/p&gt;

&lt;p&gt;You may want to try running two queries that are as similar as possible, where one passes and the other fails, and then try to figure out what it is that&apos;s different between the two compilation paths. The ones I&apos;ve been using are:&lt;/p&gt;

&lt;p&gt;&amp;#8211; Passes.&lt;br/&gt;
select t1.i, avg(t2.i2)&lt;br/&gt;
  from t1 inner join t2 on (t1.i = t2.i)&lt;br/&gt;
  group by t1.i having avg(t2.i) &amp;gt; 0;&lt;/p&gt;

&lt;p&gt;&amp;#8211; Fails.&lt;br/&gt;
select t1.i, avg(t2.i)&lt;br/&gt;
  from t1 inner join t2 on (t1.i = t2.i)&lt;br/&gt;
  group by t1.i having avg(t2.i) &amp;gt; 0;&lt;/p&gt;

&lt;p&gt;The only difference between the two is the column that is referenced in the avg for the SELECT (t2.i2 vs t2.i).  That said, I just now also noticed the following:&lt;/p&gt;

&lt;p&gt;&amp;#8211; Passes.&lt;br/&gt;
select t1.i, avg(t2.i2)&lt;br/&gt;
  from t1 inner join t2 on (t1.i = t2.i)&lt;br/&gt;
  group by t1.i having avg(t2.i) &amp;gt; 0;&lt;/p&gt;

&lt;p&gt;&amp;#8211; Passes.&lt;br/&gt;
select t1.i, avg(t2.i2)&lt;br/&gt;
  from t1 inner join t2 on (t1.i = t2.i)&lt;br/&gt;
  group by t1.i having max(t2.i) &amp;gt; 0;&lt;/p&gt;

&lt;p&gt;&amp;#8211; Fails.&lt;br/&gt;
select t1.i, avg(t2.i2)&lt;br/&gt;
  from t1 inner join t2 on (t1.i = t2.i)&lt;br/&gt;
  group by t1.i having avg(t2.i2) &amp;gt; 0;&lt;/p&gt;

&lt;p&gt;&amp;#8211; Fails.&lt;br/&gt;
select t1.i, avg(t2.i2)&lt;br/&gt;
  from t1 inner join t2 on (t1.i = t2.i)&lt;br/&gt;
  group by t1.i having min(t2.i2) &amp;gt; 0;&lt;/p&gt;

&lt;p&gt;From these tiny examples, it &lt;b&gt;seems&lt;/b&gt; that if the aggregate in the SELECT list references the same column as the aggregate in the HAVING clause, then the query fails; if they reference &lt;b&gt;different&lt;/b&gt; columns, the query passes.&lt;/p&gt;

&lt;p&gt;That might be something to investigate further?  Without having looked at all into it (I only just now realized the apparent correlation), I think the &quot;SubstituteExpressionVisitor&quot; that is used by GroupByNode relies in some way on &quot;equivalent&quot; expressions, and then it plugs VirtualColumnNodes into the tree based on that equivalency.  I wonder if  the fact that the SELECT clause and the HAVING clause are have &quot;equivalent&quot; column references is somehow messing the virtual column ids up somewhere...?  It&apos;s pure speculation, but if you&apos;re looking for options, that might be one to pursue...&lt;/p&gt;</comment>
                            <comment id="12642243" author="bryanpendleton" created="Thu, 23 Oct 2008 20:33:30 +0100"  >&lt;p&gt;Army&apos;s observation about the SubstituteExpressionVisitor made me remember&lt;br/&gt;
the discussion in &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3094&quot; title=&quot;Grouping of expressions causes NullPointerException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3094&quot;&gt;&lt;del&gt;DERBY-3094&lt;/del&gt;&lt;/a&gt;. It may not be directly related, but there is some&lt;br/&gt;
detailed discussion in the comments to that issue regarding various paths&lt;br/&gt;
through the code in question, which might be useful. So I thought I&apos;d mention it.&lt;/p&gt;

&lt;p&gt;Plus, although I have no reason to think this would be true, it might be interesting&lt;br/&gt;
to try backing out the changes for &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3094&quot; title=&quot;Grouping of expressions causes NullPointerException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3094&quot;&gt;&lt;del&gt;DERBY-3094&lt;/del&gt;&lt;/a&gt; and see if that had any affect&lt;br/&gt;
on either the repro script or on the various test cases that Army mentions.&lt;/p&gt;

&lt;p&gt;Hopefully this is just a red herring, and we don&apos;t have to drag all the complexity&lt;br/&gt;
of &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3094&quot; title=&quot;Grouping of expressions causes NullPointerException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3094&quot;&gt;&lt;del&gt;DERBY-3094&lt;/del&gt;&lt;/a&gt; into this issue but hopefully it&apos;s also helpful for people working&lt;br/&gt;
on this issue to be aware of that history.&lt;/p&gt;</comment>
                            <comment id="12643316" author="kmarsden" created="Tue, 28 Oct 2008 19:34:03 +0000"  >&lt;p&gt;Thanks Army and Brian for looking at this pesky issue. With regard to &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3094&quot; title=&quot;Grouping of expressions causes NullPointerException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3094&quot;&gt;&lt;del&gt;DERBY-3094&lt;/del&gt;&lt;/a&gt;, thank you for the write up. It was indeed most informative.  As you suggested I backed out the change for &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3094&quot; title=&quot;Grouping of expressions causes NullPointerException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3094&quot;&gt;&lt;del&gt;DERBY-3094&lt;/del&gt;&lt;/a&gt; and found no appreciable difference in the behaviour of the queries in question in this issue.&lt;/p&gt;


&lt;p&gt;I looked at the SubstituteExpressionVisitor logic and don&apos;t think it is related. The result column in question is the one created in AggregateNode.java with the code&lt;br/&gt;
node = (operand == null) ?&lt;br/&gt;
			this.getNewNullResultExpression() :&lt;br/&gt;
			operand;&lt;/p&gt;

&lt;p&gt;		return (ResultColumn) getNodeFactory().getNode(&lt;br/&gt;
								C_NodeTypes.RESULT_COLUMN,&lt;br/&gt;
								&quot;##aggregate expression&quot;,&lt;br/&gt;
								node,&lt;br/&gt;
								getContextManager());&lt;br/&gt;
	}&lt;/p&gt;

&lt;p&gt;where it is the operand being wrapped. I do not think this column is traversed with the SubstituteExpressionVisitor.&lt;/p&gt;</comment>
                            <comment id="12644199" author="army" created="Fri, 31 Oct 2008 03:16:12 +0000"  >&lt;p&gt;I looked a bit more at this issue and I think I&apos;ve discovered at least part of the problem.  A query like:&lt;/p&gt;

&lt;p&gt;  select t1.i, avg(t2.i)&lt;br/&gt;
    from t1 inner join t2 on (t1.i = t2.i)&lt;br/&gt;
    group by t1.i having avg(t2.i) &amp;gt; 0;&lt;/p&gt;

&lt;p&gt;has two aggregates in it, which means the compile time query tree has two AggregateNodes, each of which has an &quot;operand&quot; that is a column reference.  The result column to which the operand points is determined at bind time, and in this case the result column &quot;t2.i&quot; points to a bind-time JoinNode.  The JoinNode&apos;s bind-time result column list is simply a concatenation of the result column lists from its operands.  In our example, the query specifies T1 followed by T2, so the JoinNode&apos;s bind-time RCL is: &lt;/p&gt;
{ T1.i, T1.c, T2.i, T2.c2, T2.i2 }
&lt;p&gt;.  Notice how, with respect to this list, the position of &quot;t2.i&quot; is &quot;3&quot;.  So when we bind the AggregateNodes, each of them ends up with an operand that is a ColumnReference which points to the &quot;t2.i&quot; column of the bind-time JoinNode, which in turn has virtual column id of &quot;3&quot;.&lt;/p&gt;

&lt;p&gt;After binding is complete we start optimization, the first phase of which is preprocessing.  As part of SelectNode preprocessing we look at the FromList to see if there are any JoinNodes that can be flattened.  In the above query the JoinNode &lt;b&gt;can&lt;/b&gt; be flattened, which means it effectively disappears.  That in turn means that any result columns in the SELECT list have to be updated to reflect the fact that they no longer point to the JoinNode; instead, they point directly to the underlying base tables.  The process of flattening the JoinNode and updating the SelectNode&apos;s result column list begins with the following call in SelectNode.preprocess():&lt;/p&gt;

&lt;p&gt;    // Flatten any flattenable FromSubquerys or JoinNodes&lt;br/&gt;
    fromList.flattenFromTables(resultColumns, &lt;br/&gt;
        wherePredicates, &lt;br/&gt;
        whereSubquerys,&lt;br/&gt;
      groupByList);&lt;/p&gt;

&lt;p&gt;Notice how we pass the SelectNode&apos;s RCL into the flattenFromTables method, but we do &lt;b&gt;not&lt;/b&gt; pass the HAVING clause.  Long story short, the AggregateNode in the SelectNode&apos;s RCL is properly updated to reflect the removal of the JoinNode--but the AggregateNode in the HAVING clause continues to point to a result column from the now-useless JoinNode.  The &lt;b&gt;real&lt;/b&gt; column to which the Aggregate should be pointing is actually buried &lt;b&gt;beneath&lt;/b&gt; the JoinNode&apos;s ResultColumn, so the aggregate&apos;s operand should have been remapped to point to the buried column. (And indeed, that&apos;s exactly what happens with the aggregate in the SelectNode&apos;s RCL.)&lt;/p&gt;

&lt;p&gt;When optimization is done and we modify the tree, result columns are updated to reflect the final join order and also to remove any un-referenced columns.  But since the HAVING aggregate node is still pointing to the unused JoinNode result column, it doesn&apos;t see any changes--it continues to point to a ResultColumn that has a virtual column id of &quot;3&quot; and which points to a JoinNode that is no longer valid.&lt;/p&gt;

&lt;p&gt;The final query plan inclues a &lt;b&gt;new&lt;/b&gt; JoinNode between T1 and T2, and that JoinNode&apos;s RCL only contains columns which are referenced in the query.  Thus the execution-time JoinNode result column list is, for the above query, &lt;/p&gt;
{ T1.i, T2.i }
&lt;p&gt;.  Note how it only has TWO columns in it, not five like the bind-time JoinNode.  So when it comes time to execute the query, the aggregate in the having clause ends up pointing to column &quot;3&quot; of the new JoinNode&apos;s RCL, and since that doesn&apos;t exist, the column value is set to null (as Kathey noted in earlier comments).  Attempts to reference that column for GROUP BY sorting, then, result in the NPE.&lt;/p&gt;

&lt;p&gt;The reason the same query works if the two aggregates reference two &lt;em&gt;different&lt;/em&gt; columns in T2 has nothing to do with equivalence-&lt;del&gt;that was a red herring, sorry for the miscue.  The reason the query passes appears to have something to do with referenced columns&lt;/del&gt;-esp. the SelectNode (which includes the Select RCL and the Having clause) then references TWO columns from T2 plus ONE column from T1, leading to THREE columns in the execution JoinNode&apos;s RCL: &lt;/p&gt;
{ T1.i, T2.i, T2.i2 }
&lt;p&gt;.  So now the RCL has three columns instead of two, which means the result column in the HAVING aggregate, which still has the INCORRECT virtual id of &quot;3&quot;, accidentally points to a valid column, and thus the query passes--but that was just chance, the code is still technically wrong.&lt;/p&gt;

&lt;p&gt;This also explains why the original query passes if the user does NOT specify &quot;inner join&quot;.  The inclusion of &quot;inner join&quot; leads to the creation of the bind-time JoinNode between T1 and T2, against which the aggregates are then bound.  In preprocessing we realize the JoinNode is useless so we flatten it out of the query, and that causes the aforementioned problem.  But if the query does not have &quot;inner join&quot;, the bind-time JoinNode is never created, which means both aggregate nodes already point directly to the underlying base tables.  Throughout optimization and query generation the base table result columns are properly updated, which means both aggregates end up pointing to the correct place, and all is well.&lt;/p&gt;

&lt;p&gt;So all of that said, I think the fix for this problem is to somehow ensure that the HAVING clause&apos;s AggregateNode is correctly remapped when/if necessary, esp. if it points to a JoinNode that has been flattened out.  I happened to notice that, when the JoinNode is flattened, all of its result columns are marked as &quot;redundant&quot; as part of the flattening process (see JoinNode.flatten()).  So the quick (and possibly NOT complete) fix that I found was to add an &quot;if&quot; statement to the getNewExpressionResultColumn() method of AggregateNode.java.  That method is called as part of &quot;modification of access paths&quot;-&lt;del&gt;i.e. after optimization has completed&lt;/del&gt;-and is used for creating the result column that will ultimately be used for aggregate input at execution time.  I found that if I added logic to remap the Aggregate&apos;s operand (if it&apos;s a column reference), then the posted query starts running without error:&lt;/p&gt;

&lt;p&gt;Index: java/engine/org/apache/derby/impl/sql/compile/AggregateNode.java&lt;br/&gt;
===================================================================&lt;br/&gt;
&amp;#8212; java/engine/org/apache/derby/impl/sql/compile/AggregateNode.java    (revision 707244)&lt;br/&gt;
+++ java/engine/org/apache/derby/impl/sql/compile/AggregateNode.java    (working copy)&lt;br/&gt;
@@ -539,6 +539,26 @@&lt;br/&gt;
                        this.getNewNullResultExpression() :&lt;br/&gt;
                        operand;&lt;/p&gt;

&lt;p&gt; +        /* The operand for this aggregate node was initialized at bind&lt;br/&gt;
 +         * time.  Between then and now it&apos;s possible that certain changes&lt;br/&gt;
 +         * have been made to the query tree which affect this operand. In&lt;br/&gt;
 +         * particular, if the operand was pointing to a result column in&lt;br/&gt;
 +         * a JoinNode and then that JoinNode was flattened during pre-&lt;br/&gt;
 +         * processing, all of the references to that JoinNode--including&lt;br/&gt;
 +         * this aggregate&apos;s operand--need to be updated to reflect the&lt;br/&gt;
 +         * fact that the Join Node no longer exists.  So check to see if&lt;br/&gt;
 +         * the operand is a column reference, and if so, make a call to&lt;br/&gt;
 +         * remap it to its underlying expression.  If nothing has happened&lt;br/&gt;
 +         * then this will be a no-op; but if something has changed to void&lt;br/&gt;
 +         * out the result column to which the operand points, the result&lt;br/&gt;
 +         * column will be marked &quot;redundant&quot; and the following call should&lt;br/&gt;
 +         * remap as appropriate. &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3880&quot; title=&quot;NPE on a query with having clause involving a join&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3880&quot;&gt;&lt;del&gt;DERBY-3880&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
 +         */&lt;br/&gt;
 +        if (operand instanceof ColumnReference)&lt;br/&gt;
 +        &lt;/p&gt;
{
 +            ((ColumnReference)operand).remapColumnReferencesToExpressions();
 +        }
&lt;p&gt; +&lt;br/&gt;
            return (ResultColumn) getNodeFactory().getNode(&lt;br/&gt;
                                                                C_NodeTypes.RESULT_COLUMN,&lt;br/&gt;
                                                                &quot;##aggregate expression&quot;,&lt;/p&gt;

&lt;p&gt;I didn&apos;t run any other tests, and I admit that this change may not be sufficient (or it may be too general), but it does cause the reported query to run without error, so at the very least it demonstrates the problem.  There could very well be a better way to fix it...&lt;/p&gt;</comment>
                            <comment id="12644393" author="kmarsden" created="Fri, 31 Oct 2008 18:40:32 +0000"  >&lt;p&gt;Thanks Army for the great explanation and patch proposal.  I&apos;ll give it a try.&lt;/p&gt;</comment>
                            <comment id="12644992" author="kmarsden" created="Tue, 4 Nov 2008 16:35:45 +0000"  >&lt;p&gt;Army&apos;s patch passes regression tests.  I&apos;ll add a test and commit, then backport to 10.4 and 10.3. Thanks Army!&lt;/p&gt;
</comment>
                            <comment id="12645520" author="kmarsden" created="Thu, 6 Nov 2008 17:33:31 +0000"  >&lt;p&gt;The fix has been committed to trunk, 10.4 and 10.3.  Giving Army the point since he came up with the fix.&lt;/p&gt;</comment>
                            <comment id="12646605" author="bryanpendleton" created="Tue, 11 Nov 2008 17:19:07 +0000"  >&lt;p&gt;Hi Army, Kathey, sorry it took me a while to read through Army&apos;s excellent description of 30-Oct&lt;/p&gt;

&lt;p&gt;I have a couple questions that came to mind while I was studying Army&apos;s notes:&lt;/p&gt;

&lt;p&gt;1) Army says  &quot;so the JoinNode&apos;s bind-time RCL is: &lt;/p&gt;
{ T1.i, T1.c, T2.i, T2.c2, T2.i2 }
&lt;p&gt;&quot; but I don&apos;t&lt;br/&gt;
see how that is, if the query is &lt;/p&gt;

&lt;p&gt;      select t1.i, avg(t2.i)&lt;br/&gt;
          from t1 inner join t2 on (t1.i = t2.i)&lt;br/&gt;
          group by t1.i having avg(t2.i) &amp;gt; 0; &lt;/p&gt;

&lt;p&gt;Is it possible that the query Army was analyzing was actually &quot;on (t1.c = t2.c2)&quot; ? Otherwise,&lt;br/&gt;
I&apos;m having trouble seeing why T1.c and T2.c2 are in the join node&apos;s RCL. &lt;/p&gt;

&lt;p&gt;2) While I was reading Army&apos;s writeup, I anticipated that I was going to see a fix which&lt;br/&gt;
involved passing the HAVING clause expressions to fromList.flattenFromTables() so that&lt;br/&gt;
it could properly maintain the ColumnReference data in the HAVING clause during flattening. &lt;/p&gt;

&lt;p&gt;But it seems like the essence of Army&apos;s fix is to observe that we don&apos;t need to maintain&lt;br/&gt;
the ColumnReference instances inside of AggregateNode instances because we can&lt;br/&gt;
always go back at the end of optimization and re-construct the ColumnReference info.&lt;/p&gt;

&lt;p&gt;This seems very nice, because I&apos;ve seen numerous problems over the past several&lt;br/&gt;
years which involved situations where we lost track of the ColumnReference&apos;s table&lt;br/&gt;
and column pointers during the compilation and optimization processing. That code&lt;br/&gt;
overall seems very tricky and trouble-prone. I could track down the actual JIRA id&apos;s&lt;br/&gt;
if you wish; they involved GROUP BY and ORDER BY analysis, which is similar, but&lt;br/&gt;
certainly not identical, to HAVING clause analysis.&lt;/p&gt;

&lt;p&gt;So now I&apos;m wondering: if it&apos;s true that we can figure out the proper ColumnReference&lt;br/&gt;
information at the &lt;b&gt;end&lt;/b&gt; of the optimization process, and don&apos;t have to maintain&lt;br/&gt;
that data during the compilation/optimzation process, then perhaps we shouldn&apos;t be&lt;br/&gt;
doing it at all, but rather should simply wait til optimization is complete, then fix-up all&lt;br/&gt;
the ColumnReferences in the tree at the end.&lt;/p&gt;

&lt;p&gt;That is, if it&apos;s safe to allow the ColumnReference in the aggregate of a HAVING clause&lt;br/&gt;
to &quot;decay&quot; (become in-accurate) during optimization, and then fix it up at the end,&lt;br/&gt;
why do we have to re-map the ColumnReference information for the SELECT&apos;s RCL?&lt;/p&gt;

&lt;p&gt;And similarly could we avoid having to &quot;fix-up&quot; the GROUP BY and ORDER BY clauses?&lt;/p&gt;

&lt;p&gt;Or is it only safe to allow HAVING clause ColumnReference instances to diverge&lt;br/&gt;
from reality for short periods, because they are fundamentally different from the&lt;br/&gt;
aggregate nodes in the select RCL?&lt;/p&gt;

&lt;p&gt;3) Army says &quot;the compile time query tree has two AggregateNodes&quot;. I&apos;ve noticed&lt;br/&gt;
this myself. In fact, while looking at somewhat similar situations, I&apos;ve noticed that&lt;br/&gt;
(I think) the actual code that is generated to execute the query may contain&lt;br/&gt;
multiple computations of the same expressions. That is, when this query runs,&lt;br/&gt;
is it true that we are actually going to &lt;b&gt;compute&lt;/b&gt; AVG(t2.i) twice? We&apos;ll only do&lt;br/&gt;
one pass over the data, of course, but we&apos;ll have two running-total values that&lt;br/&gt;
are redundantly accumulating the t2.i sub-totals as we go?&lt;/p&gt;

&lt;p&gt;I&apos;ve been wondering if maybe there is some sort of fundamental &quot;common sub-expression&lt;br/&gt;
detection&quot; which the Derby compilation system is not performing, such that it&lt;br/&gt;
doesn&apos;t recognize when two parts of a query are actually computing the same&lt;br/&gt;
result, and so we end up generating a query which performs more computation&lt;br/&gt;
than is needed, redundantly computing values multiple times in situations where&lt;br/&gt;
they are mentioned multiple times.&lt;/p&gt;

&lt;p&gt;I noticed this in studying GROUP BY queries, where if the GROUP BY clause&lt;br/&gt;
contained an expression, and that expression matched a similar expression&lt;br/&gt;
in the SELECT list, the resulting query seemed to compute the expression twice,&lt;br/&gt;
when it would have been adequate to compute it only once.&lt;/p&gt;

&lt;p&gt;I&apos;m not intending to &quot;hijack the thread&quot; with any of these questions; I&apos;m extremely&lt;br/&gt;
happy that we&apos;ve solved this problem and that the query now runs correctly.&lt;br/&gt;
I&apos;m just trying to improve my understanding of Derby internals by taking this&lt;br/&gt;
opportunity to ask a few questions about parts of this issue that puzzled me.&lt;/p&gt;

&lt;p&gt;Thanks VERY much to Army and Kathey for all the hard work they did on this problem!&lt;/p&gt;

</comment>
                            <comment id="12646775" author="army" created="Wed, 12 Nov 2008 01:47:39 +0000"  >&lt;p&gt;Hi Bryan,&lt;/p&gt;

&lt;p&gt;Thanks for your interest in this issue.&lt;/p&gt;

&lt;p&gt;&amp;gt; Army says &quot;so the JoinNode&apos;s bind-time RCL is: &lt;/p&gt;
{ T1.i, T1.c, T2.i, T2.c2, T2.i2 }&quot; but I don&apos;t&lt;br/&gt;
&amp;gt; see how that is &lt;span class=&quot;error&quot;&gt;&amp;#91;...&amp;#93;&lt;/span&gt; I&apos;m having trouble seeing why T1.c and T2.c2 are in the join node&apos;s RCL.&lt;br/&gt;
&lt;br/&gt;
I think the key observation here is in the sentence immediately preceding the one that you quoted, namely:&lt;br/&gt;
&lt;br/&gt;
  The JoinNode&apos;s bind-time result column list is simply a concatenation of the result column&lt;br/&gt;
  lists from its operands.&lt;br/&gt;
&lt;br/&gt;
Due to the specification of &quot;inner join&quot; the parser will create a parse-time JoinNode whose left operand is a FromBaseTable representing T1 and whose right operand is a FromBaseTable representing T2.  Note how neither operand has a ProjectRestrictNode above it, which in turn means we will &lt;b&gt;not&lt;/b&gt; project out any columns (at this point).  Thus the FromBaseTable for T1 has an RCL with &lt;b&gt;ALL&lt;/b&gt; of T1&apos;s columns in it, and the FromBaseTable for T2 has an RCL with &lt;b&gt;ALL&lt;/b&gt; of T2&apos;s columns in it.  The fact that some columns are never referenced in the query has no effect on the RCLs for the FromBaseTables at this point in binding.&lt;br/&gt;
&lt;br/&gt;
To verify, you can put a breakpoint in JoinNode.buildRCL() and, when the breakpoint hits, look at the leftOperand and rightOperand.  They will both be FromBaseTables and the RCLs will have all columns that exist in the underlying base tables.  So the JoinNode&apos;s RCL then becomes a concatenation of all columns from T1 and all columns from T2, hence { T1.i, T1.c, T2.i, T2.c2, T2.i2 }
&lt;p&gt;--even though T1.c and T2.c2 are never referenced in the query.&lt;/p&gt;

&lt;p&gt;&amp;gt; I anticipated that I was going to see a fix which involved passing the HAVING clause&lt;br/&gt;
&amp;gt; expressions to fromList.flattenFromTables() so that it could properly maintain the&lt;br/&gt;
&amp;gt; ColumnReference data in the HAVING clause during flattening. &lt;/p&gt;

&lt;p&gt;To be honest, I think you&apos;re absolutely right: that seems like a more robust approach to the problem.  See below...&lt;/p&gt;

&lt;p&gt;&amp;gt; if it&apos;s safe to allow the ColumnReference in the aggregate of a HAVING clause&lt;br/&gt;
&amp;gt; to &quot;decay&quot; (become in-accurate) during optimization, and then fix it up at the end,&lt;br/&gt;
&amp;gt; why do we have to re-map the ColumnReference information for the SELECT&apos;s&lt;br/&gt;
&amp;gt; RCL?&lt;/p&gt;

&lt;p&gt;Good question.  I do not think it is generally safe to assume that a temporarily inaccurate ColumnReference is going to be okay.  The vast majority of the ColumnReference remapping that occurs during optimization happens in order to support the pushing of predicates down the tree and/or to allow the insertion of query tree nodes into an existing tree.  In both cases the column reference is being remapped from one valid ResultColumn to another valid ResultColumn.  In other words, we can&apos;t just look at the ColumnReference after optimization has finished and say &quot;pick the only one that&apos;s valid&quot;, because there could be an arbitrarily long chain of ResultColumns, VirtualColumnNodes, and ColumnReferences, all of which are valid and referenceable by different parts of the query tree.  The only way to know which one is the &quot;right&quot; one for a given ColumnReference is to remap (or un-remap) in &quot;real time&quot;--ex. when we push/pull a predicate, we have to remap its column reference as part of the push/pull.&lt;/p&gt;

&lt;p&gt;That said, the fact that a post-optimization remapping of the HAVING aggregate&apos;s ColumnReference corrected the problem was a pleasant surprise to me, as I too was more inclined to believe that, by then, it would be too late.  But I made the change, saw that it made sense and that it fixed the immediate problem, and that&apos;s what I posted.  Having done so, I think it&apos;s worth it to echo the final few sentences from that same comment, namely:&lt;/p&gt;

&lt;p&gt;  I admit that this change may not be sufficient (or it may be too general), but it does&lt;br/&gt;
  cause the reported query to run without error, so at the very least it demonstrates&lt;br/&gt;
  the problem. There could very well be a better way to fix it...&lt;/p&gt;

&lt;p&gt;I posted a quick fix to demonstrate the problem and stopped there.  Kathey was kind enough to pick it up and take it to completion.  But at a higher level, I think you&apos;re right: there&apos;s probably a better (and safer) way to fix this bug, and your suggestion that such a fix would involve passing the HAVING clause expressions to fromList.flattenFromTables() seems like a good one to me...&lt;/p&gt;

&lt;p&gt;&amp;gt; I&apos;ve noticed that (I think) the actual code that is generated to execute the query may&lt;br/&gt;
&amp;gt; contain multiple computations of the same expressions. That is, when this query&lt;br/&gt;
&amp;gt; runs, is it true that we are actually going to &lt;b&gt;compute&lt;/b&gt; AVG(t2.i) twice?&lt;/p&gt;

&lt;p&gt;I have not looked at this in any detail, but I believe the answer is &quot;Yes&quot;, at least based on the tracing I was doing when I was trying to track down the cause of this issue.  But I wasn&apos;t specifically investigating that particular behavior at the time, so it&apos;s possible I missed something...&lt;/p&gt;</comment>
                            <comment id="12646804" author="bryanpendleton" created="Wed, 12 Nov 2008 05:22:48 +0000"  >&lt;p&gt;Thanks Army!&lt;/p&gt;

&lt;p&gt;I had overlooked your explanation about the construction of the JoinNode RCL; thanks&lt;br/&gt;
for the clarification. I worked through JoinNode.buildRCL and I see exactly what you mean:&lt;/p&gt;

&lt;p&gt;                /* Now we append the propagated RCL from the right to the one from&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;the left and call it our own.&lt;br/&gt;
                 */&lt;br/&gt;
                resultColumns.nondestructiveAppend(tmpRCL);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;It seems like it would be worth following up some more on the other topics; I&apos;ll see about&lt;br/&gt;
filing them as separate JIRA issues so we can pursue them down the line.&lt;/p&gt;

&lt;p&gt;Thanks again not only for the fix, but even better for helping me understand how it works.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12415041">DERBY-4063</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12466874">DERBY-4698</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12325311">DERBY-681</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12392497" name="AggregateExpressionResultColumn.txt" size="852" author="kmarsden" created="Mon, 20 Oct 2008 17:50:10 +0100"/>
                            <attachment id="12392287" name="querytree_fail.txt" size="4485" author="kmarsden" created="Thu, 16 Oct 2008 21:58:36 +0100"/>
                            <attachment id="12392286" name="querytree_works.txt" size="3951" author="kmarsden" created="Thu, 16 Oct 2008 21:58:36 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310200" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Bug behavior facts</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10420"><![CDATA[Regression]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 17 Sep 2008 03:34:52 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23896</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310090" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Issue &amp; fix info</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10422"><![CDATA[High Value Fix]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy0lav:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>37269</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            </customfields>
    </item>
</channel>
</rss>