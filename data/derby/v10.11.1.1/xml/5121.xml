<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:28:15 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-5121/DERBY-5121.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-5121] Data corruption when executing an UPDATE trigger</title>
                <link>https://issues.apache.org/jira/browse/DERBY-5121</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;When executing an UPDATE trigger, the following error is raised. I will attach a test case:&lt;/p&gt;

&lt;p&gt;ERROR XCL12: An attempt was made to put a data value of type &apos;org.apache.derby.impl.jdbc.EmbedClob&apos; into a data value of type &apos;INTEGER&apos;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12500978">DERBY-5121</key>
            <summary>Data corruption when executing an UPDATE trigger</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mamtas">Mamta A. Satoor</assignee>
                                    <reporter username="rhillegas">Rick Hillegas</reporter>
                        <labels>
                            <label>derby_backport_reject_10_5</label>
                    </labels>
                <created>Thu, 10 Mar 2011 02:40:19 +0000</created>
                <updated>Fri, 14 Jun 2013 18:29:02 +0100</updated>
                            <resolved>Tue, 29 Mar 2011 17:55:38 +0100</resolved>
                                    <version>10.7.1.1</version>
                    <version>10.8.1.2</version>
                                    <fixVersion>10.7.1.4</fixVersion>
                    <fixVersion>10.8.1.2</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="13004952" author="rhillegas" created="Thu, 10 Mar 2011 02:42:14 +0000"  >&lt;p&gt;Attaching DummyProc.java and triggerBug.sql, a repro for this issue. Compile DummyProc then run triggerBug via ij.&lt;/p&gt;</comment>
                            <comment id="13005823" author="rhillegas" created="Fri, 11 Mar 2011 20:39:54 +0000"  >&lt;p&gt;Changing the description of this bug since experiments show that it is more general. The triggered action seems to expect a row which just contains the columns necessary to execute the action. However, if the UPDATE touches columns which aren&apos;t mentioned by the trigger, those columns turn up in the row passed to the action. These extra columns can be in the middle of the action row. This throws off the column number of the compiled action and springs this bug.&lt;/p&gt;</comment>
                            <comment id="13005828" author="rhillegas" created="Fri, 11 Mar 2011 20:47:36 +0000"  >&lt;p&gt;Attaching a second version of the triggerBug.sql repro. This does not need the procedure class because it demonstrates the bug using an INSERT action. The repro shows that the bug occurs when an extra column is set by the UPDATE statement.&lt;/p&gt;</comment>
                            <comment id="13006441" author="rhillegas" created="Mon, 14 Mar 2011 14:52:27 +0000"  >&lt;p&gt;It turns out that this bug can manifest itself as data corruptions. I will attach a repro showing that. The bug does not appear in 10.6.2.1 but it does appear in 10.7.1.1. Changing the title of this issue and marking it as a data corrupting regression.&lt;/p&gt;</comment>
                            <comment id="13006442" author="rhillegas" created="Mon, 14 Mar 2011 14:53:52 +0000"  >&lt;p&gt;Attaching triggeredCorruption.sql, a script which demonstrates how this bug can corrupt data.&lt;/p&gt;</comment>
                            <comment id="13006521" author="rhillegas" created="Mon, 14 Mar 2011 17:13:16 +0000"  >&lt;p&gt;Through binary search I have identified the checkin which introduced this data corruption:&lt;/p&gt;

&lt;p&gt;r956763 | mamta | 2010-06-21 19:41:48 -0700 (Mon, 21 Jun 2010) | 5 lines&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Only read the needed columns for the update trigger when create trigger has identified the columns which will be used in trigger action through the REFERENCING clause. This will avoid reading columns that are not needed thus avoiding OOM problems if the underlying table has large LOBs.&lt;/p&gt;</comment>
                            <comment id="13006605" author="rhillegas" created="Mon, 14 Mar 2011 20:01:56 +0000"  >&lt;p&gt;Thanks for picking up this issue, Mamta. I am raising the urgency to Blocker. I feel that this issue will affect a lot of applications when they upgrade to 10.7 or 10.8. Thanks.&lt;/p&gt;</comment>
                            <comment id="13006651" author="mamtas" created="Mon, 14 Mar 2011 21:41:40 +0000"  >&lt;p&gt;Frist of all, thanks so much for having such an easy reproducible test case. &lt;/p&gt;

&lt;p&gt;I looked at the generated code for the trigger action and see the problem Rick described. The purpose of &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; was to avoid reading the columns that are not needed by the trigger action, especially the LOB columns which could result in OOM problems. The code that I added for &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; looked at the columns referenced in trigger action and &lt;b&gt;assumed&lt;/b&gt; that the resultset would have just those columns during the trigger execution time. So, in following example, the trigger action references only 2 out of the 3 columns, the 1st and the 3rd column. The trigger action thus assumes that the resultset would have just columns 1 and 3 in the resultset&apos;s column positions 1 and 2. But it did not take into account where the triggering SQL might need additional columns of it&apos;s own. In the given example, the triggering UPDATE statement is using the column in position 2 from the trigger table and this causes the trigger action to start using the columns in incorrect column positions.&lt;/p&gt;

&lt;p&gt;I understand the urgency of this jira and based on that, I will see if I can disable the optimization introduced by &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt;. Once that is done, I will look into what could be other ways to solve the unnecessary column reads algorithm. One thing that comes to my mind is to may be read all the columns upto the highest column position required by the trigger action. So in our eg, triggeredCorruption.sql, the trigger action is looking at column positions 1 and 3 and hence we should read columns 1, 2 and 3 even though the trigger action does not need the column 2. Any columns after the highest column position required by the trigger action will be read if the triggering SQL requires it but it will not affect the column positions getting used inside the trigger action.&lt;/p&gt;

&lt;p&gt;I will also think of any other possible way to tackle the column reading optimization. If anyone has any other ideas, please let me know.&lt;/p&gt;</comment>
                            <comment id="13006670" author="mikem" created="Mon, 14 Mar 2011 22:14:59 +0000"  >&lt;p&gt;at the trigger execution time is there no way to determine the column position in the table vs the column position in the row of the update result set?  If I understand the problem the current code is correctly indicating to the update which columns are necessary, we are just accessing the wrong ones.   Seems &lt;br/&gt;
like there just needs to be some column fixup or different logic in column accessing for the trigger execution code.&lt;/p&gt;</comment>
                            <comment id="13006897" author="rhillegas" created="Tue, 15 Mar 2011 12:50:57 +0000"  >&lt;p&gt;It looks to me as though the row set which is passed to the trigger action is already wrapped in another ResultSet. In the case of row-at-a-time triggers, this is a TemporaryRowHolderResultSet. It may be attractive to put some column remapping logic in the TemporaryRowHolderResultSet. I haven&apos;t looked at the end-of-statement triggers, but I suspect that there&apos;s a wrapper ResultSet there too and some more column remapping logic could be put there. Extra credit if the remapping logic could be factored out and shared.&lt;/p&gt;</comment>
                            <comment id="13006958" author="rhillegas" created="Tue, 15 Mar 2011 15:09:33 +0000"  >&lt;p&gt;Attaching triggeredBug2.sql. This adds a test for a related case involving statement-scope (rather than row-scope) triggers. The problem does not seem to affect statement-scope triggers, at least not in this test case. I see that in both the statement-scope and row-scope cases, the row passed to the trigger is wrapped in a TemporaryRowHolderResultSet.&lt;/p&gt;</comment>
                            <comment id="13007034" author="mamtas" created="Tue, 15 Mar 2011 17:26:04 +0000"  >&lt;p&gt;This data corruption regression is in 10.8 and 10.7 codelines.&lt;/p&gt;

&lt;p&gt;I should have a patch for review soon today which will disable the column reading optimization and hence any newly created triggers will work fine. There will be still be issues with triggers already created. This can be a problem with 10.7 since we may already have customers using that release. Fortunately, 10.8 is not out yet to impact any customers. For 10.7, the users will have to drop and recreate their triggers(only the triggers which are defined at row level and which use REFERENCING clause. All the other triggers will work fine).&lt;/p&gt;

&lt;p&gt;Once we have the patch reviewed and committed, I would like to see how I can do the selective column reading and correct column mapping to the resultset at runtime. With the buggy 10.7 and 10.8 code, at the create trigger time, I do the column mapping for the trigger action columns making the assumptions that those columns are the only columns which will exist in the runtime resultset. That assumption is incorrect as shown in the test cases attached to this jira. I am thinking of pursuing the solution where the trigger action sql should not be generated at the create trigger time. Instead, it should be generated when the trigger gets fired and the column position mapping of trigger action columns should happen based on what columns exist in what positions in the runtime resultset. Please let me know if anyone sees a problem with this approach. Any existing generated trigger action sql for existing triggers will be disregarded and it will be just generated at the trigger firing time. This approach will take care of the existing triggers and the new triggers. Once we have this fix in, the 10.7 users will not have to drop and recreate their triggers.&lt;/p&gt;</comment>
                            <comment id="13007049" author="mamtas" created="Tue, 15 Mar 2011 17:53:43 +0000"  >&lt;p&gt;Rick, this data corruption should only occur with row level triggers which are using columns in trigger action through REFERENCING clause. All the other kinds of triggers including statement level triggers should not be impacted.&lt;/p&gt;

&lt;p&gt;I will soon submit a patch for review which will have the test cases provided by you in triggeredBug2.sql.&lt;/p&gt;</comment>
                            <comment id="13007081" author="rhillegas" created="Tue, 15 Mar 2011 18:36:26 +0000"  >&lt;p&gt;Thanks, Mamta. This sounds like good progress. I don&apos;t understand the performance implications of compiling the trigger action every time a firing statement is compiled. I suspect that the actions are pre-compiled because someone believed that would yield a performance boost. At a high level, I like the idea of compiling the trigger action along with the firing statement, if only because it gets us out of the business of asking people to drop and recreate their triggers when we correct problems like this. Ever since my stint at Sybase, I have not been a big fan of stored prepared statements--I believe they are a runtime optimization with a thousand brittle consequences.&lt;/p&gt;

&lt;p&gt;At a minimum we would want to make sure that this approach does not break recompilations of prepared statements which may happen because of table changes. For instance, I am thinking about what happens when someone alters the table which is the target of the trigger action.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
-Rick&lt;/p&gt;</comment>
                            <comment id="13007356" author="mamtas" created="Wed, 16 Mar 2011 05:33:55 +0000"  >&lt;p&gt;Th attached patch(derby5121_patch1_diff.txt) will disable the selective column reading for row level triggers which was introduced by &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt;. As a result of this, Derby will be required to read all the columns from the trigger table. The generated trigger action sql&apos;s columns will refer to the columns using theie actual column positions in the trigger table. I have disabled the selective colunm reading by simply assuming in the create trigger code that we are dealing with pre-10.7 database(as if we are in soft upgrade mode from pre-10.7). During the soft-upgrade mode with 10.7 and higher releases, we do not do column reading optimization because the system tables in pre-10.7 are not equipped to keep additional information about trigger action columns. &lt;/p&gt;

&lt;p&gt;This code change was done in DataDictionaryImpl.getTriggerActionString and looks as follows&lt;br/&gt;
		boolean in10_7_orHigherVersion = false;&lt;br/&gt;
In addition to the above change, I also had to catch the column missing error in this same method. This can happen if ALTER TABLE DROP COLUMN is dropping a column from the trigger table and that column is getting referenced in the trigger action sql. This scenario currently in the 10.7 and 10.8 codelines get caught when we find that the column being dropped is getting used in trigger action&apos;s referenced column list and if so, then we go ahead and drop that trigger if we are doing alter table drop column cascade or we throw an error for trigger dependency if the alter table drop column restrict is being performed. But since with this patch, we do not keep the trigger action&apos;s referenced column list anymore, we can&apos;t catch the drop column&apos;s dependency in the trigger action&apos;s referenced column list. Because of this, I have to see if the trigger action column is not found, then I should throw a column not found exception. The catch of that exception will drop the trigger is we are dealing with alter table drop column cascade or it will throw a trigger dependency exception if we are dealing with alter table drop column restrict.&lt;/p&gt;

&lt;p&gt;In addition to the above 2 changes, I had to make following change in TriggerDescriptor.getActionSPS. The if condition used to be&lt;br/&gt;
		if((!actionSPS.isValid() ||&lt;br/&gt;
				 (actionSPS.getPreparedStatement() == null)) &amp;amp;&amp;amp; &lt;br/&gt;
				 isRow &amp;amp;&amp;amp; &lt;br/&gt;
				 referencedColsInTriggerAction != null) &lt;br/&gt;
But now with this patch, we don&apos;t maintain the information in list referencedColsInTriggerAction and because of that, the above if would always be false. We want to catch triggers that are using REFERENCING clause and because of this, the new if condition will look as follows&lt;br/&gt;
		if((!actionSPS.isValid() ||&lt;br/&gt;
				 (actionSPS.getPreparedStatement() == null)) &amp;amp;&amp;amp; &lt;br/&gt;
				 isRow &amp;amp;&amp;amp; (referencingOld || referencingNew))&lt;/p&gt;

&lt;p&gt;In addition to the above three changes, I have added new test to incorporate Rick&apos;s reproducible case.&lt;/p&gt;

&lt;p&gt;I have not changed the comments in the code yet because I hope to work on the fix that I proposed earlier in the jira. Once I have that fix in, I can go ahead and change the comments to match that fix.&lt;/p&gt;

&lt;p&gt;derbyall and junit suite ran fine with my changes. If no one has any comments, I can go ahead and checkin this fix Wednesday evening.&lt;/p&gt;</comment>
                            <comment id="13007358" author="mamtas" created="Wed, 16 Mar 2011 05:53:45 +0000"  >&lt;p&gt;This patch is based on 10.7 codeline.&lt;/p&gt;</comment>
                            <comment id="13007520" author="rhillegas" created="Wed, 16 Mar 2011 15:53:37 +0000"  >&lt;p&gt;Thanks for the patch, Mamta. I can verify that this patch causes the test case to succeed. I believe there is no value in testing this on the production system where the original problem surfaced. That is because that system uses a 10.7.1.0 database. Once we have a fix which works on soft-upgrade from 10.7.1.0 I will run some tests on that production system. Thanks.&lt;/p&gt;</comment>
                            <comment id="13007684" author="mikem" created="Wed, 16 Mar 2011 20:38:15 +0000"  >&lt;p&gt;I know you said you were not &quot;fixing&quot; the existing comments, but I believe the following change is worth a comment to at least associated it with this issue, and indicating this is the key place that is disabling previous work to not fetch unneeded columns:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;boolean in10_7_orHigherVersion =&lt;/li&gt;
	&lt;li&gt;checkVersion(DataDictionary.DD_VERSION_DERBY_10_7,null);&lt;br/&gt;
+		boolean in10_7_orHigherVersion = false;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13008168" author="mamtas" created="Thu, 17 Mar 2011 21:45:40 +0000"  >&lt;p&gt;I am working on backporting this simple fix to disbale the column read optimization from 10.7 to trunk but I am seeing OOM errors for a subset of org.apache.derbyTesting.functionTests.tests.memory.TriggerTests. &lt;/p&gt;

&lt;p&gt;The OOM should depend on how much heap the test gets run with. On both 10.7 and trunk(with 10.7 changes backported). I see no failures if I run the test with higher heap as shown below&lt;br/&gt;
java  -Dderby.tests.trace=true  -Xmx256M -XX:MaxPermSize=128M junit.textui.TestRunner org.apache.derbyTesting.functionTests.tests.memory.TriggerTests&lt;/p&gt;

&lt;p&gt;But if I run the test on both 10.7 and trunk(with 10.7 changes backported) with lower heap, I see OOM errors&lt;br/&gt;
java  -Dderby.tests.trace=true  -Xmx16M -Dderby.storage.pageCacheSize=100 junit.textui.TestRunner org.apache.derbyTesting.functionTests.tests.memory.TriggerTests&lt;/p&gt;

&lt;p&gt;So the behavior on the 2 codelines with restricted and generous heap is the same when the test is run directly. But when I run the junit suite as follows, I get OOM errors on trunk but not on 10.7 codeline. At this point, I am not sure why. Is there a way that we change the available heap on trunk for org.apache.derbyTesting.functionTests.tests.memory.TriggerTests when it is run through the functionTests.suites.All junit suite? That&apos;s the only reason I can think why the test would fail anywere. It appears that on 10.7, we do not change the heap for org.apache.derbyTesting.functionTests.tests.memory.TriggerTests when it is run through the functionTests.suites.All junit suite? Does anyone have any clue about this difference in behavior between 10.7 and trunk? thanks&lt;br/&gt;
java  -Dderby.tests.trace=true  -Xmx256M -XX:MaxPermSize=128M junit.textui.TestRunner org.apache.derbyTesting.functionTests.suites.All &amp;gt; runall.out 2&amp;gt;&amp;amp;1&lt;/p&gt;</comment>
                            <comment id="13008230" author="myrna" created="Thu, 17 Mar 2011 23:54:53 +0000"  >&lt;p&gt;Is it possible a test got added in trunk that sets memory settings but doesn&apos;t set them back?&lt;br/&gt;
Do you see this behavior only with suites.All, or also with memory._Suite ?&lt;br/&gt;
I sometimes use a little non-checked in TempSuite class that basically similates AllPackages (called from suites.All) &lt;br/&gt;
but leaves sections out, to find offending tests...&lt;/p&gt;</comment>
                            <comment id="13008241" author="mamtas" created="Fri, 18 Mar 2011 00:31:29 +0000"  >&lt;p&gt;Myrna, thanks for taking the time go over the OOM problem. I will try to narrow down the suites to see where things might be going wrong on trunk. &lt;/p&gt;

&lt;p&gt;BTW, running memory._Suite by itself does not run into OOM.&lt;/p&gt;</comment>
                            <comment id="13008486" author="kmarsden" created="Fri, 18 Mar 2011 16:04:51 +0000"  >&lt;p&gt;Hi Mamta, for the IBM JVM&apos;s there is a tool tool that you can use to analyze heap dumps and memory issues , the .phd file that is generated when you get an out of memory.&lt;br/&gt;
&lt;a href=&quot;http://www.alphaworks.ibm.com/tech/heapanalyzer&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.alphaworks.ibm.com/tech/heapanalyzer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You run it like java -Xmx1200m -jar ha21.jar &amp;lt;phd file&amp;gt;&lt;/p&gt;

&lt;p&gt;And in a box that comes up on the first screen it  shows the heap size. The menu options allow you to identify leak suspects and it has other features.&lt;/p&gt;

&lt;p&gt;I don&apos;t know how the heap size could be changed at runtime though. &lt;/p&gt;</comment>
                            <comment id="13008582" author="mamtas" created="Fri, 18 Mar 2011 19:08:32 +0000"  >&lt;p&gt;I am debugging the code to see what happens at the execution time of trigger firing. Rick, you mentioned TemporaryRowHolderResultSet in one of your comments. I will debug that further but do you know offhand if each trigger gets it&apos;s own copy of TemporaryRowHolderResultSet. If so, then I can probably maddle with how column mapping happens. This mapping can be different for different triggers on the same table and I didn&apos;t want to mess up TemporaryRowHolderResultSet if it is being shared by all the triggers on the table which are going to get fired. Thanks&lt;/p&gt;</comment>
                            <comment id="13008602" author="rhillegas" created="Fri, 18 Mar 2011 19:54:51 +0000"  >&lt;p&gt;Hi Mamta,&lt;/p&gt;

&lt;p&gt;It appears to me that each trigger gets its own TemporarayRowHolderResultSet. See the calls to getNewRSOnCurrentRow(). Thanks.&lt;/p&gt;</comment>
                            <comment id="13009188" author="rhillegas" created="Mon, 21 Mar 2011 15:57:17 +0000"  >&lt;p&gt;Attaching Test_5121.java. This test exhaustively walks through all subsets and permutations of columns for a trigger which inserts into a side table based on updates to a master table. The test runs cleanly with Mamta&apos;s patch applied. I think this will be a good acceptance test for the solution. Here is how you run this test:&lt;/p&gt;

&lt;p&gt;Usage:&lt;/p&gt;

&lt;p&gt;    java Test_5121 connectionURL columnCount debug&lt;/p&gt;

&lt;p&gt;    where&lt;/p&gt;

&lt;p&gt;        connectionURL is the url to the database&lt;br/&gt;
        columnCount is the number of columns in the triggering table&lt;br/&gt;
        debug indicates whether to print out extra debug information&lt;/p&gt;

&lt;p&gt;    E.g.:&lt;/p&gt;

&lt;p&gt;    java Test_5121 &quot;jdbc:derby:memory:db;create=true&quot; 3 false&lt;/p&gt;
</comment>
                            <comment id="13009345" author="mamtas" created="Mon, 21 Mar 2011 20:15:36 +0000"  >&lt;p&gt;Rick, your test will be very useful with the code changes I am making in the my codeline. When I have the patch ready I will add these tests as part of our junit test harness.&lt;/p&gt;</comment>
                            <comment id="13009350" author="mamtas" created="Mon, 21 Mar 2011 20:21:57 +0000"  >&lt;p&gt;I just wanted to summarize the problem here to make it easier to understand the issue and the solution I am working on.&lt;/p&gt;

&lt;p&gt;Some background information : With &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt;, we decided to read only the columns really needed during trigger execution. Trigger only knows about trigger columns and columns in it&apos;s trigger action used through the REFERENCING clause. And so &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; made the assumption that those will be the only columns read from the trigger table and it uses the relative column positions in that resultset to access the columns in it&apos;s trigger action when we generate the internal sql for the trigger action. The problem is that there can be cases when the SQL causing the trigger to fire needs to read more columns than just what the trigger needs. eg&lt;br/&gt;
create table t1( id int, name varchar( 50 ) );&lt;br/&gt;
create table t2&lt;br/&gt;
(&lt;br/&gt;
	name	varchar( 50 )	not null,&lt;br/&gt;
	description	int	not null,&lt;br/&gt;
	id	integer&lt;br/&gt;
);&lt;br/&gt;
insert into t2( name, description ) values ( &apos;Foo Name&apos;, 0 );&lt;/p&gt;

&lt;p&gt;create trigger t2UpdateTrigger&lt;br/&gt;
after UPDATE of name&lt;br/&gt;
on t2&lt;br/&gt;
referencing &lt;br/&gt;
new row as nr&lt;br/&gt;
for each ROW&lt;br/&gt;
insert into t1 values ( nr.id, nr.name );&lt;/p&gt;

&lt;p&gt;The trigger above only needs columns &quot;name&quot; and &quot;id&quot; from the trigger table and hence it will assume that the runtime resultset will have just those 2 columns, &quot;name&quot; as first column in the resultset and &quot;id&quot; as the 2nd column in the resultset and using that assumption, it will change trigger action sql &quot;insert into t1 values ( nr.id, nr.name )&quot; to following &quot;insert into t1 values ( CAST(org.apache.derby.iapi.db.Factory::getTriggerExecutionContext().getNewRow().getObject(2) AS INTEGER) , CAST (org.apache.derby.iapi.db.Factory::getTriggerExecutionContext().getNewRow().getObject(1) AS VARCHAR(50))  )&lt;/p&gt;

&lt;p&gt;But the following triggering sql needs more columns than just  &quot;name&quot; and &quot;id&quot;, it also needs &quot;description&quot;.(The list of columns required by triggering sql are columns used by the triggering sql and columns needed by the triggers which will get fired).&lt;br/&gt;
update t2 set name = &apos;Another name&apos; , description = 1;&lt;br/&gt;
So the runtime resulset will end up having columns &quot;name&quot;, &quot;description&quot;  and &quot;id&quot;. So the column &quot;id&quot; is the 3rd column in the resultset and not 2nd column in the resultset as expected by the trigger.&lt;/p&gt;

&lt;p&gt;The solution I am working on is to see if we can map out only the columns needed by the trigger from the actual runtime resulset created by the triggering sql. &lt;/p&gt;</comment>
                            <comment id="13009459" author="mikem" created="Mon, 21 Mar 2011 22:59:31 +0000"  >&lt;p&gt;Are you still planning on first backporting the fix made to 10.7 into the trunk line?  Have you done any more work to determine if the out of memory is this change or something in your environment?    Given the issues we have had with triggers it may make more sense to go with the safe change for 10.8 and then later after 10.8 is cut you can check in your new fix to trunk and get testing there before putting it into a released codeline.&lt;/p&gt;

&lt;p&gt;My interpretation of reviewing the change is that it should be safe and not cause unexpected out of memory.  It is basically just&lt;br/&gt;
making all code go through the existing code path that all pre 10.7 databases are already executing.&lt;/p&gt;

&lt;p&gt;If you are uncomfortable with your current testing maybe you could post the exact patch against trunk that you are trying and someone else can run tests based on it.&lt;/p&gt;</comment>
                            <comment id="13009508" author="mamtas" created="Tue, 22 Mar 2011 01:41:44 +0000"  >&lt;p&gt;I am attaching the patch for trunk which is trying to backport changes made to 10.7 to backout &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; changes. But these changes on trunk cause a subset of trigger tests to run out of memory. Maybe someone else can try running junit suite if they have the cycle to see if they see the problem too.&lt;/p&gt;</comment>
                            <comment id="13009701" author="rhillegas" created="Tue, 22 Mar 2011 16:28:45 +0000"  >&lt;p&gt;Attaching derby-5121-01-aa-runTimeRemapping.diff. This patch remaps columns at run time in order to fix the bug. I think this at least demonstrates the feasibility of column remapping. An improvement on this patch would be to calculate the remapping at compile time rather than run time.&lt;/p&gt;

&lt;p&gt;Some trickiness is involved because some of the compiled column maps are 0-based and others are 1-based. I have run Test_5121 on this patch and it passes cleanly for 1, 2, 3, and 4 column tables. I stopped running experiments then because the 4 column table gave rise to 61440 test cases.&lt;/p&gt;

&lt;p&gt;I will run the full regression suite to see if that shows any problems.&lt;/p&gt;

&lt;p&gt;Touches the following files:&lt;/p&gt;

&lt;p&gt;M      java/engine/org/apache/derby/impl/sql/execute/TemporaryRowHolderResultSet.java&lt;br/&gt;
M      java/engine/org/apache/derby/impl/sql/execute/InsertResultSet.java&lt;br/&gt;
M      java/engine/org/apache/derby/impl/sql/execute/GenericTriggerExecutor.java&lt;br/&gt;
M      java/engine/org/apache/derby/impl/sql/execute/TriggerEventActivator.java&lt;br/&gt;
M      java/engine/org/apache/derby/impl/sql/execute/StatementTriggerExecutor.java&lt;br/&gt;
M      java/engine/org/apache/derby/impl/sql/execute/DeleteResultSet.java&lt;br/&gt;
M      java/engine/org/apache/derby/impl/sql/execute/RowTriggerExecutor.java&lt;br/&gt;
M      java/engine/org/apache/derby/impl/sql/execute/UpdateResultSet.java&lt;/p&gt;</comment>
                            <comment id="13009736" author="mikem" created="Tue, 22 Mar 2011 17:40:19 +0000"  >&lt;p&gt;I believe the tests that you see failing in your run were written specifically to test 	&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt;.  In order to test that blobs are not being read into memory the tests specifically are coded&lt;br/&gt;
to read blobs into memory in the cases that &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; fixes.  It is ASSUMED that in the normal suite run&lt;br/&gt;
that there will be enough memory for the tests to pass, and that when the same tests are run as part of the&lt;br/&gt;
&quot;small memory&quot; test suite that the bugs will be caught.  But maybe due to timing, machine resources, or&lt;br/&gt;
previous tests run these tests no longer successfully run guaranteed in default suite run on trunk.  It would&lt;br/&gt;
seem like disabling &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; should also disable the memory specific tests if we think those tests are&lt;br/&gt;
not valid once the feature is disabled.&lt;/p&gt;</comment>
                            <comment id="13009760" author="mamtas" created="Tue, 22 Mar 2011 18:27:41 +0000"  >&lt;p&gt;I am attaching a new patch (DERBY_5121_backoutDerby1492_changes_patch3_trunk_diff.txt)  for trunk which will backport &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; changes from trunk, same as 10.7 and will do some additional work(this patch has additional changes than DERBY_5121_patch2_trunk_diff.txt). &lt;/p&gt;

&lt;p&gt;The patch will also disable the tests that were added for &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;With &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt;, these tests would not read in large object columns into memory because the triggers didn&apos;t need them. But now that &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; changes are being backed out, the large object columns will be read in which can cause the test to run out of memory depending on how much heap is available to it. &lt;/p&gt;

&lt;p&gt;I am running the junit suite just one more time to make sure that I don&apos;t run into any OOMs. Once the junit tests run fine, I will go ahead and commit this patch to trunk, thus backing out &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; changes. &lt;/p&gt;

&lt;p&gt;The patch also has a comment in DataDictionaryImpl:getTriggerActionString explaining the code changes for backout. I will add that comment in 10.7 too.&lt;/p&gt;

&lt;p&gt;Once the tests run fine on trunk, I will disable &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; tests on 10.7 too.&lt;/p&gt;

&lt;p&gt;If any comments, please feel free to post them.&lt;/p&gt;</comment>
                            <comment id="13009763" author="mamtas" created="Tue, 22 Mar 2011 18:32:16 +0000"  >&lt;p&gt;Hi Rick, thanks for the patch. BTW, I have a patch too to do the remapping of the columns. It is lacking comments at this point. I will work on adding comments so it is easier to understand. I ran your extensive tests with my changes and the tests worked fine. I haven&apos;t finished running the junit and derbyall suite with it yet, junit suite is running right now. I hope to put a patch with comments sometime soon today.&lt;/p&gt;</comment>
                            <comment id="13009769" author="rhillegas" created="Tue, 22 Mar 2011 18:36:10 +0000"  >&lt;p&gt;The derby-5121-01-aa-runTimeRemapping.diff patch creates a shower of problems in the regression tests.&lt;/p&gt;</comment>
                            <comment id="13009771" author="rhillegas" created="Tue, 22 Mar 2011 18:39:19 +0000"  >&lt;p&gt;Thanks, Mamta. Just want to clarify: After you check in your disabling fix, additional work will still be needed to throw away the trigger actions which have been compiled in 10.7 databases? Thanks.&lt;/p&gt;</comment>
                            <comment id="13009830" author="mamtas" created="Tue, 22 Mar 2011 20:43:38 +0000"  >&lt;p&gt;Hi Rick.&lt;/p&gt;

&lt;p&gt;The backout of &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; changes will only take care of of new triggers. &lt;/p&gt;

&lt;p&gt;Unfortunately, the old triggers(created in 10.7) will still have problems and will have to be manually dropped and recreated. The triggers impacted are the row level triggers with REFERENCING clause. Thanks&lt;/p&gt;</comment>
                            <comment id="13009832" author="mamtas" created="Tue, 22 Mar 2011 20:47:42 +0000"  >&lt;p&gt;As a bigger solution to having to ask the users to drop and recreate the triggers during upgrade, it will be ideal if we could internally do this ourselves. I think there are 2 possibilites&lt;br/&gt;
1)mark the SPS associated with trigger actions as invalid at the time of upgrade. This way, when they get used next time, we will recreate the correction trigger action sql&lt;br/&gt;
2)drop and recreate the trigger action SPSs at the time of upgrade. I am not sure though if this will run into privileges/roles issues since the user doing the upgrade may not have permissions to touch the system tables.&lt;/p&gt;

&lt;p&gt;I would like to investigate option 1) and see if it is doable. I will hold on to posting my patch of remapping and will concentrate on option 1) because if the option 1) works than we can avoid having to ask the users to drop and recreate the triggers. Thanks&lt;/p&gt;</comment>
                            <comment id="13011512" author="mamtas" created="Sat, 26 Mar 2011 00:09:21 +0000"  >&lt;p&gt;I looked through the upgrade code and saw that we already mark all the SPS invalid during soft and hard upgrade. This is great because at the time of trigger execution, we check if the trigger is invalid, it is row level and it has REFERENCING clause then we should regenerate the trigger action sql. So, when a user with 10.7.1.1(the version where the triggers can cause data corruption) upgrades to a release which has &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; changes backed out (at this moment, that would be 10.8 and next release of 10.7. I will work on bumping the release number of 10,7), the buggy triggers will get fixed and will not cause any data corruption.&lt;/p&gt;

&lt;p&gt;Additionally, once we have the right fix for &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; so that the resultset received by the trigger during execution matches trigger&apos;s expectation of column numbering, we can introduce column reading from trigger table to only the columns that are really necessary rather than reading all the columns (which is what we do right now after backing out &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; changes).&lt;/p&gt;

&lt;p&gt;I have created upgrade test for 10.8 which will test the behavior explained above.&lt;/p&gt;

&lt;p&gt;In other words, the users do not have to drop and recreate their triggers anymore after upgrading to a release which has &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; changes backed out.&lt;/p&gt;

&lt;p&gt;If there are any questions, please let me know.&lt;/p&gt;</comment>
                            <comment id="13012555" author="mamtas" created="Tue, 29 Mar 2011 17:54:26 +0100"  >&lt;p&gt;Attaching the release note for this issue. I will go ahead and close this issue. The work to do selective column reading during trigger execution and providing the correct resultset to trigger at execution time can go as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt;. &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; is the original issue to provide this functionality.&lt;/p&gt;</comment>
                            <comment id="13012605" author="rhillegas" created="Tue, 29 Mar 2011 19:37:17 +0100"  >&lt;p&gt;Thanks, Mamta. I&apos;m afraid I can&apos;t close this issue yet. I built a quick 10.8.1.0 distribution and ran the production application with it. The good news is that the original error went away. Unfortunately, now I&apos;m getting a new error when the update trigger fires. I will put some effort into scripting the problem. Thanks.&lt;/p&gt;</comment>
                            <comment id="13012618" author="mamtas" created="Tue, 29 Mar 2011 19:53:26 +0100"  >&lt;p&gt;Rick, I was hoping that this would fix all the problems since we took out &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; changes but looks like not. Can you please post what error you are seeing and I will start poking in the code to see if I can find a reason before you have a repro case? Thanks&lt;/p&gt;</comment>
                            <comment id="13012651" author="rhillegas" created="Tue, 29 Mar 2011 20:54:24 +0100"  >&lt;p&gt;Attaching a repro for the new problem I am seeing. I haven&apos;t had time to trim this down to a smaller case, but I wanted to get this posted quickly Before running this repro, first compile Proc_5121.java. Then do the following:&lt;/p&gt;

&lt;p&gt;1) Using 10.7.1.1, run 5121_create.sql through ij. This will create a 10.7 database with a table which has a bad update trigger. The last statement in the script fails--it is the original statement which disclosed the original problem.&lt;/p&gt;

&lt;p&gt;2) Using the trunk, run 5121_upgrade.sql through ij. You will have to set -Dderby.database.allowPreReleaseUpgrade=true in order to get the soft upgrade to run. The script contains one command, namely, the statement which disclosed the original problem. Now this statement fails with the following error:&lt;/p&gt;

&lt;p&gt;ERROR 38000: The exception &apos;java.sql.SQLException: Column &apos;6&apos; not found.&apos; was thrown while evaluating an expression.&lt;br/&gt;
ERROR S0022: Column &apos;6&apos; not found.&lt;/p&gt;</comment>
                            <comment id="13012672" author="mikem" created="Tue, 29 Mar 2011 21:31:02 +0100"  >&lt;p&gt;it might be useful to run this test case where step 2 is executed against  main version without the changes submitted for &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-5121&quot; title=&quot;Data corruption when executing an UPDATE trigger&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-5121&quot;&gt;&lt;del&gt;DERBY-5121&lt;/del&gt;&lt;/a&gt; .  I am wondering if this is a different bug associated with automatic recompile of triggers where the trigger is a procedure call?&lt;/p&gt;</comment>
                            <comment id="13012776" author="mamtas" created="Wed, 30 Mar 2011 00:38:45 +0100"  >&lt;p&gt;Hi Rick, I found the problem behind the failure. This happened because &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; wasn&apos;t completely backed out. We have backed out the code for the triggers so that now that look for the columns in their actual column positions at execution time. But &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; also made changes to UPDATE code to read only the colunms needed by it and the triggers that it is going to fire. We need to backout the changes to UPDATE code to make sure that it reads all the columns from the trigger table and not do selective column reading.&lt;/p&gt;

&lt;p&gt;In the attached patch(based on trunk), I have made that change and run the test you provided and it now runs with no exception. I haven&apos;t done any other testing on it. Please feel free to use this patch for testing with the problem 10.7.1.1 database that you are working with.&lt;/p&gt;

&lt;p&gt;I would like to work on following&lt;br/&gt;
1)spend little more time on the &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; changes to make sure that I am backing out everything relevant. &lt;br/&gt;
2)run existing junit and derbyall tests once I have accomplished 1)&lt;br/&gt;
3)Add an upgrade test case for the latest example you provided.&lt;/p&gt;

&lt;p&gt;The reason we didn&apos;t see this failure with your last test case was that UPDATE sql was coincidentally reading all the columns upto the highest column position required by the trigger and hence all the columns were available in their right positions even though not all the columns may have been read from the trigger table.&lt;/p&gt;

&lt;p&gt;Please let me know if you have any questions. I would also appreciate if you would post on the list how your testing goes with my patch if you find time to do any testing.&lt;/p&gt;</comment>
                            <comment id="13012901" author="mamtas" created="Wed, 30 Mar 2011 10:55:35 +0100"  >&lt;p&gt;I have spent some time analyzing the changes that went into UpdateNode as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; and I believe that the attached patch, DERBY_5121_NotReadForCommit_patch4_trunk_diff.txt, does the correct job of undoing those changes from UpdateNode. The patch I attached on March 29th(DERBY_5121_NotReadForCommit_patche_trunk_diff.txt) did not remove those changes properly.&lt;/p&gt;

&lt;p&gt;I have also written an upgrade case testing the behavior of UPDATE reading correct columns from the trigger table so that trigger finds the columns it needs.&lt;/p&gt;

&lt;p&gt;I am running junit suite right now to make sure nothing breaks with the attached patch. will also run derbyall suite once junit is finished successfully.&lt;/p&gt;</comment>
                            <comment id="13012952" author="rhillegas" created="Wed, 30 Mar 2011 14:32:49 +0100"  >&lt;p&gt;Thanks, Mamta. I have verified that the production problem goes away if I apply DERBY_5121_NotReadForCommit_patch4_trunk_diff.txt. Thanks.&lt;/p&gt;</comment>
                            <comment id="13013615" author="rhillegas" created="Wed, 30 Mar 2011 20:47:45 +0100"  >&lt;p&gt;Attaching Test_5121_Upgrade.java. This is a modification of the previous test of column subsets and permutations. This splits the schema creation apart from the DML so that the schema can be created under 10.7 and the UPDATE statements and trigger-firings can be tested under 10.8.&lt;/p&gt;

&lt;p&gt;To run this test, do the following:&lt;/p&gt;

&lt;p&gt;1) Create the schema by setting your classpath to include the 10.7 jars. Delete the db database. Then do the following to create the schema for 3 column tables:&lt;/p&gt;

&lt;p&gt;java Test_5121_Upgrade &quot;jdbc:derby:db;create=true&quot; 3 false&lt;/p&gt;

&lt;p&gt;2) Now set your classpath to include the 10.8 jars. Test trigger-firing after soft-upgrade by doing the following:&lt;/p&gt;

&lt;p&gt;java -Dderby.database.allowPreReleaseUpgrade=true Test_5121_Upgrade &quot;jdbc:derby:db&quot; 3 false&lt;/p&gt;

&lt;p&gt;I have verified that Mamta&apos;s latest patch fixes the soft-upgrade problem for 1, 2, 3, and 4 column tables.&lt;/p&gt;</comment>
                            <comment id="13013619" author="mamtas" created="Wed, 30 Mar 2011 21:07:21 +0100"  >&lt;p&gt;Thanks Rick, I really appreciate all the testing you have done with my changes.&lt;/p&gt;

&lt;p&gt;The DERBY_5121_NotReadForCommit_patch4_trunk_diff.txt has been committed to trunk. I am now working on making the same engine changes to 10.7 codeline. The upgrade test can&apos;t be copied from trunk to 10,7 because at this point, there is no way to test upgrades between point releases. It will be good to have the framework in place. I will create a jira for that.&lt;/p&gt;

&lt;p&gt;Once the derbyall and junit run fine on 10.7, I will commit the changes on that codeline too.&lt;/p&gt;</comment>
                            <comment id="13013622" author="rhillegas" created="Wed, 30 Mar 2011 21:15:12 +0100"  >&lt;p&gt;Attaching a second version of the detailed release note. This version gives users more information about what kinds of triggers are vulnerable to this corruption. I hope that I have described the situation accurately.&lt;/p&gt;</comment>
                            <comment id="13013848" author="mamtas" created="Thu, 31 Mar 2011 07:19:46 +0100"  >&lt;p&gt;Hi Rick, I looked at the release note and it looks good to me.&lt;/p&gt;

&lt;p&gt;Also, I have backported engine related changes from trunk(revision 1087049) to 10,7 codeline&lt;/p&gt;</comment>
                            <comment id="13013858" author="mamtas" created="Thu, 31 Mar 2011 07:35:09 +0100"  >&lt;p&gt;I do not forsee any further code changes related to backing out &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; changes so I think it should be safe to resolve this issue so we don&apos;t have any blockers for 10.8 release.&lt;/p&gt;

&lt;p&gt;The right fix for &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; can go in as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; even after 10.8 release is out. Those changes can then be made available as next point release of 10.8 and since at the time of upgrade, the trigger SPSes get marked invalid, any changes made for &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt; will get automatically picked up. &lt;/p&gt;</comment>
                            <comment id="13036919" author="mamtas" created="Fri, 20 May 2011 17:40:54 +0100"  >&lt;p&gt;I have converted Rick&apos;s test into junit test with revision 1125453. Rick. please feel free to add comments to the junit test if you think it needs any.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                                                <inwardlinks description="is broken by">
                                        <issuelink>
            <issuekey id="12345511">DERBY-1482</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12474918" name="5121_create.sql" size="1501" author="rhillegas" created="Tue, 29 Mar 2011 20:54:24 +0100"/>
                            <attachment id="12474919" name="5121_upgrade.sql" size="123" author="rhillegas" created="Tue, 29 Mar 2011 20:54:24 +0100"/>
                            <attachment id="12474941" name="DERBY_5121_NotReadForCommit_patch3_trunk_diff.txt" size="1288" author="mamtas" created="Wed, 30 Mar 2011 00:38:45 +0100"/>
                            <attachment id="12474957" name="DERBY_5121_NotReadForCommit_patch4_trunk_diff.txt" size="6133" author="mamtas" created="Wed, 30 Mar 2011 10:55:35 +0100"/>
                            <attachment id="12474318" name="DERBY_5121_backoutDerby1492_changes_patch3_trunk_diff.txt" size="12585" author="mamtas" created="Tue, 22 Mar 2011 18:27:41 +0000"/>
                            <attachment id="12474258" name="DERBY_5121_patch2_trunk_diff.txt" size="4479" author="mamtas" created="Tue, 22 Mar 2011 01:41:43 +0000"/>
                            <attachment id="12473234" name="DummyProc.java" size="209" author="rhillegas" created="Thu, 10 Mar 2011 02:42:13 +0000"/>
                            <attachment id="12474917" name="Proc_5121.java" size="237" author="rhillegas" created="Tue, 29 Mar 2011 20:54:24 +0100"/>
                            <attachment id="12474185" name="Test_5121.java" size="17114" author="rhillegas" created="Mon, 21 Mar 2011 15:57:17 +0000"/>
                            <attachment id="12475006" name="Test_5121_Upgrade.java" size="20291" author="rhillegas" created="Wed, 30 Mar 2011 20:47:45 +0100"/>
                            <attachment id="12474307" name="derby-5121-01-aa-runTimeRemapping.diff" size="13139" author="rhillegas" created="Tue, 22 Mar 2011 16:28:45 +0000"/>
                            <attachment id="12473762" name="derby5121_patch1_diff.txt" size="3940" author="mamtas" created="Wed, 16 Mar 2011 05:53:45 +0000"/>
                            <attachment id="12475008" name="releaseNote.html" size="3912" author="rhillegas" created="Wed, 30 Mar 2011 21:15:12 +0100"/>
                            <attachment id="12474901" name="releaseNote.html" size="4051" author="mamtas" created="Tue, 29 Mar 2011 17:54:26 +0100"/>
                            <attachment id="12473431" name="triggerBug.sql" size="743" author="rhillegas" created="Fri, 11 Mar 2011 20:47:36 +0000"/>
                            <attachment id="12473235" name="triggerBug.sql" size="770" author="rhillegas" created="Thu, 10 Mar 2011 02:42:13 +0000"/>
                            <attachment id="12473691" name="triggeredBug2.sql" size="866" author="rhillegas" created="Tue, 15 Mar 2011 15:09:33 +0000"/>
                            <attachment id="12473570" name="triggeredCorruption.sql" size="672" author="rhillegas" created="Mon, 14 Mar 2011 14:53:52 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>18.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310200" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Bug behavior facts</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10364"><![CDATA[Data corruption]]></customfieldvalue>
    <customfieldvalue key="10420"><![CDATA[Regression]]></customfieldvalue>
    <customfieldvalue key="10421"><![CDATA[Seen in production]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 14 Mar 2011 21:41:40 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>24666</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310090" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Issue &amp; fix info</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10101"><![CDATA[Release Note Needed]]></customfieldvalue>
    <customfieldvalue key="10424"><![CDATA[Repro attached]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy0a47:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>35457</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310050" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Urgency</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10050"><![CDATA[Blocker]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>