<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:29:00 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-606/DERBY-606.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-606] SYSCS_UTIL.SYSCS_INPLACE_COMPRESS_TABLE fails on (very) large tables</title>
                <link>https://issues.apache.org/jira/browse/DERBY-606</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;SYSCS_UTIL.SYSCS_INPLACE_COMPRESS_TABLE fails with one of the following error messages when applied to a very large table (&amp;gt;2GB):&lt;/p&gt;

&lt;p&gt;Log operation null encounters error writing itself out to the log stream, this could be caused by an errant log operation or internal log buffer full due to excessively large log operation. SQLSTATE: XJ001: Java exception: &apos;: java.io.IOException&apos;.&lt;/p&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;p&gt;The exception &apos;java.lang.ArrayIndexOutOfBoundsException&apos; was thrown while evaluating an expression. SQLSTATE: XJ001: Java exception: &apos;: java.lang.ArrayIndexOutOfBoundsException&apos;.&lt;/p&gt;

&lt;p&gt;In either case, no entry is written to the console log or to derby.log.&lt;/p&gt;</description>
                <environment>Java 1.5.0_04 on Windows Server 2003 Web Edition</environment>
        <key id="12317695">DERBY-606</key>
            <summary>SYSCS_UTIL.SYSCS_INPLACE_COMPRESS_TABLE fails on (very) large tables</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mayureshnirhali">Mayuresh Nirhali</assignee>
                                    <reporter username="jeff@redcondor.com">Jeffrey Aguilera</reporter>
                        <labels>
                    </labels>
                <created>Fri, 7 Oct 2005 09:08:17 +0100</created>
                <updated>Thu, 24 Jan 2008 13:09:59 +0000</updated>
                            <resolved>Thu, 4 Jan 2007 12:36:35 +0000</resolved>
                                    <version>10.1.1.0</version>
                                    <fixVersion>10.3.1.4</fixVersion>
                                    <component>Store</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12431025" author="skambha" created="Mon, 28 Aug 2006 18:52:19 +0100"  >&lt;p&gt;I can reproduce this failure in one of my  test scenarios on a very large table:&lt;br/&gt;
ij&amp;gt; call syscs_util.syscs_inplace_compress_table(&apos;APP&apos;,&apos;STOCK&apos;,1,1,1);&lt;br/&gt;
ERROR XSLB1: Log operation null encounters error writing itself out to the log stream, this could be caused by an errant log operation or internal log buffer full due to excessively large log operation.&lt;br/&gt;
ERROR XJ001: Java exception: &apos;: java.io.IOException&apos;.&lt;/p&gt;

&lt;p&gt;stock has 60million rows. &lt;/p&gt;

&lt;p&gt;schema for stock table.&lt;br/&gt;
ij&amp;gt; create table stock (&lt;br/&gt;
        s_i_id          int NOT NULL,&lt;br/&gt;
        s_w_id          smallint NOT NULL,&lt;br/&gt;
        s_quantity      int NOT NULL,&lt;br/&gt;
        s_dist_01       char(24) NOT NULL,&lt;br/&gt;
        s_dist_02       char(24) NOT NULL,&lt;br/&gt;
        s_dist_03       char(24) NOT NULL,&lt;br/&gt;
        s_dist_04       char(24) NOT NULL,&lt;br/&gt;
        s_dist_05       char(24) NOT NULL,&lt;br/&gt;
        s_dist_06       char(24) NOT NULL,&lt;br/&gt;
        s_dist_07       char(24) NOT NULL,&lt;br/&gt;
        s_dist_08       char(24) NOT NULL,&lt;br/&gt;
        s_dist_09       char(24) NOT NULL,&lt;br/&gt;
        s_dist_10       char(24) NOT NULL,&lt;/p&gt;

&lt;p&gt;        s_ytd           decimal(8) NOT NULL,&lt;br/&gt;
        s_order_cnt     int NOT NULL,&lt;br/&gt;
        s_remote_cnt    int NOT NULL,&lt;br/&gt;
        s_data          varchar(50) NOT NULL&lt;br/&gt;
);&lt;/p&gt;

&lt;p&gt;There is no error messages in derby.log.  I&apos;ll try to rerun the test and run with ij.execptionTrace=true to get the entire trace. &lt;/p&gt;</comment>
                            <comment id="12431280" author="skambha" created="Tue, 29 Aug 2006 17:01:45 +0100"  >&lt;p&gt;Here is the stacktrace:&lt;br/&gt;
ij version 10.2&lt;br/&gt;
ij&amp;gt; connect &apos;jdbc:derby:dbtpcc&apos;;&lt;br/&gt;
ij&amp;gt; call syscs_util.syscs_inplace_compress_table(&apos;APP&apos;,&apos;STOCK&apos;,1,1,1);&lt;br/&gt;
ERROR XSLB1: Log operation null encounters error writing itself out to the log stream, this could be caused by an errant log operation or internal log buffer full due to excessively large log operation.&lt;br/&gt;
ERROR XSLB1: Log operation null encounters error writing itself out to the log stream, this could be caused by an errant log operation or internal log buffer full due to excessively large log operation.&lt;br/&gt;
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.log.FileLogger.logAndDo(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.xact.Xact.logAndDo(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.LoggableAllocActions.actionCompressSpaceOperation(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.AllocExtent.compress(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.AllocPage.compress(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.FileContainer.compressContainer(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.BaseContainer.compressContainer(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.BaseContainerHandle.compressContainer(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.heap.Heap.compressConglomerate(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.RAMTransaction.compressConglomerate(Unknown Source)&lt;br/&gt;
	at org.apache.derby.iapi.db.OnlineCompress.truncateEnd(Unknown Source)&lt;br/&gt;
	at org.apache.derby.iapi.db.OnlineCompress.compressTable(Unknown Source)&lt;br/&gt;
	at org.apache.derby.catalog.SystemProcedures.SYSCS_INPLACE_COMPRESS_TABLE(Unknown Source)&lt;br/&gt;
	at org.apache.derby.exe.ac601a400fx010dx55efx588dx0000001d75e80.g0(Unknown Source)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:85)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:58)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:60)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:391)&lt;br/&gt;
	at org.apache.derby.impl.services.reflect.ReflectMethod.invoke(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.CallStatementResultSet.open(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.ij.executeImmediate(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.utilMain.doCatch(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.utilMain.runScriptGuts(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.utilMain.go(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.Main.go(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.Main.mainCore(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.Main14.main(Unknown Source)&lt;br/&gt;
	at org.apache.derby.tools.ij.main(Unknown Source)&lt;br/&gt;
ERROR XJ001: Java exception: &apos;: java.io.IOException&apos;.&lt;br/&gt;
java.io.IOException&lt;br/&gt;
	at org.apache.derby.iapi.services.io.CompressedNumber.writeInt(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.CompressSpacePageOperation.writeExternal(Unknown Source)&lt;br/&gt;
	at org.apache.derby.iapi.services.io.FormatIdOutputStream.writeObject(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.log.LogRecord.writeExternal(Unknown Source)&lt;br/&gt;
	at org.apache.derby.iapi.services.io.FormatIdOutputStream.writeObject(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.log.FileLogger.logAndDo(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.xact.Xact.logAndDo(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.LoggableAllocActions.actionCompressSpaceOperation(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.AllocExtent.compress(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.AllocPage.compress(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.FileContainer.compressContainer(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.BaseContainer.compressContainer(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.BaseContainerHandle.compressContainer(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.heap.Heap.compressConglomerate(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.RAMTransaction.compressConglomerate(Unknown Source)&lt;br/&gt;
	at org.apache.derby.iapi.db.OnlineCompress.truncateEnd(Unknown Source)&lt;br/&gt;
	at org.apache.derby.iapi.db.OnlineCompress.compressTable(Unknown Source)&lt;br/&gt;
	at org.apache.derby.catalog.SystemProcedures.SYSCS_INPLACE_COMPRESS_TABLE(Unknown Source)&lt;br/&gt;
	at org.apache.derby.exe.ac601a400fx010dx55efx588dx0000001d75e80.g0(Unknown Source)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:85)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:58)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:60)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:391)&lt;br/&gt;
	at org.apache.derby.impl.services.reflect.ReflectMethod.invoke(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.CallStatementResultSet.open(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.ij.executeImmediate(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.utilMain.doCatch(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.utilMain.runScriptGuts(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.utilMain.go(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.Main.go(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.Main.mainCore(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.Main14.main(Unknown Source)&lt;br/&gt;
	at org.apache.derby.tools.ij.main(Unknown Source)&lt;br/&gt;
ij&amp;gt; exit;&lt;/p&gt;</comment>
                            <comment id="12440827" author="mayureshnirhali" created="Mon, 9 Oct 2006 09:34:40 +0100"  >&lt;p&gt;I was able to reproduce this error.&lt;br/&gt;
I am working with 30 million rows of schema mentioned in the previous comments. Total size of the DB is about 12 GB.&lt;/p&gt;

&lt;p&gt;I am also able to reproduce this issue by just setting the truncate bit (&apos;APP&apos;, &apos;TEST&apos;, 0, 0, 1). here, I am not sure if this has any dependency on the previous runs of Defragment operation, as I am working with the same DB setup. But, just setting the truncate bit is convinient and faster to debug the scenario.&lt;/p&gt;

&lt;p&gt;On further investigation, It was found that while Allocated Extent associated with last allocated page is being compressed, All the pages are found to be free, thus new_highest_page is set to &apos;-1&apos;. Now, when the CompressSpaceOperation is being logged CompressedNumber.writeInt method is called with value -1. This method is written to throw exception if the value is less than Zero, hence the IOException occurs.&lt;/p&gt;

&lt;p&gt;In my opinion, Having a scenario with new_highest_page set to -1 is valid and in such a case there should not be any issue logging such operation. But, I am no expert in the Store module and would like to  know If this assumption is wrong or if I am missing something. If I am on the right track then the fix would be to update CompressedNumber.writeInt method to handle *valid negative values.&lt;/p&gt;</comment>
                            <comment id="12448803" author="mayureshnirhali" created="Fri, 10 Nov 2006 17:10:49 +0000"  >&lt;p&gt;Attaching a repro for this issue.&lt;/p&gt;

&lt;p&gt;The idea for reproduction is to create a table with large number of records and delete most of them so that atleast the last AllocExtent  is empty and then attempt to do a inplace_compress. This demonstrates the scenario of compressing AllocExtent with new_highest_page = -1.&lt;/p&gt;

&lt;p&gt;I would like to add this testcase to the existing suite. Any thoughts on which suite would be the most appropriate for such case and if there is any existing test which I can extend to include this case instead ??&lt;/p&gt;</comment>
                            <comment id="12448813" author="mikem" created="Fri, 10 Nov 2006 18:08:57 +0000"  >&lt;p&gt;Do you know how you are going to fix this issue, definitely consider upgrade implications of any change made.&lt;/p&gt;

&lt;p&gt;I think any change to allow CompressedNumber to write a negative number is likely not going to be backward&lt;br/&gt;
compatible - now maybe that does not matter as any attempt to write a negative number with it, is already a bug.&lt;br/&gt;
The bit patterns for the compressed number representation are pretty carefully chosen assuming non-negative&lt;br/&gt;
numbers.  This code is used extensively in every row/column on disk in the database, so requiring a hard &lt;br/&gt;
upgrade of the format is a large issue.&lt;/p&gt;

&lt;p&gt;a few easier paths:&lt;br/&gt;
1) rewrite the log format for the record to not compress the numbers.  The space doesn&apos;t really matter as it doesn&apos;t happen very much.  As this would be a new log format it should be handled under hard upgrade.  The bug would&lt;br/&gt;
not be fixed under soft upgrade.  Probably should throw an error earlier if you see a negative number under&lt;br/&gt;
soft upgrade.  If we could set back time on the db this would seem the natural fix.  Or maybe if you are soft &lt;br/&gt;
upgrade you change the -1 to be the last page in the conglomerate, which would mean in this special case&lt;br/&gt;
the code would think there was a free page when we know there aren&apos;t any, but this is only a hint anyway.  &lt;br/&gt;
If you go this route look at the upgrade tests and add a case for both soft and hard upgrade in 10.3.&lt;/p&gt;

&lt;p&gt;2) change the conglomerate code to not generate negative numbers, maybe use something like maxint or maxlong.  This will of course require looking at all the code that currently checks for -1.  &lt;/p&gt;</comment>
                            <comment id="12449683" author="mayureshnirhali" created="Tue, 14 Nov 2006 15:19:27 +0000"  >&lt;p&gt;Thanks mike for looking into this and also for the valuable suggestions. They were really helpful to put me in the right direction while I am working on this fix. and sorry, I could not write sooner.&lt;/p&gt;

&lt;p&gt;I realized that changing CompressedNumber to write negative values will not be appropriate, after looking at the bit patterns. That is for 2 reasons. 1, Need for hard upgrade and 2, the only possible negative value written by CompressedNumber is newHighestPage. So, It is not worth the effort of making it write negative&lt;br/&gt;
values.&lt;/p&gt;

&lt;p&gt;Since this is a special case which is true only for CompressSpaceOperation, I was wondering if this can be handled by write/readExternal methods of CompressSpaceOperation itself. When log record is written for this case, a positive value is passed to the log and when it is read back, it is identified to be the correct value. Choosing this positive value would be very critical, I was thinking of Integer.MAX_VALUE. Please let me know if there are any sideaffects of this approach.&lt;br/&gt;
This can be considered for handling the soft upgrade mode case as well.&lt;/p&gt;

&lt;p&gt;I am also looking into your suggestions. Is it accepted to change the Log format of record only for one particular operation by not compressing the numbers or did you mean to not compress the numbers for all the operations ??&lt;/p&gt;

&lt;p&gt;I can extend the upgradetests based on the approach we agree upon. although, I havent had a chance to look at those tests yet.&lt;br/&gt;
I would appreciate any more comments on this. Thanks.&lt;/p&gt;</comment>
                            <comment id="12449751" author="mikem" created="Tue, 14 Nov 2006 19:45:20 +0000"  >&lt;p&gt;o my suggestion was to only change what this log record wrote, not all log records that used compressed number.  If you are going to change the format of what is written, then it seems simpler to just write the number uncompressed than to add an extra decoding.&lt;br/&gt;
Note &quot;change&quot; the format is not really allowed.  What you need to do is support the old log record&lt;br/&gt;
and add a new log record which has the changed format.  For soft upgrade you need to always read/write&lt;br/&gt;
the old log record.  For hard upgrade you need to write new format and be able to read both old and new log&lt;br/&gt;
record, once you have hard upgraded you don&apos;t have to worry about older versions of the software encountering&lt;br/&gt;
this unknown new log record.&lt;br/&gt;
o note if you choose a fix which in any way alters what is written, I think you basically have to add a new log record&lt;br/&gt;
in case of hard upgrade (and bug will continue to exist in soft upgrade).  &lt;br/&gt;
You can save copying code by having the new log record extend the existing one and just update the &lt;br/&gt;
getTypeFormatId(), readExternal(), writeExternal() routines.  This way soft upgrade can still read/write the old&lt;br/&gt;
record.  Need some code to write the new vs. the old one in case of hard upgrade.  &lt;br/&gt;
o if you decide you want to look at runtime fix vs. log record fix let me know and maybe I can give some pointers.&lt;/p&gt;</comment>
                            <comment id="12449853" author="tsuresh" created="Tue, 14 Nov 2006 23:01:41 +0000"  >&lt;p&gt;Can this problem be soved by writing a different log records for this special case ?   If the rest of system is working fine with the current assumption that negative numbers are not be written to the log. &lt;/p&gt;


&lt;p&gt;-suresh&lt;/p&gt;





</comment>
                            <comment id="12450071" author="mayureshnirhali" created="Wed, 15 Nov 2006 15:39:41 +0000"  >&lt;p&gt;Thanks Mike and Suresh.&lt;/p&gt;

&lt;p&gt;Yes. It makes sense to only change the log record format for this special case.&lt;/p&gt;

&lt;p&gt;Looking at possible runtime fix, I feel, this approach would create some Major-Minor version checks in write/readExternal methods which would not be ideal. Approach of Extending the class would make the changes much simpler.&lt;/p&gt;

&lt;p&gt;So, currently this is what I have in mind. CompressSpacePageOperation will be extended to form a new class CompressSpacePageOperation10_3. This class over override readExternal, writeExternal and getTypeFormatId methods. read/writeExternal methods would write the new_highest_page field without compression and the other fields are compressed and written to the Log. A new ID StoreFormatIds.LOGOP_COMPRESS10_3_SPACE is created.&lt;/p&gt;

&lt;p&gt;Now, when LOggableAllocActions creates CompressSpacePageOperation, a new check will be added to identify whether this is a soft or hard upgrade. The only way to do this is by calling LogToFile.checkVersion(Major, Minor). Based on the flag returned either the old CompressSpacePageOperation or the new one will be called. LogFactory is not accessible at this level in the code and hence calling checkVersion is not possible. Xact has no interface to get XContext so there isnt any way to reach LogFactory. I need some inputs here.&lt;br/&gt;
------&lt;br/&gt;
While investigating, I also realized that even if you write the record with newHighestPage set to -1, the log is written successfully but the transaction does not commit because AllocPage.compressSpace has an assertion (only in DEBUG mode btw) which checks if the newHighestPage is not positive. Thus an Exception is thrown. I think this assertion check is invalid. Also it causes inconsistency in the behavior between sane-insane builds as it only happens when SanityManager.DEBUG is true. Will it be okay to remove this assertion ?&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;Lastly, If the compress space operation involving data pages spanned across multiple AllocExtents (which is the current case), the compress operation happens only on the last page. Ideally, it should clean up the last AllocPage (with referred datapages) and also clean up data pages which might be empty in the previous AllocationExtent. I realized this when I saw a very small decrease in physical size when I ran the reproducible testcase. Can someone please confirm this ?? So, I can file a JIRA for this.&lt;/p&gt;</comment>
                            <comment id="12450263" author="tsuresh" created="Thu, 16 Nov 2006 02:52:43 +0000"  >&lt;p&gt;I agree with you , it might be trickey to  check  db versions especially on  a readExpternal() call.   It would be nice to avoid creating another class.  Hopefully some one on the list some has  ideas to do that. &lt;/p&gt;

&lt;p&gt;If you would like to proceed with a new class approach.  It would be better to make the new class handle &lt;br/&gt;
the old behavior . i.e   create a new class  CompressSpacePageOperation_V10_2  that extends the    CompressSpacePageOperation  and  change the format id for  the  CompressSpacePageOperation  class to  a new one.   This way it is easier to read the code,  and remove the _v0 class later   when upgrade  is not supported from old version. &lt;/p&gt;

&lt;p&gt;Looks like  assertion check is incorrect  in the case you mentioned,   please  fix it.   I would  not call the assertion code under debug is  in-consistent  with insane-builds unless  behaviour is different.  In debug builds it  is  normal to do some extra checks ,  they are useful   to get some information   when stress tests fail after  a few days run. &lt;/p&gt;

&lt;p&gt;actionCompressSpaceOperation() in   LoggableAllocaction  has  RawTransaction   as argument. &lt;br/&gt;
It would be ok  to  expose the checkVersion method from logFactory  to RawTransaction,  Concrete implementation of     RawTransaction   abstract  class ,   raw/xact/Xact.java  already  has the logFactory information. &lt;/p&gt;

&lt;p&gt;I would expect   compress operation to  work even if there are  multiple  alloc pages, .may  be there is bug some where ; please file a JIRA. &lt;/p&gt;

&lt;p&gt;Thanks &lt;br/&gt;
-suresh&lt;/p&gt;
</comment>
                            <comment id="12450437" author="mayureshnirhali" created="Thu, 16 Nov 2006 16:00:58 +0000"  >&lt;p&gt;Thanks Suresh for your comments.&lt;/p&gt;

&lt;p&gt;I got a little further with the additional Class approach and as you mentioned I had to create another child of CompressSpacePageOperation that will behave just like the original one was until now. But, The new class will still use the typeFormatId of the base class.&lt;br/&gt;
I also added another method in RawTransaction that returns LogFactory and with this the DB versio checks are made in LoggableAllocActions, thanks for this suggestion. I hope this will be useful in the future as well. The assertion is still kept, but modified to handle -1 value.&lt;/p&gt;

&lt;p&gt;having said that, I will be glad to consider any other approach than creating these child classes. But, the approach of doing db versions checks in read/write methods, I believe, isnt a good option.&lt;/p&gt;

&lt;p&gt;I shall move onto extending OnlineCompressTest to cover this case.&lt;br/&gt;
I am currently running derbyall with my patch and shall attach it soon.&lt;/p&gt;


&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="12450734" author="mayureshnirhali" created="Fri, 17 Nov 2006 13:23:20 +0000"  >&lt;p&gt;I am attaching a preliminary patch. This does not include changes to upgradeTest and also the repro is not added to the testsuite yet. But, This is a initial proposal for the fix for the bug and the fix in itself is complete.&lt;/p&gt;

&lt;p&gt;I have ran derbyall and junit tests and have not seen any relevant new failures.&lt;/p&gt;

&lt;p&gt;As mentioned in my earlier comments, this fix adds two new classes and some code changes to support that. Also, it adds a new interface in RawTrans to expose to LogFactory. &lt;br/&gt;
I would appreciate review comments on this.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="12450785" author="mayureshnirhali" created="Fri, 17 Nov 2006 16:42:51 +0000"  >&lt;p&gt;I looked at the OnlineCompressTest and realized that to reproduce this case, the simplest way is to increase the number of rows added to the table in one of the existing testcases. However, I see a following comment in the testcase,&lt;/p&gt;

&lt;p&gt;&amp;lt;snip&amp;gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;4000 rows  - reasonable number of pages to test out, still 1 alloc page&lt;br/&gt;
     *&lt;/li&gt;
	&lt;li&gt;note that row numbers greater than 4000 may lead to lock escalation&lt;/li&gt;
	&lt;li&gt;issues, if queries like &quot;delete from x&quot; are used to delete all the&lt;/li&gt;
	&lt;li&gt;rows.&lt;br/&gt;
&amp;lt;/snip&amp;gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This is very relevant to the testcase which I would like to add and so, would like to know the Lock Escalation issue here. Has anyone seen this kind of issue before ? any pointers ??&lt;/p&gt;

&lt;p&gt;The repro attached to the bug has almost similar testcase, I have not seen any problems with that so far. So, it might be that the Lock Escalation issue has already been fixed. (I did not find any related JIRA for this though). Can someone please confirm this ?? I can update the comments if that problem has been fixed.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="12454241" author="mayureshnirhali" created="Wed, 29 Nov 2006 07:18:18 +0000"  >&lt;p&gt;Attaching next version of patch. This patch now includes changes to the OnlineCompressTest and UpgradeTest.&lt;/p&gt;

&lt;p&gt;I have created Upgrade_10_2_10_3, but it is not currently included in the upgrade.runall, because the 10.2 binaries are not available in the trunk for upgrade testing.&lt;/p&gt;

&lt;p&gt;The patch has grown more than what I had imagined. I would really appreciate review comments.&lt;/p&gt;</comment>
                            <comment id="12454250" author="fuzzylogic" created="Wed, 29 Nov 2006 08:08:11 +0000"  >&lt;p&gt;The 10.2.1.6 jars are checked into the repository and available at &lt;a href=&quot;http://svn.apache.org/repos/asf/db/derby/jars/10.2.1.6/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/db/derby/jars/10.2.1.6/&lt;/a&gt;. To add them to a trunk checkout, execute the following from the top of a checkout of the trunk:&lt;/p&gt;

&lt;p&gt;svn pe svn:externals tools/testing&lt;/p&gt;

&lt;p&gt;and then add a line for the 10.2 jars, e.g.:&lt;/p&gt;

&lt;p&gt;derby/10.2 &lt;a href=&quot;https://svn.apache.org/repos/asf/db/derby/jars/10.2.1.6&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://svn.apache.org/repos/asf/db/derby/jars/10.2.1.6&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The next time you do an svn update, the 10.2.1.6 jars will be checked out to tools/testing/derby/10.2&lt;/p&gt;</comment>
                            <comment id="12454827" author="tsuresh" created="Fri, 1 Dec 2006 08:06:03 +0000"  >&lt;p&gt;Thanks for working on this issue. Patch looks good , i have only few minor comments. &lt;/p&gt;

&lt;p&gt;1) Two new classes CompressSpacePageOperation10_2.java and&lt;br/&gt;
CompressSpacePageOperation10_3.java may not be required. I think CompressSpacePageOperation.java  &lt;br/&gt;
can be modified to handle the new 10.3/10.2 behavior and create one new class&lt;br/&gt;
CompressSpacePageOperation10_2  that extends the CompressSpacePageOperation&lt;br/&gt;
and sets the old format id.&lt;/p&gt;


&lt;p&gt;2) CompressSpacePageOperation10_2.java Copyright has a wrong class name.&lt;/p&gt;

&lt;p&gt;Index: java/engine/org/apache/derby/impl/store/raw/data/CompressSpacePageOperation10_2.java&lt;/p&gt;

&lt;p&gt;+   Derby - Class org.apache.derby.impl.store.raw.data.ChainAllocPageOperation&lt;/p&gt;


&lt;p&gt;3) Minor comment error in &lt;br/&gt;
   Index: java/engine/org/apache/derby/iapi/store/raw/RawStoreFactory.java&lt;/p&gt;

&lt;p&gt;+	/** Derby Store Minor Version (2) **/&lt;br/&gt;
+	public static final int DERBY_STORE_MINOR_VERSION_3    = 3;&lt;/p&gt;


&lt;p&gt;version number in the comment , should be 3. &lt;/p&gt;

&lt;p&gt;4) Great work with tests.  One minor nit : &lt;br/&gt;
When I looked first time , following change in the OnlineCompressTest.java, &lt;br/&gt;
got me confused. &lt;/p&gt;


&lt;p&gt;+        int[] test_cases = &lt;/p&gt;
{104000}
&lt;p&gt;;&lt;/p&gt;

&lt;p&gt;+        for (int i = 0; i &amp;lt; test_cases.length; i++)&lt;br/&gt;
+        {&lt;br/&gt;
+            // first create new table and run the tests.&lt;br/&gt;
+            createAndLoadLargeTable(conn, true, table_name, test_cases&lt;span class=&quot;error&quot;&gt;&amp;#91;i&amp;#93;&lt;/span&gt;, 0);&lt;br/&gt;
+&lt;/p&gt;


&lt;p&gt;I am sure you must have added it to try different no of rows to reproduce the&lt;br/&gt;
problem. Now that you know the no of of rows required to reproduce&lt;br/&gt;
the problem. It might be better to change the code to noRows= 104000  &lt;br/&gt;
instead of test_cases; just to make it more clear.&lt;/p&gt;


&lt;p&gt;5) tests/upgradeTests/Upgrade_10_2_10_3.java  has to be disabled due to&lt;br/&gt;
   &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1135&quot; title=&quot;Run upgrade test using a security manager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1135&quot;&gt;&lt;del&gt;DERBY-1135&lt;/del&gt;&lt;/a&gt; bug ,  please see build.xml in this directory. &lt;/p&gt;

&lt;p&gt;   There is another Jira entry&lt;br/&gt;
   (&lt;a href=&quot;http://issues.apache.org/jira/browse/DERBY-1689&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/DERBY-1689&lt;/a&gt;)  to add upgrade tests&lt;br/&gt;
   for 10.2 to 102.  If you would like to address the 10.2 to 10.3 upgrade&lt;br/&gt;
   support in a  separate patch, that is fine with me. &lt;/p&gt;</comment>
                            <comment id="12454834" author="mayureshnirhali" created="Fri, 1 Dec 2006 08:34:35 +0000"  >&lt;p&gt;Attaching next version of the patch!&lt;/p&gt;

&lt;p&gt;This version now will work well with 10.2 binaries integrated in the trunk.&lt;/p&gt;

&lt;p&gt;Another modification is that, the 10.1 -10.3 upgrade is now taken out. I believe it was a temporary workaround when we transitioned to 10.3. So, the only upgradeTest that should be run is Upgrade10.2_10.3 and ofcourse this test also has cases for previous upgrades as it uses the same framework and the new case is added to the existing framework.&lt;/p&gt;

&lt;p&gt;I am going to file a bug for cleaning up the 10.1 related files.&lt;/p&gt;</comment>
                            <comment id="12454932" author="mayureshnirhali" created="Fri, 1 Dec 2006 15:26:00 +0000"  >&lt;p&gt;Thanks a lot suresh,&lt;/p&gt;

&lt;p&gt;I think I misunderstood the proposal you gave initially about CompressSpacePageOperation10_2 class. This new solution of having only 1 class extending the old one to support old behavior seems to be the right thing to do. I have done so, but  the main class will need to have one extra check which I could not avoid. Let me know if you have any workaround to this small nit in the new approach.&lt;/p&gt;

&lt;p&gt;I have also addressed your comments in this new set of patches. I have created 2 patches, one which includes implementation and test changes and another one specifically for upgradeTest changes. Thanks for this tip.&lt;/p&gt;

&lt;p&gt;I would really appreciate review comments on this.&lt;/p&gt;</comment>
                            <comment id="12455046" author="tsuresh" created="Fri, 1 Dec 2006 23:33:03 +0000"  >&lt;p&gt;Thanks for considering my suggestions.  Extra check(if( !(this instanceof&lt;br/&gt;
CompressSpacePageOperation10_2) ) in the  CompressSpacePageOperation.java &lt;br/&gt;
is ok. You need some kind of check in  to correctly call the &lt;br/&gt;
writeExternal/readExternal. Only othe alternative I can think of is to &lt;br/&gt;
check for formatId instead of using the &quot;instanceof&quot;. &lt;/p&gt;


&lt;p&gt;While reviewing the latest patches(derby606_impl-v4.diff and derby606_upgrade-v4.diff ), &lt;br/&gt;
noticed you are disabling IN_PLACE_COMPRESS  on soft-upgrade to 10.3, in my &lt;br/&gt;
view that is incorrect. If I understand correctly this bug happens only on &lt;br/&gt;
large data size and does not leave the database in the corrupt state. &lt;/p&gt;

&lt;p&gt;I believe right thing to do is to use the old log record on soft-upgrade to&lt;br/&gt;
10.3 and allow compress. If you would like to be real nice to the users &lt;br/&gt;
then you can catch the bugs case and throw an error message, but I think it is&lt;br/&gt;
not required; users hitting the bug case first time on a a soft-upgrade is &lt;br/&gt;
almost zero probability. &lt;/p&gt;

&lt;p&gt;Index: java/engine/org/apache/derby/impl/store/raw/data/LoggableAllocActions.java&lt;/p&gt;

&lt;p&gt;+	if( t.getLogFactory().checkVersion(RawStoreFactory.DERBY_STORE_MAJOR_VERSION_10,&lt;br/&gt;
+					RawStoreFactory.DERBY_STORE_MINOR_VERSION_3,&lt;br/&gt;
+					&quot;CompressSpace operation on an existing database&quot;) )&lt;/p&gt;

&lt;p&gt;Above call throws an exception if version is not at the correct level, in this&lt;br/&gt;
case if not at  10.3. I think if you pass &quot;null&quot; for feature name , it will&lt;br/&gt;
just return true/false. &lt;/p&gt;


&lt;p&gt;Please also fix the upgrade tests also, if you decide to allow compress on soft-upgrade. &lt;/p&gt;

&lt;p&gt;I am sorry for missing this in my previous review. &lt;/p&gt;


&lt;p&gt;There is one major problem with the latest patch, it can make database &lt;br/&gt;
non-recoverable on upgrade from 10.2.&lt;/p&gt;

&lt;p&gt;1) Formatid are incorrect for CompressSpacePageOperation10_2 and    CompressSpacePageOperation. &lt;br/&gt;
   CompressSpacePageOperation should have the new format id and  the&lt;br/&gt;
   CompressSpacePageOperation10_2 should have the OLD one. &lt;/p&gt;

&lt;p&gt;Related changes :&lt;/p&gt;

&lt;p&gt;Index: java/engine/org/apache/derby/impl/store/raw/data/CompressSpacePageOperation10_2.java&lt;br/&gt;
+&lt;br/&gt;
+	/**&lt;br/&gt;
+		Return my format identifier.&lt;br/&gt;
+	*/&lt;br/&gt;
+	public int getTypeFormatId() &lt;/p&gt;
{
+		return super.getTypeFormatId();
+	}

&lt;p&gt;I am sure , you wanted it to return StoredFormatIds.LOGOP_COMPRESS10_2_SPACE;  &lt;/p&gt;

&lt;p&gt;and  also :&lt;br/&gt;
Index: java/engine/org/apache/derby/iapi/services/io/RegisteredFormatIds.java&lt;br/&gt;
+	/* 465 */   &quot;org.apache.derby.impl.store.raw.data.CompressSpacePageOperation10_2&quot;,&lt;/p&gt;

&lt;p&gt;That shoud have been&lt;br/&gt;
&quot;org.apache.derby.impl.store.raw.data.CompressSpacePageOperation&quot; and you&lt;br/&gt;
should change existing entry for compress to &quot;CompressSpacePageOperation10_2&quot;.&lt;/p&gt;

&lt;p&gt;and the format id numbers should get changed  also :&lt;br/&gt;
Index: java/engine/org/apache/derby/iapi/services/io/StoredFormatIds.java&lt;br/&gt;
         public static final int LOGOP_COMPRESS_SPACE =&lt;br/&gt;
                 (MIN_ID_2 + 454);&lt;/p&gt;

&lt;p&gt;+	/* org.apache.derby.impl.store.raw.data.CompressSpacePageOperation10_2 */&lt;br/&gt;
+        public static final int LOGOP_COMPRESS10_2_SPACE =&lt;br/&gt;
+                (MIN_ID_2 + 465);&lt;br/&gt;
+&lt;/p&gt;



&lt;p&gt;2) In the upgrade test , why you need to insert  104000 rows ? I think you &lt;br/&gt;
can produce the compress log record with less number of records and reduce&lt;br/&gt;
the test time.  &lt;/p&gt;

&lt;p&gt;+			try &lt;/p&gt;
{
+				checkDataToCase606(conn, 0, 104000, true);
+			}
&lt;p&gt; catch(SQLException sqle) &lt;/p&gt;
{
+				passed = isExpectedException(sqle, &quot;XSLB1&quot;);
+			}



&lt;p&gt;Thanks&lt;br/&gt;
-suresh&lt;/p&gt;</comment>
                            <comment id="12455260" author="mayureshnirhali" created="Mon, 4 Dec 2006 09:23:40 +0000"  >&lt;p&gt;Thanks Suresh for catching that!&lt;/p&gt;

&lt;p&gt;I have created new patches based on your feedback and they are attached.&lt;/p&gt;

&lt;p&gt;Regarding the UpgradeTest  with 10400 rows, I believe it is good to test the soft and hard upgrade when the edge case is hit. Hence I use the case almost as is from OnlineCompressTest.&lt;/p&gt;

&lt;p&gt;This case is not only about large size table data but it happens when data stored  (in multiple allocation pages) is deleted to an extent where the last allocation page is completely empty. In this case, when the compress is called, the operation does not complete successfully because the log record is not written due to the fact that newHighestPage is negative.&lt;/p&gt;

&lt;p&gt;To simulate this, I created a table with data (for a particualr db schema) that will just grow beyond the size that can be managed by 1 alloc page. Then deleted enough data to make sure the last allocpage is empty. The combination of 10400 + the db schema is optimized for minimum time. I could not get the other 2 db schemas in OnlineCompressTest to work for this case, for a shorter duration.&lt;/p&gt;

&lt;p&gt;This is a large patch and Comments on this new patch are most welcome.&lt;/p&gt;

&lt;p&gt;-Mayuresh&lt;/p&gt;</comment>
                            <comment id="12456260" author="tsuresh" created="Wed, 6 Dec 2006 23:30:36 +0000"  >&lt;p&gt;derby606_impl-v5.diff :&lt;/p&gt;

&lt;p&gt;This patch looks good to be committed. Did you run the regression tests ?&lt;br/&gt;
For some reason I can not apply this patch to my code-line.  &lt;br/&gt;
Could you please recreate the patch and post it. &lt;/p&gt;


&lt;p&gt;$ patch -i c:/temp/derby606_impl-v5.diff&lt;br/&gt;
patching file `java/engine/org/apache/derby/impl/store/raw/xact/Xact.java&apos;&lt;br/&gt;
patching file `java/engine/org/apache/derby/impl/store/raw/data/CompressSpacePag&lt;br/&gt;
eOperation10_2.java&apos;&lt;br/&gt;
patch: **** malformed patch at line 120: Index: java/engine/org/apache/derby/imp&lt;br/&gt;
l/store/raw/data/LoggableAllocActions.java&lt;/p&gt;


&lt;p&gt;1) One minor thing I noticed is you did not update the MAX_ID_2 in the&lt;br/&gt;
following file :&lt;/p&gt;

&lt;p&gt;Index: java/engine/org/apache/derby/iapi/services/io/StoredFormatIds.java&lt;/p&gt;

&lt;p&gt;public static final int MAX_ID_2 =&lt;br/&gt;
                (MIN_ID_2 + 464);&lt;/p&gt;


&lt;p&gt;File  derby606_upgrade-v5.diff :&lt;br/&gt;
--------------------------------&lt;/p&gt;

&lt;p&gt;As Bryan and others pointed out Derby supports upgrade from 10.1 to 10.3&lt;br/&gt;
also. This patch seems to incorrectly remove 10.1 to 10.3 upgrade test.&lt;/p&gt;

&lt;p&gt;After your latest change to allow Compress on softupgrade , following error&lt;br/&gt;
check  is not valid any more:&lt;/p&gt;

&lt;p&gt;+			try &lt;/p&gt;
{
+				checkDataToCase606(conn, 0, 104000, true);
+			}
&lt;p&gt; catch(SQLException sqle) {&lt;br/&gt;
+				passed = isExpectedException(sqle, &quot;XSLB1&quot;);&lt;/p&gt;

&lt;p&gt;Now the above check  is going to fail on softupgrade because of the derby-606 bug. &lt;/p&gt;

&lt;p&gt;As I understand changes to upgrade is going to test :&lt;/p&gt;

&lt;p&gt;1) Compress Log Record writes on compress operation.&lt;br/&gt;
2) On hard upgrade , derby-606 problem does not occur. &lt;/p&gt;

&lt;p&gt;Following cases is not tested : &lt;br/&gt;
1) Replay of the old compress log record  on softupgrade/hardupgrade (&lt;br/&gt;
readExternal() execution), because database is shutdown after each upgrade test&lt;br/&gt;
phase. This might be tricky to do because you need to simulate crash-recovery, &lt;br/&gt;
you can work on it separately if you are interested. Let&apos;s try to get the &lt;br/&gt;
current patches committed.     &lt;/p&gt;


&lt;p&gt;Thanks&lt;br/&gt;
-suresh&lt;/p&gt;</comment>
                            <comment id="12456356" author="mayureshnirhali" created="Thu, 7 Dec 2006 11:22:34 +0000"  >&lt;p&gt;new patch for the implementation is attached.&lt;/p&gt;

&lt;p&gt;I had some problems with svn:eol settings and they have been fixed now and the patch has been updated and also tested.&lt;br/&gt;
I have also modified the StoredFormatIds to correct the max_id now. Thanks Suresh for catching that.&lt;/p&gt;</comment>
                            <comment id="12456497" author="mayureshnirhali" created="Thu, 7 Dec 2006 17:52:39 +0000"  >&lt;p&gt;&amp;gt; As Bryan and others pointed out Derby supports upgrade from 10.1 to 10.3&lt;br/&gt;
&amp;gt; also. This patch seems to incorrectly remove 10.1 to 10.3 upgrade test.&lt;/p&gt;

&lt;p&gt;I considered this. The current framework for upgrade testing needs some modification to support upgrade from more than 1 prev releases. build.xml should create &amp;lt;test&amp;gt;_app.properties file for each such test in the upgradeSuite. Also, upgrade from 10.0 to 10.3 should be considered.  I looked into 10.2 and 10.1 workspaces and they contain only one test. One good thing is that, as mentioned in my other comments, UpgradeTester still includes all the testcases for upgrade from 10.0 and 10.1, so this work can be used to make upgradetest support upgrade from 10.0 and 10.1 to 10.3.&lt;/p&gt;

&lt;p&gt;In my opinion, all This is probably out of scope for this bug. I feel, A follow up patch tracked by different JIRA entry can handle this effort. It might be useful to comment out the lines instead of removing, I shall do that. Please let me know what do you think.&lt;/p&gt;

&lt;p&gt;------------------&lt;/p&gt;

&lt;p&gt;Attached is another patch for upgrade tests. I simplified the 606 case to call compress for common scenario where old log record is used, instead of exercising the bug case. This case in Upgrade testing framework will also work with old/new releases and not just the combination of 10.2-10.3.&lt;/p&gt;


&lt;p&gt;Thanks for your help !!&lt;br/&gt;
&amp;#8211; Mayuresh&lt;/p&gt;</comment>
                            <comment id="12456705" author="mayureshnirhali" created="Fri, 8 Dec 2006 05:52:40 +0000"  >&lt;p&gt;Suresh pointed out that 10.1 to 10.3 upgrade test will be more appropriate at this time. I think that is wise also because it will still exercise a relevant upgrade for this bug.&lt;/p&gt;

&lt;p&gt;So, in the new attached patch, I have cleaned up 10.2-10.3 test related code and the patch looks neat now. It  only has a added testcase to UpgradeTester with corresponding changes to the out file.&lt;/p&gt;

&lt;p&gt;please note that, we are not including 10.2-10.3 upgrade tests here, so the patch does not include additional trunk settings to checkout 10.2 binaries. This will be added as a part of fix to 1689, I feel.&lt;/p&gt;

&lt;p&gt;thanks&lt;/p&gt;</comment>
                            <comment id="12456988" author="tsuresh" created="Fri, 8 Dec 2006 21:51:35 +0000"  >&lt;p&gt;Committed     derby606_impl-v6.diff and derby606_upgrade-v7.diff   to trunk,  revision 484797.  Thanks Mayuresh. &lt;/p&gt;</comment>
                            <comment id="12461933" author="kristwaa" created="Wed, 3 Jan 2007 10:32:43 +0000"  >&lt;p&gt;Cleared patch available flag.&lt;br/&gt;
Can anyone help me to confirm and update the status of this issue?&lt;br/&gt;
It is still reported as in progress and unresolved, which indicate there are more patches to come.&lt;/p&gt;</comment>
                            <comment id="12462202" author="mayureshnirhali" created="Thu, 4 Jan 2007 12:36:35 +0000"  >&lt;p&gt;patch has been committed by Suresh on 12/09. No more pending patches, and No backports required.&lt;br/&gt;
Changing the status to Resolved.&lt;/p&gt;

&lt;p&gt;Thanks Kristian for pointing this out.&lt;/p&gt;
</comment>
                            <comment id="12562046" author="dyret" created="Thu, 24 Jan 2008 13:09:59 +0000"  >&lt;p&gt;This issue is resolved and has not been updated in the last 12 months (since 24/Jan/07). &lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12344771" name="A606Test.java" size="5395" author="mayureshnirhali" created="Fri, 10 Nov 2006 17:10:49 +0000"/>
                            <attachment id="12345992" name="derby606-v2.diff" size="40462" author="mayureshnirhali" created="Wed, 29 Nov 2006 07:18:18 +0000"/>
                            <attachment id="12346186" name="derby606-v3.diff" size="263619" author="mayureshnirhali" created="Fri, 1 Dec 2006 08:34:35 +0000"/>
                            <attachment id="12346233" name="derby606_impl-v4.diff" size="21739" author="mayureshnirhali" created="Fri, 1 Dec 2006 15:26:00 +0000"/>
                            <attachment id="12346321" name="derby606_impl-v5.diff" size="22450" author="mayureshnirhali" created="Mon, 4 Dec 2006 09:23:40 +0000"/>
                            <attachment id="12346631" name="derby606_impl-v6.diff" size="22966" author="mayureshnirhali" created="Thu, 7 Dec 2006 11:22:34 +0000"/>
                            <attachment id="12346234" name="derby606_upgrade-v4.diff" size="244073" author="mayureshnirhali" created="Fri, 1 Dec 2006 15:26:00 +0000"/>
                            <attachment id="12346322" name="derby606_upgrade-v5.diff" size="244278" author="mayureshnirhali" created="Mon, 4 Dec 2006 09:23:40 +0000"/>
                            <attachment id="12346693" name="derby606_upgrade-v6.diff" size="240680" author="mayureshnirhali" created="Thu, 7 Dec 2006 17:52:39 +0000"/>
                            <attachment id="12346737" name="derby606_upgrade-v7.diff" size="9876" author="mayureshnirhali" created="Fri, 8 Dec 2006 05:52:40 +0000"/>
                            <attachment id="12345218" name="derby606_v1.diff" size="15836" author="mayureshnirhali" created="Fri, 17 Nov 2006 13:23:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 28 Aug 2006 17:52:19 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>22041</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy0zpz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>39605</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            </customfields>
    </item>
</channel>
</rss>