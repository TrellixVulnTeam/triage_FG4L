<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:30:52 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-2549/DERBY-2549.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-2549] ArrayIndexOutOfBoundsException in SYSCS_UTIL.SYSCS_INPLACE_COMPRESS_TABLE</title>
                <link>https://issues.apache.org/jira/browse/DERBY-2549</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;I am doing this in my code:&lt;/p&gt;

&lt;p&gt;CALL SYSCS_UTIL.SYSCS_INPLACE_COMPRESS_TABLE(&apos;SPONTS&apos;,&apos;&quot; + &quot;journal&quot;.toUpperCase(Locale.US) + &quot;&apos;,1,1,1)&quot;)&lt;/p&gt;

&lt;p&gt;(&quot;journal&quot; is actually a String-variable, but I replaced it here for easier understanding)&lt;/p&gt;

&lt;p&gt;Sometime - not always - I am getting this exception:&lt;/p&gt;

&lt;p&gt;java.sql.SQLException: The exception &apos;java.lang.ArrayIndexOutOfBoundsException: 100&apos; was thrown while evaluating an expression. SQLSTATE: XJ001:&lt;br/&gt;
Java exception: &apos;100: java.lang.ArrayIndexOutOfBoundsException&apos;.&lt;br/&gt;
        at org.apache.derby.client.am.SQLExceptionFactory.getSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.client.am.SqlException.getSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.client.am.Statement.execute(Unknown Source)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;br/&gt;
Caused by: org.apache.derby.client.am.SqlException: The exception &apos;java.lang.ArrayIndexOutOfBoundsException: 100&apos; was thrown while evaluating an expression.&lt;br/&gt;
 SQLSTATE: XJ001: Java exception: &apos;100: java.lang.ArrayIndexOutOfBoundsException&apos;.&lt;br/&gt;
        at org.apache.derby.client.am.Statement.completeExecute(Unknown Source)&lt;br/&gt;
        at org.apache.derby.client.net.NetStatementReply.parseEXCSQLSTTreply(Unknown Source)&lt;br/&gt;
        at org.apache.derby.client.net.NetStatementReply.readExecuteCall(Unknown Source)&lt;br/&gt;
        at org.apache.derby.client.net.StatementReply.readExecuteCall(Unknown Source)&lt;br/&gt;
        at org.apache.derby.client.net.NetStatement.readExecuteCall_(Unknown Source)&lt;br/&gt;
        at org.apache.derby.client.am.Statement.readExecuteCall(Unknown Source)&lt;br/&gt;
        at org.apache.derby.client.am.Statement.flowExecute(Unknown Source)&lt;br/&gt;
        at org.apache.derby.client.am.Statement.executeX(Unknown Source)&lt;br/&gt;
        ... 12 more&lt;/p&gt;</description>
                <environment>Linux 2.6.x, JRE 1.5.0_b7</environment>
        <key id="12367248">DERBY-2549</key>
            <summary>ArrayIndexOutOfBoundsException in SYSCS_UTIL.SYSCS_INPLACE_COMPRESS_TABLE</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mayureshnirhali">Mayuresh Nirhali</assignee>
                                    <reporter username="kurti">Kurt Huwig</reporter>
                        <labels>
                    </labels>
                <created>Mon, 16 Apr 2007 08:26:39 +0100</created>
                <updated>Fri, 21 Jan 2011 17:50:03 +0000</updated>
                            <resolved>Tue, 22 May 2007 21:47:08 +0100</resolved>
                                    <version>10.2.2.0</version>
                                    <fixVersion>10.2.2.1</fixVersion>
                    <fixVersion>10.3.1.4</fixVersion>
                                    <component>Store</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12489716" author="kurti" created="Wed, 18 Apr 2007 14:13:21 +0100"  >&lt;p&gt;I am able to reproduce it with Sun Java build 1.6.0-b105. I changed the exception reporting code to show the real source:&lt;/p&gt;

&lt;p&gt;java.lang.ArrayIndexOutOfBoundsException: 100&lt;br/&gt;
	at org.apache.derby.impl.store.access.heap.HeapCompressScan.fetchRowsForCompress(HeapCompressScan.java:213)&lt;br/&gt;
	at org.apache.derby.impl.store.access.heap.HeapCompressScan.fetchNextGroup(HeapCompressScan.java:116)&lt;br/&gt;
	at org.apache.derby.iapi.db.OnlineCompress.defragmentRows(OnlineCompress.java:384)&lt;br/&gt;
	at org.apache.derby.iapi.db.OnlineCompress.compressTable(OnlineCompress.java:228)&lt;br/&gt;
	at org.apache.derby.catalog.SystemProcedures.SYSCS_INPLACE_COMPRESS_TABLE(SystemProcedures.java:927)&lt;br/&gt;
	at org.apache.derby.exe.ac601a400fx0112x04cex382ex00000045c1b80.g0(Unknown Source)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.derby.impl.services.reflect.ReflectMethod.invoke(ReflectMethod.java:46)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.CallStatementResultSet.open(CallStatementResultSet.java:68)&lt;br/&gt;
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(GenericPreparedStatement.java:358)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(EmbedStatement.java:1182)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.execute(EmbedStatement.java:585)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.execute(EmbedStatement.java:517)&lt;/p&gt;</comment>
                            <comment id="12489772" author="kristwaa" created="Wed, 18 Apr 2007 15:48:09 +0100"  >&lt;p&gt;FYI, a user claimed to have a reproducible example for this on IRC. Unfortunately, he/she wasn&apos;t sure what to do with it, and left before I was able to answer.&lt;/p&gt;</comment>
                            <comment id="12489795" author="kristwaa" created="Wed, 18 Apr 2007 16:31:21 +0100"  >&lt;p&gt;A little app printing simple disk space diagnostics.&lt;br/&gt;
Not very well tested...&lt;/p&gt;</comment>
                            <comment id="12489800" author="kurti" created="Wed, 18 Apr 2007 16:43:41 +0100"  >&lt;p&gt;Output from the app is&lt;/p&gt;

&lt;p&gt;Tablename                 Type   ALLOC   FREE PSIZE   SAVE File      Size KB &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -&lt;br/&gt;
ATTACHMENTFILTER          TABLE      1      0  4096      0 c3c0.dat        8&lt;br/&gt;
  SQL070409002320120      INDEX      1      0  4096      0 c3d1.dat        8&lt;br/&gt;
AUTOBLACKLIST             TABLE      1      0  4096      0 c3e0.dat        8&lt;br/&gt;
  SQL070409002320240      INDEX      1      0  4096      0 c3f1.dat        8&lt;br/&gt;
CACHE                     TABLE    670      0  4096      0 c400.dat     2684&lt;br/&gt;
  SQL070409002320280      INDEX    596      0  4096      0 c411.dat     2388&lt;br/&gt;
DISINFECTIONOPTIN         TABLE      1      0  4096      0 c420.dat        8&lt;br/&gt;
  SQL070409002320310      INDEX      1      0  4096      0 c431.dat        8&lt;br/&gt;
DISPOSABLEOPTIN           TABLE      1      0  4096      0 c440.dat        8&lt;br/&gt;
  SQL070409002320350      INDEX      1      0  4096      0 c451.dat        8&lt;br/&gt;
DISPOSABLERECIPIENTS      TABLE      1      0  4096      0 c460.dat        8&lt;br/&gt;
  SQL070409002320380      INDEX      1      0  4096      0 c471.dat        8&lt;br/&gt;
DOMAINADMIN               TABLE      1      0  4096      0 c480.dat        8&lt;br/&gt;
  SQL070409002320410      INDEX      1      0  4096      0 c491.dat        8&lt;br/&gt;
ENVELOPEPOLICY            TABLE      2      0  4096      0 c4a0.dat       12&lt;br/&gt;
  SQL070409002320450      INDEX      1      0  4096      0 c4b1.dat        8&lt;br/&gt;
FETCHACCOUNT              TABLE      1      0  4096      0 c4c0.dat        8&lt;br/&gt;
  SQL070409002320520      INDEX      1      0  4096      0 c4d1.dat        8&lt;br/&gt;
FTPUSER                   TABLE      1      0  4096      0 c4e0.dat        8&lt;br/&gt;
  SQL070409002320570      INDEX      1      0  4096      0 c4f1.dat        8&lt;br/&gt;
JOURNAL                   TABLE   4710    377 32768 12353536 c500.dat   162816&lt;br/&gt;
  SQL070409002320610      INDEX   4619   1125  4096 4608000 c511.dat    22980&lt;br/&gt;
  JOURNAL_RECEIVEDDATE_DESC INDEX   5795      0  4096      0 c521.dat    23204&lt;br/&gt;
LOCALDOMAINS              TABLE      1      0  4096      0 c530.dat        8&lt;br/&gt;
  SQL070409002320700      INDEX      1      0  4096      0 c541.dat        8&lt;br/&gt;
MONITORPROXIES            TABLE      1      0  4096      0 c550.dat        8&lt;br/&gt;
  SQL070409002320730      INDEX      1      0  4096      0 c561.dat        8&lt;br/&gt;
RCPTREWRITE               TABLE      1      0  4096      0 c570.dat        8&lt;br/&gt;
  SQL070409002320780      INDEX      1      0  4096      0 c581.dat        8&lt;br/&gt;
RECIPIENTBACKEND          TABLE      1      0  4096      0 c590.dat        8&lt;br/&gt;
  SQL070409002320820      INDEX      1      0  4096      0 c5a1.dat        8&lt;br/&gt;
RECIPIENTKEYS             TABLE      1      0  4096      0 c5b0.dat        8&lt;br/&gt;
  SQL070409002320860      INDEX      1      0  4096      0 c5c1.dat        8&lt;br/&gt;
RECIPIENTSTATISTIC        TABLE     14      0  4096      0 c5d0.dat       60&lt;br/&gt;
  SQL070409002320890      INDEX     12      0  4096      0 c5e1.dat       52&lt;br/&gt;
REPLAYADMIN               TABLE      1      0  4096      0 c5f0.dat        8&lt;br/&gt;
  SQL070409002320930      INDEX      1      0  4096      0 c601.dat        8&lt;br/&gt;
REPLAYLOG                 TABLE      1      0 32768      0 c610.dat       64&lt;br/&gt;
  SQL070409002320970      INDEX      1      0  4096      0 c621.dat        8&lt;br/&gt;
  REPLAYLOG_RECEIVEDDATE_DESC INDEX      1      0  4096      0 c631.dat        8&lt;br/&gt;
STATISTICOPTIN            TABLE      1      0  4096      0 c640.dat        8&lt;br/&gt;
  SQL070409002321100      INDEX      1      0  4096      0 c651.dat        8&lt;br/&gt;
  SYSALIASES_INDEX1       INDEX      1      0  4096      0 c191.dat        8&lt;br/&gt;
  SYSALIASES_INDEX2       INDEX      1      0  4096      0 c1a1.dat        8&lt;br/&gt;
  SYSALIASES_INDEX3       INDEX      1      0  4096      0 c1b1.dat        8&lt;br/&gt;
SYSALIASES                TABLE      5      0  4096      0 c180.dat       24&lt;br/&gt;
  SYSCHECKS_INDEX1        INDEX      1      0  4096      0 c1f1.dat        8&lt;br/&gt;
SYSCHECKS                 TABLE      1      0  4096      0 c1e0.dat        8&lt;br/&gt;
  SYSCOLPERMS_INDEX1      INDEX      1      0  4096      0 c351.dat        8&lt;br/&gt;
  SYSCOLPERMS_INDEX2      INDEX      1      0  4096      0 c361.dat        8&lt;br/&gt;
  SYSCOLPERMS_INDEX3      INDEX      1      0  4096      0 c371.dat        8&lt;br/&gt;
SYSCOLPERMS               TABLE      1      0  4096      0 c340.dat        8&lt;br/&gt;
  SYSCOLUMNS_INDEX1       INDEX      7      0  4096      0 ca1.dat        32&lt;br/&gt;
  SYSCOLUMNS_INDEX2       INDEX      5      0  4096      0 cb1.dat        24&lt;br/&gt;
SYSCOLUMNS                TABLE      8      0  4096      0 c90.dat        36&lt;br/&gt;
  SYSCONGLOMERATES_INDEX1 INDEX      3      0  4096      0 c31.dat        16&lt;br/&gt;
  SYSCONGLOMERATES_INDEX2 INDEX      4      0  4096      0 c41.dat        20&lt;br/&gt;
  SYSCONGLOMERATES_INDEX3 INDEX      3      0  4096      0 c51.dat        16&lt;br/&gt;
SYSCONGLOMERATES          TABLE      7      0  4096      0 c20.dat        32&lt;br/&gt;
  SYSCONSTRAINTS_INDEX1   INDEX      1      0  4096      0 c101.dat        8&lt;br/&gt;
  SYSCONSTRAINTS_INDEX2   INDEX      1      0  4096      0 c111.dat        8&lt;br/&gt;
  SYSCONSTRAINTS_INDEX3   INDEX      1      0  4096      0 c121.dat        8&lt;br/&gt;
SYSCONSTRAINTS            TABLE      1      0  4096      0 cf0.dat         8&lt;br/&gt;
  SYSDEPENDS_INDEX1       INDEX      1      0  4096      0 c161.dat        8&lt;br/&gt;
  SYSDEPENDS_INDEX2       INDEX      1      0  4096      0 c171.dat        8&lt;br/&gt;
SYSDEPENDS                TABLE      1      0  4096      0 c150.dat        8&lt;br/&gt;
SYSDUMMY1                 TABLE      1      0  4096      0 c2f0.dat        8&lt;br/&gt;
  SYSFILES_INDEX1         INDEX      1      0  4096      0 c271.dat        8&lt;br/&gt;
  SYSFILES_INDEX2         INDEX      1      0  4096      0 c281.dat        8&lt;br/&gt;
SYSFILES                  TABLE      1      0  4096      0 c260.dat        8&lt;br/&gt;
  SYSFOREIGNKEYS_INDEX1   INDEX      1      0  4096      0 c211.dat        8&lt;br/&gt;
  SYSFOREIGNKEYS_INDEX2   INDEX      1      0  4096      0 c221.dat        8&lt;br/&gt;
SYSFOREIGNKEYS            TABLE      1      0  4096      0 c200.dat        8&lt;br/&gt;
  SYSKEYS_INDEX1          INDEX      1      0  4096      0 c141.dat        8&lt;br/&gt;
SYSKEYS                   TABLE      1      0  4096      0 c130.dat        8&lt;br/&gt;
  SYSROUTINEPERMS_INDEX1  INDEX      1      0  4096      0 c391.dat        8&lt;br/&gt;
  SYSROUTINEPERMS_INDEX2  INDEX      1      0  4096      0 c3a1.dat        8&lt;br/&gt;
  SYSROUTINEPERMS_INDEX3  INDEX      1      0  4096      0 c3b1.dat        8&lt;br/&gt;
SYSROUTINEPERMS           TABLE      1      0  4096      0 c380.dat        8&lt;br/&gt;
  SYSSCHEMAS_INDEX1       INDEX      1      0  4096      0 cd1.dat         8&lt;br/&gt;
  SYSSCHEMAS_INDEX2       INDEX      1      0  4096      0 ce1.dat         8&lt;br/&gt;
SYSSCHEMAS                TABLE      1      0  4096      0 cc0.dat         8&lt;br/&gt;
  SYSSTATEMENTS_INDEX1    INDEX      1      0  4096      0 c241.dat        8&lt;br/&gt;
  SYSSTATEMENTS_INDEX2    INDEX      3      0  4096      0 c251.dat       16&lt;br/&gt;
SYSSTATEMENTS             TABLE     25     23  4096  94208 c230.dat      196&lt;br/&gt;
  SYSSTATISTICS_INDEX1    INDEX      1      0  4096      0 c2e1.dat        8&lt;br/&gt;
SYSSTATISTICS             TABLE      1      0  4096      0 c2d0.dat        8&lt;br/&gt;
  SYSTABLEPERMS_INDEX1    INDEX      1      0  4096      0 c311.dat        8&lt;br/&gt;
  SYSTABLEPERMS_INDEX2    INDEX      1      0  4096      0 c321.dat        8&lt;br/&gt;
  SYSTABLEPERMS_INDEX3    INDEX      1      0  4096      0 c331.dat        8&lt;br/&gt;
SYSTABLEPERMS             TABLE      1      0  4096      0 c300.dat        8&lt;br/&gt;
  SYSTABLES_INDEX1        INDEX      1      0  4096      0 c71.dat         8&lt;br/&gt;
  SYSTABLES_INDEX2        INDEX      1      0  4096      0 c81.dat         8&lt;br/&gt;
SYSTABLES                 TABLE      2      0  4096      0 c60.dat        12&lt;br/&gt;
  SYSTRIGGERS_INDEX1      INDEX      1      0  4096      0 c2a1.dat        8&lt;br/&gt;
  SYSTRIGGERS_INDEX2      INDEX      1      0  4096      0 c2b1.dat        8&lt;br/&gt;
  SYSTRIGGERS_INDEX3      INDEX      1      0  4096      0 c2c1.dat        8&lt;br/&gt;
SYSTRIGGERS               TABLE      1      0  4096      0 c290.dat        8&lt;br/&gt;
  SYSVIEWS_INDEX1         INDEX      1      0  4096      0 c1d1.dat        8&lt;br/&gt;
SYSVIEWS                  TABLE      1      0  4096      0 c1c0.dat        8&lt;br/&gt;
UCEOPTIN                  TABLE      1      0  4096      0 c660.dat        8&lt;br/&gt;
  SQL070409002321140      INDEX      1      0  4096      0 c671.dat        8&lt;br/&gt;
USERS                     TABLE      1      0  4096      0 c680.dat        8&lt;br/&gt;
  SQL070409002321170      INDEX      1      0  4096      0 c691.dat        8&lt;br/&gt;
VALIDRECIPIENTS           TABLE    192      4  4096  16384 c6a0.dat      788&lt;br/&gt;
  SQL070409002321210      INDEX    263      0  4096      0 c6b1.dat     1056&lt;/li&gt;
	&lt;li&gt;- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -&lt;br/&gt;
Total                            17030   1529   n/a 17072128 KB n/a     217200&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The table is basically a log file. It is created by only adding new records and when 350.000 records are reached, the first (oldest) 50.000 entries are deleted. This is done by determining the 50.000th element and then deleting entries with &quot;WHERE xxx &amp;lt; yyy&quot; where xxx is an order column and yyy is the value of this column of the 50.000th element.&lt;/p&gt;</comment>
                            <comment id="12489826" author="kurti" created="Wed, 18 Apr 2007 18:30:09 +0100"  >&lt;p&gt;I digged somehow deeper into this issue: I dropped all other tables and dropped the index of the table; there is only the primary key left. I replaced all values by &apos;&apos; and still the problem appeared. Then I tried to replace all values with &apos;xxxx&apos; of the same size; after 6857 successful row updates, this happened:&lt;/p&gt;

&lt;p&gt;Exception in thread &quot;main&quot; org.apache.derby.shared.common.sanity.AssertFailure: ASSERT FAILED statementContext is not expected to equal statementContexts&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;&lt;br/&gt;
	at org.apache.derby.shared.common.sanity.SanityManager.ASSERT(SanityManager.java:120)&lt;br/&gt;
	at org.apache.derby.impl.sql.conn.GenericLanguageConnectionContext.popStatementContext(GenericLanguageConnectionContext.java:2095)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedResultSet.updateRow(EmbedResultSet.java:3773)&lt;/p&gt;

&lt;p&gt;table DDL is:&lt;/p&gt;

&lt;p&gt;CREATE TABLE journal(&lt;br/&gt;
  ID VARCHAR(20) PRIMARY KEY default &apos;&apos; NOT NULL,&lt;br/&gt;
  IP VARCHAR(45) default &apos;&apos; NOT NULL,&lt;br/&gt;
  SENDER VARCHAR(32000) default &apos;&apos; NOT NULL,&lt;br/&gt;
  RECIPIENT VARCHAR(32000) default &apos;&apos; NOT NULL,&lt;br/&gt;
  MAILSENDER VARCHAR(32000) default &apos;&apos; NOT NULL,&lt;br/&gt;
  MAILFROM VARCHAR(32000) default &apos;&apos; NOT NULL,&lt;br/&gt;
  MAILTO VARCHAR(32000) default &apos;&apos; NOT NULL,&lt;br/&gt;
  CC VARCHAR(32000) default &apos;&apos; NOT NULL,&lt;br/&gt;
  BCC VARCHAR(32000) default &apos;&apos; NOT NULL,&lt;br/&gt;
  REPLYTO VARCHAR(32000) default &apos;&apos; NOT NULL,&lt;br/&gt;
  MAILDATE TIMESTAMP default &apos;0001-01-01 00:00:00&apos;,&lt;br/&gt;
  RECEIVEDDATE TIMESTAMP default &apos;0001-01-01 00:00:00&apos; NOT NULL,&lt;br/&gt;
  SUBJECT VARCHAR(32000) default &apos;&apos; NOT NULL,&lt;br/&gt;
  TOTALLENGTH BIGINT default 0 NOT NULL,&lt;br/&gt;
  ATTACHMENTS VARCHAR(32000) default &apos;&apos; NOT NULL,&lt;br/&gt;
  SPAMSCORE DOUBLE NOT NULL,&lt;br/&gt;
  STATUS VARCHAR(11) default &apos;aborted&apos; NOT NULL,&lt;br/&gt;
  REASON VARCHAR(32000) NOT NULL);&lt;br/&gt;
CREATE INDEX journal_receiveddate_desc ON journal(receiveddate DESC);&lt;/p&gt;

&lt;p&gt;FYI, I compiled Derby from the current SVN 10.2 branch and added &quot;line,vars,source&quot; as debug options so that I can see where the issue happens. And it is a &quot;sane&quot; build.&lt;/p&gt;</comment>
                            <comment id="12489899" author="kurti" created="Wed, 18 Apr 2007 23:14:28 +0100"  >&lt;p&gt;I just tried the replacement with batches of 2000 rows like this:&lt;/p&gt;

&lt;p&gt;        int errorRow = 0;&lt;br/&gt;
l1:        while(true) {&lt;br/&gt;
    final ResultSet rs = stm.executeQuery(&quot;SELECT * FROM journal FOR UPDATE&quot;);&lt;br/&gt;
        for (int row = 1; rs.next(); row++) {&lt;br/&gt;
            if (row &amp;lt; errorRow) &lt;/p&gt;
{
                continue;
            }
&lt;p&gt;            update(rs, &quot;ip&quot;);&lt;br/&gt;
            update(rs, &quot;sender&quot;);&lt;br/&gt;
            update(rs, &quot;recipient&quot;);&lt;br/&gt;
            update(rs, &quot;mailsender&quot;);&lt;br/&gt;
            update(rs, &quot;mailfrom&quot;);&lt;br/&gt;
            update(rs, &quot;mailto&quot;);&lt;br/&gt;
            update(rs, &quot;cc&quot;);&lt;br/&gt;
            update(rs, &quot;bcc&quot;);&lt;br/&gt;
            update(rs, &quot;replyto&quot;);&lt;br/&gt;
            update(rs, &quot;subject&quot;);&lt;br/&gt;
            update(rs, &quot;attachments&quot;);&lt;br/&gt;
            update(rs, &quot;status&quot;);&lt;br/&gt;
            update(rs, &quot;reason&quot;);&lt;br/&gt;
            rs.updateInt(&quot;totallength&quot;, 0);&lt;br/&gt;
            rs.updateDouble(&quot;spamscore&quot;, 0);&lt;br/&gt;
            rs.updateRow();&lt;br/&gt;
            if (row == errorRow + 2000) &lt;/p&gt;
{
                errorRow = row;
                rs.close();
                continue l1;
            }

&lt;p&gt;            if (row % 500 == 0) &lt;/p&gt;
{
                System.out.println(row);
            }
&lt;p&gt;        }&lt;br/&gt;
        break;&lt;br/&gt;
        }&lt;/p&gt;

&lt;p&gt;but this only brought me up to 9500+. Then I tried it with closing the Statement and Connection and recreating them after 2000 updates. This worked fine.&lt;/p&gt;</comment>
                            <comment id="12491558" author="kurti" created="Wed, 25 Apr 2007 09:33:48 +0100"  >&lt;p&gt;I&apos;ve prepared a database and a sample application, that reproduces this problem: if you compress it, then the Exception occurs. If you insert one additional row, the compress will work fine. As I said before, the database contains logfiles from a mailserver, so I cannot post the file here in Jira.&lt;/p&gt;

&lt;p&gt;Can someone send me his email address and some kind of confidential statement to kurt AT huwig DOT de, please?&lt;/p&gt;

&lt;p&gt;Otherwise, is there a way to erase/overwrite the data contained in the files? I tried to overwrite them, but this cannot be done with the entries that are already deleted.&lt;/p&gt;</comment>
                            <comment id="12491613" author="kurti" created="Wed, 25 Apr 2007 12:55:10 +0100"  >&lt;p&gt;I created a small patch that fixes the problem for me. Although I do not understand the code fully, it seems to me that the reason for the failure is that it finds more then 100 empty rows to be cleaned up but the result array only has space for 100 entries.&lt;/p&gt;</comment>
                            <comment id="12491681" author="bryanpendleton" created="Wed, 25 Apr 2007 17:01:53 +0100"  >&lt;p&gt;If your theory about the hard-coded limit of 100 rows to be compressed on a single page is true, perhaps you could construct a completely clean test case by just starting with a fresh empty database, creating the table with the appropriate DDL, then populating it with a bunch of  test data that you make up, deleting that test data, and trying to compress the table.&lt;/p&gt;

&lt;p&gt;That is, do you actually need your real database for a test case? Can you make a test case by making a new database which has a table which has more than 100 rows on the page eligible for compression?&lt;/p&gt;

&lt;p&gt;That would be ideal, because then you could contribute the test case without concern for data sensitivity.&lt;/p&gt;</comment>
                            <comment id="12491700" author="kurti" created="Wed, 25 Apr 2007 17:50:53 +0100"  >&lt;p&gt;Bryan,&lt;/p&gt;

&lt;p&gt;I tried this, but even after several hours of running time, it was working fine. I am not 100% percent sure, but I think the same problem occured on two different databases. I will give it a try and let the code run for some more hours. Also I will try it with the 10.2.2.0 release. I had to switch to the 10.2 SVN trunk, as there are two bugs fixed that I ran into frequently. Does anybody know when there will be a new release?&lt;/p&gt;</comment>
                            <comment id="12491873" author="mayureshnirhali" created="Thu, 26 Apr 2007 06:11:17 +0100"  >&lt;p&gt;You might want to look at Derby-606. The testcases that were added could be useful for this scenario.&lt;/p&gt;</comment>
                            <comment id="12491955" author="kurti" created="Thu, 26 Apr 2007 11:38:26 +0100"  >&lt;p&gt;I tweaked the code a bit to use arrays of size 1000 instead of 100 and put debugging code in it that prints the used space of the array if it is larger than 100. There was only one occurence of a usage of more than 100 elements which was 111. I will attach a histogram of the frequencies of the different array usages.&lt;/p&gt;</comment>
                            <comment id="12491956" author="kurti" created="Thu, 26 Apr 2007 11:39:48 +0100"  >&lt;p&gt;Histogram of the frequency of the &quot;number of elements in the array&quot;. X is array usage, Y is frequency.&lt;/p&gt;</comment>
                            <comment id="12491961" author="kurti" created="Thu, 26 Apr 2007 11:50:32 +0100"  >&lt;p&gt;My patch does not compress the full database. I will limit the case when there are 111 compressable elements to 100, so that they fit into the result array. But after that, the remaining 11 elements are still not compressed. If I run INPLACE_COMPRESS again, my debugging output shows me that it compressed just these 11 elements. A third or more runs will yield no further changes to the database.&lt;/p&gt;

&lt;p&gt;Therefore I guess that the limitation to 100 is somehow arbitrary and does not apply to my specifiy database.&lt;/p&gt;

&lt;p&gt;Comparing to &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-606&quot; title=&quot;SYSCS_UTIL.SYSCS_INPLACE_COMPRESS_TABLE fails on (very) large tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-606&quot;&gt;&lt;del&gt;DERBY-606&lt;/del&gt;&lt;/a&gt;, the size of my database is 159MB vs several GB and it contains only 301.451 elements vs 60 million.&lt;/p&gt;</comment>
                            <comment id="12492282" author="mayureshnirhali" created="Fri, 27 Apr 2007 13:48:41 +0100"  >&lt;p&gt;I was able to reproduce this error. Attaching a sample program here.&lt;/p&gt;

&lt;p&gt;I think, the issue here is that, During Heap Scan (in Compress operation) the size of the array that can hold  the records is hard coded to 100. So when the recordCount for a page is more than 100, during compress operation, it will throw AIOBE. This is possible in 2 cases, either the record size is small so that in a page (with default size, 8192) more than 100 records are stored, or default page size is changed to a higher value that will accomodate more than 100 records.&lt;/p&gt;

&lt;p&gt;To reproduce this bug, please run the attached program as below,&lt;/p&gt;

&lt;p&gt;java -cp $CLASSPATH:. -Dderby.debug.true=SpaceTrace -Dderby.storage.pageSize=32768 A2549Test &amp;gt; log.txt&lt;/p&gt;
</comment>
                            <comment id="12492301" author="bryanpendleton" created="Fri, 27 Apr 2007 15:11:37 +0100"  >&lt;p&gt;Great work Mayuresh! Your test program reproduces the problem for me, too.&lt;/p&gt;
</comment>
                            <comment id="12492307" author="kurti" created="Fri, 27 Apr 2007 15:23:08 +0100"  >&lt;p&gt;This explanations sounds reasonable. I tried to find some documentation on how to determine the row and page sizes. According to the Derby tuning docs&lt;/p&gt;

&lt;p&gt;docs/html/tuning/ctunperf10065.html&lt;/p&gt;

&lt;p&gt;the default page size is 4k, not 8k.&lt;/p&gt;</comment>
                            <comment id="12492312" author="bryanpendleton" created="Fri, 27 Apr 2007 15:33:41 +0100"  >&lt;p&gt;It seems to me like there might be two alternate solutions:&lt;br/&gt;
1) Kurt&apos;s technique of compressing only the first 100 rows on&lt;br/&gt;
the page in a single run, requiring, potentialy, multiple runs to&lt;br/&gt;
compress all the rows&lt;br/&gt;
2) Adjusting the array size dynamically, so that it doesn&apos;t have&lt;br/&gt;
a hard limit of 100, but rather can be sized appropriately for&lt;br/&gt;
however many rows are on the page.&lt;/p&gt;

&lt;p&gt;Is there any reason to prefer one solution over the other?&lt;/p&gt;</comment>
                            <comment id="12492316" author="mayureshnirhali" created="Fri, 27 Apr 2007 16:07:32 +0100"  >&lt;p&gt;Bryan, I am also inclined towards Option 2. I think that will be the right fix, just that I was caught up with something, hence could not produce a patch today.&lt;br/&gt;
I will create a patch for this early next week and will try to submit it for review.&lt;/p&gt;
</comment>
                            <comment id="12492319" author="kurti" created="Fri, 27 Apr 2007 16:20:02 +0100"  >&lt;p&gt;Byan, the array check I introduced keeps Derby from crashing. IMHO, a check like this should be kept in order to prevent further crashes. Most preferable I would like to have a check that issues a warning when more rows are found than fit into the array. This way, we would keep the crash from happening ever again while still it is reportable when it occurs. An array bounds check is cheap so it will not decrease the defragmentation significantly.&lt;/p&gt;

&lt;p&gt;Still having properly sized arrays is the best solution and the necessary array size should not be significantly larger than the now used 100 and I guess its even smaller than that for most tables. Calculation the maximum number of rows could be done at the beginning, so it won&apos;t affect running time.&lt;/p&gt;</comment>
                            <comment id="12492405" author="mikem" created="Fri, 27 Apr 2007 23:00:32 +0100"  >&lt;p&gt;I think there is yet a third option.  The intent of this loop is to operate like the standard group fetch for normal scans.  So  it should just work to fetch N rows and have the loop check for N, and just return from the middle of the loop and leave the scan to get the rest of the rows on the next scan.  It shouldn&apos;t be necessary to size the group exactly and should not be necessary to just give up on a page if it has more rows.&lt;/p&gt;

&lt;p&gt;I have attached a quick patch i did, but have not run full tests.  It did seem to pass the attached bug case and passed the existing online compress test.  Would appreciate if you could run this patch with your debugging to verify that we get all 111 rows rather than skipping the remaining 11.&lt;/p&gt;

&lt;p&gt;A real checkin should include a new test case, probably based on the recent case that  reproduces the problem.  Though I noted that license has not been granted on that attachment.  &lt;/p&gt;</comment>
                            <comment id="12492447" author="kurti" created="Sat, 28 Apr 2007 08:16:11 +0100"  >&lt;p&gt;Mike,&lt;/p&gt;

&lt;p&gt;I had to run the compress 3 times until it stopped finding empty rows, which is one pass worse than my patch &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12494970" author="mayureshnirhali" created="Fri, 11 May 2007 07:54:40 +0100"  >&lt;p&gt;Thanks Mike for clarifying the behavior.&lt;/p&gt;

&lt;p&gt;On a second thought, Option 2 mentioned above would not be suitable because the size will also have to changed for few other arrays and huge size might lead to OOME. The existing approach as described in mike&apos;s comment sounds reasonable.&lt;/p&gt;

&lt;p&gt;I debugged mike&apos;s quick patch and it seems that after reaching the limit (page is unlatched), scan_position is not repositioned correctly. In fact, in this special case, on attempt to fetch next group, no valid page is found. So, only 100 rows can be cleaned per Compress operation.&lt;/p&gt;

&lt;p&gt;I will work on a follow up patch from tje patch mike attached. Thanks again mike.&lt;/p&gt;</comment>
                            <comment id="12495008" author="mayureshnirhali" created="Fri, 11 May 2007 10:27:24 +0100"  >&lt;p&gt;I have created a new patch, derby2549_v2.diff.&lt;/p&gt;

&lt;p&gt;This change ensures that for the case when no of rows are more than row_array can hold, the same page will be fetched again in the next cycle to make sure the remaining rows are looked at.&lt;/p&gt;

&lt;p&gt;Kurt, could you please try out this patch.&lt;br/&gt;
I will start the testruns now.&lt;/p&gt;</comment>
                            <comment id="12495045" author="kurti" created="Fri, 11 May 2007 13:52:15 +0100"  >&lt;p&gt;Mayuresh,&lt;/p&gt;

&lt;p&gt;the patch is working fine and it compresses the database within one pass.&lt;/p&gt;

&lt;p&gt;Thanks for the good work!&lt;/p&gt;</comment>
                            <comment id="12495105" author="mikem" created="Fri, 11 May 2007 18:40:55 +0100"  >&lt;p&gt;notes on the recent patch:&lt;br/&gt;
o it looks like your new lines expect 8 space tabs, derby code should either use not indent tabs or should use&lt;br/&gt;
    4 space tabs.  &lt;br/&gt;
o this level of code should not be doing &amp;#8211; on the page number, it should use the raw store interfaces to move &lt;br/&gt;
    to next and previous pages.  There are a couple of reasons:&lt;br/&gt;
    1) even though the current raw store implementation dones have pages for each container laid out from 0 to N,&lt;br/&gt;
         future implementations may not.&lt;br/&gt;
     2) The get next and get previous interfaces take care of  postioning on the next USER head page &amp;#8211; by doing &lt;br/&gt;
           &amp;#8211; or ++ you may get put on an overflow row page, a raw store internal bit map page, ...&lt;/p&gt;

&lt;p&gt;o As you found in your debugging the problem with my previous patch was that the position of the scan was not&lt;br/&gt;
    properly maintained in the scan_position (that will teach me to copy/paste code from other parts of system).  &lt;br/&gt;
    I think a better fix would be to properly position the scan on the right  row, rather than letting the code get to &lt;br/&gt;
     the postion at next page code path and then reposition backward to the previous page.   &lt;/p&gt;

&lt;p&gt;    Scan positions are meant to be maintained by a couple of different means.  While you have a latch on the page&lt;br/&gt;
    it is fine to just maintain the slot number as nothing can change out from under you unless you do it.  If you &lt;br/&gt;
    are going to give up the latch on heap scan then the usual way to maintain a scan is by getting the record &lt;br/&gt;
     handl associated with the current slot number, then this can be used to repostion the scan the next trip back.&lt;br/&gt;
     I&apos;ll post another patch with a suggestion, let me know what you think.  Again I haven&apos;t had time to debug it.&lt;/p&gt;

&lt;p&gt;     Also it would be good to get a test added to the test suite for this bug, do you plan on doing that?  I think  the&lt;br/&gt;
     easiest case would be:&lt;br/&gt;
     o create a table with 1 column, smallest datatype possible - say smallint, and largest page size.  It would be good if the&lt;br/&gt;
         test case had more than 200 rows that could be moved so it would test visiting the same page more than&lt;br/&gt;
         2 times.&lt;br/&gt;
     o add enough rows to get a reasonable number of pages - say 10.&lt;br/&gt;
     o delete rows leaving at least one row per page, probably easiest if you just delete every row execept each 100th row in the order you inserted them , or something like that. &lt;/p&gt;</comment>
                            <comment id="12495107" author="mikem" created="Fri, 11 May 2007 18:44:41 +0100"  >&lt;p&gt;patch illustrating most recent comments on saving row position.  Not ready for commit - no tests/debugging done.&lt;/p&gt;</comment>
                            <comment id="12495167" author="kurti" created="Fri, 11 May 2007 22:07:32 +0100"  >&lt;p&gt;I created a testcase as Michael described, but it DOES NOT reproduce the problem, i.e. there is nothing compressed. But maybe it is a good start for somebody else.&lt;/p&gt;</comment>
                            <comment id="12495492" author="mayureshnirhali" created="Mon, 14 May 2007 08:12:45 +0100"  >&lt;p&gt;Thanks Mike for your expert comments. I realized that &apos;--&apos; is inappropriate after posting the patch. I am sure it would have taken a bit more time for me to come up with that solution due to my limited understanding. I appreciate your time for the explanation and the patch.&lt;/p&gt;

&lt;p&gt;I found two small nits in the latest patch. When, getRecordHandleAtSlot is called scan_position has already moved back to the previous slot. This will imply incorrect behavior when current_slot becomes -1. I have fixed this by storing the current_slot number in a new variable temp_current_slot and passing this to getRecordHandleAtSlot.&lt;/p&gt;

&lt;p&gt;I am starting testruns for this latest patch now.&lt;/p&gt;

&lt;p&gt;I plan to add a test for this based on the repro attached. I will try to cut down the time taken by the test by using small size data. I need some time for this as I am not very familiar with junit fixtures. I am hoping that the testcase addition will go as a separate patch. let me know your thoughts ??&lt;/p&gt;


</comment>
                            <comment id="12495573" author="mayureshnirhali" created="Mon, 14 May 2007 13:04:31 +0100"  >&lt;p&gt;derbyall and Suites_All did NOT show any new failures for the patch v3.&lt;/p&gt;</comment>
                            <comment id="12495895" author="mayureshnirhali" created="Tue, 15 May 2007 09:39:52 +0100"  >&lt;p&gt;I have added another test to store/OnlineCompressTest.java.&lt;br/&gt;
The test is based on the repro I had attached. I have downsized the time required by the test to something much lower than the repro.&lt;/p&gt;

&lt;p&gt;The patch only has test changes (test code + master files)&lt;/p&gt;

&lt;p&gt;The 2 patches, derby2549_v3.diff and derby2549_testv1.diff are ready for review.&lt;/p&gt;</comment>
                            <comment id="12497638" author="mikem" created="Tue, 22 May 2007 00:49:07 +0100"  >&lt;p&gt;I am ready to commit your test and  patch, but the attachments you have submitted are not checked to grant &lt;br/&gt;
license to the ASF.  &lt;/p&gt;</comment>
                            <comment id="12497639" author="mikem" created="Tue, 22 May 2007 00:51:32 +0100"  >&lt;p&gt;If you click on the manage attachments link to the left of the attachments you will see a report  on each of the attachements.  Actually don&apos;t know if you can change the grant, so in the worst case you may have to submit your latest 2 again, this time checking the box to grant license when you submit them.&lt;/p&gt;</comment>
                            <comment id="12497727" author="mayureshnirhali" created="Tue, 22 May 2007 07:21:26 +0100"  >&lt;p&gt;attaching patches with Grant license flag set.&lt;/p&gt;</comment>
                            <comment id="12498002" author="mikem" created="Tue, 22 May 2007 21:47:08 +0100"  >&lt;p&gt;I have committed  the fix to the trunk with change 540657, and backported the change into the 10.2 line with &lt;br/&gt;
change 540743&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12356313" name="2549-histogram.png" size="3533" author="kurti" created="Thu, 26 Apr 2007 11:39:47 +0100"/>
                            <attachment id="12356405" name="A2549Test.java" size="4572" author="mayureshnirhali" created="Fri, 27 Apr 2007 13:48:41 +0100"/>
                            <attachment id="12357138" name="A2549Test2.java" size="1025" author="kurti" created="Fri, 11 May 2007 22:07:32 +0100"/>
                            <attachment id="12355772" name="DerbyDiskSpaceDiag.java" size="9834" author="kristwaa" created="Wed, 18 Apr 2007 16:31:21 +0100"/>
                            <attachment id="12356228" name="derby-2549-v1.diff" size="671" author="kurti" created="Wed, 25 Apr 2007 12:55:05 +0100"/>
                            <attachment id="12356441" name="derby2549_mikem.diff" size="2072" author="mikem" created="Fri, 27 Apr 2007 23:00:31 +0100"/>
                            <attachment id="12357125" name="derby2549_mikemv2.diff" size="2304" author="mikem" created="Fri, 11 May 2007 18:44:40 +0100"/>
                            <attachment id="12357837" name="derby2549_testv1.diff" size="3107" author="mayureshnirhali" created="Tue, 22 May 2007 07:21:26 +0100"/>
                            <attachment id="12357362" name="derby2549_testv1.diff" size="3107" author="mayureshnirhali" created="Tue, 15 May 2007 09:39:52 +0100"/>
                            <attachment id="12357093" name="derby2549_v2.diff" size="2707" author="mayureshnirhali" created="Fri, 11 May 2007 10:27:23 +0100"/>
                            <attachment id="12357836" name="derby2549_v3.diff" size="2858" author="mayureshnirhali" created="Tue, 22 May 2007 07:21:26 +0100"/>
                            <attachment id="12357226" name="derby2549_v3.diff" size="2858" author="mayureshnirhali" created="Mon, 14 May 2007 08:12:45 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>12.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 18 Apr 2007 14:48:09 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23095</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310090" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Issue &amp; fix info</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10102"><![CDATA[Patch Available]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy0mgv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>37458</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            </customfields>
    </item>
</channel>
</rss>