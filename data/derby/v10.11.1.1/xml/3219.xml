<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:53:50 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-3219/DERBY-3219.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-3219] Group by query with many aggregate columns and case statements fails with: ERROR XSDA7: Restore of a serializable or SQLData object of class , attempted to read more data than was originally stored</title>
                <link>https://issues.apache.org/jira/browse/DERBY-3219</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;using the attached database (v10.3) - &quot; select * from pivotview &quot; fails with the stack trace below.  A view (pivotview_ok) created on a subset of the columns in pivotview executes fine.  Adding one column back into pivotview_ok causes failures most of the time.  See attached for view definitions.&lt;/p&gt;

&lt;p&gt;2007-11-21 00:58:49.421 GMT Thread&lt;span class=&quot;error&quot;&gt;&amp;#91;main,5,main&amp;#93;&lt;/span&gt; (XID = 2734422), (SESSIONID = 0), (DATABASE = pivotview), (DRDAID = null), Failed Statement is: select * from pivotview&lt;br/&gt;
ERROR XSDA7: Restore of a serializable or SQLData object of class , attempted to read more data than was originally stored&lt;br/&gt;
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.StreamFileContainer.fetchNext(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.StreamFileContainerHandle.fetchNext(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.sort.MergeScan.mergeARow(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.sort.MergeScan.init(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.sort.MergeSort.openSortScan(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.RAMTransaction.openSortScan(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.GroupedAggregateResultSet.loadSorter(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.GroupedAggregateResultSet.openCore(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.ProjectRestrictResultSet.openCore(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.BasicNoPutResultSetImpl.open(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.ij.executeImmediate(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.utilMain.doCatch(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.utilMain.runScriptGuts(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.utilMain.go(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.Main.go(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.Main.mainCore(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.Main14.main(Unknown Source)&lt;br/&gt;
	at org.apache.derby.tools.ij.main(Unknown Source)&lt;br/&gt;
Caused by: java.io.EOFException&lt;br/&gt;
	at java.io.DataInputStream.readBoolean(DataInputStream.java:248)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.MaxMinAggregator.readExternal(Unknown Source)&lt;br/&gt;
	at org.apache.derby.iapi.services.io.FormatIdInputStream.readObject(Unknown Source)&lt;br/&gt;
	at org.apache.derby.iapi.types.UserType.readExternal(Unknown Source)&lt;br/&gt;
	... 22 more&lt;br/&gt;
============= begin nested exception, level (1) ===========&lt;br/&gt;
java.io.EOFException&lt;br/&gt;
	at java.io.DataInputStream.readBoolean(DataInputStream.java:248)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.MaxMinAggregator.readExternal(Unknown Source)&lt;br/&gt;
	at org.apache.derby.iapi.services.io.FormatIdInputStream.readObject(Unknown Source)&lt;br/&gt;
	at org.apache.derby.iapi.types.UserType.readExternal(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.StreamFileContainer.fetchNext(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.raw.data.StreamFileContainerHandle.fetchNext(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.sort.MergeScan.mergeARow(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.sort.MergeScan.init(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.sort.MergeSort.openSortScan(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.store.access.RAMTransaction.openSortScan(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.GroupedAggregateResultSet.loadSorter(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.GroupedAggregateResultSet.openCore(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.ProjectRestrictResultSet.openCore(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.execute.BasicNoPutResultSetImpl.open(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.ij.executeImmediate(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.utilMain.doCatch(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.utilMain.runScriptGuts(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.utilMain.go(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.Main.go(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.Main.mainCore(Unknown Source)&lt;br/&gt;
	at org.apache.derby.impl.tools.ij.Main14.main(Unknown Source)&lt;br/&gt;
	at org.apache.derby.tools.ij.main(Unknown Source)&lt;br/&gt;
============= end nested exception, level (1) ===========&lt;br/&gt;
Cleanup action completed&lt;/p&gt;</description>
                <environment></environment>
        <key id="12382936">DERBY-3219</key>
            <summary>Group by query with many aggregate columns and case statements fails with: ERROR XSDA7: Restore of a serializable or SQLData object of class , attempted to read more data than was originally stored</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="bryanpendleton">Bryan Pendleton</assignee>
                                    <reporter username="stan">Stan Bradbury</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 Nov 2007 01:16:44 +0000</created>
                <updated>Fri, 21 Jan 2011 17:51:05 +0000</updated>
                            <resolved>Sat, 31 May 2008 18:08:35 +0100</resolved>
                                    <version>10.3.1.4</version>
                                    <fixVersion>10.5.1.1</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12544134" author="stan" created="Wed, 21 Nov 2007 01:22:26 +0000"  >&lt;p&gt;Zipfile contains database and a file with the view definitions.  Note that with this database the test query returns over 2000 rows.  With a smaller set of data (&amp;gt;1000 rows) the PIVOTVIEW query returns without failing.&lt;/p&gt;</comment>
                            <comment id="12553525" author="gregburrow" created="Wed, 19 Dec 2007 22:46:14 +0000"  >&lt;p&gt;I believe the stack trace below is the same issue but the java.io.EOFException occurs at a slightly different location.  Test was run on Derby 10.3.1.4.&lt;/p&gt;

&lt;p&gt;Internal Exception: java.sql.SQLException: Restore of a serializable or SQLData object of class , attempted to read more data than was originally stored&lt;br/&gt;
Error Code: 20000&lt;br/&gt;
Call: SELECT MAX(ID) AS ID, INCALLID, MAX(SEIZEDATE), MAX(SEIZETIME), MAX(SYSTEMTIME), MAX(ORIGCALLEDNUMBER), MAX(ORIGCALLINGNUMBER), MAX(MYRESOURCEGROUP), MAX(THEOTHERRESOURCEGROUP), MAX(ROUTELIST), MAX(RELEASECAUSE), MAX(CALLINGNUMBER), MAX(CALLEDNUMBER), MAX(REDIRECTNUMBER) FROM CDRENTITY WHERE ((ID &amp;gt; 0) AND (DIRECTION LIKE &apos;1&apos;)) GROUP BY INCALLID ORDER BY ID ASC&lt;br/&gt;
Query: DataReadQuery()&lt;br/&gt;
        at oracle.toplink.essentials.exceptions.DatabaseException.sqlException(DatabaseException.java:319)&lt;br/&gt;
        at oracle.toplink.essentials.internal.databaseaccess.DatabaseAccessor.basicExecuteCall(DatabaseAccessor.java:566)&lt;br/&gt;
        at oracle.toplink.essentials.internal.databaseaccess.DatabaseAccessor.executeCall(DatabaseAccessor.java:452)&lt;br/&gt;
        at oracle.toplink.essentials.threetier.ServerSession.executeCall(ServerSession.java:473)&lt;br/&gt;
        at oracle.toplink.essentials.internal.queryframework.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:228)&lt;br/&gt;
        at oracle.toplink.essentials.internal.queryframework.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:214)&lt;br/&gt;
        at oracle.toplink.essentials.internal.queryframework.DatasourceCallQueryMechanism.executeSelectCall(DatasourceCallQueryMechanism.java:285)&lt;br/&gt;
        at oracle.toplink.essentials.internal.queryframework.DatasourceCallQueryMechanism.executeSelect(DatasourceCallQueryMechanism.java:267)&lt;br/&gt;
        at oracle.toplink.essentials.queryframework.DataReadQuery.executeNonCursor(DataReadQuery.java:120)&lt;br/&gt;
        at oracle.toplink.essentials.queryframework.DataReadQuery.executeDatabaseQuery(DataReadQuery.java:112)&lt;br/&gt;
        at oracle.toplink.essentials.queryframework.DatabaseQuery.execute(DatabaseQuery.java:628)&lt;br/&gt;
        at oracle.toplink.essentials.queryframework.DatabaseQuery.executeInUnitOfWork(DatabaseQuery.java:555)&lt;br/&gt;
        at oracle.toplink.essentials.internal.sessions.UnitOfWorkImpl.internalExecuteQuery(UnitOfWorkImpl.java:2233)&lt;br/&gt;
        at oracle.toplink.essentials.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:952)&lt;br/&gt;
        at oracle.toplink.essentials.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:924)&lt;br/&gt;
        at oracle.toplink.essentials.internal.ejb.cmp3.base.EJBQueryImpl.executeReadQuery(EJBQueryImpl.java:367)&lt;br/&gt;
        at oracle.toplink.essentials.internal.ejb.cmp3.base.EJBQueryImpl.getResultList(EJBQueryImpl.java:478)&lt;br/&gt;
        at com.stratus.emergent.server.database.SupportDbQuery.nativeCdrQuery(SupportDbQuery.java:296)&lt;br/&gt;
        at com.stratus.emergent.server.database.SupportDbQuery.nativeFirstCdrQuery(SupportDbQuery.java:391)&lt;br/&gt;
        at com.stratus.emergent.server.database.SupportDbQuery.getCdrsClient(SupportDbQuery.java:512)&lt;br/&gt;
        at com.stratus.emergent.web.servlet.NewCdrServlet.queryCdrs(NewCdrServlet.java:109)&lt;br/&gt;
        at com.stratus.emergent.web.servlet.NewCdrServlet.processRequest(NewCdrServlet.java:86)&lt;br/&gt;
        at com.stratus.emergent.web.servlet.NewCdrServlet.doPost(NewCdrServlet.java:153)&lt;br/&gt;
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:709)&lt;br/&gt;
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)&lt;br/&gt;
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:252)&lt;br/&gt;
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)&lt;br/&gt;
        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:213)&lt;br/&gt;
        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:178)&lt;br/&gt;
        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:126)&lt;br/&gt;
        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:105)&lt;br/&gt;
        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:107)&lt;br/&gt;
        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:148)&lt;br/&gt;
        at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:869)&lt;br/&gt;
        at org.apache.coyote.http11.Http11BaseProtocol$Http11ConnectionHandler.processConnection(Http11BaseProtocol.java:664)&lt;br/&gt;
        at org.apache.tomcat.util.net.PoolTcpEndpoint.processSocket(PoolTcpEndpoint.java:527)&lt;br/&gt;
        at org.apache.tomcat.util.net.LeaderFollowerWorkerThread.runIt(LeaderFollowerWorkerThread.java:80)&lt;br/&gt;
        at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:684)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:595)&lt;br/&gt;
Caused by: java.sql.SQLException: Restore of a serializable or SQLData object of class , attempted to read more data than was originally stored&lt;br/&gt;
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeStatement(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeQuery(Unknown Source)&lt;br/&gt;
        at oracle.toplink.essentials.internal.databaseaccess.DatabaseAccessor.executeSelect(DatabaseAccessor.java:726)&lt;br/&gt;
        at oracle.toplink.essentials.internal.databaseaccess.DatabaseAccessor.basicExecuteCall(DatabaseAccessor.java:501)&lt;br/&gt;
        ... 37 more&lt;br/&gt;
Caused by: java.sql.SQLException: Java exception: &apos;: java.io.EOFException&apos;.&lt;br/&gt;
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.Util.javaException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)&lt;br/&gt;
        ... 46 more&lt;br/&gt;
Caused by: java.io.EOFException&lt;br/&gt;
        at java.io.DataInputStream.readBoolean(DataInputStream.java:222)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.MaxMinAggregator.readExternal(Unknown Source)&lt;br/&gt;
        at org.apache.derby.iapi.services.io.FormatIdInputStream.readObject(Unknown Source)&lt;br/&gt;
        at org.apache.derby.iapi.types.UserType.readExternal(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.store.raw.data.StreamFileContainer.fetchNext(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.store.raw.data.StreamFileContainerHandle.fetchNext(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.store.access.sort.MergeScan.mergeARow(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.store.access.sort.MergeScan.init(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.store.access.sort.MergeSort.openSortScan(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.store.access.RAMTransaction.openSortScan(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.GroupedAggregateResultSet.loadSorter(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.GroupedAggregateResultSet.openCore(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.ProjectRestrictResultSet.openCore(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.SortResultSet.openCore(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.BasicNoPutResultSetImpl.open(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)&lt;br/&gt;
        ... 42 more&lt;/p&gt;</comment>
                            <comment id="12595926" author="bryanpendleton" created="Sun, 11 May 2008 18:37:47 +0100"  >&lt;p&gt;In a sane build of the current trunk, I see:&lt;/p&gt;

&lt;p&gt;DEBUG DebugByteTeeOutputStream OUTPUT: FormatableError:read error    : java.io.EOFException&lt;br/&gt;
FormatableError:class written : class org.apache.derby.impl.sql.execute.MaxMinAggregatorFormatableError:read back as nullFormatableError:write id      : 152&lt;br/&gt;
Exception trace: &lt;br/&gt;
java.io.EOFException&lt;br/&gt;
    at java.io.DataInputStream.readBoolean(DataInputStream.java:222)&lt;br/&gt;
    at org.apache.derby.impl.sql.execute.MaxMinAggregator.readExternal(MaxMinAggregator.java:107)&lt;br/&gt;
    at org.apache.derby.iapi.services.io.FormatIdInputStream.readObject(FormatIdInputStream.java:126)&lt;br/&gt;
    at org.apache.derby.iapi.services.io.DebugByteTeeOutputStream.checkObject(DebugByteTeeOutputStream.java:61)&lt;br/&gt;
    at org.apache.derby.iapi.services.io.FormatIdOutputStream.writeObject(FormatIdOutputStream.java:168)&lt;br/&gt;
    at org.apache.derby.iapi.types.UserType.writeExternal(UserType.java:286)&lt;br/&gt;
    at org.apache.derby.impl.store.raw.data.StreamFileContainer.writeColumn(StreamFileContainer.java:758)&lt;br/&gt;
    at org.apache.derby.impl.store.raw.data.StreamFileContainer.load(StreamFileContainer.java:525)&lt;br/&gt;
    at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.addAndLoadStreamContainer(BaseDataFileFactory.java:921)&lt;br/&gt;
    at org.apache.derby.impl.store.raw.xact.Xact.addAndLoadStreamContainer(Xact.java:1341)&lt;br/&gt;
    at org.apache.derby.impl.store.access.sort.MergeSort.createMergeRun(MergeSort.java:766)&lt;br/&gt;
    at org.apache.derby.impl.store.access.sort.MergeInserter.insert(MergeInserter.java:178)&lt;br/&gt;
    at org.apache.derby.impl.sql.execute.GroupedAggregateResultSet.loadSorter(GroupedAggregateResultSet.java:308)&lt;br/&gt;
    at org.apache.derby.impl.sql.execute.GroupedAggregateResultSet.openCore(GroupedAggregateResultSet.java:180)&lt;br/&gt;
    at org.apache.derby.impl.sql.execute.ProjectRestrictResultSet.openCore(ProjectRestrictResultSet.java:168)&lt;br/&gt;
    at org.apache.derby.impl.sql.execute.BasicNoPutResultSetImpl.open(BasicNoPutResultSetImpl.java:245)&lt;br/&gt;
    at org.apache.derby.impl.sql.GenericPreparedStatement.execute(GenericPreparedStatement.java:384)&lt;br/&gt;
    at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(EmbedStatement.java:1235)&lt;br/&gt;
    at org.apache.derby.impl.jdbc.EmbedStatement.execute(EmbedStatement.java:625)&lt;br/&gt;
    at org.apache.derby.impl.jdbc.EmbedStatement.execute(EmbedStatement.java:555)&lt;br/&gt;
    at org.apache.derby.impl.tools.ij.ij.executeImmediate(ij.java:329)&lt;br/&gt;
    at org.apache.derby.impl.tools.ij.utilMain.doCatch(utilMain.java:508)&lt;br/&gt;
    at org.apache.derby.impl.tools.ij.utilMain.runScriptGuts(utilMain.java:353)&lt;br/&gt;
    at org.apache.derby.impl.tools.ij.utilMain.go(utilMain.java:248)&lt;br/&gt;
    at org.apache.derby.impl.tools.ij.Main.go(Main.java:215)&lt;br/&gt;
    at org.apache.derby.impl.tools.ij.Main.mainCore(Main.java:181)&lt;br/&gt;
    at org.apache.derby.impl.tools.ij.Main.main(Main.java:73)&lt;br/&gt;
    at org.apache.derby.tools.ij.main(ij.java:59)&lt;/p&gt;</comment>
                            <comment id="12595966" author="bryanpendleton" created="Mon, 12 May 2008 05:14:29 +0100"  >&lt;p&gt;I kind of wandered around in the debugger for a while, and I noticed the following:&lt;/p&gt;

&lt;p&gt;1) The problem appears to occur when the &quot;max&quot; value in question is a SQLVarChar&lt;br/&gt;
     whose value is &quot;&quot; (that is, a string of length 0).&lt;br/&gt;
2) The underlying exception which causes the problem is a EOFException&lt;br/&gt;
3) When reading a SQLVarchar whose value is &quot;&quot;, we seem to normally&lt;br/&gt;
     expect and handle an EOFException. See, in particular, this section of code&lt;br/&gt;
     in SQLChar.readExternal:&lt;/p&gt;


&lt;p&gt;            } catch (EOFException eof) &lt;/p&gt;
{
                if (utflen != 0)
                    throw new EOFException();

                // This is the case for a 0 length string.
                // OR the string was originally streamed in
                // which puts a 0 for utflen but no trailing
                // E0,0,0 markers.
                break readingLoop;
            }

&lt;p&gt;4) When the problem occurs, it seems that we don&apos;t get the expected EOFException,&lt;br/&gt;
    but rather we proceed a bit farther and then get the EOFException at an&lt;br/&gt;
    unexpected point.&lt;/p&gt;

&lt;p&gt;I&apos;m wondering whether the problem is that the readExternal/writeExternal&lt;br/&gt;
implementation for SQL&lt;span class=&quot;error&quot;&gt;&amp;#91;var&amp;#93;&lt;/span&gt;char values of length 0 is flawed, because it&lt;br/&gt;
can only handle the case where the SQL&lt;span class=&quot;error&quot;&gt;&amp;#91;var&amp;#93;&lt;/span&gt;char value is at the &lt;b&gt;end&lt;/b&gt; of&lt;br/&gt;
the buffer, but in the case of the MaxMinAggregator, the SQL&lt;span class=&quot;error&quot;&gt;&amp;#91;var&amp;#93;&lt;/span&gt;char value&lt;br/&gt;
is buried inside of a larger data structure (with boolean isNull and boolean isMax)&lt;br/&gt;
bookends around the underlying value), and thus the EOFException occurs&lt;br/&gt;
unexpectedly.&lt;/p&gt;</comment>
                            <comment id="12596257" author="bryanpendleton" created="Tue, 13 May 2008 04:05:14 +0100"  >&lt;p&gt;I&apos;m increasingly convinced that the problem lies in SQLChar.readExternal,&lt;br/&gt;
due to the fact that it can&apos;t tell the difference between a true string-of-length-0,&lt;br/&gt;
and a string which is longer than 65536 bytes in length, and therefore is&lt;br/&gt;
being &quot;streamed&quot; with a 0 length.&lt;/p&gt;

&lt;p&gt;That is, for a string with a length &amp;lt; 65536, SQLChar.readExternal expects:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;2 byte actual length of the string&lt;/li&gt;
	&lt;li&gt;the string&apos;s bytes&lt;br/&gt;
While for a string with a length &amp;gt;= 65536, SQLChar.readExternal expects:&lt;/li&gt;
	&lt;li&gt;2 byte length code with a value of 0&lt;/li&gt;
	&lt;li&gt;the string&apos;s bytes&lt;/li&gt;
	&lt;li&gt;a special 3-byte marker sequence that indicates that the string is complete&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The problem is that with a string-of-length-0, SQLChar.readExternal can&apos;t&lt;br/&gt;
tell the difference. It sees the length of 0, and doesn&apos;t know whether it&lt;br/&gt;
will be followed by 0 bytes of actual data, or by at least 65536 bytes of&lt;br/&gt;
actual data.&lt;/p&gt;

&lt;p&gt;I&apos;ve had two ideas:&lt;/p&gt;

&lt;p&gt;1) If we are allowed to change the data format used by readExternal/writeExternal,&lt;br/&gt;
we could change the externalized representaiton of the string-of-length-0&lt;br/&gt;
so that it was:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;two byte length code (0)&lt;/li&gt;
	&lt;li&gt;0 bytes of actual string data&lt;/li&gt;
	&lt;li&gt;3 byte EOF marker sequence&lt;br/&gt;
This way, if we ever saw the initial length code set to 0, we&apos;d know that&lt;br/&gt;
we&apos;d &lt;b&gt;always&lt;/b&gt; read until we saw the 3-byte EOF marker sequence, and&lt;br/&gt;
it would &lt;b&gt;never&lt;/b&gt; be acceptable to read until EOF&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;2) If we are not allowed to change the SQL char external data format, then&lt;br/&gt;
perhaps we could tell the difference after the fact by realizing that we hit an&lt;br/&gt;
EOF exception after a non-zero number of bytes were read, but before 65536+&lt;br/&gt;
bytes were read, and therefore we accidentally processed a string-of-length-0&lt;br/&gt;
in such a way as to &quot;gobble&quot; data that wasn&apos;t ours, and perhaps we could&lt;br/&gt;
then use an algorithm which would &quot;mark&quot; the input stream and be able&lt;br/&gt;
to push back the data we weren&apos;t supposed to have read, by restoring back&lt;br/&gt;
to the mark.&lt;/p&gt;

&lt;p&gt;Anybody know if we&apos;re allowed to change the format used by SQLChar.read/writeExternal?&lt;/p&gt;</comment>
                            <comment id="12596258" author="bryanpendleton" created="Tue, 13 May 2008 04:13:36 +0100"  >&lt;p&gt;Well, this one line patch makes the repro script pass:&lt;/p&gt;

&lt;p&gt;Index: java/engine/org/apache/derby/iapi/types/SQLChar.java&lt;br/&gt;
===================================================================&lt;br/&gt;
&amp;#8212; java/engine/org/apache/derby/iapi/types/SQLChar.java        (revision 649830)&lt;br/&gt;
+++ java/engine/org/apache/derby/iapi/types/SQLChar.java        (working copy)&lt;br/&gt;
@@ -551,7 +551,7 @@&lt;/p&gt;

&lt;p&gt;                boolean isLongUTF = false;&lt;br/&gt;
                // for length than 64K, see format description above&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (utflen &amp;gt; 65535)&lt;br/&gt;
+               if (utflen &amp;gt; 65535 || utflen == 0)&lt;br/&gt;
                {&lt;br/&gt;
                        isLongUTF = true;&lt;br/&gt;
                        utflen = 0;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;ll have to do more testing to see if it breaks other parts of the system.&lt;/p&gt;</comment>
                            <comment id="12596395" author="bryanpendleton" created="Tue, 13 May 2008 14:46:42 +0100"  >&lt;p&gt;The full regression test run was successful with this change.&lt;/p&gt;

&lt;p&gt;It would be nice to develop a standalone test case, but I&apos;m not&lt;br/&gt;
sure of how to cause SQLChar.readExternal to be invoked in&lt;br/&gt;
a simple test case. The reproduction script is quite complicated,&lt;br/&gt;
because it has to fetch a large number of intermediate results,&lt;br/&gt;
enough to force the internal buffers to fill and the partial results&lt;br/&gt;
to be written out to temp files.&lt;/p&gt;

&lt;p&gt;Any suggestions for how to write a simple standalone test case&lt;br/&gt;
which exercises SQLChar.readExternal/writeExternal?&lt;/p&gt;</comment>
                            <comment id="12596435" author="mikem" created="Tue, 13 May 2008 17:45:56 +0100"  >&lt;p&gt;I have not been following this issue, so just commenting on the idea of changing the format understood by read/write external for SQLchar.  I believe while readExternal is not used to read data from store pages into returned user columns, the corresponding interface readExternalFromArray() depends on understanding the same exact format as readExternal and both are tied to the format output by writeExternal.&lt;/p&gt;

&lt;p&gt;Originally readExternal and writeExternal was the only way data was read/written to disk by the store.  So when changing&lt;br/&gt;
them you need to consider the upgrade of existing data on disk.  At some point, pre-derby new interfaces were added for store&lt;br/&gt;
to use which could be highly optimized for reading and writing the data to the in memory array that represents the page whenever&lt;br/&gt;
store is interacting with the page - this was a huge performance win at the time, I have not idea given the advances in JIT technology&lt;br/&gt;
whether that is still the case. &lt;/p&gt;

&lt;p&gt;So there is no &quot;rule&quot; against changing the format, but if one does it they need to consider soft and hard upgrade dependencies for&lt;br/&gt;
all system and user character based data.  Unfortunately  the current format does not include any type of version id in the data&lt;br/&gt;
itself, so handling the formating has to be at a higher level.  For instance we could handle it at the column format id level by having&lt;br/&gt;
and old char format id and new char format id.&lt;/p&gt;</comment>
                            <comment id="12596437" author="mikem" created="Tue, 13 May 2008 17:49:30 +0100"  >&lt;p&gt;I notice that the stack trace printed involves the sorter, so it may be able to reproduce by just creating a test case with enough&lt;br/&gt;
rows that also include the problem data item and then writing a simple query with an order by.  The trick is to add enough rows&lt;br/&gt;
so the sort is not in memory.&lt;/p&gt;</comment>
                            <comment id="12596446" author="bryanpendleton" created="Tue, 13 May 2008 18:01:35 +0100"  >&lt;p&gt;Hi Mike, thanks for the suggestions; I&apos;ll try to create a test case along those lines.&lt;/p&gt;

&lt;p&gt;I&apos;m actually proposing to change &lt;b&gt;writeExternal&lt;/b&gt; but not &lt;b&gt;readExternal&lt;/b&gt;, as&lt;br/&gt;
readExternal already understands the new format that I propose to use&lt;br/&gt;
for zero-length-strings.&lt;/p&gt;

&lt;p&gt;Where would be a good place to set a breakpoint so I can step through&lt;br/&gt;
the code which writes a SQLChar onto a Store page and reads it from the page?&lt;/p&gt;</comment>
                            <comment id="12596472" author="mikem" created="Tue, 13 May 2008 18:59:54 +0100"  >&lt;p&gt;The normal path through the code for getting a record off the page and putting it into a &quot;row&quot; is in&lt;br/&gt;
opensource/java/engine/org/apache/derby/impl/store/raw/data/StoredPage!readRecordFromArray()&lt;br/&gt;
Look for readExternalFromArray calls in this routine.  There is one other call to readExternalFromArray&lt;br/&gt;
which is used for qualifying rows in store - so depending on query it may also be called to read the&lt;br/&gt;
data.&lt;/p&gt;

&lt;p&gt;Writing the data to the page is more complicated.  The data first gets written to a log record -&lt;br/&gt;
just search for writeExternal in same file.  And then it makes it way to the page as part of &lt;br/&gt;
calling the doMe() method of the log record - for instance:&lt;br/&gt;
opensource/java/engine/org/apache/derby/impl/store/raw/data/InsertOperation.java!doMe()&lt;/p&gt;</comment>
                            <comment id="12596480" author="mikem" created="Tue, 13 May 2008 19:22:32 +0100"  >&lt;p&gt;Off hand I don&apos;t know if current derby code will ever read existing on disk character code using readExternal.  Definitlely that is&lt;br/&gt;
not the normal path.  If so then changing writeExternal to write new data in a format that is backward compatible readable would &lt;br/&gt;
be ok, though is a lot of overhead for a &quot;0&quot; length string.  I will try to think of a case where old db&apos;s may still have the old format for the empty string and thus would not be fixed by your writeExternal change.&lt;/p&gt;</comment>
                            <comment id="12597740" author="bryanpendleton" created="Sat, 17 May 2008 18:13:14 +0100"  >&lt;p&gt;Thanks for the pointers Mike. I stepped through the read/write code to try to&lt;br/&gt;
understand it better. For completeness, the stack at the point of the&lt;br/&gt;
writeExternal call is:&lt;/p&gt;

&lt;p&gt;BasePage.insert&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;StoredPage.insertAtSlot&lt;/li&gt;
	&lt;li&gt;BasePage.insertAtSlot&lt;/li&gt;
	&lt;li&gt;BasePage.insertNoOverflow&lt;/li&gt;
	&lt;li&gt;LoggableActions.actionInsert&lt;/li&gt;
	&lt;li&gt;InsertOperation.&amp;lt;init&amp;gt;&lt;/li&gt;
	&lt;li&gt;InsertOperation.writeOptionalDataToBuffer&lt;/li&gt;
	&lt;li&gt;StoredPage.logRow&lt;/li&gt;
	&lt;li&gt;StoredPage.logColumn&lt;/li&gt;
	&lt;li&gt;SQLChar.writeExternal&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12597741" author="bryanpendleton" created="Sat, 17 May 2008 18:23:37 +0100"  >&lt;p&gt;Since (I believe) the essence of this problem is that if a SQLChar-based&lt;br/&gt;
data value is included in an externalized object, it must be the last&lt;br/&gt;
item in that object&apos;s stream (so that the expected EOFException occurs&lt;br/&gt;
at the expected location in the stream), I tried an alternate technique&lt;br/&gt;
for patching this problem, which was to reverse the order of the items&lt;br/&gt;
in the MaxMinAggregator&apos;s externalized format, so that the data value&lt;br/&gt;
comes last in the stream:&lt;/p&gt;

&lt;p&gt;Index: java/engine/org/apache/derby/impl/sql/execute/MaxMinAggregator.java&lt;br/&gt;
===================================================================&lt;br/&gt;
&amp;#8212; java/engine/org/apache/derby/impl/sql/execute/MaxMinAggregator.java	(revision 656933)&lt;br/&gt;
+++ java/engine/org/apache/derby/impl/sql/execute/MaxMinAggregator.java	(working copy)&lt;br/&gt;
@@ -91,8 +91,8 @@&lt;br/&gt;
 	/////////////////////////////////////////////////////////////&lt;br/&gt;
 	public void writeExternal(ObjectOutput out) throws IOException&lt;/p&gt;
 	{
+		out.writeBoolean(isMax);
 		super.writeExternal(out);
-		out.writeBoolean(isMax);
 	}

&lt;p&gt; 	/** &lt;br/&gt;
@@ -103,8 +103,8 @@&lt;br/&gt;
 	 */&lt;br/&gt;
 	public void readExternal(ObjectInput in) &lt;br/&gt;
 		throws IOException, ClassNotFoundException &lt;/p&gt;
{
+		isMax = in.readBoolean();
 		super.readExternal(in);
-		isMax = in.readBoolean();
 	}
&lt;p&gt; 	/**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Get the formatID which corresponds to this class.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;With this patch, the repro script runs successfully. I haven&apos;t&lt;br/&gt;
yet done any other testing to see whether this patch has&lt;br/&gt;
any downsides.&lt;/p&gt;

&lt;p&gt;Any feedback on whether this is a more promising approach&lt;br/&gt;
would be appreciated.&lt;/p&gt;</comment>
                            <comment id="12597856" author="bryanpendleton" created="Sun, 18 May 2008 23:22:19 +0100"  >&lt;p&gt;The MaxMinAggregator change passes the regression tests.&lt;/p&gt;

&lt;p&gt;It seems like it should be less risky to be changing MaxMinAggregator&apos;s&lt;br/&gt;
external data format than SQLChar&apos;s external data format.&lt;/p&gt;

&lt;p&gt;How do we evaluate the risks (if there are any) of changing the&lt;br/&gt;
external data format for MaxMinAggregator? That is, how can we tell&lt;br/&gt;
if it affects any situations other than this particular issue (which is, when the&lt;br/&gt;
intermediate results for a GROUP BY aggregation overflow and have to&lt;br/&gt;
be written to a temp file).&lt;/p&gt;

&lt;p&gt;Meanwhile, I still need to attempt to write a standalone test case.&lt;/p&gt;
</comment>
                            <comment id="12597864" author="bryanpendleton" created="Mon, 19 May 2008 04:45:16 +0100"  >&lt;p&gt;Attached is &apos;maxminPatch.diff&apos;, the patch which was&lt;br/&gt;
pasted as a comment, and now is attached as a diff file.&lt;/p&gt;

&lt;p&gt;Also attached is &apos;repro.java&apos;, a standalone program&lt;br/&gt;
which reproduces the problem for me with the current&lt;br/&gt;
trunk. It would be great if somebody else could&lt;br/&gt;
confirm that &apos;repro.java&apos; reproduces the problem for them.&lt;/p&gt;

&lt;p&gt;I&apos;ll try to convert repro.java into a form which is&lt;br/&gt;
suitable for inclusion as a new test case in one&lt;br/&gt;
of our junit test suites, perhaps GroupByTest.java.&lt;/p&gt;</comment>
                            <comment id="12597865" author="bryanpendleton" created="Mon, 19 May 2008 05:02:18 +0100"  >&lt;p&gt;Attached is &apos;patchWithTest.diff&apos;, a patch proposal,&lt;br/&gt;
which contains the code change from minmaxPatch.diff&lt;br/&gt;
and the test program from repro.java converted to&lt;br/&gt;
run as a test case in GroupByTest.&lt;/p&gt;

&lt;p&gt;Please have a look and let me know what you think.&lt;/p&gt;</comment>
                            <comment id="12597879" author="thomanie" created="Mon, 19 May 2008 07:48:41 +0100"  >&lt;p&gt;I tried repro.java on a unpatched head of trunk on solaris x86, with multiple sun jdks (1.5.0_14, 1.6.0_04, 1.6.0_05), but it did not show any failures for me.&lt;br/&gt;
Could this be platform or jvm related?&lt;/p&gt;</comment>
                            <comment id="12597954" author="bryanpendleton" created="Mon, 19 May 2008 14:42:35 +0100"  >&lt;p&gt;Thanks for running the test, Thomas. The test is trying to force the intermediate sort&lt;br/&gt;
results to overflow and no longer fit in memory, so it could definitely be machine or&lt;br/&gt;
JDK related. On my machine, I was fiddling with the &quot;number of rows&quot; setting in the&lt;br/&gt;
test to try to provoke the error, and 2000 rows achieved the error, but 1900 did not,&lt;br/&gt;
but perhaps on other configurations still more rows are needed.&lt;/p&gt;

&lt;p&gt;Can you try increasing the number of rows (the &quot;for&quot; loop in repro.java) and see if you&lt;br/&gt;
can reproduce the problem by increasing the value?&lt;/p&gt;</comment>
                            <comment id="12597959" author="knutanders" created="Mon, 19 May 2008 15:03:22 +0100"  >&lt;p&gt;I managed to reproduce it if I turned down the heap size (-Xmx32M). I don&apos;t know how the sorters do this, but at least BackingStoreHashtable overflows to disk if it takes more than 1% of the total heap space (and the default size of the heap depends on JVM, OS and available RAM).&lt;/p&gt;</comment>
                            <comment id="12597967" author="bryanpendleton" created="Mon, 19 May 2008 15:29:40 +0100"  >&lt;p&gt;Thanks Knut Anders, that makes sense. So perhaps I should do something like:&lt;/p&gt;

&lt;p&gt;  ((Runtime.getRuntime().totalMemory()/100) / 1000) * 1.2&lt;/p&gt;

&lt;p&gt;to get the number of rows to load into the table, since my rows are each about 1000&lt;br/&gt;
characters in length, and the 1.2 fudge should cause me to have slightly more rows&lt;br/&gt;
than will fit into the BackingStoreHashtable.&lt;/p&gt;

&lt;p&gt;I&apos;ll give that a try, and see if it seems to make the test less sensitive to the heap size.&lt;/p&gt;
</comment>
                            <comment id="12597997" author="bryanpendleton" created="Mon, 19 May 2008 17:44:56 +0100"  >&lt;p&gt;Hmmm. Well, trying to use Runtime.totalMemory() in a&lt;br/&gt;
JUnit test did not have the behavior that I expected.&lt;/p&gt;

&lt;p&gt;Can somebody please try taking the attached &apos;testWithMemControls.diff&apos;&lt;br/&gt;
and apply it in your environment, and run it for me?&lt;/p&gt;

&lt;p&gt;I tried 4 experiments:&lt;/p&gt;

&lt;p&gt;1) java -Xmx32m junit.textui.TestRunner org.apache.derbyTesting.functionTests.tests.lang.GroupByTest | head&lt;br/&gt;
2) -Xmx256m&lt;br/&gt;
3) -Xmx1024m&lt;br/&gt;
4) -Xmx2048m&lt;/p&gt;

&lt;p&gt;And I expected to see Runtime.totalMemory() reporting results&lt;br/&gt;
that were roughly in line with the -Xmx values that I was setting.&lt;/p&gt;

&lt;p&gt;Instead, I saw these results:&lt;br/&gt;
1) -Xmx32m: heap size is 5500928&lt;br/&gt;
2) -Xmx256m: heap size is 10063872&lt;br/&gt;
3) -Xmx1024m: heap size is 5177344&lt;br/&gt;
4) -Xmx2048m: heap size is 5427200&lt;br/&gt;
which doesn&apos;t make any sense to me at all.&lt;/p&gt;

&lt;p&gt;This is with the Sun JDK 1.5.0_05 on RedHat Linux.&lt;/p&gt;

&lt;p&gt;Am I misunderstanding -Xmx? or misunderstanding&lt;br/&gt;
Runtime.totalMemory()? Or is something in the JUnit&lt;br/&gt;
harness interacting with my memory specifications?&lt;/p&gt;</comment>
                            <comment id="12598120" author="bryanpendleton" created="Mon, 19 May 2008 23:28:54 +0100"  >&lt;p&gt;Knut Anders raised another good point, which is how the sorter &lt;br/&gt;
decides when to overflow from memory to disk, and whether&lt;br/&gt;
it uses the same &apos;1% of memory&apos; test that BackingStoreHashtable does?&lt;/p&gt;</comment>
                            <comment id="12598131" author="bryanpendleton" created="Tue, 20 May 2008 00:19:32 +0100"  >&lt;p&gt;This code from MergeInserter.java may be relevant to the question of when the&lt;br/&gt;
sorter decides to transition from an in-memory sort to a disk-based sort:&lt;/p&gt;

&lt;p&gt;                // we want to double the sort buffer size if that will result&lt;br/&gt;
                // in the sort to use up no more than 1/2 of all the free&lt;br/&gt;
                // memory (including the sort memory)&lt;br/&gt;
                // or if GC is so effective we are now using less memory than before&lt;br/&gt;
                // or if we are using less than 1Meg of memory and the jvm is&lt;br/&gt;
                // using &amp;lt; 5 meg of memory (this indicates that the JVM can&lt;br/&gt;
                // afford to be more bloated ?)&lt;br/&gt;
                if (estimatedMemoryUsed &amp;lt; 0 ||&lt;br/&gt;
                    ((2*estimatedMemoryUsed) &amp;lt; (estimatedMemoryUsed+currentFreeMemory)/2) ||&lt;br/&gt;
                    (2*estimatedMemoryUsed &amp;lt; ExternalSortFactory.DEFAULT_MEM_USE &amp;amp;&amp;amp;&lt;br/&gt;
                     currentTotalMemory &amp;lt; (5*1024*1024)))&lt;/p&gt;
                {
                    // ok, double the sort buffer size
                    sortBuffer.grow(100);

                    if (sortBuffer.insert(row) != SortBuffer.INSERT_FULL)
                        return;
                }</comment>
                            <comment id="12598219" author="knutanders" created="Tue, 20 May 2008 09:16:37 +0100"  >&lt;p&gt;&amp;gt; Am I misunderstanding -Xmx? or misunderstanding&lt;br/&gt;
&amp;gt; Runtime.totalMemory()? Or is something in the JUnit&lt;br/&gt;
&amp;gt; harness interacting with my memory specifications?&lt;/p&gt;

&lt;p&gt;-Xmx only specifies the maximum amount of memory for the heap, but&lt;br/&gt;
it&apos;ll be smaller initially. I think you&apos;ll see totalMemory() returning&lt;br/&gt;
the expected values if you also specify -Xms.&lt;/p&gt;</comment>
                            <comment id="12598223" author="knutanders" created="Tue, 20 May 2008 09:40:53 +0100"  >&lt;p&gt;I think I was wrong about when BackingStoreHashtable would spill to disk. It wasn&apos;t when it used 1% of the heap, but when the number of rows in it exceeded 1% of the number of bytes on the heap. So hopefully each row is smaller than 100 bytes...&lt;/p&gt;</comment>
                            <comment id="12598541" author="bryanpendleton" created="Wed, 21 May 2008 03:41:57 +0100"  >&lt;p&gt;Hi Knut, Thomas, I&apos;m still confused as to why the repro test case that I&lt;br/&gt;
wrote isn&apos;t reliably demonstrating the problem in your environment.&lt;/p&gt;

&lt;p&gt;Would it be possible for you to run the &apos;repro.java&apos; test&lt;br/&gt;
program with  -Dderby.debug.true=SortTuning and have a look in your derby.log&lt;br/&gt;
to see if you are seeing the same sort of values I am seeing?&lt;/p&gt;

&lt;p&gt;In the original repro (select * from pivotview), we encounter some&lt;br/&gt;
memory-overflow-sizing code in ExternalSortFactory.createSort:&lt;/p&gt;

&lt;p&gt;    // if we have some idea on row size, set sort approx 1 meg of&lt;br/&gt;
    // memory sort.&lt;br/&gt;
    if (estimatedRowSize &amp;gt; 0)&lt;/p&gt;
    {
    	// 
    	// for each column, there is a reference from the key array and
    	//   the 4 bytes reference to the column object plus 12 bytes
    	//   tax on the  column object  
    	// for each row, SORT_ROW_OVERHEAD is the Node and 4 bytes to
    	// point to the column array and 4 for alignment
    	//
    	estimatedRowSize += SORT_ROW_OVERHEAD +
			(template.length*(4+12)) + 8; 
    	sortBufferMax = DEFAULT_MEM_USE/estimatedRowSize;
    }
&lt;p&gt;    else&lt;/p&gt;
    {
    	sortBufferMax = defaultSortBufferMax;
    }

&lt;p&gt;    // if there are barely more rows than sortBufferMax, use 2&lt;br/&gt;
    // smaller runs of similar size instead of one larger run&lt;br/&gt;
    //&lt;br/&gt;
    // 10% slush is added to estimated Rows to catch the case where&lt;br/&gt;
    // estimated rows underestimate the actual number of rows by 10%.&lt;br/&gt;
    //&lt;br/&gt;
    if (estimatedRows &amp;gt; sortBufferMax &amp;amp;&amp;amp;&lt;br/&gt;
    	(estimatedRows*1.1) &amp;lt; sortBufferMax*2)&lt;br/&gt;
    	sortBufferMax = (int)(estimatedRows/2 + estimatedRows/10);&lt;/p&gt;

&lt;p&gt;In the original reproduction case, the variables have the following values:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;estimatedRowSize: 0&lt;/li&gt;
	&lt;li&gt;estimatedRows: 1407&lt;/li&gt;
	&lt;li&gt;defaultSortBufferMax: 1024&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;With these values, the last &quot;if&quot; statement above evalutes to TRUE, and&lt;br/&gt;
this causes us to compute a SortBuffer size of 843 rows, and since the&lt;br/&gt;
actual result has 2065 rows, we overflow the in-memory sort buffer and&lt;br/&gt;
we externalize the MaxMinAggregator instances, leading to the problem.&lt;/p&gt;

&lt;p&gt;In the &apos;repro.java&apos; case that I attached to &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3219&quot; title=&quot;Group by query with many aggregate columns and case statements fails with: ERROR XSDA7: Restore of a serializable or SQLData object of class , attempted to read more data than was originally stored&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3219&quot;&gt;&lt;del&gt;DERBY-3219&lt;/del&gt;&lt;/a&gt;, when I get to&lt;br/&gt;
ExternalSortFactory.createSort, the variables have the values:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;estimatedRowSize: 0&lt;/li&gt;
	&lt;li&gt;estimatedRows: 30&lt;/li&gt;
	&lt;li&gt;defaultSortBufferMax: 1024&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;With these values, the &quot;if&quot; statement is NOT true, and so we leave&lt;br/&gt;
sortBufferMax set to 1024, and since the actual result has 2000 rows,&lt;br/&gt;
we again overflow the in-memory sort buffer and trigger the problem.&lt;/p&gt;

&lt;p&gt;In a SANE build, I can observe this processing by running with&lt;br/&gt;
-Dderby.debug.true=SortTuning, and then looking in derby.log for&lt;br/&gt;
lines like:&lt;/p&gt;

&lt;p&gt;DEBUG SortTuning OUTPUT: sortBufferMax = 1024 estimatedRows = 30 estimatedRowSize = 0 defaultSortBufferMax = 1024&lt;br/&gt;
DEBUG SortTuning OUTPUT: Growing sortBuffer dynamically, current sortBuffer capacity= 1023 estimatedMemoryUsed = 8587736 currentTotalMemory = 23293952 currentFreeMemory = 10340912 numcolumn = 4 real per row memory = 8394&lt;/p&gt;
</comment>
                            <comment id="12598579" author="thomanie" created="Wed, 21 May 2008 08:42:48 +0100"  >&lt;p&gt;Running the repro on an unpatched head of trunk, on solaris10 x86 with sun jdk 1.6.0_04, with -Dderby.debug.true=SortTuning gives:&lt;br/&gt;
&amp;#8212;&lt;br/&gt;
DEBUG SortTuning OUTPUT: sortBufferMax = 1024 estimatedRows = 30 estimatedRowSize = 0 defaultSortBufferMax = 1024&lt;br/&gt;
DEBUG SortTuning OUTPUT: Growing sortBuffer dynamically, current sortBuffer capacity= 1023 estimatedMemoryUsed = 8264424 currentTotalMemory = 92667904 currentFreeMemory = 79419968 numcolumn = 4 real per row memory = 8078&lt;br/&gt;
&amp;#8212;&lt;br/&gt;
Seems that the currentTotalMemory and currentFreeMemory are the only real differences from your platform.&lt;/p&gt;

&lt;p&gt;Limiting the memory to 16M or 32M triggers the reported error on my machine too:&lt;br/&gt;
   java -Dderby.debug.true=SortTuning -Xmx32M -Xms32M repro&lt;/p&gt;

&lt;p&gt;The SortTuning in this case is&lt;br/&gt;
&amp;#8212;&lt;br/&gt;
DEBUG SortTuning OUTPUT: sortBufferMax = 1024 estimatedRows = 30 estimatedRowSize = 0 defaultSortBufferMax = 1024&lt;br/&gt;
DEBUG SortTuning OUTPUT: Growing sortBuffer dynamically, current sortBuffer capacity= 1023 estimatedMemoryUsed = 7836080 currentTotalMemory = 32374784 currentFreeMemory = 19119984 numcolumn = 4 real per row memory = 7659&lt;br/&gt;
&amp;#8212;&lt;/p&gt;

&lt;p&gt;Like Knut says -Xmx only specifies the maximum allowed but it will start out lower than that. Also -Xms defined the minimum, so with min=max and increasing &lt;b&gt;both&lt;/b&gt; these values you should get the scenario I think you expect &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12598643" author="knutanders" created="Wed, 21 May 2008 14:40:11 +0100"  >&lt;p&gt;Hi Bryan,&lt;br/&gt;
I see the same numbers (more or less) as Thomas on my machine running Solaris Express.&lt;br/&gt;
What&apos;s interesting is that the heuristics try to prevent that the heap grows, so if you want to give your queries more memory in order to improve the sort performance, you should always specify both -Xms and -Xmx. Otherwise, if you only specify -Xmx, they won&apos;t use the extra memory.&lt;/p&gt;</comment>
                            <comment id="12598668" author="bryanpendleton" created="Wed, 21 May 2008 15:35:45 +0100"  >&lt;p&gt;Thanks Thomas and Knut. I hear what you are saying about -Xmx and -Xms.&lt;br/&gt;
And, if I run the repro script with:&lt;/p&gt;

&lt;p&gt;   java -Xms1024m -Xmx1024m repro&lt;/p&gt;

&lt;p&gt;then the problem does NOT reproduce for me, either. So it&apos;s completely&lt;br/&gt;
clear that the repro program is sensitive to the memory configuration.&lt;/p&gt;

&lt;p&gt;What I haven&apos;t yet managed to do is to make the program dynamically adjust&lt;br/&gt;
the size of the test case in such a way that it reliably reproduces the&lt;br/&gt;
problem, regardless of the memory settings.&lt;/p&gt;

&lt;p&gt;But I think I&apos;m closer now, so I&apos;ll keep fiddling with the test program &lt;br/&gt;
and see if I can solve that problem.&lt;/p&gt;</comment>
                            <comment id="12598760" author="mikem" created="Wed, 21 May 2008 20:18:33 +0100"  >&lt;p&gt;I have not used it for a very long time, but there use to be a debug/SANE version only hack&lt;br/&gt;
that would allow you to force an external sort - no matter what the memory.  I think&lt;br/&gt;
if you set the folllowing, then it will go external as long as you have enough rows to&lt;br/&gt;
exceed the buffer max that is also setable.:&lt;br/&gt;
derby.debug.true=testSort&lt;/p&gt;

&lt;p&gt;See:&lt;br/&gt;
opensource/java/testing/org/apache/derbyTesting/functionTests/tests/unit/T_SortController__derby.properties&lt;/p&gt;

&lt;p&gt;or&lt;br/&gt;
opensource/java/testing/org/apache/derbyTesting/functionTests/tests/store/streamingColumn_derby.properties&lt;/p&gt;


&lt;p&gt;The area of trying to auto configure sort into memory or not could use a good idea.  &lt;/p&gt;

&lt;p&gt;The question is how to provide a zero admin solution that makes everyone happy,&lt;br/&gt;
for a product that both might be used completely embedded as part of a lot of other&lt;br/&gt;
components so it probably should not take over all memory of the JVM vs use as&lt;br/&gt;
the single db server on the machine at that time so quite desirable to use all &lt;br/&gt;
avaliable resources as efficiently as possible.&lt;/p&gt;

&lt;p&gt;The existing code is based on jvm features available many years ago and against assumed default configurations where 1 megabyte was ALOT of memory (some&lt;br/&gt;
of the target devices didn&apos;t even have that much memory).&lt;br/&gt;
The code really wanted access to MX available memory but the jvm would&lt;br/&gt;
not give access to that number.  So it had to work off actual amount of memory free which may be 0 even if the MX has been set to allow for 100 megabytes more growth.  The current free number is VERY system dependent - depending on garbage collection, jvm implementation, OS, scheduling within and outside of the JVM, ...&lt;/p&gt;</comment>
                            <comment id="12600362" author="bryanpendleton" created="Wed, 28 May 2008 05:27:07 +0100"  >&lt;p&gt;Hi Mike, thanks for the suggestion.&lt;/p&gt;

&lt;p&gt;I think that the testSort hook may be just the&lt;br/&gt;
right thing for forcing the desired test conditions&lt;br/&gt;
for this issue.&lt;/p&gt;

&lt;p&gt;Attached is &apos;sanityTest.diff&apos;, which adjusts the&lt;br/&gt;
previous test case so that, if this is a sane debug&lt;br/&gt;
build, we call SanityManager.DEBUG_SET(&quot;testSort&quot;)&lt;br/&gt;
to ensure that the sort is forced to be external.&lt;/p&gt;

&lt;p&gt;With this in place, using a sane debug build, the&lt;br/&gt;
GroupByTest failed as I expected it to, even when&lt;br/&gt;
I forced the memory setting to be artificially high&lt;br/&gt;
using -Xms and -Xmx.&lt;/p&gt;

&lt;p&gt;Although this means that the test only reproduces&lt;br/&gt;
the test conditions in debug sane builds, I think&lt;br/&gt;
that should be OK, because tests do get run in&lt;br/&gt;
those builds routinely (for example, I routinely run&lt;br/&gt;
tests using sane debug builds).&lt;/p&gt;

&lt;p&gt;I think this &apos;sanityTest.diff&apos; patch is starting to look&lt;br/&gt;
pretty good, and I&apos;d love to get additional feedback&lt;br/&gt;
on it.&lt;/p&gt;</comment>
                            <comment id="12600363" author="bryanpendleton" created="Wed, 28 May 2008 05:28:30 +0100"  >&lt;p&gt;Also, I was successful using the &apos;repro.java&apos; program and running&lt;br/&gt;
it with -Dderby.debug.true=testSort, and in that case the repro&lt;br/&gt;
program reliably reproduced the problem for me, with a variety of&lt;br/&gt;
alternate -Xms and -Xmx memory settings. So that&apos;s more evidence&lt;br/&gt;
that this flag is useful to reproduce this problem.&lt;/p&gt;</comment>
                            <comment id="12600381" author="thomanie" created="Wed, 28 May 2008 07:29:03 +0100"  >&lt;p&gt;FWIW:&lt;br/&gt;
-Dderby.debug.true=testSort makes it fail consistently for me too, even without the -Xmx and -Xms flags.&lt;/p&gt;</comment>
                            <comment id="12600675" author="bryanpendleton" created="Thu, 29 May 2008 05:22:18 +0100"  >&lt;p&gt;Committed sanityTest.diff to the trunk as revision 661204.&lt;/p&gt;

&lt;p&gt;I&apos;ll investigate merging this change back to 10.4.&lt;/p&gt;</comment>
                            <comment id="12601398" author="bryanpendleton" created="Sat, 31 May 2008 18:07:45 +0100"  >&lt;p&gt;Attached is ten_four_patch.diff, which I think is the correct patch&lt;br/&gt;
for the 10.4 branch.&lt;/p&gt;

&lt;p&gt;My 10.4  build environment doesn&apos;t seem to be working right&lt;br/&gt;
now; I&apos;m getting dozens of failures in the test suites. So I&apos;m&lt;br/&gt;
not going to commit this patch to the 10.4 branch now, but I&apos;m&lt;br/&gt;
attaching it in case anybody gets the itch to move the patch to&lt;br/&gt;
the 10.4 branch later.&lt;/p&gt;</comment>
                            <comment id="12601399" author="bryanpendleton" created="Sat, 31 May 2008 18:08:35 +0100"  >&lt;p&gt;The patch seems to be stable in the trunk, so for now I&apos;m resolving this issue.&lt;/p&gt;</comment>
                            <comment id="12601402" author="kristwaa" created="Sat, 31 May 2008 18:58:27 +0100"  >&lt;p&gt;Lots of the errors you see in 10.4 are caused by &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3690&quot; title=&quot;EmbedPooledConnection doesn&amp;#39;t reset schema when creating a new logical connection&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3690&quot;&gt;&lt;del&gt;DERBY-3690&lt;/del&gt;&lt;/a&gt; (tracked by &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3692&quot; title=&quot;&amp;#39;javax.transaction.xa.XAException&amp;#39; ++  in  &amp;#39;J2EEDataSourceTest&amp;#39; &quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3692&quot;&gt;&lt;del&gt;DERBY-3692&lt;/del&gt;&lt;/a&gt;).&lt;br/&gt;
I agree waiting is a good idea, but if you want to test right away, you can apply the patch &apos;derby-3327-5a-extracted_initial_schema_patch.diff &apos; under &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3327&quot; title=&quot;SQL roles: Implement authorization stack (and SQL session context to hold it)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3327&quot;&gt;&lt;del&gt;DERBY-3327&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12382280" name="maxminPatch.diff" size="837" author="bryanpendleton" created="Mon, 19 May 2008 04:45:16 +0100"/>
                            <attachment id="12382282" name="patchWithTest.diff" size="3095" author="bryanpendleton" created="Mon, 19 May 2008 05:02:18 +0100"/>
                            <attachment id="12369940" name="pivotView.zip" size="6896829" author="stan" created="Wed, 21 Nov 2007 01:22:26 +0000"/>
                            <attachment id="12382281" name="repro.java" size="1456" author="bryanpendleton" created="Mon, 19 May 2008 04:45:16 +0100"/>
                            <attachment id="12382900" name="sanityTest.diff" size="4847" author="bryanpendleton" created="Wed, 28 May 2008 05:27:07 +0100"/>
                            <attachment id="12383171" name="ten_four_patch.diff" size="4737" author="bryanpendleton" created="Sat, 31 May 2008 18:07:45 +0100"/>
                            <attachment id="12382313" name="testWithMemControls.diff" size="2772" author="bryanpendleton" created="Mon, 19 May 2008 17:44:56 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 19 Dec 2007 22:46:14 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23500</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy0lwn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>37367</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            </customfields>
    </item>
</channel>
</rss>