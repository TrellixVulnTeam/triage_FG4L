<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:23:24 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-5937/DERBY-5937.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-5937] File handle is leaked when a Slave replication is shutdown with failover=true</title>
                <link>https://issues.apache.org/jira/browse/DERBY-5937</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;As part of our use of derby replication, we shut the slave down if we detect reachability issues with the master. Normally we shut it down, and bring it back up as a regular database in read-only mode.  Then when the master can, it tries to push a fresh copy back to the slave system. However, during the failover=true shutdown on the slave, the log file  &quot;.../name/log/log1.dat&quot; is still open. &lt;/p&gt;

&lt;p&gt;Because of this open file, at least on Windows, it&apos;s impossible to move the database file out of the way, and to install a fresh copy from the master.&lt;/p&gt;</description>
                <environment>Windows 7</environment>
        <key id="12608927">DERBY-5937</key>
            <summary>File handle is leaked when a Slave replication is shutdown with failover=true</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="knutanders">Knut Anders Hatlen</assignee>
                                    <reporter username="glennmcg">Glenn McGregor</reporter>
                        <labels>
                            <label>derby_triage10_10</label>
                    </labels>
                <created>Mon, 24 Sep 2012 21:54:04 +0100</created>
                <updated>Wed, 3 Sep 2014 09:31:37 +0100</updated>
                            <resolved>Tue, 16 Oct 2012 20:41:47 +0100</resolved>
                                    <version>10.8.2.2</version>
                                    <fixVersion>10.8.3.0</fixVersion>
                    <fixVersion>10.9.2.2</fixVersion>
                    <fixVersion>10.10.1.1</fixVersion>
                                    <component>Replication</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13463152" author="knutanders" created="Tue, 25 Sep 2012 20:52:54 +0100"  >&lt;p&gt;Hi Glenn,&lt;/p&gt;

&lt;p&gt;If I understand correctly, this is what you&apos;re doing when you see the problem:&lt;/p&gt;

&lt;p&gt;1) You have a master database that is being replicated to the slave, and you detect some kind of trouble with the master database&lt;/p&gt;

&lt;p&gt;2) You invoke failover=true on the slave database (which completes as expected)&lt;/p&gt;

&lt;p&gt;3) You then invoke shutdown=true on the slave database (which also completes as expected)&lt;/p&gt;

&lt;p&gt;After these steps, the slave process is still holding log1.dat open.&lt;/p&gt;

&lt;p&gt;Does that sound about right?&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="13463156" author="knutanders" created="Tue, 25 Sep 2012 20:59:22 +0100"  >&lt;p&gt;I just tried the above steps with OpenJDK on FreeBSD, and verified with lsof that log1.dat indeed is still open.&lt;/p&gt;</comment>
                            <comment id="13463210" author="glennmcg" created="Tue, 25 Sep 2012 21:54:51 +0100"  >&lt;p&gt;1. Close enough. The master database is embedded in a JVM that is pinged using an RMI call and some timers. When that fails, the switchover is attempted.&lt;br/&gt;
2. Yes.&lt;br/&gt;
2.5  I change the database property defaultConnectionMode to readOnlyAccess. The database is left up (in readonly mode) for use until the master is reachable again.&lt;/p&gt;

&lt;p&gt;... time passes&lt;/p&gt;

&lt;p&gt;3. The master detects it can talk to the slave JVM, and does a shutdown=true on the slave database. It succeeds.&lt;br/&gt;
4. Many additional steps to get it back into master/slave replication.&lt;/p&gt;
</comment>
                            <comment id="13466796" author="knutanders" created="Mon, 1 Oct 2012 14:38:11 +0100"  >&lt;p&gt;The patch d5937-1a-test.diff adds a regression test case that exposes the bug when run on Windows. The test case fails because it cannot delete all files in the slave database directory after shutdown:&lt;/p&gt;

&lt;p&gt;&amp;lt;assertDirectoryDeleted&amp;gt; attempt 1 left 3 files/dirs behind: 0=C:\cygwin\home\lroot\derbytst\system\d5937-slave-db\log\log1.dat 1=C:\cygwin\home\lroot\derbytst\system\d5937-slave-db\log 2=C:\cygwin\home\lroot\derbytst\system\d5937-slave-db&lt;br/&gt;
&amp;lt;assertDirectoryDeleted&amp;gt; attempt 2 left 3 files/dirs behind: 0=C:\cygwin\home\lroot\derbytst\system\d5937-slave-db\log\log1.dat 1=C:\cygwin\home\lroot\derbytst\system\d5937-slave-db\log 2=C:\cygwin\home\lroot\derbytst\system\d5937-slave-db&lt;br/&gt;
&amp;lt;assertDirectoryDeleted&amp;gt; attempt 3 left 3 files/dirs behind: 0=C:\cygwin\home\lroot\derbytst\system\d5937-slave-db\log\log1.dat 1=C:\cygwin\home\lroot\derbytst\system\d5937-slave-db\log 2=C:\cygwin\home\lroot\derbytst\system\d5937-slave-db&lt;br/&gt;
&amp;lt;assertDirectoryDeleted&amp;gt; attempt 4 left 3 files/dirs behind: 0=C:\cygwin\home\lroot\derbytst\system\d5937-slave-db\log\log1.dat 1=C:\cygwin\home\lroot\derbytst\system\d5937-slave-db\log 2=C:\cygwin\home\lroot\derbytst\system\d5937-slave-db&lt;br/&gt;
F&lt;br/&gt;
Time: 18,891&lt;br/&gt;
There was 1 failure:&lt;br/&gt;
1) testSlaveFailoverLeak(org.apache.derbyTesting.functionTests.tests.replicationTests.Derby5937SlaveShutdownTest)junit.framework.AssertionFailedError: Failed to delete 3 files (root=C:\cygwin\home\lroot\derbytst\system\d5937-slave-db): C:\cygwin\home\lroot\derbytst\system\d5937-slave-db\log\log1.dat (isDir=false, canRead=true, canWrite=true, size=1048576), C:\cygwin\home\lroot\derbytst\system\d5937-slave-db\log (isDir=true, canRead=true, canWrite=true, size=0), C:\cygwin\home\lroot\derbytst\system\d5937-slave-db (isDir=true, canRead=true, canWrite=true, size=4096)&lt;br/&gt;
	at org.apache.derbyTesting.junit.BaseTestCase.assertDirectoryDeleted(BaseTestCase.java:1027)&lt;br/&gt;
	at org.apache.derbyTesting.functionTests.tests.replicationTests.Derby5937SlaveShutdownTest.testSlaveFailoverLeak(Derby5937SlaveShutdownTest.java:169)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)&lt;br/&gt;
	at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:117)&lt;br/&gt;
	at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBareOverridable(BaseJDBCTestCase.java:424)&lt;br/&gt;
	at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBare(BaseJDBCTestCase.java:441)&lt;br/&gt;
	at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)&lt;br/&gt;
	at junit.extensions.TestSetup$1.protect(TestSetup.java:21)&lt;br/&gt;
	at junit.extensions.TestSetup.run(TestSetup.java:25)&lt;br/&gt;
	at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)&lt;br/&gt;
	at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)&lt;br/&gt;
	at junit.extensions.TestSetup$1.protect(TestSetup.java:21)&lt;br/&gt;
	at junit.extensions.TestSetup.run(TestSetup.java:25)&lt;br/&gt;
	at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)&lt;br/&gt;
	at junit.extensions.TestSetup$1.protect(TestSetup.java:21)&lt;br/&gt;
	at junit.extensions.TestSetup.run(TestSetup.java:25)&lt;/p&gt;

&lt;p&gt;FAILURES!!!&lt;br/&gt;
Tests run: 1,  Failures: 1,  Errors: 0&lt;/p&gt;</comment>
                            <comment id="13467616" author="knutanders" created="Tue, 2 Oct 2012 12:26:12 +0100"  >&lt;p&gt;I&apos;ve committed the test case to trunk with revision 1392847. It&apos;s not enabled yet, though.&lt;/p&gt;</comment>
                            <comment id="13467629" author="kristwaa" created="Tue, 2 Oct 2012 12:48:10 +0100"  >&lt;p&gt;Verified that the test failed, as expected, on Windows 7 (Cygwin + cmd).&lt;/p&gt;</comment>
                            <comment id="13467653" author="knutanders" created="Tue, 2 Oct 2012 13:34:12 +0100"  >&lt;p&gt;Thanks for verifying the test, Kristian.&lt;/p&gt;

&lt;p&gt;I&apos;m attaching a new patch (d5937-2a-close.diff) which attempts to fix the bug.&lt;/p&gt;

&lt;p&gt;While a slave is running, LogToFile blocks in recover() waiting for fail-over to happen. When it is notified that fail-over has happened, it continues with ordinary recovery as a first step in booting the database, and in this process it reads the log files. In a &quot;normal&quot; boot process, the log file isn&apos;t already open when recovery runs, so recover() doesn&apos;t care about closing the currently active log file first. This causes a problem when promoting a slave database, which holds a log file open, as the re-opening of the log file will make LogToFile forget about the old file handle without ever closing it.&lt;/p&gt;

&lt;p&gt;The fix makes recover() check if a log file is open, and close that file, before re-opening the log. It also enables the regression test case for the bug in ReplicationSuite.&lt;/p&gt;

&lt;p&gt;I&apos;ve verified that the test case passes on Windows when the fix is applied. I&apos;m also running the full regression test suite on Solaris and Windows. Will report back when all the tests have completed.&lt;/p&gt;</comment>
                            <comment id="13468027" author="knutanders" created="Tue, 2 Oct 2012 21:11:28 +0100"  >&lt;p&gt;All the regression tests ran cleanly on Solaris.&lt;/p&gt;

&lt;p&gt;There were two failures on Windows. One of them looked identical to the already known instability logged as &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-5866&quot; title=&quot; testFiringConstraintOrder(org.apache.derbyTesting.functionTests.tests.lang.TriggerTest)junit.framework.AssertionFailedError: matching triggers need to be fired in order creation:1,NO CASCADE BEFORE,DELETE,ROW&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-5866&quot;&gt;&lt;del&gt;DERBY-5866&lt;/del&gt;&lt;/a&gt;. The other failure was in lang/triggerGeneral.sql, apparently caused by a race between the B-tree post-commit worker thread and SYSCS_DIAG.LOCK_TABLE, resulting in more locks than expected in the lock table. I couldn&apos;t find any JIRA issue for the latter failure, so I&apos;ll file a new one.&lt;/p&gt;

&lt;p&gt;None of the test failures seem to be related to the patch, so I&apos;m setting the Patch Available flag.&lt;/p&gt;</comment>
                            <comment id="13470109" author="knutanders" created="Fri, 5 Oct 2012 09:42:35 +0100"  >&lt;p&gt;Committed revision 1394407.&lt;/p&gt;

&lt;p&gt;I&apos;ll keep the issue open for backporting to 10.9 and 10.8.&lt;/p&gt;</comment>
                            <comment id="13471459" author="knutanders" created="Mon, 8 Oct 2012 10:04:13 +0100"  >&lt;p&gt;The new test case hangs forever when run on Java 5. The root cause is the same as &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-5607&quot; title=&quot;Deadlock in Java 5 VM when using NATIVE authentication with a client running in the same VM as the server&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-5607&quot;&gt;&lt;del&gt;DERBY-5607&lt;/del&gt;&lt;/a&gt;. DriverManager.getConnection() used to be synchronized in Java 5/JDBC 3, and since the test case runs the slave and the master in the same JVM, it runs into a deadlock when setting up replication. That is, the startSlave command blocks in DriverManager.getConnection() until the master has started, but the master cannot start because it can&apos;t get into DriverManager.getConnection() as long as the slave hasn&apos;t completed its startup. This is not a problem in Java 6 or later, as DriverManager.getConnection() is no longer synchronized.&lt;/p&gt;

&lt;p&gt;I&apos;ve attached a patch (3a) that makes the test use DataSource instead of DriverManager. This avoids the problem on Java 5. It also makes it possible to run the test on JSR-169 platforms, which don&apos;t have the DriverManager class.&lt;/p&gt;

&lt;p&gt;Committed revision 1395482.&lt;/p&gt;</comment>
                            <comment id="13473233" author="knutanders" created="Wed, 10 Oct 2012 14:59:21 +0100"  >&lt;p&gt;The regression test case uses a helper method, TestConfiguration.getDatabasePath(), which is not available on the 10.9 branch. The attached backport-10.9.diff patch is a backport of the three commits that went into trunk, with the missing method added manually. All the regression tests ran cleanly on the 10.9 branch with this patch.&lt;/p&gt;</comment>
                            <comment id="13473240" author="knutanders" created="Wed, 10 Oct 2012 15:04:57 +0100"  >&lt;p&gt;Committed the 10.9 backport with revision 1396606.&lt;/p&gt;</comment>
                            <comment id="13477276" author="knutanders" created="Tue, 16 Oct 2012 20:34:37 +0100"  >&lt;p&gt;In addition to the issues seen when backporting to 10.9, the test framework on the 10.8 branch is missing functionality for adding permissions incrementally, so I had to disable the security manager in the test case in order to get it to compile on 10.8. See the attached backport-10.8.diff patch.&lt;/p&gt;

&lt;p&gt;All the regression tests ran cleanly on the 10.8 branch.&lt;/p&gt;</comment>
                            <comment id="13477282" author="knutanders" created="Tue, 16 Oct 2012 20:41:47 +0100"  >&lt;p&gt;Committed the 10.8 backport with revision 1398947.&lt;/p&gt;

&lt;p&gt;I&apos;m not planning to backport it further for now. Marking the issue as resolved.&lt;/p&gt;</comment>
                            <comment id="14119609" author="knutanders" created="Wed, 3 Sep 2014 09:31:37 +0100"  >&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;bulk update&amp;#93;&lt;/span&gt; Close all resolved issues that haven&apos;t been updated for more than one year.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12549365" name="backport-10.8.diff" size="6190" author="knutanders" created="Tue, 16 Oct 2012 20:34:37 +0100"/>
                            <attachment id="12548562" name="backport-10.9.diff" size="10174" author="knutanders" created="Wed, 10 Oct 2012 14:59:21 +0100"/>
                            <attachment id="12547214" name="d5937-1a-test.diff" size="12779" author="knutanders" created="Mon, 1 Oct 2012 14:38:11 +0100"/>
                            <attachment id="12547381" name="d5937-2a-close.diff" size="1954" author="knutanders" created="Tue, 2 Oct 2012 13:34:12 +0100"/>
                            <attachment id="12548215" name="d5937-3a-test-datasource.diff" size="8418" author="knutanders" created="Mon, 8 Oct 2012 10:04:13 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310200" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Bug behavior facts</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10421"><![CDATA[Seen in production]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 25 Sep 2012 19:52:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>242703</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hxwtu7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>15321</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310050" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Urgency</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10052"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>