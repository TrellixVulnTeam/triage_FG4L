<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:10:26 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-4348/DERBY-4348.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-4348] Copy table content with &quot;INSERT INTO table SELECT FROM (...)&quot; statement leads to corrupt data</title>
                <link>https://issues.apache.org/jira/browse/DERBY-4348</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;I had to change a the primary key of a table and used ddlutils to do so. Ddlutils recreated the table to perform this task.&lt;br/&gt;
After the schema conversion the row data of the changed table were corrupted. &lt;br/&gt;
The values of the last table column were filled with values from other rows!&lt;/p&gt;

&lt;p&gt;After performing a few tests I could break down the problem to the SQL statement &quot;INSERT INTO table SELECT FROM (...)&quot;&lt;/p&gt;

&lt;p&gt;To reprocude the effect do the following:&lt;/p&gt;

&lt;p&gt;1. unpack attached database &apos;rmdb.zip&apos;&lt;/p&gt;

&lt;p&gt;2. connect to the database with embedded driver &lt;br/&gt;
    User: IGEL&lt;br/&gt;
    Password: test &lt;/p&gt;

&lt;p&gt;3. read data of an example row from database&lt;br/&gt;
    select * from stringrangenew where classname = &apos;x.xserver%.colordepth&apos;;&lt;/p&gt;

&lt;p&gt;result is &lt;br/&gt;
    x.xserver%.colordepth	2	&lt;span class=&quot;error&quot;&gt;&amp;#91;16&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;24&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;32&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;4. now copy the data to the second table (column INSTANCENR has been added to this table)&lt;br/&gt;
    INSERT INTO STRINGRANGENEW_ (CLASSNAME,FIRMWAREID,RVALUE) SELECT CLASSNAME,FIRMWAREID,RVALUE FROM STRINGRANGENEW;&lt;/p&gt;

&lt;p&gt;5. select data of example row from second table&lt;br/&gt;
    select * from stringrangenew_ where classname = &apos;x.xserver%.colordepth&apos;;&lt;/p&gt;

&lt;p&gt;result is &lt;br/&gt;
    x.xserver%.colordepth	2	-1	&lt;span class=&quot;error&quot;&gt;&amp;#91;CCW&amp;#93;&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;CW&amp;#93;&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;XX&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;-&amp;gt; value of last column is not the same as in orignal table!&lt;/p&gt;


&lt;p&gt;Here some additional information i worked out during my tests:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;if you change the copy statement to include the additional column INSTANCENR, the copied data are correct.&lt;br/&gt;
    delete from STRINGRANGENEW_;&lt;br/&gt;
    INSERT INTO STRINGRANGENEW_ (CLASSNAME,FIRMWAREID, INSTANCENR, RVALUE) SELECT CLASSNAME,FIRMWAREID, -1, RVALUE FROM STRINGRANGENEW;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;if you select the rows only &apos;SELECT CLASSNAME,FIRMWAREID,RVALUE FROM STRINGRANGENEW&apos;, the result shows correct data&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Note: &lt;br/&gt;
The effect is not restricted to this row but also applies to other rows. But it&apos;s always the same rows, that get corrupted.&lt;/p&gt;</description>
                <environment>Derby: embedded driver 10.5.1.1 - (764942); testet with 10.4 and client driver also&lt;br/&gt;
OS: Windows XP&lt;br/&gt;
SQL statements executed using SQuirrel SQL Client, but behavior is the same with ij</environment>
        <key id="12432866">DERBY-4348</key>
            <summary>Copy table content with &quot;INSERT INTO table SELECT FROM (...)&quot; statement leads to corrupt data</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="knutanders">Knut Anders Hatlen</assignee>
                                    <reporter username="s_huber">Stefan Huber</reporter>
                        <labels>
                    </labels>
                <created>Wed, 12 Aug 2009 12:21:23 +0100</created>
                <updated>Fri, 21 Jan 2011 17:52:32 +0000</updated>
                            <resolved>Mon, 31 Aug 2009 08:47:52 +0100</resolved>
                                    <version>10.0.2.1</version>
                    <version>10.1.1.0</version>
                    <version>10.2.1.6</version>
                    <version>10.2.2.0</version>
                    <version>10.3.1.4</version>
                    <version>10.4.2.0</version>
                    <version>10.5.1.1</version>
                    <version>10.6.1.0</version>
                                    <fixVersion>10.5.3.1</fixVersion>
                    <fixVersion>10.6.1.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12742315" author="kristwaa" created="Wed, 12 Aug 2009 13:29:17 +0100"  >&lt;p&gt;Verified in trunk with the provided repro database.&lt;/p&gt;

&lt;p&gt;Observations:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;database is in 10.4 format&lt;br/&gt;
(experiments below run with trunk)&lt;/li&gt;
	&lt;li&gt;consistency checks pass&lt;/li&gt;
	&lt;li&gt;exporting data, importing and repeating the repro procedure seems to work (at least the exact row is the not corrupt). I didn&apos;t create any indexes.&lt;/li&gt;
	&lt;li&gt;dropping and recreating STRINGRANGENEW_ without indexes works without corruption&lt;/li&gt;
	&lt;li&gt;dropping and recreating STRINGRANGENEW_ with primary key works without corruption&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This issue needs further qualification.&lt;br/&gt;
When I ran the repro, 42 rows got corrupted.&lt;br/&gt;
The attached sql script executes the steps required to reproduce (download and unzip database, then run script with ij - &apos;ij d4348.sql&apos;).&lt;/p&gt;

&lt;p&gt;I don&apos;t have time to follow up on this issue (finally some vacation &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; ), but maybe it would be good to figure out if any of the tables are corrupt, or if it is a single index or a combination of indexes that causes the corruption.&lt;/p&gt;

&lt;p&gt;Maybe the reporter can post the SQL that created the indexes for completeness?&lt;/p&gt;</comment>
                            <comment id="12742316" author="kristwaa" created="Wed, 12 Aug 2009 13:30:19 +0100"  >&lt;p&gt;Attached repro script &apos;d4348.sql&apos;.&lt;/p&gt;</comment>
                            <comment id="12742343" author="s_huber" created="Wed, 12 Aug 2009 14:22:21 +0100"  >&lt;p&gt;Orignal table create statements:&lt;/p&gt;

&lt;p&gt;CREATE TABLE STRINGRANGENEW&lt;br/&gt;
(&lt;br/&gt;
    CLASSNAME VARCHAR(200) NOT NULL,&lt;br/&gt;
    FIRMWAREID INTEGER NOT NULL,&lt;br/&gt;
    RVALUE LONG VARCHAR NOT NULL,&lt;br/&gt;
    PRIMARY KEY (CLASSNAME, FIRMWAREID)&lt;br/&gt;
);&lt;br/&gt;
CREATE INDEX IDX_CLASSNAME_05 ON STRINGRANGENEW (CLASSNAME);&lt;/p&gt;


&lt;p&gt;Statements for second table:&lt;/p&gt;

&lt;p&gt;CREATE TABLE STRINGRANGENEW_&lt;br/&gt;
(&lt;br/&gt;
    CLASSNAME VARCHAR(200) NOT NULL,&lt;br/&gt;
    FIRMWAREID INTEGER NOT NULL,&lt;br/&gt;
    INSTANCENR INTEGER DEFAULT -1 NOT NULL,&lt;br/&gt;
    RVALUE LONG VARCHAR NOT NULL,&lt;br/&gt;
    PRIMARY KEY (CLASSNAME, FIRMWAREID, INSTANCENR)&lt;br/&gt;
);&lt;/p&gt;

&lt;p&gt;(All statements are created by DDLUTILS automatically)&lt;/p&gt;


&lt;p&gt;There are no explicit indexes created for table STRINGRANGENEW_.&lt;/p&gt;

&lt;p&gt;The orignial table STRINGRANGENEW has additional foreign keys (one on column CLASSNAME and another one on column FIRMWAREID) in production environment. If you need the complete production database for further examination, please let me know.&lt;/p&gt;</comment>
                            <comment id="12742365" author="kristwaa" created="Wed, 12 Aug 2009 15:03:21 +0100"  >&lt;p&gt;Thanks, Stefan.&lt;/p&gt;

&lt;p&gt;I&apos;m not seeing the same behavior when I use your exact table definition, so the index is probably a dead end.  Right now my suspicion is directed at the combination of DEFAULT and NOT NULL for the newly added column.&lt;/p&gt;</comment>
                            <comment id="12742436" author="kristwaa" created="Wed, 12 Aug 2009 17:28:06 +0100"  >&lt;p&gt;Attaching a new repro - which imports the data (&apos;d4348-import.sql&apos; contains the script, &apos;out.dat&apos; the data to import).&lt;br/&gt;
I removed all the indexes to simplify the script. Note the comments for the SQL creating the two tables.&lt;/p&gt;

&lt;p&gt;As it is now, the repro fails (by showing 42 rows where RVALUE differs from the original).&lt;br/&gt;
By tweaking the DDL slightly, it passes.&lt;/p&gt;</comment>
                            <comment id="12742438" author="kristwaa" created="Wed, 12 Aug 2009 17:31:48 +0100"  >&lt;p&gt;Note that I haven&apos;t checked if the bug occurs in versions prior to 10.3 (didn&apos;t have the jars easily available at the moment).&lt;/p&gt;</comment>
                            <comment id="12744983" author="knutanders" created="Wed, 19 Aug 2009 11:26:55 +0100"  >&lt;p&gt;I checked three random samples out of the 42 corrupt rows, and all of them had an RVALUE identical to the row 15 places ahead of it. So at least there seems to be some kind of pattern.&lt;/p&gt;</comment>
                            <comment id="12745012" author="knutanders" created="Wed, 19 Aug 2009 12:48:56 +0100"  >&lt;p&gt;More info about the pattern (thanks to Dag for his &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3634&quot; title=&quot;Cannot use row_number() in ORDER BY clause&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3634&quot;&gt;&lt;del&gt;DERBY-3634&lt;/del&gt;&lt;/a&gt; patch which made it a lot easier to find!):&lt;/p&gt;

&lt;p&gt;The corrupted rows in STRINGRANGENEW_ are all rows whose row number (counting from the beginning of the the table, starting with 1) is 16*N, N in &lt;/p&gt;
{2,3,4,...,40}
&lt;p&gt; or N in &lt;/p&gt;
{49,50,51}
&lt;p&gt;.&lt;/p&gt;

&lt;p&gt;Each corrupted row in STRINGRANGENEW_ with row number RN, has the same RVALUE as the row in STRINGRANGENEW with row number RN-15.&lt;/p&gt;</comment>
                            <comment id="12745033" author="knutanders" created="Wed, 19 Aug 2009 13:37:01 +0100"  >&lt;p&gt;The attached class D4348.java reproduces the bug with a simpler schema and data set.&lt;/p&gt;</comment>
                            <comment id="12745035" author="knutanders" created="Wed, 19 Aug 2009 13:39:22 +0100"  >&lt;p&gt;I&apos;m able to reproduce this bug all the way back to 10.0.&lt;/p&gt;</comment>
                            <comment id="12746003" author="knutanders" created="Fri, 21 Aug 2009 15:59:27 +0100"  >&lt;p&gt;I&apos;ve had a look at the repro in a debugger. It looks like the rows returned by the BulkTableScanResultSet that reads the source table are correct. The corruption seems to happen somewhere in the normalization after a chunk of 16 rows has been fetched from the BTSRS (BTSRS has an internal fetch buffer which holds 16 rows) and before the rows are inserted into the destination table. When the (16N+1)th row is normalized (N&amp;gt;0), the contents of the LONG VARCHAR column are actually copied into the SQLLongVarchar that holds the value for the (16N+16)th row. Why that happens is still not clear to me, but I suspect there&apos;s some kind of aliasing problem where two SQLLongVarchar references point to the same underlying instance.&lt;/p&gt;

&lt;p&gt;DataTypeDescriptor.normalize() has a special case for LONG VARCHAR (see below). If I comment out the special case, the repro doesn&apos;t produce a corrupt table, which is also an indication that the problem is related to the normalization.&lt;/p&gt;

&lt;p&gt;			//doing the following check after normalize so that normalize method would get called on long varchs and long varbinary&lt;br/&gt;
			//Need normalize to be called on long varchar for bug 5592 where we need to enforce a lenght limit in db2 mode&lt;br/&gt;
			if ((jdbcId == Types.LONGVARCHAR) || (jdbcId == Types.LONGVARBINARY)) &lt;/p&gt;
{
				// special case for possible streams
				if (source.getClass() == cachedDest.getClass()) 
					return source;
			}</comment>
                            <comment id="12747355" author="knutanders" created="Tue, 25 Aug 2009 12:24:08 +0100"  >&lt;p&gt;Here&apos;s a patch (derby-4348-1a.diff) that adds a regression test case&lt;br/&gt;
and fixes the problem.&lt;/p&gt;

&lt;p&gt;It turns out that there in fact is a problem with the special case for&lt;br/&gt;
LONG VARCHAR and LONG VARBINARY when performing normalization of the&lt;br/&gt;
values. Normally, DataTypeDescriptor.normalize() normalizes a&lt;br/&gt;
DataValueDescriptor by copying it into another DataValueDescriptor and&lt;br/&gt;
returning the copy. This destination DVD is cached and reused so that&lt;br/&gt;
one doesn&apos;t need to reallocate it for every value to normalize.&lt;/p&gt;

&lt;p&gt;The special case for LONG VARCHAR and LONG VARBINARY changes this&lt;br/&gt;
slightly by returning the source DVD instead of the destination DVD,&lt;br/&gt;
apparently to avoid problems with shared streams.&lt;/p&gt;

&lt;p&gt;Now, NormalizeResultSet has an ExecRow field, called normalizedRow, in&lt;br/&gt;
which the cached destination DVDs are stored. It is reused so that&lt;br/&gt;
NormalizeResultSet.getNextRowCore() returns the exact same instance&lt;br/&gt;
for every row. But since DataTypeDescriptor.normalize() returns the&lt;br/&gt;
source DVD instead of the copy for LONG VARCHAR, the cached ExecRow&lt;br/&gt;
will contain the original DVD and not the copy. When the next row is&lt;br/&gt;
requested from the NormalizeResultSet, it will therefore use the&lt;br/&gt;
source DVD for the previous row as the destination DVD for the call to&lt;br/&gt;
normalize().&lt;/p&gt;

&lt;p&gt;Copying a column from the current row to the previous row is not a&lt;br/&gt;
problem for most of the rows, as the previous row has already been&lt;br/&gt;
processed. However, when processing the first row in a new chunk&lt;br/&gt;
returned from BulkTableScanResultSet, the DVDs in the previous row&lt;br/&gt;
have also been reused in the fetch buffer to hold the last row in the&lt;br/&gt;
chunk. Since that row has not yet been processed, copying into it from&lt;br/&gt;
the current row will affect what we see when we get to it later.&lt;/p&gt;

&lt;p&gt;The problem here is that NormalizeResultSet.normalizedRow serves two&lt;br/&gt;
purposes: (1) Hold an ExecRow object that can be reused, and (2) hold&lt;br/&gt;
one DataValueDescriptor per column that can be reused. This works fine&lt;br/&gt;
as long as the actual DVD references in the ExecRow are not changed,&lt;br/&gt;
but when one of the values is a LONG VARCHAR/LONG VARBINARY the&lt;br/&gt;
references are changed.&lt;/p&gt;

&lt;p&gt;The patch addresses the problem by having a separate data structure&lt;br/&gt;
for each of the two purposes. NormalizeResultSet.normalizedRow&lt;br/&gt;
continues to cache the ExecRow object for reuse. A new field&lt;br/&gt;
(cachedDestinations[]) is added to hold each individual&lt;br/&gt;
DataValueDescriptor that should be reused. This way, changing the DVD&lt;br/&gt;
references in normalizedRow does not change which destination DVD is&lt;br/&gt;
used when processing the next row, and we don&apos;t end up modifying a DVD&lt;br/&gt;
which is also present later in the fetch buffer of the bulk scan.&lt;/p&gt;

&lt;p&gt;Description of changes:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;NormalizeResultSet.java:&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new field cachedDestinations which takes over some of the&lt;br/&gt;
  responsibility from normalizedRow&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new helper methods getCachedDestination() and getDesiredType() to&lt;br/&gt;
  reduce the complexity of normalizeRow()&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;removed unneeded throws clause from fetchResultTypes() to prevent&lt;br/&gt;
  getDesiredType() from having to inherit the unneeded clause&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;DataTypeDescriptor.java:&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;removed code in normalize() that initializes the cached destination&lt;br/&gt;
  if it is null, since this is now handled by&lt;br/&gt;
  NormalizeResultSet.getCachedDestination()&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;InsertTest.java:&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new JUnit test which exposes the bug&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The regression tests ran cleanly with this patch.&lt;/p&gt;</comment>
                            <comment id="12748783" author="knutanders" created="Fri, 28 Aug 2009 12:18:23 +0100"  >&lt;p&gt;Committed revision 808850.&lt;/p&gt;</comment>
                            <comment id="12749407" author="knutanders" created="Mon, 31 Aug 2009 08:47:52 +0100"  >&lt;p&gt;Merged fix to 10.5 and committed revision 809490.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12417012" name="D4348.java" size="1221" author="knutanders" created="Wed, 19 Aug 2009 13:37:01 +0100"/>
                            <attachment id="12416335" name="d4348-import.sql" size="1904" author="kristwaa" created="Wed, 12 Aug 2009 17:28:06 +0100"/>
                            <attachment id="12416307" name="d4348.sql" size="614" author="kristwaa" created="Wed, 12 Aug 2009 13:30:19 +0100"/>
                            <attachment id="12417603" name="derby-4348-1a.diff" size="8439" author="knutanders" created="Tue, 25 Aug 2009 12:24:08 +0100"/>
                            <attachment id="12417604" name="derby-4348-1a.stat" size="236" author="knutanders" created="Tue, 25 Aug 2009 12:24:08 +0100"/>
                            <attachment id="12416334" name="out.dat" size="155206" author="kristwaa" created="Wed, 12 Aug 2009 17:28:06 +0100"/>
                            <attachment id="12416302" name="rmdb.zip" size="400207" author="s_huber" created="Wed, 12 Aug 2009 12:23:12 +0100"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310200" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Bug behavior facts</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10364"><![CDATA[Data corruption]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 12 Aug 2009 12:29:17 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>24201</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310090" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Issue &amp; fix info</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10424"><![CDATA[Repro attached]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy0kzz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>37220</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310050" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Urgency</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10051"><![CDATA[Urgent]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>