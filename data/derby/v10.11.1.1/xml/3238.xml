<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:11:44 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-3238/DERBY-3238.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-3238] When table contains large LOB values (&gt; ~32K) trigger execution fails for that row with ERROR XCL30: An IOException was thrown when reading a &apos;BLOB&apos; </title>
                <link>https://issues.apache.org/jira/browse/DERBY-3238</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;See attached test case.  &lt;br/&gt;
At execution/run-time a trigger that handles a row that contains a large LOB value will fail with the following error and stack trace:&lt;br/&gt;
 = = =&lt;br/&gt;
Testing blob of size=1024&lt;/p&gt;

&lt;p&gt; . . Now executing update to fire the trigger&lt;br/&gt;
PASSED&lt;br/&gt;
Testing blob of size=16384&lt;/p&gt;

&lt;p&gt; . . Now executing update to fire the trigger&lt;br/&gt;
PASSED&lt;br/&gt;
Testing blob of size=32658&lt;/p&gt;

&lt;p&gt; . . Now executing update to fire the trigger&lt;br/&gt;
PASSED&lt;br/&gt;
Testing blob of size=32659&lt;/p&gt;

&lt;p&gt; . . Now executing update to fire the trigger&lt;br/&gt;
Error! java.sql.SQLException: An IOException was thrown when reading a &apos;BLOB&apos; from an InputStream.&lt;br/&gt;
java.sql.SQLException: An IOException was thrown when reading a &apos;BLOB&apos; from an InputStream.&lt;br/&gt;
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.executeUpdate(Unknown Source)&lt;br/&gt;
        at blob_insert2.testBlob(blob_insert2.java:102)&lt;br/&gt;
        at blob_insert2.main(blob_insert2.java:55)&lt;br/&gt;
Caused by: java.sql.SQLException: Java exception: &apos;: java.io.EOFException&apos;.&lt;br/&gt;
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.Util.javaException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)&lt;br/&gt;
        ... 9 more&lt;br/&gt;
Caused by: java.io.EOFException&lt;br/&gt;
        at org.apache.derby.iapi.types.SQLBinary.readBinaryLength(Unknown Source)&lt;br/&gt;
        at org.apache.derby.iapi.types.SQLBinary.readExternal(Unknown Source)&lt;br/&gt;
        at org.apache.derby.iapi.types.SQLBinary.getValue(Unknown Source)&lt;br/&gt;
        at org.apache.derby.iapi.types.SQLBinary.loadStream(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.UpdateResultSet.objectifyStream(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.UpdateResultSet.collectAffectedRows(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.UpdateResultSet.open(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)&lt;br/&gt;
        ... 5 more&lt;/p&gt;


</description>
                <environment></environment>
        <key id="12383676">DERBY-3238</key>
            <summary>When table contains large LOB values (&gt; ~32K) trigger execution fails for that row with ERROR XCL30: An IOException was thrown when reading a &apos;BLOB&apos; </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kmarsden">Kathey Marsden</assignee>
                                    <reporter username="stan">Stan Bradbury</reporter>
                        <labels>
                    </labels>
                <created>Fri, 30 Nov 2007 22:08:45 +0000</created>
                <updated>Thu, 24 Jan 2008 23:07:36 +0000</updated>
                            <resolved>Thu, 6 Dec 2007 14:42:58 +0000</resolved>
                                    <version>10.1.3.1</version>
                    <version>10.2.2.0</version>
                    <version>10.3.1.4</version>
                    <version>10.3.2.1</version>
                    <version>10.4.1.3</version>
                                    <fixVersion>10.1.3.2</fixVersion>
                    <fixVersion>10.2.2.1</fixVersion>
                    <fixVersion>10.3.3.0</fixVersion>
                    <fixVersion>10.4.1.3</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12547305" author="stan" created="Fri, 30 Nov 2007 22:09:57 +0000"  >&lt;p&gt;Delete database blobInsertDB before rerunning the program.&lt;/p&gt;</comment>
                            <comment id="12547328" author="kmarsden" created="Fri, 30 Nov 2007 23:06:22 +0000"  >&lt;p&gt;In an UpdateResultSet row there is a column for each &quot;before&quot; value and another column for the &quot;after&quot; value. When a trigger is present all columns are pulled in as update columns even if they are not updated, so each column has  a duplicate  column values in the row.  In this case, the BLOB column  was not updated, so the before value and the after value point to the same stream.&lt;/p&gt;

&lt;p&gt;The before value gets materialized in getNextRowCore-&amp;gt; DMLWriteResultSet.getNextRowCore(), but the  after value does not get updated at that time.  Later in collectAffectedRows we try to materialize the after  value by calling objectifyStream on the after columns, but because the stream was already read, we get the EOFException.&lt;/p&gt;

&lt;p&gt;It seems there are a few options.&lt;/p&gt;

&lt;p&gt;1) Try to fix &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1482&quot; title=&quot;Update triggers on tables with blob columns stream blobs into memory even when the blobs are not referenced/accessed.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1482&quot;&gt;&lt;del&gt;DERBY-1482&lt;/del&gt;&lt;/a&gt;  so that the non-updated columns don&apos;t even show up in the UpdateResultSet or at least we don&apos;t have to materialize them (hard?).&lt;/p&gt;

&lt;p&gt;2) Try to make sure that duplicate columns in the row get updated when the stream is originally loaded. I am looking at this, but am not sure exactly the best place in the code to copy the stream value.  &lt;/p&gt;

&lt;p&gt;3) Something more clever. Ideas?&lt;/p&gt;
</comment>
                            <comment id="12547346" author="mikem" created="Sat, 1 Dec 2007 00:17:23 +0000"  >&lt;p&gt;I think long term a fix along the lines of 1 would be great, and probably more appropriate for a future feature release.  It seems like trigger access code could be optimized if we had new complile time code which gathered all the following:&lt;br/&gt;
1) which columns are ever accessed for both before and after values in the trigger.&lt;br/&gt;
2) in case of after values, which columns actually may change as part of the update (maybe we have this - i don&apos;t know).  &lt;br/&gt;
Then execution code could be changed to not have to deal with any columns that the trigger need ever access.&lt;/p&gt;

&lt;p&gt;But if the goal is to get a fix for existing release, I think something along the lines of your #2 suggestion would be fine.  I assume the problem is that when we &quot;copy&quot; the datavaluedescriptor to the &quot;after&quot; column we do a &quot;shallow&quot;&lt;br/&gt;
copy.  Then subsequently we drain the stream for the before rows, leaving the shallow copy thinking it has a &lt;br/&gt;
stream when it really does not.  So if you can get the objectify to happen on the before column before the copy things should work right.  &lt;/p&gt;</comment>
                            <comment id="12547353" author="kmarsden" created="Sat, 1 Dec 2007 00:38:36 +0000"  >&lt;p&gt;Here is an initial patch attempted to resolve the issue. I am running tests now. It changes DMLWriteResultSet.objectifyStreams() to check for duplicate streams and update them with a cloned DataValueDescriptor of the value that we objectified. I wish I had been able to have more context and been able to calculate the exact offset to update. As it is, when a stream is objectified, we search all the other columns to see if there are duplicates. It has the advantage of working, but seems like unnecessary work.&lt;/p&gt;

&lt;p&gt;Anyway, just throwing this out there while the tests runs to see if I am on the right track.&lt;/p&gt;

&lt;p&gt;Kathey&lt;/p&gt;</comment>
                            <comment id="12547941" author="mamtas" created="Mon, 3 Dec 2007 18:56:33 +0000"  >&lt;p&gt;Kathey, I was wondering if the new test testClobInTriggerTable is supposed to be creating a CLOB column rather than BLOB. Because it looks like BLOB is already getting tested in the other new test testBlobInTriggerTable.&lt;/p&gt;</comment>
                            <comment id="12547948" author="kmarsden" created="Mon, 3 Dec 2007 19:13:45 +0000"  >&lt;p&gt;Thanks Mamta,&lt;/p&gt;

&lt;p&gt;I must have gotten distracted mid cut and paste.  Here is the revised patch.&lt;/p&gt;</comment>
                            <comment id="12547949" author="kmarsden" created="Mon, 3 Dec 2007 19:15:51 +0000"  >&lt;p&gt;tests ran ok except an OutOfMemory exception in DatabaseMetaDataTest which looks unrelated.  I ran the test individually and it ran ok.  I am rerunning the whole suite to make sure this test did not somehow have a negative impact on the full run with its 15MB Blob.&lt;/p&gt;
</comment>
                            <comment id="12547962" author="djd" created="Mon, 3 Dec 2007 19:44:59 +0000"  >&lt;p&gt;The test fixtures do not close the statements they create. If they created the statement using the utility methods instead then the statements would be closed automatically.&lt;/p&gt;</comment>
                            <comment id="12547966" author="kmarsden" created="Mon, 3 Dec 2007 19:52:28 +0000"  >&lt;p&gt;Thanks Dan, attaching v3 patch.&lt;/p&gt;</comment>
                            <comment id="12547967" author="mamtas" created="Mon, 3 Dec 2007 19:52:37 +0000"  >&lt;p&gt;Kathey, can we add a test where there is an update trigger defined on LOB column and then write a test that updates theLOB to make sure that the LOBs get updated correctly with their befor and after values in trigger code. I am not sure if there are any restrictions on defining triggers which deal with LOB columns.&lt;/p&gt;

&lt;p&gt;Also, can we have a test on a table that has mutliple LOB columns to make sure that DMLWriteResultSet.objectifyStreams() works correctly for more than one LOB column in a table?&lt;/p&gt;</comment>
                            <comment id="12547971" author="djd" created="Mon, 3 Dec 2007 20:04:20 +0000"  >&lt;p&gt;The statements in testBlobSize()/testClobSize() are not closed.&lt;/p&gt;

&lt;p&gt;I think if you made these methods non-static and did not pass in the connection, then it becomes clearer for readers that these methods are using the default connection, otherwise one has to assume that they are not.&lt;/p&gt;</comment>
                            <comment id="12548047" author="kmarsden" created="Mon, 3 Dec 2007 23:30:41 +0000"  >&lt;p&gt;Attached is derby-3238_diffv4.txt which contains the tests Mamta suggested as well as cleaning up the testBlobInTriggerTable() and testClobInTriggerTable() tests.  Hopefully I am only using utility methods now so don&apos;t need to close the statements.&lt;/p&gt;

&lt;p&gt;Kathey&lt;/p&gt;</comment>
                            <comment id="12548154" author="mamtas" created="Tue, 4 Dec 2007 07:03:59 +0000"  >&lt;p&gt;thanks for adding additional tests, Kathey. The changes look good to me.&lt;/p&gt;</comment>
                            <comment id="12548426" author="djd" created="Tue, 4 Dec 2007 21:56:12 +0000"  >&lt;p&gt; testBlobInTriggerTable(int blobSize) (and the clob version) do the following ...&lt;/p&gt;

&lt;p&gt;Connection conn = getConnection();&lt;br/&gt;
....&lt;br/&gt;
conn.commit();&lt;br/&gt;
....&lt;br/&gt;
conn.commit();&lt;/p&gt;

&lt;p&gt;etc.&lt;/p&gt;

&lt;p&gt;A commit() utility method exists that would remove the need for getConnection().&lt;/p&gt;

&lt;p&gt;While the functionality is the same, the use of the utility methods allow a reader to instantly see that this is a fixture (code) working on the default connection. Use of a local conn variable means a reader has to figure out if this a multi-onnection test or not. Thus the utility methods try to remove the amount of code needed for a test (to make the asserts stand out), and to make the simple typical single user test easier to understand.&lt;/p&gt;

&lt;p&gt;Cleanup is not required for committing the patch.&lt;/p&gt;

</comment>
                            <comment id="12548742" author="kmarsden" created="Wed, 5 Dec 2007 17:40:15 +0000"  >&lt;p&gt;The problem on 10.1 looks different than on 10.2,10.3, and 10.4&lt;br/&gt;
It fails at a slightly larger blob and error is when we try to objectify the before column not the after column.&lt;/p&gt;

&lt;p&gt;Also in 10.1 clobs work fine without the fix.  I will backport the fix to 10.3 and 10.2 and&lt;br/&gt;
investigate the 10.1 problem. Not sure yet if I should file a separate bug for that.&lt;/p&gt;

&lt;p&gt;&amp;gt;java blob_insert2&lt;br/&gt;
Testing blob of size=1024&lt;br/&gt;
 . . Now executing update to fire the trigger&lt;br/&gt;
PASSED&lt;br/&gt;
Testing blob of size=16384&lt;br/&gt;
 . . Now executing update to fire the trigger&lt;br/&gt;
PASSED&lt;br/&gt;
Testing blob of size=32658&lt;br/&gt;
 . . Now executing update to fire the trigger&lt;br/&gt;
PASSED&lt;br/&gt;
Testing blob of size=32659&lt;br/&gt;
 . . Now executing update to fire the trigger&lt;br/&gt;
PASSED&lt;br/&gt;
Testing blob of size=32767&lt;br/&gt;
 . . Now executing update to fire the trigger&lt;br/&gt;
Error! SQL Exception: An IOException was thrown when reading a &apos;BLOB&apos; from an InputStream.&lt;br/&gt;
ERROR XCL30: An IOException was thrown when reading a &apos;BLOB&apos; from an InputStream.&lt;br/&gt;
        at org.apache.derby.iapi.error.StandardException.newException(StandardException.java:315)&lt;br/&gt;
        at org.apache.derby.iapi.types.SQLBinary.getValue(SQLBinary.java:214)&lt;br/&gt;
        at org.apache.derby.iapi.types.SQLBinary.loadStream(SQLBinary.java:529)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.DMLWriteResultSet.objectifyStreams(DMLWriteResultSet.java:151)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.DMLWriteResultSet.getNextRowCore(DMLWriteResultSet.java:132)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.UpdateResultSet.collectAffectedRows(UpdateResultSet.java:450)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.UpdateResultSet.open(UpdateResultSet.java:276)&lt;br/&gt;
        at org.apache.derby.impl.sql.GenericPreparedStatement.execute(GenericPreparedStatement.java:379)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(EmbedStatement.java:1123)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.execute(EmbedStatement.java:529)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.executeUpdate(EmbedStatement.java:165)&lt;br/&gt;
        at blob_insert2.testBlob(blob_insert2.java:114)&lt;br/&gt;
        at blob_insert2.main(blob_insert2.java:65)&lt;br/&gt;
[&lt;/p&gt;</comment>
                            <comment id="12548811" author="kmarsden" created="Wed, 5 Dec 2007 20:41:49 +0000"  >&lt;p&gt;fixed in trunk, 10.3, and 10.2.  Investigating 10.1&lt;/p&gt;</comment>
                            <comment id="12548892" author="kmarsden" created="Thu, 6 Dec 2007 00:27:03 +0000"  >&lt;p&gt;Attached is a patch for version 10.1 for this issue.  In addition to the trunk patch, I had to change SQLBlob.setWidth to not materialize the lob if the length is unknown.  This change was checked into trunk with revision 437980 as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1417&quot; title=&quot;Add new, lengthless overloads to the streaming api&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1417&quot;&gt;&lt;del&gt;DERBY-1417&lt;/del&gt;&lt;/a&gt;, but as far as I can tell it is not dependent on the rest of that change.   Kristian, I would most appreciate if you could confirm that this is the case.&lt;/p&gt;

&lt;p&gt;The extra problem in 10.1 was that the &quot;after&quot; column was getting materialized with normalizeRow  which called setWidth, so we were in a state where the before column was still pointing to the stream, even though the after column had been materialized.  The error was occurring when we tried to objectify the before column.  Eliminating the materialization with setWidth means the stream has not been read when we call objectifyStream.  That in combination with the trunk patch allows the test case to pass.&lt;/p&gt;

&lt;p&gt;The reason the clob case was passing without the patch on 10.1 is that the before and after columns were pointing to the same DataValueDescriptor.  That, I did not change and I am not sure what problems that might cause, but for this case it worked to our advantage.&lt;/p&gt;

&lt;p&gt;Tests are running on 10.1.&lt;/p&gt;

&lt;p&gt;Kathey&lt;/p&gt;

</comment>
                            <comment id="12562284" author="stan" created="Thu, 24 Jan 2008 23:07:36 +0000"  >&lt;p&gt;Catching up on Closing my reported issues.  Thanks to Dyre for the workflow reminder today.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12370703" name="blob_insert2.java" size="4041" author="stan" created="Fri, 30 Nov 2007 22:09:57 +0000"/>
                            <attachment id="12371081" name="derby-3238_10_1_diff.txt" size="13791" author="kmarsden" created="Thu, 6 Dec 2007 00:27:03 +0000"/>
                            <attachment id="12370726" name="derby-3238_diff.txt" size="7031" author="kmarsden" created="Sat, 1 Dec 2007 00:38:36 +0000"/>
                            <attachment id="12370865" name="derby-3238_diffv2.txt" size="7058" author="kmarsden" created="Mon, 3 Dec 2007 19:13:44 +0000"/>
                            <attachment id="12370869" name="derby-3238_diffv3.txt" size="7048" author="kmarsden" created="Mon, 3 Dec 2007 19:52:28 +0000"/>
                            <attachment id="12370889" name="derby-3238_diffv4.txt" size="10149" author="kmarsden" created="Mon, 3 Dec 2007 23:33:37 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 30 Nov 2007 23:06:22 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23512</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310090" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Issue &amp; fix info</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10102"><![CDATA[Patch Available]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy0zlj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>39585</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            </customfields>
    </item>
</channel>
</rss>