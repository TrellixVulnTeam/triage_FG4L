<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:14:52 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-802/DERBY-802.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-802] OutofMemory Error when reading large blob when statement type is ResultSet.TYPE_SCROLL_INSENSITIVE</title>
                <link>https://issues.apache.org/jira/browse/DERBY-802</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;Gr&#233;goire Dubois on the list reported this problem.  From his mail: the reproduction is attached below. &lt;br/&gt;
When statement type is set to ResultSet.TYPE_SCROLL_INSENSITIVE, outofmemory exception is thrown when reading large blobs. &lt;/p&gt;

&lt;p&gt;import java.sql.*;&lt;br/&gt;
import java.io.*;&lt;/p&gt;

&lt;p&gt;/**&lt;br/&gt;
*&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@author greg&lt;br/&gt;
*/&lt;br/&gt;
public class derby_filewrite_fileread {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    private static File file = new File(&quot;/mnt/BigDisk/Clips/BabyMamaDrama-JShin.wmv&quot;);&lt;br/&gt;
    private static File destinationFile = new File(&quot;/home/greg/DerbyDatabase/&quot;+file.getName());&lt;/p&gt;

&lt;p&gt;    /** Creates a new instance of derby_filewrite_fileread */&lt;br/&gt;
    public derby_filewrite_fileread() {       &lt;/p&gt;

&lt;p&gt;    }&lt;/p&gt;

&lt;p&gt;    public static void main(String args[]) {&lt;br/&gt;
        try {&lt;br/&gt;
            Class.forName(&quot;org.apache.derby.jdbc.EmbeddedDriver&quot;).newInstance();&lt;br/&gt;
            Connection connection = DriverManager.getConnection (&quot;jdbc:derby:/home/greg/DerbyDatabase/BigFileTestDB;create=true&quot;, &quot;APP&quot;, &quot;&quot;);&lt;br/&gt;
            connection.setAutoCommit(false);&lt;/p&gt;

&lt;p&gt;            Statement statement = connection.createStatement(ResultSet.TYPE_SCROLL_INSENSITIVE, ResultSet.CONCUR_READ_ONLY);&lt;br/&gt;
            ResultSet result = statement.executeQuery(&quot;SELECT TABLENAME FROM SYS.SYSTABLES&quot;);&lt;/p&gt;

&lt;p&gt;            // Create table if it doesn&apos;t already exists.&lt;br/&gt;
            boolean exist=false;&lt;br/&gt;
            while ( result.next() ) &lt;/p&gt;
{
                if (&quot;db_file&quot;.equalsIgnoreCase(result.getString(1)))
                    exist=true;
            }
&lt;p&gt;            if ( !exist ) &lt;/p&gt;
{
                System.out.println(&quot;Create table db_file.&quot;);
                statement.execute(&quot;CREATE TABLE db_file (&quot;+
                                           &quot;     name          VARCHAR(40),&quot;+
                                           &quot;     file          BLOB(2G) NOT NULL)&quot;);
                connection.commit();
            }

&lt;p&gt;            // Read file from disk, write on DB.&lt;br/&gt;
            System.out.println(&quot;1 - Read file from disk, write on DB.&quot;);&lt;br/&gt;
            PreparedStatement preparedStatement=connection.prepareStatement(&quot;INSERT INTO db_file(name,file) VALUES (?,?)&quot;);&lt;br/&gt;
            FileInputStream fileInputStream = new FileInputStream(file);&lt;br/&gt;
            preparedStatement.setString(1, file.getName());&lt;br/&gt;
            preparedStatement.setBinaryStream(2, fileInputStream, (int)file.length());           &lt;br/&gt;
            preparedStatement.execute();&lt;br/&gt;
            connection.commit();&lt;br/&gt;
            System.out.println(&quot;2 - END OF Read file from disk, write on DB.&quot;);&lt;/p&gt;


&lt;p&gt;            // Read file from DB, and write on disk.&lt;br/&gt;
            System.out.println(&quot;3 - Read file from DB, and write on disk.&quot;);&lt;br/&gt;
            result = statement.executeQuery(&quot;SELECT file FROM db_file WHERE name=&apos;&quot;&lt;ins&gt;file.getName()&lt;/ins&gt;&quot;&apos;&quot;);&lt;br/&gt;
            byte[] buffer = new byte &lt;span class=&quot;error&quot;&gt;&amp;#91;1024&amp;#93;&lt;/span&gt;;&lt;br/&gt;
            result.next();&lt;br/&gt;
            BufferedInputStream     inputStream=new BufferedInputStream(result.getBinaryStream(1),1024);&lt;br/&gt;
            FileOutputStream outputStream = new FileOutputStream(destinationFile);&lt;br/&gt;
            int readBytes = 0;&lt;br/&gt;
            while (readBytes!=-1) &lt;/p&gt;
{
                readBytes=inputStream.read(buffer,0,buffer.length);
                if ( readBytes != -1 )
                    outputStream.write(buffer, 0, readBytes);
            }
&lt;p&gt;     &lt;br/&gt;
            inputStream.close();&lt;br/&gt;
            outputStream.close();&lt;br/&gt;
            System.out.println(&quot;4 - END OF Read file from DB, and write on disk.&quot;);&lt;br/&gt;
        }&lt;br/&gt;
        catch (Exception e) &lt;/p&gt;
{
            e.printStackTrace(System.err);
        }
&lt;p&gt;    }&lt;br/&gt;
}&lt;/p&gt;


&lt;p&gt;It returns&lt;br/&gt;
1 - Read file from disk, write on DB.&lt;br/&gt;
2 - END OF Read file from disk, write on DB.&lt;br/&gt;
3 - Read file from DB, and write on disk.&lt;br/&gt;
java.lang.OutOfMemoryError&lt;br/&gt;
if the file is ~10MB or more&lt;/p&gt;</description>
                <environment>all</environment>
        <key id="12327431">DERBY-802</key>
            <summary>OutofMemory Error when reading large blob when statement type is ResultSet.TYPE_SCROLL_INSENSITIVE</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="andreask">Andreas Korneliussen</assignee>
                                    <reporter username="skambha">Sunitha Kambhampati</reporter>
                        <labels>
                    </labels>
                <created>Tue, 10 Jan 2006 02:33:57 +0000</created>
                <updated>Thu, 13 Dec 2007 09:04:46 +0000</updated>
                            <resolved>Tue, 18 Jul 2006 11:01:25 +0100</resolved>
                                    <version>10.0.2.0</version>
                    <version>10.0.2.1</version>
                    <version>10.0.2.2</version>
                    <version>10.1.1.0</version>
                    <version>10.1.2.1</version>
                    <version>10.1.3.1</version>
                    <version>10.2.1.6</version>
                                    <fixVersion>10.2.1.6</fixVersion>
                                    <component>JDBC</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>1</watches>
                                                                                                            <comments>
                            <comment id="12362225" author="skambha" created="Tue, 10 Jan 2006 02:40:19 +0000"  >&lt;p&gt;From list, Dan suggested the following workaround  Change statement type to default ResultSet.TYPE_FORWARD_ONLY  and this works ok. &lt;/p&gt;

&lt;p&gt;===================&lt;/p&gt;

&lt;p&gt;I modified the repro and tried to do a read of a 100mb blob,  did  a heap profiler run and found the following trace. &lt;br/&gt;
         percent         live       alloc&apos;ed  stack class&lt;br/&gt;
 rank   self  accum    bytes objs   bytes objs trace name&lt;br/&gt;
    1 59.59% 59.59% 30653040  935 31682912 1046  2050 [B&lt;br/&gt;
    2 32.61% 92.20% 16777232    1 33489040    9  7268 [B&lt;br/&gt;
    3  3.12% 95.33%  1606416   49 1737552   53  6935 [B&lt;br/&gt;
    4  0.35% 95.68%   181632  946  194688 1014  2014 org.apache.derby.impl.store.raw.data.StoredPage&lt;br/&gt;
......&lt;br/&gt;
 I havent looked very closely here but it seems to me that some materialization is happening by looking at this trace and code.  )&lt;/p&gt;

&lt;p&gt;TRACE 7268:&lt;br/&gt;
	org.apache.derby.iapi.types.SQLBinary.readFromStream(SQLBinary.java:384)&lt;br/&gt;
	org.apache.derby.iapi.types.SQLBinary.readExternal(SQLBinary.java:301)&lt;br/&gt;
	org.apache.derby.iapi.types.SQLBinary.getValue(SQLBinary.java:194)&lt;br/&gt;
	org.apache.derby.iapi.types.SQLBinary.getClone(SQLBinary.java:498)&lt;/p&gt;</comment>
                            <comment id="12362232" author="skambha" created="Tue, 10 Jan 2006 03:34:20 +0000"  >&lt;p&gt;changing priority to minor as workaround exists. &lt;/p&gt;</comment>
                            <comment id="12417500" author="andreask" created="Fri, 23 Jun 2006 22:50:50 +0100"  >&lt;p&gt;The problem here is caused by ScrollInsensitiveResultSet doing a clone of the rows before inserting the into the BackingStoreHashtable.  The cloning of a blob, will cause a new column to be created, which reads all the data of the blob into a byte-array in memory. So if there is a 1GB blob, all the data will be read into memory.&lt;/p&gt;

&lt;p&gt;To fix, I intent to avoid the cloning in ScrollInsensitiveResultSet. If the row, based on estimated memory usage, can go into memory, it should be cloned in BackingStoreHashTable. If it cannot go into memory, it should be spilt to disk (in which case you do not need a clone.&lt;/p&gt;</comment>
                            <comment id="12419535" author="andreask" created="Thu, 6 Jul 2006 22:44:14 +0100"  >&lt;p&gt;Attached is a patch which should fix the OutOfMemory problem.&lt;/p&gt;

&lt;p&gt;In ScrollInsensitiveResultSet.java and ProjectRestrictResultSet, the cloning has been removed.&lt;br/&gt;
When the ScrollInsensitiveResultSet inserts rows to the BackingStoreHashTable, it leaves it up to the BackingStoreHashTable to do cloning. If the row is too big to go into memory, BackingStoreHashTable will put it on disk.&lt;/p&gt;

&lt;p&gt;BackingStoreHashTable had to be fixed to avoid unneccassry inmemory cloning there as well.&lt;/p&gt;

&lt;p&gt;The changes in SQLBinary and its subclasses is to make the method estimateMemoryUsage() return a number which is at least as big as the memory the column actually will use in memory. Before this fix, the estimated memory usage for a 64MB blob was on a few bytes ~ 50 bytes.  &lt;/p&gt;

&lt;p&gt;Finally, I found that when storing a SQLBinary (SQLBlob) to a conglomerate, the ExecRow which the column is within cannot be used again when backing the row to another conglomerate (if the row goes over multiple pages, I think). This is exactly what happens in ScrollInsensitiveResultset.updateRow(..). To get around this problem, I had do reassign some of the values in the updateRow(..) method to refer to the data backed to the BackingStoreHashTable.&lt;/p&gt;</comment>
                            <comment id="12420624" author="andreask" created="Wed, 12 Jul 2006 22:21:38 +0100"  >&lt;p&gt;The attached diff (derby-802v2.diff) has one change compared to the first diff:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;The logic for undoing the projection is moved to ProjectRestricResultSet and takes advantage of the projectMappings array already built there.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12420819" author="andreask" created="Thu, 13 Jul 2006 16:45:51 +0100"  >&lt;p&gt;Withdrawing derby-802v2.diff, since it makes SURQueryMixTest.junit fail.&lt;br/&gt;
The first patch has been run with no failures in derbyall.&lt;br/&gt;
I will commit tomorrow, unless I receive any review comments.&lt;/p&gt;</comment>
                            <comment id="12420883" author="fernanda" created="Thu, 13 Jul 2006 23:22:51 +0100"  >&lt;p&gt;I am reviewing your patch (derby-802.diff), but I won&apos;t have time to finish today. Can you wait a bit longer before you commit?&lt;/p&gt;</comment>
                            <comment id="12421121" author="fernanda" created="Fri, 14 Jul 2006 15:22:52 +0100"  >&lt;p&gt;I have looked at the patch (derby-802.diff), and I have a few comments/questions.&lt;/p&gt;

&lt;p&gt;In ScrollInsensitiveResultSet you are building an array for mapping the positions in the original row to the positions on the projected row (origPos).&lt;/p&gt;

&lt;p&gt;+			// Array of original position in row&lt;br/&gt;
+			final int[] origPos = new int&lt;span class=&quot;error&quot;&gt;&amp;#91;newRowData.length&amp;#93;&lt;/span&gt;;&lt;br/&gt;
+			&lt;br/&gt;
+			for (int i=0; i&amp;lt;origPos.length; i++) &lt;/p&gt;
{
+				origPos[i] = -1 ; 
+			}
&lt;p&gt;+&lt;br/&gt;
+			// Make the origPos, by brute-force comparison of identity:&lt;br/&gt;
+			for (int i=0; i&amp;lt;newRowData.length; i++) {&lt;br/&gt;
+				for (int j=0; j&amp;lt;rowData.length; j++) {&lt;br/&gt;
+					if (rowData&lt;span class=&quot;error&quot;&gt;&amp;#91;j&amp;#93;&lt;/span&gt;==newRowData&lt;span class=&quot;error&quot;&gt;&amp;#91;i&amp;#93;&lt;/span&gt;) &lt;/p&gt;
{
+						origPos[i] = j;
+						break;
+					}
&lt;p&gt;+				}&lt;br/&gt;
+			}&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;+			for (int i=0; i&amp;lt;origPos.length; i++) {&lt;br/&gt;
+				if (origPos&lt;span class=&quot;error&quot;&gt;&amp;#91;i&amp;#93;&lt;/span&gt;&amp;gt;=0) &lt;/p&gt;
{
+					rowData[origPos[i]] = backedData[i];
+				}
&lt;p&gt;+			}&lt;/p&gt;

&lt;p&gt;ProjectRestrictResultSet already contains (projectMapping) a similar array to the one you are building here (origPos), wouldn&apos;t it be better to build this array in ProjectRestrictRestultSet using &quot;projectMapping&quot; instead of using brute-force comparison of identity?&lt;/p&gt;

&lt;p&gt;Suggestion:&lt;/p&gt;

&lt;p&gt;ScrollInsensitiveResultSet:&lt;br/&gt;
+			// Array of original position in row&lt;br/&gt;
+			int[] origPos = ((ProjectRestrictResultSet)source).getBaseProjectMapping();&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;+			for (int i=0; i&amp;lt;origPos.length; i++) {&lt;br/&gt;
+				if (origPos&lt;span class=&quot;error&quot;&gt;&amp;#91;i&amp;#93;&lt;/span&gt;&amp;gt;=0) &lt;/p&gt;
{
+					rowData[origPos[i] - 1] = backedData[i];
+				}
&lt;p&gt;+			}&lt;/p&gt;

&lt;p&gt;ProjectRestrictResultSet:&lt;br/&gt;
+    public int[] getBaseProjectMapping() {&lt;br/&gt;
+        int[] result;&lt;br/&gt;
+        if (source instanceof ProjectRestrictResultSet) {&lt;br/&gt;
+            result = new int&lt;span class=&quot;error&quot;&gt;&amp;#91;projectMapping.length&amp;#93;&lt;/span&gt;;&lt;br/&gt;
+            ProjectRestrictResultSet prs = (ProjectRestrictResultSet) source;&lt;br/&gt;
+            int[] sourceMap = prs.getBaseProjectMapping();&lt;br/&gt;
+            for (int i=0; i&amp;lt;projectMapping.length; i++) {&lt;br/&gt;
+                if (projectMapping&lt;span class=&quot;error&quot;&gt;&amp;#91;i&amp;#93;&lt;/span&gt; &amp;gt; 0) &lt;/p&gt;
{
+                    result[i] = sourceMap[projectMapping[i] - 1];
+                }
&lt;p&gt;+            }            &lt;br/&gt;
+        } else &lt;/p&gt;
{
+            result = projectMapping;
+        }
&lt;p&gt;+        return result;&lt;br/&gt;
+    }&lt;/p&gt;

&lt;p&gt;I have also looked into the tests added in &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-1477&quot; title=&quot;create JUnit tests for testing BLOB OutOfMemory problems&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-1477&quot;&gt;&lt;del&gt;DERBY-1477&lt;/del&gt;&lt;/a&gt; and I found out that neither of them use projection. Since part of the changes made in &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-802&quot; title=&quot;OutofMemory Error when reading large blob when statement type is ResultSet.TYPE_SCROLL_INSENSITIVE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-802&quot;&gt;&lt;del&gt;DERBY-802&lt;/del&gt;&lt;/a&gt; are for cases where you have a projection, it would be nice if you could add some tests where projections where being used.&lt;/p&gt;

</comment>
                            <comment id="12421136" author="andreask" created="Fri, 14 Jul 2006 16:39:26 +0100"  >&lt;p&gt;Thank you very much for the review comments. I agree that the undo-projection code can be improved, (something I tried to do in the v2 diff). Your suggested approach sounds promising, I will try it out, and add more tests to BLOBTest.&lt;/p&gt;</comment>
                            <comment id="12421620" author="andreask" created="Mon, 17 Jul 2006 14:46:58 +0100"  >&lt;p&gt;Attached is a patch (derby-802v3.diff and derby-802v3.stat) which uses projectmappings calculated from ProjectRestrictResultSet, and 4 new testcases with projections has been added to BLOBTest.junit&lt;/p&gt;</comment>
                            <comment id="12421829" author="fernanda" created="Tue, 18 Jul 2006 10:51:35 +0100"  >&lt;p&gt;All my comments have been addressed in patch (derby-802v3.diff).&lt;/p&gt;</comment>
                            <comment id="12421830" author="andreask" created="Tue, 18 Jul 2006 11:01:25 +0100"  >&lt;p&gt;Thanks for reviewing.&lt;/p&gt;

&lt;p&gt;Committed revision 423034.&lt;/p&gt;</comment>
                            <comment id="12551301" author="fuzzylogic" created="Thu, 13 Dec 2007 09:04:46 +0000"  >&lt;p&gt;This issue has been resolved for over a year with no further movement. Closing.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12336441" name="derby-802.diff" size="15899" author="andreask" created="Thu, 6 Jul 2006 22:44:14 +0100"/>
                            <attachment id="12336442" name="derby-802.stat" size="697" author="andreask" created="Thu, 6 Jul 2006 22:44:14 +0100"/>
                            <attachment id="12336739" name="derby-802v2.diff" size="16048" author="andreask" created="Wed, 12 Jul 2006 22:21:38 +0100"/>
                            <attachment id="12337029" name="derby-802v3.diff" size="26354" author="andreask" created="Mon, 17 Jul 2006 14:46:58 +0100"/>
                            <attachment id="12337030" name="derby-802v3.stat" size="879" author="andreask" created="Mon, 17 Jul 2006 14:46:58 +0100"/>
                    </attachments>
                <subtasks>
                            <subtask id="12345408">DERBY-1477</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 23 Jun 2006 21:50:50 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>22156</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy10fr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>39721</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            </customfields>
    </item>
</channel>
</rss>