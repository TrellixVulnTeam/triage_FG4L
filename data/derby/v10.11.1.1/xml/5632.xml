<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:55:08 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-5632/DERBY-5632.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-5632] Logical deadlock happened when freezing/unfreezing the database</title>
                <link>https://issues.apache.org/jira/browse/DERBY-5632</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;Tried to make a quick database backup by freezing the database, performing a ZFS snapshot, and then unfreezing the database.   The database was frozen but then a connection to the database could not be established to unfreeze the database.&lt;/p&gt;

&lt;p&gt;Looking at the stack trace of the network server, , I see 3 threads that are trying to process a connection request.   Each of these is waiting on:&lt;/p&gt;

&lt;p&gt;                at org.apache.derby.impl.store.access.RAMAccessManager.conglomCacheFind(Unknown Source)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;waiting to lock &amp;lt;0xfffffffd3a7fcc68&amp;gt; (a org.apache.derby.impl.services.cache.ConcurrentCache)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;That object is owned by:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;locked &amp;lt;0xfffffffd3a7fcc68&amp;gt; (a org.apache.derby.impl.services.cache.ConcurrentCache)&lt;br/&gt;
                at org.apache.derby.impl.store.access.RAMTransaction.findExistingConglomerate(Unknown Source)&lt;br/&gt;
                at org.apache.derby.impl.store.access.RAMTransaction.openGroupFetchScan(Unknown Source)&lt;br/&gt;
                at org.apache.derby.impl.services.daemon.IndexStatisticsDaemonImpl.updateIndexStatsMinion(Unknown Source)&lt;br/&gt;
                at org.apache.derby.impl.services.daemon.IndexStatisticsDaemonImpl.runExplicitly(Unknown Source)&lt;br/&gt;
                at org.apache.derby.impl.sql.execute.AlterTableConstantAction.updateStatistics(Unknown Source)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;which itself is waiting for the object:&lt;/p&gt;

&lt;p&gt;                at java.lang.Object.wait(Native Method)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;waiting on &amp;lt;0xfffffffd3ac1d608&amp;gt; (a org.apache.derby.impl.store.raw.log.LogToFile)&lt;br/&gt;
                at java.lang.Object.wait(Object.java:485)&lt;br/&gt;
                at org.apache.derby.impl.store.raw.log.LogToFile.flush(Unknown Source)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0xfffffffd3ac1d608&amp;gt; (a org.apache.derby.impl.store.raw.log.LogToFile)&lt;br/&gt;
                at org.apache.derby.impl.store.raw.log.LogToFile.flush(Unknown Source)&lt;br/&gt;
                at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.flush(Unknown Source)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So basically what I think is happening is that the database is frozen, the statistics are being updated on another thread which has the &quot;org.apache.derby.impl.services.cache.ConcurrentCache&quot; locked and then waits for the LogToFile lock and the connecting threads are waiting to lock &quot;org.apache.derby.impl.services.cache.ConcurrentCache&quot; to connect and these are where the database is going to be unfrozen.    Not a deadlock as far as the JVM is concerned but it will never leave this state either.&lt;/p&gt;

</description>
                <environment>Oracle M3000/Solaris 10</environment>
        <key id="12544300">DERBY-5632</key>
            <summary>Logical deadlock happened when freezing/unfreezing the database</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="knutanders">Knut Anders Hatlen</assignee>
                                    <reporter username="bbergquist">Brett Bergquist</reporter>
                        <labels>
                            <label>derby_triage10_10</label>
                    </labels>
                <created>Mon, 27 Feb 2012 19:28:29 +0000</created>
                <updated>Wed, 21 Jan 2015 00:23:39 +0000</updated>
                            <resolved>Thu, 14 Mar 2013 07:52:24 +0000</resolved>
                                    <version>10.8.2.2</version>
                                    <fixVersion>10.10.1.1</fixVersion>
                                    <component>Documentation</component>
                    <component>Services</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                            <comments>
                            <comment id="13217433" author="bbergquist" created="Mon, 27 Feb 2012 19:29:17 +0000"  >&lt;p&gt;Network server threads stack dump&lt;/p&gt;</comment>
                            <comment id="13217649" author="mikem" created="Mon, 27 Feb 2012 22:37:36 +0000"  >&lt;p&gt;Here is the documentation for using freeze/unfreeze to do a backup.  The expectation is that the freeze and unfreeze comes&lt;br/&gt;
from the same connection (or at least that is likely what is tested in derby).&lt;br/&gt;
&lt;a href=&quot;http://db.apache.org/derby/docs/dev/adminguide/cadminhubbkup75469.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://db.apache.org/derby/docs/dev/adminguide/cadminhubbkup75469.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I don&apos;t remember but think it might be likely that future connection requests are stalled while a database is frozen, as part of work&lt;br/&gt;
necessary to keep a database in an ok state for a user backup routine to be called.  Logically you just need to stop writing transactions&lt;br/&gt;
but the implementation may just of have stall all connections.&lt;/p&gt;

&lt;p&gt;Obviously this does not work well for the 3 separate script steps you describe, but would be good to know if your use case works for&lt;br/&gt;
the intended use of freeze/unfreeze.  And even if derby only supports same connection freeze&lt;br/&gt;
and unfreeze, we should understand what is expected if the connection executing the freeze fails or exits before doing unfreeze. &lt;/p&gt;

</comment>
                            <comment id="13217796" author="bbergquist" created="Tue, 28 Feb 2012 01:24:09 +0000"  >&lt;p&gt;I don&apos;t think it is clear that one MUST use the same connection.   To me that is an example of how one MIGHT do the backup.   In any case, I could do it as suggested by invoking a system command from within a Java utility but my fear is as you suggested, what happens if the utility fails before performing an unfreeze?   Having to kill the network server is really not a good answer.&lt;/p&gt;

&lt;p&gt;The 3 separate steps as I mentioned does in fact work frequently.  I ran it a bunch of other times with no problems, but unfortunately (or maybe fortunately), it failed for me the very first time I tried it.&lt;/p&gt;

&lt;p&gt;So if one were to do it within one connection, I think that maybe if the connection is lost, then an unfreeze is done automatically to ensure not being locked out of the network server.&lt;/p&gt;
</comment>
                            <comment id="13220277" author="rhillegas" created="Thu, 1 Mar 2012 19:20:22 +0000"  >&lt;p&gt;Unchecking the &apos;crash&apos; box. There is probably room for improvement here, if only in the documentation.&lt;/p&gt;</comment>
                            <comment id="13462076" author="kmarsden" created="Mon, 24 Sep 2012 21:16:17 +0100"  >&lt;p&gt;Should this be marked as an improvement?&lt;/p&gt;</comment>
                            <comment id="13462172" author="bbergquist" created="Mon, 24 Sep 2012 22:50:41 +0100"  >&lt;p&gt;I think this should be looked at and improved upon.   Even following Mike&apos;s comment of trying to perform the freeze/backup/unfreeze using the same connection, I have this fail and lock out of the database occur and not be able to unfreeze.   So at a minimum the documentation should be updated indicating that this might happen.&lt;/p&gt;</comment>
                            <comment id="13462211" author="kmarsden" created="Mon, 24 Sep 2012 23:40:53 +0100"  >&lt;p&gt;Changing Component to Services and Documentation from Network Server as the issue is not network server specific and at a minimum  the documentation needs to be improved.  It might make sense to open a subtask for the doc change if the behavior isn&apos;t changed to allow unfreeze from a separate connection.&lt;/p&gt;</comment>
                            <comment id="13504728" author="chaase3" created="Tue, 27 Nov 2012 16:27:13 +0000"  >&lt;p&gt;I can open a subtask for the documentation for this issue. &lt;/p&gt;</comment>
                            <comment id="13528381" author="bbergquist" created="Mon, 10 Dec 2012 22:39:39 +0000"  >&lt;p&gt;This is still a major problem even when using the same connection, the database can get into a state that the freeze works, but the unfreeze locks up.   &lt;/p&gt;

&lt;p&gt;At a customer site, this procedure is done each night to backup the database.  Since the 9/1/2012, this has failed 5 times, causing the database to remain in a frozen state with no possibility of unfreezing it.   When in this state, no connections to the database can be created including a connection to shut down the database.   Forcefully killing the network server is the only way to recover.&lt;/p&gt;

&lt;p&gt;Note that there is a background job in the system that is running an UPDATE_STATISTICS every minute as in Derby 10.8.2.2, the automatic statistics update daemon has problems and cannot be used.&lt;/p&gt;</comment>
                            <comment id="13529019" author="knutanders" created="Tue, 11 Dec 2012 14:48:07 +0000"  >&lt;p&gt;I think the way the conglomerate cache is accessed breaks with the intention of how our generic cache implementation should be accessed. It should not be necessary to synchronize on the cache instance, like RAMAccessManager.conglomCacheFind() and some other callers do.&lt;/p&gt;

&lt;p&gt;To take conglomCacheFind() as an example, I think it ideally should have been implemented like this:&lt;/p&gt;

&lt;p&gt;Conglomerate conglom = null;&lt;br/&gt;
CacheableConglomerate entry = (CacheableConglomerate) conglomCache.find(new Long(conglomid));&lt;br/&gt;
if (entry != null) &lt;/p&gt;
{
    conglom = entry.getConglom();
    conglom_cache.release(entry);
}
&lt;p&gt;return conglom;&lt;/p&gt;

&lt;p&gt;That is, no explicit synchronization, and let the cache implementation take care of faulting in the conglomerate if it&apos;s not in the cache.&lt;/p&gt;

&lt;p&gt;However, CacheableConglomerate.setIdentity(), which is where the code that faults in the conglomerate is supposed to be, is just an empty shell:&lt;/p&gt;

&lt;p&gt;	public Cacheable setIdentity(Object key) throws StandardException&lt;br/&gt;
    {&lt;br/&gt;
		if (SanityManager.DEBUG) &lt;/p&gt;
{
			SanityManager.THROWASSERT(&quot;not supported.&quot;);
		}

&lt;p&gt;        return(null);&lt;br/&gt;
    }&lt;/p&gt;

&lt;p&gt;I&apos;ll have a look and see if it&apos;s possible to rewrite the code in a way so that we can remove the explicit synchronization on the conglomerate cache instance. Hopefully, that would be enough to break the deadlock.&lt;/p&gt;</comment>
                            <comment id="13530950" author="knutanders" created="Thu, 13 Dec 2012 12:30:50 +0000"  >&lt;p&gt;I think there are two reasons why RAMAccessManager synchronizes on the conglomerate cache instance whenever it accesses it:&lt;/p&gt;

&lt;p&gt;1) Because it manually faults in missing items in the cache, and it needs to ensure that no others fault it in between its calls to findCached() and create().&lt;/p&gt;

&lt;p&gt;2) Because conglomCacheUpdateEntry() implements a create-or-replace operation, which is not provided by the CacheManager interface, and it needs to ensure no others add an item with the same key between findCached() and create().&lt;/p&gt;

&lt;p&gt;As mentioned in an earlier comment, I think (1) should be solved by implementing CacheableConglomerate.setIdentity(), so that the cache manager takes care of faulting in the conglomerate.&lt;/p&gt;

&lt;p&gt;(2) might be solved by adding a create-or-replace operation to CacheManager interface. However, I&apos;m not sure it is needed. The conglomCacheUpdateEntry() method is only called once; by RAMTransaction.addColumnToConglomerate(). That method fetches a Conglomerate instance from the cache, modifies it, and reinserts it into the cache. The instance that&apos;s reinserted into the cache is the exact same instance that was fetched from the cache, so the call to conglomCacheUpdateEntry() doesn&apos;t really update the conglomerate cache, it just replaces an existing entry with itself.&lt;/p&gt;

&lt;p&gt;It looks to me as if the conglomCacheUpdateEntry() can be removed, and that will take care of (2).&lt;/p&gt;

&lt;p&gt;I created an experimental patch, attached as experimental-v1.diff. It removes conglomCacheUpdateEntry() as suggested. It also makes CacheableConglomerate implement setIdentity() so that conglomCacheFind() doesn&apos;t need to fault in conglomerates manually.&lt;/p&gt;

&lt;p&gt;The patch is not ready for commit, as it doesn&apos;t pass all regression tests. But it could be used for testing, if someone has a test environment where the deadlock can be reliably reproduced.&lt;/p&gt;

&lt;p&gt;There was only one failure in the regression tests. store/xaOffline1.sql had a diff in one of the transaction table listings, where a transaction showed up in the ACTIVE state whereas IDLE was expected.&lt;/p&gt;

&lt;p&gt;This probably happens because the transaction used in the CacheableConglomerate.setIdentity() method is not necessarily the same as the one previously used by RAMAccessManager.conglomCacheFind().&lt;/p&gt;

&lt;p&gt;The current implementation of setIdentity() in the patch just fetches the first transaction it finds on the context stack. That seems to do the trick in most cases, but it doesn&apos;t know whether conglomCacheFind() was called with a top-level transaction or a nested transaction, as setIdentity() cannot access conglomCacheFind()&apos;s parameters. Maybe it can be solved by pushing some other context type (with a reference to the correct tx) on the context stack before accessing the conglomerate cache, and let setIdentity() check that instead?&lt;/p&gt;</comment>
                            <comment id="13535839" author="knutanders" created="Wed, 19 Dec 2012 10:10:59 +0000"  >&lt;p&gt;Attaching version 2 of the patch that removes the explicit synchronization on the conglomerate cache. The only difference from version 1 is the way it retrieves a handle to the current transaction from CacheableConglomerate.setIdentity(). Now it uses the nested transaction instead of the top-level user transaction if there is one.&lt;/p&gt;

&lt;p&gt;I wasn&apos;t quite happy with the approach used to get the current transaction (see RAMAccessManager.getCurrentTransactionContext()) as it needed to make some assumptions on how different transaction context types are stacked. I think it should do the right thing, though.&lt;/p&gt;

&lt;p&gt;Apart from that, I think the patch is an improvement, as it allows more concurrent access to the conglomerate cache. Whether or not it helps with the deadlock, or if it just makes it block on some other monitor, I don&apos;t know.&lt;/p&gt;</comment>
                            <comment id="13535846" author="knutanders" created="Wed, 19 Dec 2012 10:17:28 +0000"  >&lt;p&gt;I forgot to mention that all the regression tests passed with the updated patch.&lt;/p&gt;</comment>
                            <comment id="13602120" author="knutanders" created="Thu, 14 Mar 2013 07:52:24 +0000"  >&lt;p&gt;Committed revision 1456352.&lt;/p&gt;

&lt;p&gt;I&apos;m marking the issue as resolved, although I can&apos;t tell if the problem is completely fixed. In any case, if there still is a deadlock after the fix, it should not involve synchronization on the conglomerate cache.&lt;/p&gt;</comment>
                            <comment id="13602143" author="knutanders" created="Thu, 14 Mar 2013 08:38:55 +0000"  >&lt;p&gt;I noticed that some of the blocked threads in the thread dump were trying to open a new connection in BrokeredConnection.isClosed(). That looks suspicious, so I have filed &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-6110&quot; title=&quot;BrokeredConnection.isClosed() may open a new connection&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-6110&quot;&gt;&lt;del&gt;DERBY-6110&lt;/del&gt;&lt;/a&gt; to investigate.&lt;/p&gt;</comment>
                            <comment id="13602303" author="bbergquist" created="Thu, 14 Mar 2013 14:16:44 +0000"  >&lt;p&gt;Knut, originally this was all done using a script and IJ.   The script invoked IJ to freeze the database, then did a file system backup (using bash and ZFS commands) and then invoked IJ to unfreeze the database.  Mike Matrigali indicated that the expectation was that the freeze/unfreeze would be done using the same connection, so I wrote a utility in Java that would create a connection, invoke the freeze, issue a system level call to perform the file system backup, and then issue the unfreeze all in one connection.   The problem still exists even doing it this way but the stack traces tare probably from the original.&lt;/p&gt;

&lt;p&gt;I really do have an issue with the expectation that this all be done in one connection.  Even with the utility that there is a chance that the utility could fail between the time the freeze is done and the unfreeze is done.   At that point Derby is done and will require to be forcefully killed.&lt;/p&gt;

&lt;p&gt;It would seem to me that it should always be possible to connect to the database engine.  It may be that specific requests on the connection will block when the database is frozen, but the one that should not block is the unfreeze.&lt;/p&gt;

&lt;p&gt;I think not allowing the freeze/unfreeze from different connections is a bug.&lt;/p&gt;</comment>
                            <comment id="13602328" author="knutanders" created="Thu, 14 Mar 2013 15:08:46 +0000"  >&lt;p&gt;I agree that only allowing unfreeze from the connection that froze the database would be limiting. Are you saying that the deadlocks involve different kinds of objects in the single-connection case than in the multiple-connection case, and that the committed fix would only have effect on the single-connection case?&lt;/p&gt;</comment>
                            <comment id="13602354" author="bbergquist" created="Thu, 14 Mar 2013 15:40:52 +0000"  >&lt;p&gt;I think the deadlocks are the same.   I think we are triggering this more often.  The 10.8 added the index stats daemon capability but it turned out there were some issues (that I reported).  Because index statistics are important for our application and we have tables that are initially empty and quickly get filled with data, we disable the index stats daemon (or rather don&apos;t enable it) and have a background job that is running an UPDATE_STATISTICS command across all tables that appear to not have statistics.  This runs every minute in the background and does not seem to have a negative effect since it is only running against those tables that don&apos;t have any index statistics.&lt;/p&gt;

&lt;p&gt;So there is probably a timing issue with the FREEZE and the UPDATE_STATISTICS. &lt;/p&gt;

&lt;p&gt;I am going to try to force a reproducible case by increasing the frequency of both of these in my utility.  I will remove the actually file system backup between the freeze/unfreeze and increase the rate at with the background UPDATE_STATISTICS is being done.   If I can get this to happen with a good deal of regularity, I will apply your patch and try again.&lt;/p&gt;

&lt;p&gt;I will post the results.&lt;/p&gt;</comment>
                            <comment id="14284837" author="myrna" created="Wed, 21 Jan 2015 00:23:39 +0000"  >&lt;p&gt;bulk change to close all issues resolved but not closed and not changed since June 1, 2014.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12636987">DERBY-6110</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12676750">DERBY-6398</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12560770" name="experimental-v1.diff" size="9996" author="knutanders" created="Thu, 13 Dec 2012 12:30:50 +0000"/>
                            <attachment id="12561677" name="experimental-v2.diff" size="10853" author="knutanders" created="Wed, 19 Dec 2012 10:10:59 +0000"/>
                            <attachment id="12516201" name="stack.txt" size="109829" author="bbergquist" created="Mon, 27 Feb 2012 19:29:17 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12617819">DERBY-6005</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310200" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Bug behavior facts</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10421"><![CDATA[Seen in production]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 27 Feb 2012 22:37:36 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>229537</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy09on:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>35387</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310050" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Urgency</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10052"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>