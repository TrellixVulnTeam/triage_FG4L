<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun May 17 03:49:02 UTC 2015

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/DERBY-4477/DERBY-4477.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[DERBY-4477] Selecting / projecting a column whose value is represented by a stream more than once fails</title>
                <link>https://issues.apache.org/jira/browse/DERBY-4477</link>
                <project id="10594" key="DERBY">Derby</project>
                    <description>&lt;p&gt;Selecting / projecting a column whose value is represented as a stream more than once crashes Derby, i.e.:&lt;br/&gt;
ResultSet rs = stmt.executeQuery(&quot;SELECT clobValue AS clobOne, clobValue AS clobTwo FROM mytable&quot;);&lt;br/&gt;
rs.getString(1);&lt;br/&gt;
rs.getString(2);&lt;/p&gt;

&lt;p&gt;After having looked at the class of bugs having to do with reuse of stream data types, I now have a possible fix. It fixes &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3645&quot; title=&quot;Insert into selecting BLOB column twice leads to SQLException: Restore of a serializable or SQLData object of class error selecting from the table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3645&quot;&gt;&lt;del&gt;DERBY-3645&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3646&quot; title=&quot;Embedded returns wrong results when selecting a blob column twice and using getBinaryStream()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3646&quot;&gt;&lt;del&gt;DERBY-3646&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-2349&quot; title=&quot;Accessing a BLOB column twice in an INSERT trigger leads to errors in the value on-disk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-2349&quot;&gt;&lt;del&gt;DERBY-2349&lt;/del&gt;&lt;/a&gt; (there may be more Jiras).&lt;br/&gt;
The core of the fix is cloning certain DVDs being selected/projected in multiple columns. There are two types of cloning:&lt;br/&gt;
 A) materializing clone&lt;br/&gt;
 B) stream clone&lt;/p&gt;

&lt;p&gt;(A) can be implemented already, (B) requires code to clone a stream without materializing it. Note that the streams I&apos;m talking about are streams originating from the store.&lt;/p&gt;

&lt;p&gt;Testing revealed the following:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the cost of the checks performed to figure out if cloning is required seems acceptable (negligible?)&lt;/li&gt;
	&lt;li&gt;in some cases (A) has better performance than (B) because the raw data only has to be decoded once&lt;/li&gt;
	&lt;li&gt;stream clones are preferred when the data value is above a certain size for several reasons:&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;avoids potential out-of-memory errors (and in case of a server environment, it lowers the memory pressure)&lt;/li&gt;
	&lt;li&gt;avoids decoding the whole value if the JDBC streaming APIs are used to access only parts of the value&lt;/li&gt;
	&lt;li&gt;avoids decoding overall in cases where the value isn&apos;t accessed by the client / user&lt;br/&gt;
       (this statement conflicts with the performance observation above)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;We don&apos;t always know the size of a value, and since the fix code deals with all kinds of data types, it is slightly more costly to try to obtain the size.&lt;/p&gt;

&lt;p&gt;What do people think about the following goal statement?&lt;br/&gt;
Goals:&lt;br/&gt;
----- Phase 1&lt;br/&gt;
 1) No crashes or wrong results due to stream reuse when executing duplicate column selections (minus goal 4)&lt;br/&gt;
 2) Minimal performance degradation for non-duplicate column selections&lt;br/&gt;
 3) Only a minor performance degradation for duplicate [&lt;span class=&quot;error&quot;&gt;&amp;#91;LONG&amp;#93;&lt;/span&gt; VAR]CHAR &lt;span class=&quot;error&quot;&gt;&amp;#91;FOR BIT DATA&amp;#93;&lt;/span&gt; column selections&lt;br/&gt;
----- Phase 2&lt;br/&gt;
 4) No out-of-memory exceptions during execution of duplicate column selections of BLOB/CLOB&lt;br/&gt;
 5) Optimize BLOB/CLOB cloning&lt;/p&gt;

&lt;p&gt;I think phase 1 can proceed by reviewing and discussing the prototype patch. Phase 2 requires more discussion and work (see &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3650&quot; title=&quot;internal multiple references from different rows to a single BLOB/CLOB stream leads to various errors when second reference used.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3650&quot;&gt;&lt;del&gt;DERBY-3650&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;


&lt;p&gt;A note about the bug behavior facts:&lt;br/&gt;
Since this issue is the underlying cause for several other reported issues, I have decided to be liberal when setting the bug behavior facts. Depending on where the duplicate column selection is used, it can cause both crashes, wrong results and data corruption.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12443382">DERBY-4477</key>
            <summary>Selecting / projecting a column whose value is represented by a stream more than once fails</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dagw">Dag H. Wanvik</assignee>
                                    <reporter username="kristwaa">Kristian Waagan</reporter>
                        <labels>
                    </labels>
                <created>Tue, 15 Dec 2009 13:13:30 +0000</created>
                <updated>Thu, 22 Jul 2010 08:20:27 +0100</updated>
                            <resolved>Mon, 12 Jul 2010 17:21:49 +0100</resolved>
                                    <version>10.3.3.0</version>
                    <version>10.4.2.0</version>
                    <version>10.5.3.0</version>
                                    <fixVersion>10.5.3.1</fixVersion>
                    <fixVersion>10.6.1.0</fixVersion>
                                    <component>SQL</component>
                    <component>Store</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12790733" author="kristwaa" created="Tue, 15 Dec 2009 13:20:03 +0000"  >&lt;p&gt;Removed unused imports with revision 890789.&lt;/p&gt;</comment>
                            <comment id="12790818" author="kristwaa" created="Tue, 15 Dec 2009 16:57:08 +0000"  >&lt;p&gt;Attached a prototype patch 0a.&lt;/p&gt;

&lt;p&gt;The logic is isolated in ProjectRestrictResultSet, the rest of the patch is code from the patch attached to &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3650&quot; title=&quot;internal multiple references from different rows to a single BLOB/CLOB stream leads to various errors when second reference used.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3650&quot;&gt;&lt;del&gt;DERBY-3650&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
Currently, the prototype tried to implement something along the lines of phase 2.&lt;br/&gt;
I&apos;m running the regressions tests, and tomorrow I will post a performance test and some results.&lt;/p&gt;

&lt;p&gt;I&apos;d like some feedback on how we want Derby to behave:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;what should the clone stream threshold be?&lt;/li&gt;
	&lt;li&gt;is it okay to always materialize [&lt;span class=&quot;error&quot;&gt;&amp;#91;LONG&amp;#93;&lt;/span&gt; VAR]CHAR &lt;span class=&quot;error&quot;&gt;&amp;#91;FOR BIT DATA&amp;#93;&lt;/span&gt;?&lt;/li&gt;
	&lt;li&gt;the DataValueDescriptor.getLengthIfKnow was something I added just before posting the patch, to optimize where possible. Keep it or ditch it? Useful in other scenarios?&lt;br/&gt;
   (as a side note, getCharLengthIfKnown was added to InternalClob)&lt;/li&gt;
	&lt;li&gt;the second check could be done in the constructor if there was a way to reliably find the types of the relevant columns (I was only able to find the descriptors for the top-level result set, but then I don&apos;t know the available structures very well)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Finally, with the exception of the code in the constructor, the added code should only be activated if the user selects a &quot;store streamable&quot; &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; column more than once. I don&apos;t know if that is very common, and I guess the most important issue is that Derby is able to handle it without crashing.&lt;/p&gt;


&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; The store streamable are the various CHAR and CHAR FOR BIT DATA types, BLOB, and CLOB.&lt;br/&gt;
     (Hmm, what about XML?)&lt;/p&gt;</comment>
                            <comment id="12803490" author="dagw" created="Thu, 21 Jan 2010 21:23:09 +0000"  >&lt;p&gt;Uploading a patch derby-4477-partial, which is a variant of the phase 1 patch, which has moved the establishment of which which column potentially need cloning from execution time to compile-time and adds the repro test from &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3645&quot; title=&quot;Insert into selecting BLOB column twice leads to SQLException: Restore of a serializable or SQLData object of class error selecting from the table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3645&quot;&gt;&lt;del&gt;DERBY-3645&lt;/del&gt;&lt;/a&gt; to BLOBTest, which passes with the patch.&lt;/p&gt;

&lt;p&gt;This partial patch does not address cloning at the store level (it materializes always) so the code needs to be updated (I have put in a FIXME comment) when that work is finished. Running regressions.&lt;/p&gt;
</comment>
                            <comment id="12803511" author="dagw" created="Thu, 21 Jan 2010 22:27:55 +0000"  >&lt;p&gt;I notice that test repro for &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3646&quot; title=&quot;Embedded returns wrong results when selecting a blob column twice and using getBinaryStream()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3646&quot;&gt;&lt;del&gt;DERBY-3646&lt;/del&gt;&lt;/a&gt; still fails with my version of the patch. The derby-4477-0a-prototype patch makes that repro pass, but only because the limit for materialization is set low: increase it from 32K to 64K , and that repro fails with that patch as well, so there seems to be more to be done here? Or maybe I misunderstood something of the prototype patch... In my version I marked for cloning all occurences which had duplicates in the RCL (not just occurence 2..n as the prototype patch does), but that does not seem to make a difference..&lt;/p&gt;</comment>
                            <comment id="12803533" author="dagw" created="Thu, 21 Jan 2010 23:17:26 +0000"  >&lt;p&gt;The repro for &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3646&quot; title=&quot;Embedded returns wrong results when selecting a blob column twice and using getBinaryStream()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3646&quot;&gt;&lt;del&gt;DERBY-3646&lt;/del&gt;&lt;/a&gt; fails because it&apos;s coded wrong: Per JDBC, the stream should be digested before a new get* method is called, cf. &lt;a href=&quot;http://java.sun.com/j2se/1.5.0/docs/api/java/sql/ResultSet.html#getBinaryStream(int&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://java.sun.com/j2se/1.5.0/docs/api/java/sql/ResultSet.html#getBinaryStream(int&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;When I fix that error in the repro, both derby-4477-partial and derby-4477-0a-prototype (with 64K limit) passes. When above the limit with derby-4477-0a-prototype, materialization is not done, but rather the new copyForRead method is used. This will eventually return a wrapped stream, BinaryToRawStream which extends java.io.FilterInputStream. Strangely,  FilterInputStream does not give an error on read even after it has been closed (by EmbedResultSet#closeCurrentStream), so that&apos;s why the repro passed with the original derby-4477-0a-prototype, so the wrong usage in the repro is not caught.&lt;/p&gt;</comment>
                            <comment id="12803553" author="dagw" created="Fri, 22 Jan 2010 00:12:48 +0000"  >&lt;p&gt;BinaryToRawStream qua FilterInputStream.close merely closes the passed in InputStream, in our case&lt;br/&gt;
this is a FormatIdInputStream, which again wraps a  OverflowInputStream which fails to take any action on close. This explains why no error was seen initially for the &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3646&quot; title=&quot;Embedded returns wrong results when selecting a blob column twice and using getBinaryStream()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3646&quot;&gt;&lt;del&gt;DERBY-3646&lt;/del&gt;&lt;/a&gt; repro. This is unfortunate and I think we should override the close method somewhere, maybe in BinaryToRawStream to avoid allowing reading after close.&lt;/p&gt;</comment>
                            <comment id="12803695" author="dagw" created="Fri, 22 Jan 2010 13:39:16 +0000"  >&lt;p&gt;Regressions passed. I will file a new JIRA for the lack of heeding close in our internal streams, and add the corrected repro from derby-3646 to the test as well, and spin a new rev of my patch.&lt;/p&gt;</comment>
                            <comment id="12803724" author="kristwaa" created="Fri, 22 Jan 2010 15:29:41 +0000"  >&lt;p&gt;Hi Dag,&lt;/p&gt;

&lt;p&gt;The current patch looks good to me. A few nits and one question:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;typo in BLOBTest.testDerby4477Repro JavaDoc&lt;/li&gt;
	&lt;li&gt;typo in PRRS: &quot;columsn&quot;&lt;/li&gt;
	&lt;li&gt;typo in RCL.mapSourceColumns JavaDoc: &quot;column&quot; -&amp;gt; &quot;columns&quot;&lt;/li&gt;
	&lt;li&gt;if you make PRRS.cloneMap final and return null if there are no columns to clone (and add the check for cloneMap != null), do you think that will matter performance-wise?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I think it&apos;s safe to not clone the first occurrence, but I don&apos;t know how much it matters. My assumption is that the clone code will only be activated for a very small percentage of queries. I would be more worried about not incurring extra cost in the normal case, where each column is reference only once.&lt;/p&gt;</comment>
                            <comment id="12803736" author="dagw" created="Fri, 22 Jan 2010 16:01:37 +0000"  >&lt;p&gt;Thanks for the comments, Kristian, I&apos;ll include those in my next rev of the patch. I don&apos;t think always creating a column map matters for performance here, since the object is allocated at compilation time. Upside is slightly simpler code at execution time (one test in stead of two), although testing for a member in a boolean array is slightly expensive that checking to find an empty pointer perhaps. If you like, I can reintroduce that logic.&lt;/p&gt;</comment>
                            <comment id="12803746" author="knutanders" created="Fri, 22 Jan 2010 16:22:20 +0000"  >&lt;p&gt;I would expect the performance impact of these checks to be negligible, so +1 from me to keeping the code simple.&lt;/p&gt;

&lt;p&gt;The approach looks good to me. It&apos;s not obvious after the first quick look that it&apos;s a complete solution (that is, whether it&apos;s enough to do this duplication check in PRN), but I don&apos;t have any evidence suggesting it&apos;s not. The first thing that comes to mind is what if the duplication happens in HashTableNode (the other caller of mapSourceColumns()). Could it be that that code path will be triggered by this (untested) case&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;set page size to 4k&lt;/li&gt;
	&lt;li&gt;create table t (x varchar(32000))&lt;/li&gt;
	&lt;li&gt;insert into t values (..string longer than 4k..)&lt;/li&gt;
	&lt;li&gt;select distinct x,x from t&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;?&lt;/p&gt;</comment>
                            <comment id="12803788" author="dagw" created="Fri, 22 Jan 2010 18:01:37 +0000"  >&lt;p&gt;Thanks, Knut! Yes, I was concerned with the similar code in HashTableResultset; LOBs can&apos;t be involved in a distinct, so the remaining suspects would be the long character types. I am going to do some experiments to establish if this can be an issue. Thanks for the suggestion scenario! Probably the safest thing would be to just include the logic for the cloning in HashTableResultset as well.&lt;/p&gt;</comment>
                            <comment id="12803927" author="dagw" created="Fri, 22 Jan 2010 23:03:21 +0000"  >&lt;p&gt;Uploading revision 2; derby-4477-partial-2, which changes the cloning to only happen in occurences 2..n in the RCL and incorporates Kristian&apos;s comments (except that the map is always present) and the repros for 3646 and 2349. Regressions ran ok.&lt;/p&gt;</comment>
                            <comment id="12804471" author="knutanders" created="Mon, 25 Jan 2010 09:50:56 +0000"  >&lt;p&gt;I don&apos;t think the scenario I suggested will cause any problems. If the data type is VARCHAR, the value appears to be materialized in memory even in the case of overflow. If one of the long data types is used, DISTINCT queries are not allowed.&lt;/p&gt;</comment>
                            <comment id="12804589" author="dagw" created="Mon, 25 Jan 2010 16:25:24 +0000"  >&lt;p&gt;Committed patch derby-4477-partial-2 as svn 902857.&lt;/p&gt;</comment>
                            <comment id="12804834" author="dagw" created="Tue, 26 Jan 2010 01:24:45 +0000"  >&lt;p&gt;Trying again to make HashTableResultSet fail in a similar way....&lt;br/&gt;
I was able to make stream column appear duplicated in HashJoin/HashTableResultSet, e.g with the following query:&lt;/p&gt;

&lt;p&gt;select t1.b, t1.c, t2.b, t2.c from&lt;br/&gt;
     (select id, v, v, (select count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; from sys.systables) w from mytab) t1(a,b,c,d), &lt;br/&gt;
     (select id, v, v, (select count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; from sys.systables) w from mytab) t2(a,b,c,d) &lt;br/&gt;
            where t1.a=t2.a&lt;/p&gt;

&lt;p&gt;where v is the blob similar to repro in &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3646&quot; title=&quot;Embedded returns wrong results when selecting a blob column twice and using getBinaryStream()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3646&quot;&gt;&lt;del&gt;DERBY-3646&lt;/del&gt;&lt;/a&gt;, but there is a ProjectRestrictResultset under the HashTableResultset which takes care of the cloning after svn 902857 (before the patch, the query will fail).&lt;br/&gt;
If I remove the subquery in the select list flattening is allowed, and I see a HashExistsJoin/HashScanResultset instead.&lt;/p&gt;

&lt;p&gt;I am not yet entirely convinced that a HashTableResultSet can&apos;t appear without an underlying ProjectRestrictResultset, though, but it may be the case.&lt;/p&gt;</comment>
                            <comment id="12805979" author="dagw" created="Thu, 28 Jan 2010 16:45:30 +0000"  >&lt;p&gt;Uploading a new patch, derby-4477-lowmem, which adds test cases to BlobMemTest for the repros from 3645 and 3646, but with large blobs to test that materialization is not happening. These tests should be enabled when we update the &quot;partial&quot; patch when the support for cloning of streams without materializations becomes available. For now, the test cases uses a small blob, so the test does pass. Note, BlobMemTest is not part of the regression suite, but is run separately in ther lowmem suite, e.g. as &quot;ant junit-lowmem&quot;.&lt;/p&gt;</comment>
                            <comment id="12806326" author="knutanders" created="Fri, 29 Jan 2010 12:44:52 +0000"  >&lt;p&gt;BaseTestCase already implements assertEquals() methods specialized for InputStreams and Readers, so I think the new methods assertEqualStreams() and assertEqualReaders() could be removed.&lt;/p&gt;</comment>
                            <comment id="12806341" author="dagw" created="Fri, 29 Jan 2010 14:10:47 +0000"  >&lt;p&gt;Thanks for looking at the patch, Knut. I&apos;ll substitute the existing assert methods in a new rev.&lt;/p&gt;</comment>
                            <comment id="12806352" author="dagw" created="Fri, 29 Jan 2010 14:41:08 +0000"  >&lt;p&gt;Uploading patch *-lowmem-2, which now uses the exisiting methods to verify equality between two InputStreams and between two Readers. I introduced a reopen method to LoopingAlphabetReader, since the BaseTestCase comparison method closes the reader after use and i needed to use it several times. I also moved the clob version of test test case to ClobMemTest to keep the pattern.&lt;/p&gt;</comment>
                            <comment id="12806376" author="dagw" created="Fri, 29 Jan 2010 16:13:08 +0000"  >&lt;p&gt;Committed patch derby-4477-lowmem-2 as svn 904538. There are not two committed patches on this issue, both of which should be revisited when cloning streams are properly handled (not materialized when large).&lt;/p&gt;</comment>
                            <comment id="12828061" author="knutanders" created="Mon, 1 Feb 2010 10:18:01 +0000"  >&lt;p&gt;ClobMemTest.testDerby4477_3645_3646_Repro_lowmem_clob is failing intermittently in the nightly regression tests. See here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://dbtg.foundry.sun.com/derby/test/Daily/jvm1.6/testing/testlog/vista/904556-suitesAll_diff.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://dbtg.foundry.sun.com/derby/test/Daily/jvm1.6/testing/testlog/vista/904556-suitesAll_diff.txt&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://dbtg.foundry.sun.com/derby/test/Daily/jvm1.6/testing/testlog/vista-64/904812-suitesAll_diff.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://dbtg.foundry.sun.com/derby/test/Daily/jvm1.6/testing/testlog/vista-64/904812-suitesAll_diff.txt&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://dbtg.foundry.sun.com/derby/test/Daily/jvm1.6/testing/testlog/solN+1/904812-suitesAll_diff.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://dbtg.foundry.sun.com/derby/test/Daily/jvm1.6/testing/testlog/solN+1/904812-suitesAll_diff.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;There are three different stack traces, but they all report that the LoopingAlphabetReader is closed, which is kind of odd since LoopingAlphabetReader.reopen() is called right before the failing line in all three cases.&lt;/p&gt;</comment>
                            <comment id="12828110" author="dagw" created="Mon, 1 Feb 2010 13:56:05 +0000"  >&lt;p&gt;Hmm, could it be a finalizer for the prepared statement that closes the stream? I&apos;ll look into it.&lt;/p&gt;</comment>
                            <comment id="12828302" author="dagw" created="Mon, 1 Feb 2010 22:15:49 +0000"  >&lt;p&gt;The reason is that the client driver has a finalizer for the Class EncodedInputStream&lt;br/&gt;
which when run, also closes the Reader passed in. This was introduced in 10.2; the embedded driver does not close the Reader when done with it. I filed &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-4531&quot; title=&quot;Client setCharacterStream closes its Reader argument stream in finalizer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-4531&quot;&gt;&lt;del&gt;DERBY-4531&lt;/del&gt;&lt;/a&gt; for this difference in behavior. I&apos;ll change the ClobMemTest to side-step this.&lt;/p&gt;</comment>
                            <comment id="12828325" author="dagw" created="Mon, 1 Feb 2010 23:13:51 +0000"  >&lt;p&gt;Uploading a patch, *-lowmem-followup, which fixes the problem with ClobMemTest,&lt;br/&gt;
rerunning regressions.&lt;/p&gt;</comment>
                            <comment id="12828620" author="dagw" created="Tue, 2 Feb 2010 13:35:31 +0000"  >&lt;p&gt;Committed *-lowmem-followup as svn 905621, regressions ran ok.&lt;/p&gt;</comment>
                            <comment id="12832005" author="dagw" created="Wed, 10 Feb 2010 14:28:19 +0000"  >&lt;p&gt;Uploading the patch which uses the new stream cloning referred to earlier as a coming follow-up for this issue: derby-4477-useCloning.&lt;/p&gt;

&lt;p&gt;It also bumps the lob size in the lowmem suite&apos;s test cases added for this issue in ClobMemTest and BlobMemTest, which will run out of memory without this cloning used by this patch.&lt;/p&gt;

&lt;p&gt;Regressions ran ok, as well as the lowmem suite.&lt;/p&gt;</comment>
                            <comment id="12832018" author="kristwaa" created="Wed, 10 Feb 2010 15:07:32 +0000"  >&lt;p&gt;+1 to commit patch &apos;derby-4477-useCloning&apos;&lt;/p&gt;

&lt;p&gt;Note that the &quot;length-materialization optimization&quot; (code that was commented out earlier, and removed by the latest patch) hasn&apos;t been implemented yet. However, I think it is better placed inside the various cloneValue-methods and hope to get to it at a later time.&lt;/p&gt;</comment>
                            <comment id="12832043" author="dagw" created="Wed, 10 Feb 2010 16:14:01 +0000"  >&lt;p&gt;Thanks, Kristian!&lt;br/&gt;
Committed as svn 908563, resolving.&lt;/p&gt;</comment>
                            <comment id="12835711" author="kristwaa" created="Fri, 19 Feb 2010 11:50:02 +0000"  >&lt;p&gt;Dag, this issue is resolved as &quot;Not A Problem&quot;. Is this correct?&lt;br/&gt;
Also, no fix version has been set.&lt;/p&gt;</comment>
                            <comment id="12835767" author="dagw" created="Fri, 19 Feb 2010 15:10:25 +0000"  >&lt;p&gt;reopening due to wrong resolution; thank for noticing Kristian.&lt;/p&gt;</comment>
                            <comment id="12835769" author="dagw" created="Fri, 19 Feb 2010 15:11:05 +0000"  >&lt;p&gt;resolving as fixed in 10.6.&lt;/p&gt;</comment>
                            <comment id="12861795" author="kristwaa" created="Wed, 28 Apr 2010 14:06:05 +0100"  >&lt;p&gt;Closing this issue, no problems with the fix have been reported.&lt;/p&gt;</comment>
                            <comment id="12884451" author="kmarsden" created="Thu, 1 Jul 2010 23:01:54 +0100"  >&lt;p&gt;reopen for 10.5 back port&lt;/p&gt;</comment>
                            <comment id="12887406" author="kmarsden" created="Mon, 12 Jul 2010 17:21:49 +0100"  >&lt;p&gt;Re-closing after back port to 10.5&lt;/p&gt;</comment>
                            <comment id="12887679" author="kristwaa" created="Tue, 13 Jul 2010 08:23:56 +0100"  >&lt;p&gt;Backport went in with revision 963326.&lt;/p&gt;

&lt;p&gt;I just want to point out that the way the problematic scenario is handled in 10.5 and 10.6/trunk is different.&lt;br/&gt;
10.5 will materialize the values (&apos;((StreamStorable)dvd).loadStream()&apos;), whereas 10.6/trunk will clone the source streams if possible (dvd.cloneValue(false)&apos;&apos;). This will probably not cause much trouble, as LOBs would have to be projected more than once to trigger an OOME (i.e &apos;select myclob as clob1, myclob as clob2 ...&apos;).&lt;/p&gt;</comment>
                            <comment id="12888064" author="kmarsden" created="Tue, 13 Jul 2010 23:39:58 +0100"  >&lt;p&gt;Myrna pointed out that back porting the change introduced the following javadoc warnings.&lt;/p&gt;

&lt;p&gt;	  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; D:\svnnightlies\v10_5\src\opensource\java\testing\org\apache\derbyTesting\functionTests\tests\jdbcapi\BLOBTest.java:398: warning - Tag @see: can&apos;t find testDerby4477_3645_3646_Repro_lowmem in org.apache.derbyTesting.functionTests.tests.memory.BlobMemTest&lt;br/&gt;
		  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; D:\svnnightlies\v10_5\src\opensource\java\testing\org\apache\derbyTesting\functionTests\tests\jdbcapi\BLOBTest.java:398: warning - Tag @see: can&apos;t find testDerby4477_3645_3646_Repro_lowmem_clob in org.apache.derbyTesting.functionTests.tests.memory.ClobMemTest&lt;/p&gt;

&lt;p&gt;Based on Kristian&apos;s earlier comment&lt;br/&gt;
I am unclear on whether this means I should also backport revison 908563 along with the lowmem tests and hopefully in doing so resolve the difference in trunk and 10.5 or just fix up the javadoc not to refer to these methods which are not currently in 10.5.&lt;/p&gt;

</comment>
                            <comment id="12888242" author="kristwaa" created="Wed, 14 Jul 2010 09:09:08 +0100"  >&lt;p&gt;You can&apos;t backport 908563 without also backporting &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-4520&quot; title=&quot;Refactor and extend data type cloning facilities&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-4520&quot;&gt;&lt;del&gt;DERBY-4520&lt;/del&gt;&lt;/a&gt;, which includes rather significant changes.&lt;br/&gt;
I was a bit surprised to see these issues being backported, since the comment on the &apos;10.5 backporting&apos; thread on derby-dev suggested they wouldn&apos;t.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3645&quot; title=&quot;Insert into selecting BLOB column twice leads to SQLException: Restore of a serializable or SQLData object of class error selecting from the table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3645&quot;&gt;&lt;del&gt;DERBY-3645&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3646&quot; title=&quot;Embedded returns wrong results when selecting a blob column twice and using getBinaryStream()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3646&quot;&gt;&lt;del&gt;DERBY-3646&lt;/del&gt;&lt;/a&gt; will also work in 10.5 as it stands now, as long as there is enough memory for the materialized LOB.&lt;/p&gt;

&lt;p&gt;I think the easiest thing to do here is to simply remove the @see tags, but I haven&apos;t looked in detail at the state of the code in 10.5.&lt;/p&gt;</comment>
                            <comment id="12888441" author="kmarsden" created="Wed, 14 Jul 2010 18:24:34 +0100"  >&lt;p&gt;Thank you Kristian for the clarification. I am not sure where I got off track and ended up linking these issues. I must have pulled up the wrong email the day Lily and I made the links. &lt;/p&gt;

&lt;p&gt;I will remove the tags for now and take a closer look at whether &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3645&quot; title=&quot;Insert into selecting BLOB column twice leads to SQLException: Restore of a serializable or SQLData object of class error selecting from the table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3645&quot;&gt;&lt;del&gt;DERBY-3645&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3646&quot; title=&quot;Embedded returns wrong results when selecting a blob column twice and using getBinaryStream()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3646&quot;&gt;&lt;del&gt;DERBY-3646&lt;/del&gt;&lt;/a&gt; should be backed out of 10.5. Although they merged cleanly and passed regression tests, the severed fix may be problematic.&lt;/p&gt;
</comment>
                            <comment id="12890929" author="kmarsden" created="Wed, 21 Jul 2010 23:17:16 +0100"  >&lt;p&gt;I looked at the changes that did get back ported for &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3645&quot; title=&quot;Insert into selecting BLOB column twice leads to SQLException: Restore of a serializable or SQLData object of class error selecting from the table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3645&quot;&gt;&lt;del&gt;DERBY-3645&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-3646&quot; title=&quot;Embedded returns wrong results when selecting a blob column twice and using getBinaryStream()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;DERBY-3646&quot;&gt;&lt;del&gt;DERBY-3646&lt;/del&gt;&lt;/a&gt; and the partial fix for this issue and I think they are ok to leave in 10.5 as the behavior has improved and seem to accomplish the phase 1 goals of this fix:&lt;/p&gt;

&lt;p&gt;----- Phase 1&lt;br/&gt;
 1) No crashes or wrong results due to stream reuse when executing duplicate column selections (minus goal 4)&lt;br/&gt;
 2) Minimal performance degradation for non-duplicate column selections&lt;br/&gt;
 3) Only a minor performance degradation for duplicate [&lt;span class=&quot;error&quot;&gt;&amp;#91;LONG&amp;#93;&lt;/span&gt; VAR]CHAR &lt;span class=&quot;error&quot;&gt;&amp;#91;FOR BIT DATA&amp;#93;&lt;/span&gt; column selections&lt;/p&gt;

&lt;p&gt;But not the phase 2 goals of:&lt;br/&gt;
----- Phase 2&lt;br/&gt;
 4) No out-of-memory exceptions during execution of duplicate column selections of BLOB/CLOB&lt;br/&gt;
 5) Optimize BLOB/CLOB cloning&lt;/p&gt;


&lt;p&gt;and thus are good fixes for 10.5.  I fixed up the javadoc warnings for the references to the 10.5 lowmem tests with revision &lt;br/&gt;
966440 in 10.5&lt;/p&gt;


</comment>
                            <comment id="12891038" author="kristwaa" created="Thu, 22 Jul 2010 08:20:26 +0100"  >&lt;p&gt;Sounds good to me. Thanks, Kathey.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12394818">DERBY-3645</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12394819">DERBY-3646</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                                                <inwardlinks description="is required by">
                                        <issuelink>
            <issuekey id="12468384">DERBY-4728</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12428056" name="derby-4477-0a-prototype.diff" size="26312" author="kristwaa" created="Tue, 15 Dec 2009 16:57:08 +0000"/>
                            <attachment id="12431778" name="derby-4477-lowmem-2.diff" size="7945" author="dagw" created="Fri, 29 Jan 2010 15:09:25 +0000"/>
                            <attachment id="12431779" name="derby-4477-lowmem-2.stat" size="364" author="dagw" created="Fri, 29 Jan 2010 15:09:25 +0000"/>
                            <attachment id="12434448" name="derby-4477-lowmem-followup.diff" size="1806" author="dagw" created="Mon, 1 Feb 2010 23:13:51 +0000"/>
                            <attachment id="12434449" name="derby-4477-lowmem-followup.stat" size="188" author="dagw" created="Mon, 1 Feb 2010 23:13:51 +0000"/>
                            <attachment id="12431679" name="derby-4477-lowmem.diff" size="7627" author="dagw" created="Thu, 28 Jan 2010 16:45:30 +0000"/>
                            <attachment id="12431680" name="derby-4477-lowmem.stat" size="176" author="dagw" created="Thu, 28 Jan 2010 16:45:30 +0000"/>
                            <attachment id="12431167" name="derby-4477-partial-2.diff" size="23349" author="dagw" created="Fri, 22 Jan 2010 23:03:21 +0000"/>
                            <attachment id="12431168" name="derby-4477-partial-2.stat" size="558" author="dagw" created="Fri, 22 Jan 2010 23:03:21 +0000"/>
                            <attachment id="12431064" name="derby-4477-partial.diff" size="14117" author="dagw" created="Thu, 21 Jan 2010 21:23:08 +0000"/>
                            <attachment id="12431065" name="derby-4477-partial.stat" size="558" author="dagw" created="Thu, 21 Jan 2010 21:23:09 +0000"/>
                            <attachment id="12435448" name="derby-4477-useCloning.diff" size="2705" author="dagw" created="Wed, 10 Feb 2010 14:28:19 +0000"/>
                            <attachment id="12435449" name="derby-4477-useCloning.stat" size="262" author="dagw" created="Wed, 10 Feb 2010 14:28:19 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>13.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310200" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Bug behavior facts</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10365"><![CDATA[Crash]]></customfieldvalue>
    <customfieldvalue key="10364"><![CDATA[Data corruption]]></customfieldvalue>
    <customfieldvalue key="10366"><![CDATA[Wrong query result]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 21 Jan 2010 21:23:09 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>24285</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2|hy0pdb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>37928</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                            </customfields>
    </item>
</channel>
</rss>